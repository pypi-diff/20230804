# Comparing `tmp/nemo_toolkit-1.8.2.tar.gz` & `tmp/nemo_toolkit-1.9.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "/home/eharper/tmp/NeMo/dist/tmp2itfijpl/nemo_toolkit-1.8.2.tar", last modified: Tue Apr 26 20:26:24 2022, max compression
+gzip compressed data, was "/home/eharper/tmp/NeMo/dist/tmp55r_ukoo/nemo_toolkit-1.9.0.tar", last modified: Fri Jun  3 19:32:19 2022, max compression
```

## Comparing `nemo_toolkit-1.8.2.tar` & `nemo_toolkit-1.9.0.tar`

### file list

```diff
@@ -1,1406 +1,1447 @@
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11356 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/LICENSE
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2168 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/PKG-INFO
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12544 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/README.rst
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.491201 nemo_toolkit-1.8.2/nemo/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      874 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.491201 nemo_toolkit-1.8.2/nemo/collections/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.491201 nemo_toolkit-1.8.2/nemo/collections/asr/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      922 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.495201 nemo_toolkit-1.8.2/nemo/collections/asr/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3578 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_ctm_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    39964 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_label.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6146 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_label_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    67631 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_text.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    34518 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_text_dali.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    17939 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_text_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5664 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/feature_to_label.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1206 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/data/feature_to_label_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.495201 nemo_toolkit-1.8.2/nemo/collections/asr/losses/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      879 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/losses/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2362 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/losses/angularloss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2695 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/losses/ctc.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6989 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/losses/lattice_losses.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.495201 nemo_toolkit-1.8.2/nemo/collections/asr/losses/pt_losses/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      689 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/losses/pt_losses/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11415 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/losses/pt_losses/contrastive.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11393 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/losses/rnnt.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.495201 nemo_toolkit-1.8.2/nemo/collections/asr/metrics/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/metrics/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    29647 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/metrics/rnnt_wer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/metrics/rnnt_wer_bpe.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11763 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/metrics/wer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10566 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/metrics/wer_bpe.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.495201 nemo_toolkit-1.8.2/nemo/collections/asr/models/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1293 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5361 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/asr_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    32972 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/classification_models.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    22811 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/clustering_diarizer.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.495201 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1659 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1331 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/aligner_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3161 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/asr_models_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3421 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/classification_models_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1296 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/k2_sequence_models_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12828 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/matchboxnet_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    19689 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/quartznet_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    22699 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/ctc_bpe_models.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    36154 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/ctc_models.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    16348 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/k2_aligner_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8202 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/k2_sequence_models.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    20836 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/label_models.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    22066 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/rnnt_bpe_models.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    41826 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/rnnt_models.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15384 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/models/ssl_models.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/modules/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1507 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    26400 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/audio_preprocessing.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4440 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/beam_search_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11927 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/conformer_encoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    32170 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/conv_asr.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9509 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/graph_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3416 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/lstm_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6649 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/rnn_encoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    46949 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/rnnt.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11315 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/rnnt_abstract.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    13955 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/modules/wav2vec_modules.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1897 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/features.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3428 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/autograd.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6962 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/classes.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3676 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/grad_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6260 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/graph_compilers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10346 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/graph_decoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12130 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/map_loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5493 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/ml_loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4866 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/topologies.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9241 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/mixins/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      710 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/mixins/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18511 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/mixins/mixins.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      693 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      782 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8560 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/rnnt.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12848 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_numpy.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9576 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_pytorch.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1194 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15598 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/cpu_rnnt.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1194 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11243 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18797 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt_kernel.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12486 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/reduce.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1727 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/global_constants.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3788 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/rnnt_helper.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/spec_augment/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      746 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/spec_augment/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11697 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/spec_augment/spec_aug_numba.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1390 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2886 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/feature_loader.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18256 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/features.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    38635 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/perturb.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11660 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/segment.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.499201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7070 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/conformer_modules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    46709 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/jasper.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12886 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/multi_head_attention.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    50962 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/rnnt_beam_decoding.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    47470 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/rnnt_greedy_decoding.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5193 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/spectr_augment.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7258 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/ssl_quantizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6319 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/subsampling.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/tdnn_attention.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      847 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/activations.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3292 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/asr_module_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    33251 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/decoder_timestamps_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    48307 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/diarization_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    25134 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/nmesc_clustering.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3386 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/numba_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5863 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/rnnt_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    24848 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/speaker_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    46770 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/streaming_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3762 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/transcribe_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    38203 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/vad_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      946 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/callbacks/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      688 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/callbacks/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3997 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/callbacks/callbacks.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      674 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/data/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6839 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/data/dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12727 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/data/vocabs.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/losses/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1146 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2181 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/aggregator.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2719 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/bce_logits_loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5369 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/cross_entropy.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1777 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/mse_loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3487 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/multi_similarity_loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4573 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/smoothed_cross_entropy.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3108 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/losses/spanning_loss.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/metrics/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      867 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/metrics/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7320 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/metrics/classification_accuracy.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3532 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/metrics/global_average_loss_metric.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3558 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/metrics/perplexity.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/parts/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      809 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2222 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/multi_layer_perceptron.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      806 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/patch_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8093 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/cleaners.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18255 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/collections.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3957 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/manifest.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6574 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/parsers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1012 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/ptl_overrides.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    20507 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/rnn.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3026 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/transformer_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1605 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/parts/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.503201 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1364 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6302 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/aggregate_tokenizer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3233 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/bytelevel_tokenizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    25682 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/char_tokenizer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2724 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/chinese_tokenizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11242 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/column_coder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2956 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/en_ja_tokenizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4159 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/fairseq_tokenizer.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/huggingface/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      699 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/huggingface/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10598 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/huggingface/auto_tokenizer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1537 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/indic_tokenizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1597 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/moses_tokenizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9288 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/regex_tokenizer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    13770 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/sentencepiece_tokenizer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6901 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/tabular_tokenizer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1398 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/tokenizer_spec.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2475 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/word_tokenizer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2605 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/youtokentome_tokenizer.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/cv/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      912 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/cv/datasets/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      699 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/datasets/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4475 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/datasets/mnist_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/cv/losses/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      667 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/losses/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1902 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/losses/nll_loss.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/cv/models/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      694 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/models/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4870 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/models/mnist_lenet5.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/cv/modules/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      665 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/modules/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3381 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/cv/modules/lenet5.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      921 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1942 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/data_utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      681 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/data_utils/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18798 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/data_utils/data_preprocessing.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1092 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8461 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/assistant_data_processor.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    22211 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/data_processor.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    30287 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/dialogue_bert_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11742 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/dialogue_gpt_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    13388 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/evaluate.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    20431 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/input_example.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    14948 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/metrics.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10814 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/prediction_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7971 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/schema.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/entity_linking/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      708 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/entity_linking/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4723 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/entity_linking/entity_linking_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      699 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15465 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/data_processors.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    21656 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/glue_benchmark_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    19440 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/gpt_ptune_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9941 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/t5_ptune_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/information_retrieval/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      742 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/information_retrieval/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11066 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/information_retrieval/information_retrieval_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1232 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11111 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6833 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_descriptor.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5038 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6488 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_descriptor.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.507201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      968 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11078 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/l2r_lm_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    16799 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/lm_bert_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      890 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/Makefile
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1105 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4604 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/bart_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2899 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/base_dataset_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7854 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/bert_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2657 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/blendable_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5204 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/data_samplers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    29883 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/dataset_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    22652 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/gpt_dataset.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)     7954 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/gpt_prompt_tuning_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    27118 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/helpers.cpp
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18914 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/indexed_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2582 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/lm_adapted_t5_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9729 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/megatron_batch_samplers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2736 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/megatron_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3866 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/request_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11942 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/t5_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12270 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/sentence_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/machine_translation/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      755 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/machine_translation/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    19249 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/machine_translation/machine_translation_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    49825 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/machine_translation/preproc_mt_data.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/question_answering_squad/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/question_answering_squad/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18239 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/question_answering_squad/qa_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    26029 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/question_answering_squad/qa_squad_processing.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text2sparql/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      701 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text2sparql/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5974 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text2sparql/text2sparql_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_classification/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      757 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_classification/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2578 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_classification/ptune_text_classification_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12536 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_classification/text_classification_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      917 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3364 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/constants.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    24934 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/decoder_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9876 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/tagger_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11947 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/test_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10635 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    76449 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/punctuation_capitalization_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18289 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/punctuation_capitalization_infer_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    61761 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/punctuation_capitalization_tarred_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    13473 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/token_classification_dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5061 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/token_classification_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/data/zero_shot_intent_recognition/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      784 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/zero_shot_intent_recognition/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12144 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/data/zero_shot_intent_recognition/zero_shot_intent_dataset.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/losses/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      681 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/losses/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10084 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/losses/sgd_loss.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/metrics/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      807 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/metrics/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10625 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/metrics/classification_report.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3486 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/metrics/sequence_perplexity.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1990 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_generative/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      845 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_generative/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    29684 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_generative/dialogue_gpt_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4645 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_generative/dialogue_metrics.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.511201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_sgdqa/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      815 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_sgdqa/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    27574 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_sgdqa/sgdqa_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      947 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    23679 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    17562 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/duplex_tagger.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12676 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/duplex_tn.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1182 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2640 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/enc_dec_nlp_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/entity_linking/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      706 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/entity_linking/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6740 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/entity_linking/entity_linking_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/glue_benchmark/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      697 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/glue_benchmark/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11270 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/glue_benchmark/glue_benchmark_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2168 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/glue_benchmark/metrics_for_glue.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      800 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8249 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/base_ir_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5524 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/bert_dpr_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3368 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/bert_joint_ir_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      911 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    19361 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification/intent_slot_classification_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18367 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification/multi_label_intent_slot_classification_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification_refactor/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      759 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification_refactor/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    27435 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification_refactor/intent_slot_classification_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      793 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11471 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/bert_lm_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      971 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10544 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron/bert_model.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)     8183 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron/gpt_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1938 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_bart_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3033 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_base_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    23475 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_bert_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    19769 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_glue_model.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)    56761 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_gpt_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    44249 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_lm_encoder_decoder_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    21080 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_ptune_gpt_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    20189 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_ptune_t5_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8129 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_t5_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11996 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/transformer_lm_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      808 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    20166 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/megatron_nmt_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18727 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/mt_enc_dec_bottleneck_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5782 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/mt_enc_dec_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    63218 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/mt_enc_dec_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    17434 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/nlp_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/question_answering/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      687 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/question_answering/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    17410 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/question_answering/qa_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/text2sparql/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      698 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/text2sparql/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10438 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/text2sparql/text2sparql_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/text_classification/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      967 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/text_classification/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    21173 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/text_classification/ptune_text_classification_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12217 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/text_classification/text_classification_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      999 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15777 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/punctuation_capitalization_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    64924 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/punctuation_capitalization_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    21076 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/token_classification_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/models/zero_shot_intent_recognition/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      723 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/zero_shot_intent_recognition/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12848 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/models/zero_shot_intent_recognition/zero_shot_intent_model.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.515201 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1130 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.519201 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1517 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3647 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/bert_module.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2905 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/classifier.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2099 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/decoder_module.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1440 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/encoder_module.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4150 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/gpt_module.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.519201 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1187 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1256 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/albert.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1258 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/bert.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1237 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/camembert.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1332 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/distilbert.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1887 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/gpt2.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3387 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/huggingface_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4367 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/huggingface_encoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5694 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/huggingface_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1230 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/roberta.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9328 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/lm_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.519201 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      749 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5650 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/clip_grads.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2118 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/fused_bias_dropout_add.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2215 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/fused_bias_gelu.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1702 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/fused_layer_norm.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)    35484 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/language_model.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4370 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_decoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5963 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_encoder_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4350 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_encoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11662 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_init.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6883 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_transformer_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6448 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_transformer_encoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8520 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12735 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/module.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15834 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/token_level_encoder_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    44446 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/transformer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10338 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3293 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/prompt_encoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2950 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/sequence_classifier.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2746 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/sequence_regression.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3227 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/sequence_token_classifier.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6101 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/text_generation_server.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    33040 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/text_generation_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6176 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/token_classifier.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9240 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/tokenizer_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1188 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5302 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/bridge_encoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6712 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/perceiver_encoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5048 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/reduction_encoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5956 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/text_generation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9484 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12598 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_bottleneck.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9310 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_decoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6910 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_encoders.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    40354 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_generators.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11622 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_modules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7895 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/dialogue_state_tracking/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/dialogue_state_tracking/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7653 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_decoder.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2643 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_encoder.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/nlp/parts/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      685 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/parts/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    29459 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/parts/nlp_overrides.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4525 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/nlp/parts/utils_funcs.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/tts/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      715 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/tts/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      655 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/data/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    34584 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/data/datalayers.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/tts/helpers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      655 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/helpers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    17491 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/tts/helpers/helpers.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/tts/losses/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      708 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3070 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/aligner_loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5560 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/fastpitchloss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4754 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/fastspeech2loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3299 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/glow_tts_loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4380 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/hifigan_losses.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9869 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/stftlosses.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3827 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/tacotron2loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2334 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/uniglowloss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1991 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/losses/waveglowloss.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.523201 nemo_toolkit-1.8.2/nemo/collections/tts/models/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2520 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9129 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/aligner.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12628 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/base.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)    13320 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/degli.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)    11608 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/ed_mel2spec.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    23509 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/fastpitch.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18413 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/fastpitch_hifigan_e2e.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    14064 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/fastspeech2.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    20755 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/fastspeech2_hifigan_e2e.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12342 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/glow_tts.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18802 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/hifigan.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15555 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/melgan.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    30408 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/mixer_tts.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10849 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/squeezewave.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    13816 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/tacotron2.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    17544 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/talknet.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6521 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/two_stages.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12364 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/uniglow.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15795 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/univnet.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10780 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/models/waveglow.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/collections/tts/modules/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1306 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7024 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/aligner.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)    21871 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/degli.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)     8658 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/ed_mel2spec.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12234 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/fastpitch.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    13021 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/fastspeech2.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5170 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/fastspeech2_submodules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    17698 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/glow_tts.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    14280 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/glow_tts_parser.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    24275 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/glow_tts_submodules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    15910 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/hifigan_modules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18262 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/melgan_modules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8379 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/mixer_tts.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9217 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/squeezewave.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6244 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/squeezewave_submodules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11119 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/submodules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    18403 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/tacotron2.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4638 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/talknet.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9197 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/transformer.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7326 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/uniglow.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    23269 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/univnet_modules.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10732 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/modules/waveglow.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/collections/tts/torch/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    38892 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/data.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      686 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/de_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2843 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/en_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10475 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/g2ps.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2973 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/helpers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1540 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/tts_data_types.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    13991 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/collections/tts/torch/tts_tokenizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1019 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/constants.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/core/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      673 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/core/classes/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1128 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/classes/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    40516 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/core/classes/common.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3361 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/classes/dataset.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7593 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/classes/exportable.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      905 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/classes/loss.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    59040 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/core/classes/modelPT.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2132 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/classes/module.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/core/config/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1582 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      918 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/base_config.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5028 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/hydra_runner.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6927 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/modelPT.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9394 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/optimizers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1478 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/pytorch.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3569 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/pytorch_lightning.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8149 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/config/schedulers.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/core/connectors/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      652 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/connectors/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    22571 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/connectors/save_restore_connector.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/core/neural_types/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      797 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/neural_types/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3980 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/neural_types/axes.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1343 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/neural_types/comparison.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    10053 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/neural_types/elements.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9499 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/neural_types/neural_type.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.527201 nemo_toolkit-1.8.2/nemo/core/optim/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1230 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/optim/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8725 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/optim/adafactor.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    34336 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/optim/lr_scheduler.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5714 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/optim/novograd.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    16961 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/optim/optimizer_with_main_params.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7189 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/optim/optimizers.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo/core/utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      661 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/utils/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2214 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/utils/k2_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2281 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/utils/neural_type_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5719 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/core/utils/numba_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1400 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/package_info.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo/utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      954 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    14601 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/app_state.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5605 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/arguments.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3117 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/cloud.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12528 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/config_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo/utils/decorators/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      786 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/decorators/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2353 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/decorators/deprecated.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1047 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/decorators/experimental.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2947 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/decorators/port_docs.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1629 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/distributed.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6654 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/env_var_parsing.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1385 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/exceptions.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    42036 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo/utils/exp_manager.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9154 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/export_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo/utils/formatters/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/formatters/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5339 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/formatters/base.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2834 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/formatters/colors.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1537 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/formatters/utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1478 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/get_rank.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2504 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/lightning_logger_patch.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1452 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/metaclasses.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    21570 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/model_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    16740 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/nemo_logging.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4567 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo/utils/timers.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo_text_processing/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      942 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1255 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3413 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3694 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2758 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1709 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2773 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4016 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3686 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1743 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2192 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2096 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8284 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1485 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/whitelist.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.531201 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1590 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2092 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2556 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1639 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2585 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2446 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1930 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize_final.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1255 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12771 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/clean_eval_data.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      626 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/currency.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       32 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      121 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      263 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/electronic/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       41 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/magnitudes.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1476 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/measurements.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       85 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/months.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       62 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/hundred.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      109 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      261 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/thousands.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       78 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/zero.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/ordinals/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/ordinals/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      105 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/ordinals/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       14 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/ordinals/teen.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/time/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/time/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/time/time_suffix.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       88 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/time/time_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/time/time_zone.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      157 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/whitelist.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5378 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5589 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4043 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3970 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      962 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3691 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4584 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1878 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1334 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/punctuation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5903 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5147 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5389 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1579 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1355 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1227 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1770 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2850 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2461 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1998 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      916 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2308 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1599 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2157 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1665 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2811 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2867 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1894 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1497 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1440 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.535200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1268 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       90 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/currency_plural.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       78 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/currency_singular.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       77 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      117 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       36 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/electronic/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      269 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/measurements_plural.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      249 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/measurements_singular.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       88 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/months.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       82 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      239 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/hundreds.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      108 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       93 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      206 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/twenties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/zero.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      280 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      473 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/hundreds.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1192 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      312 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      556 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/twenties.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/time/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/time/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      103 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/time/time_suffix.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      423 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/time/time_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       23 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/whitelist.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8325 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2656 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5079 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4126 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3831 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4786 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4328 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1305 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/punctuation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5392 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6059 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5339 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1548 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1326 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      864 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1783 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2265 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3016 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2088 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2279 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1600 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1759 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1361 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2799 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2839 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1865 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1468 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1411 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.539200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1268 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       77 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      120 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      126 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/electronic/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      737 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/fractions.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/measurements/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/measurements/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      122 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/measurements/magnitudes.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      391 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/measurements/measurements.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/money/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/money/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      674 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/money/currency_major.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       60 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/money/currency_minor.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       87 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/months.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       68 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       10 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/hundreds.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       57 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      236 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/thousands.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      146 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      470 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/ties_unique.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        8 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/zero.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      318 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/digits_root_change.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       51 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/firsts.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/key_nouns.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       43 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/second.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/roman/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/roman/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/roman/digits_large.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/roman/hundreds_large.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/roman/ties_large.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        0 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/suppletive.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/hour_to_night.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      255 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/hours.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      129 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/hours_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      881 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/minutes.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      353 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/minutes_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        8 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/time_suffix_am.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/time_suffix_pm.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      300 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/whitelist.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7004 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/graph_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.543200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11998 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2716 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5296 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4497 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3457 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3502 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5899 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3573 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1408 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/punctuation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3810 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5699 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5598 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1536 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1334 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      864 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1791 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2658 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3702 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1775 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2058 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2682 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1630 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3317 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1373 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2441 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3060 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1873 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1497 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1440 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5592 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/inverse_normalize.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1988 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1651 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2690 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/decimals.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1686 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1711 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1624 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1810 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1816 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3099 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5842 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1658 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/whitelist.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1885 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1309 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2044 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1331 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1461 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1326 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1567 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1347 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1893 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2817 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1865 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4892 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/run_evaluate.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2426 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/run_predict.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1255 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      105 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/currency.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       35 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      113 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      213 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/electronic/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       40 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/magnitudes.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/math/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/math/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       90 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/math/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2485 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/measurements.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      114 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/months.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       71 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        5 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/hundred.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      172 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       54 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/thousands.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       63 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        8 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/zero.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.547200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       85 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/digit.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      356 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/hours.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      129 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/hours_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/hours_to_night.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1789 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/minutes.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      353 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/minutes_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/time_suffix.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/time_zone.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        0 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/whitelist.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5820 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/graph_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6023 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5984 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4914 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3839 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2507 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3779 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2940 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1629 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1342 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/punctuation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1891 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4278 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5624 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1587 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1363 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      843 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1778 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2788 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2463 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2006 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1882 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2811 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1607 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1514 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1393 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3197 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3070 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1901 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1526 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1469 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      943 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7567 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/data_loader_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      118 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       84 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      258 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/electronic/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      542 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/fractions.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/measure/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/measure/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1198 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/measure/measurements.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      139 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/measure/suppletive.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.551200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/money/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/money/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      396 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/money/currency.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/money/currency_minor_plural.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/money/currency_minor_singular.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.555200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/months/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/months/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      147 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/months/abbr_to_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      230 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/months/numbers.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.555200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       59 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       27 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/ones.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      119 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/quantities.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      109 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       81 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/zero.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.555200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/ordinals/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/ordinals/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       93 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/ordinals/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       70 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/ordinals/thousands.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      139 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/ordinals/ties.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.555200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/time/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/time/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       53 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/time/hour_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       67 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/time/hour_to_night.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      336 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/time/minute_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/time/time_zone.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       89 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/whitelist.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.555200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7770 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5997 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3832 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3311 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2340 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7219 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7422 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2116 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3815 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4095 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7012 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2925 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1427 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1317 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.555200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1848 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2873 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2549 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3675 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3144 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2243 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3493 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2417 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1965 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5632 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3770 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2005 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/verbalize_final.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.555200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1231 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    12763 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/clean_eval_data.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/address/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/address/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      137 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/address/address_words.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      621 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/address/states.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/currency/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/currency/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      595 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/currency/currency.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       26 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/currency/currency_minor_plural.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/currency/currency_minor_singular.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      128 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       80 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      254 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/electronic/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       41 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/magnitudes.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       71 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/math_operations.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1692 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/measurements.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/months/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/months/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      141 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/months/abbr.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      257 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/months/days.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       86 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/months/names.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      234 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/months/numbers.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/__init__.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)   325078 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/cardinal_number_name.far
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       62 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/hundred.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      109 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      261 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/thousands.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       69 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/zero.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/ordinals/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/ordinals/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      105 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/ordinals/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       14 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/ordinals/teen.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.559200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/roman/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/roman/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      366 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/roman/digit_teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/roman/hundreds.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       31 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/roman/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      522 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/suppletive.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       96 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/time_suffix.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      140 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/time_zone.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)   175151 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/whitelist.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      275 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/whitelist_alternatives.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      263 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/whitelist_lj_speech.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7238 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/graph_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2307 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/abbreviation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8101 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11686 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4750 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3420 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2191 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9499 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9673 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1907 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1828 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/punctuation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2793 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/roman.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4250 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5163 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7743 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11421 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify_with_audio.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3292 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1950 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1153 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1603 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/abbreviation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2165 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3610 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2792 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3752 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3326 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3739 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3515 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2354 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1812 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/roman.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2621 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3794 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4036 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2321 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1739 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1669 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      682 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/dates/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/dates/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      115 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/dates/months.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      189 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       73 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      300 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/electronic/symbols.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/fractions/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/fractions/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       28 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/fractions/ordinal_exceptions.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      224 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/fractions/powers_of_ten.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      137 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/fractions/powers_of_ten_fem.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/measures/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/measures/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      228 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/measures/measurements.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       54 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/measures/measurements_plural_fem.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      332 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/measures/measurements_plural_masc.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/money/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/money/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      390 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/money/currency_major.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       44 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/money/currency_minor.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      173 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/money/currency_plural_fem.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      441 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/money/currency_plural_masc.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.563200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      111 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/hundreds.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       52 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/quantities.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      108 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       72 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      141 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/twenties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/zero.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      137 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      471 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/hundreds.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      200 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/teen.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      165 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/ties.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      295 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/twenties.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/roman/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/roman/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/roman/digit.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/roman/hundreds.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/roman/ties.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       19 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/afternoon_times.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       27 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/alt_minutes.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       37 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/evening_times.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       53 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/hour_to_12.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      128 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/hour_to_24.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       67 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/hour_to_night.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      336 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/minute_to.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       60 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/morning_times.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      150 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/time_suffix.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       63 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/time_zone.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      532 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/whitelist.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8466 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/graph_utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7980 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4513 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5873 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/decimals.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3633 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5819 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6593 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9090 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7615 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5947 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8998 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7473 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2926 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1442 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1140 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2514 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3415 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3822 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/decimals.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3840 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8523 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5305 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7249 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3077 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1638 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9173 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3588 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2001 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    16064 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/normalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    16914 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/normalize_with_audio.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2435 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/alphabet.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.567200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/currency/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/currency/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1420 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/currency/currency_plural.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1085 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/currency/currency_singular.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.571200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/electronic/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/electronic/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       47 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/electronic/domain.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      290 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/electronic/server_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      668 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/electronic/symbols.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      275 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/latin_to_cyrillic.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8212 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/measurements.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.571200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/months/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/months/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      239 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/months/abbr.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1541 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/months/abbr_to_name.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      214 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/months/numbers.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.571200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      969 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/1_cardinals_nominative.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      911 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/2_cardinals_genitive.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      933 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/3_cardinals_dative.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      913 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/4_cardinals_accusative.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1048 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/5_cardinals_instrumental.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      951 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/6_cardinals_prepositional.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      549 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_alternatives.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      710 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_nominative_case.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      565 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/decimal_delimiter.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1026 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/decimal_endings.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      119 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/digits_nominative_case.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      430 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/ordinal_endings.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    21537 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/ordinals.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      537 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/quantity.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.571200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      469 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/increment_hour_cardinal.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      611 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/increment_hour_ordinal.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      828 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/minutes_to_hour.tsv
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       62 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/time_convert.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.579200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3206 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/g.fst
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    69495 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/universal_thousands_punct.far
--rw-rw-r--   0 eharper   (1000) eharper   (1000)  7085564 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/util_arithmetic.far
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    14099 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/util_byte.far
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1005 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/whitelist.tsv
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.579200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6933 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6128 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4584 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/decimals.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4911 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7057 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     4112 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6746 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/number_names.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3107 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3422 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5368 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     7271 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/tokenize_and_classify.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3201 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1427 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/word.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1304 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.579200 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2048 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1654 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2346 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1727 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1916 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1652 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1619 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1940 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2272 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3035 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/verbalize.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2096 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/verbalize_final.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5055 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/run_evaluate.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2432 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/run_predict.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     5130 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/token_parser.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.583200 nemo_toolkit-1.8.2/nemo_toolkit.egg-info/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2168 2022-04-26 20:26:23.000000 nemo_toolkit-1.8.2/nemo_toolkit.egg-info/PKG-INFO
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    73571 2022-04-26 20:26:24.000000 nemo_toolkit-1.8.2/nemo_toolkit.egg-info/SOURCES.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        1 2022-04-26 20:26:24.000000 nemo_toolkit-1.8.2/nemo_toolkit.egg-info/dependency_links.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)        1 2022-04-26 19:56:35.000000 nemo_toolkit-1.8.2/nemo_toolkit.egg-info/not-zip-safe
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2943 2022-04-26 20:26:24.000000 nemo_toolkit-1.8.2/nemo_toolkit.egg-info/requires.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       32 2022-04-26 20:26:24.000000 nemo_toolkit-1.8.2/nemo_toolkit.egg-info/top_level.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1325 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/setup.cfg
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9427 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/setup.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.583200 nemo_toolkit-1.8.2/tests/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/__init__.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)     4386 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/check_copyright_header.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     8277 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/conftest.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.583200 nemo_toolkit-1.8.2/tests/core/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3917 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/test_config_utils.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    19386 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/test_exp_manager.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    11315 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/test_fileio.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     9537 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/test_neural_types.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    32351 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/test_optimizers_schedulers.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    21745 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/test_save_restore.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6123 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/core/test_serialization.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)    36350 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/tests/core/test_typecheck.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3583 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/manualtest_model_downloads.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.583200 nemo_toolkit-1.8.2/tests/nemo_text_processing/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.583200 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2710 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2697 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2706 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2715 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2710 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2707 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2701 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1732 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_normalization_with_audio.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2368 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2713 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2697 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2713 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2698 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.583200 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2060 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_address.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2004 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_boundary.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2802 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3686 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2698 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2708 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1978 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2051 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_math.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2699 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2720 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1744 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_normalization_with_audio.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2726 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2138 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_punctuation.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2744 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2715 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     3576 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2765 2022-04-26 19:38:39.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2722 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2709 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2718 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2736 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2004 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2728 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2713 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1730 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_normalization_with_audio.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2719 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2733 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2718 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2731 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2780 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1486 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1492 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1483 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1491 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1491 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_whitelist.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1481 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_word.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/__init__.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      972 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1712 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal_normalize_with_audio.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      458 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_date.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1003 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_decimal.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      527 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_electronic.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      788 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_measure.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      567 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_money.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2913 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_ordinal.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      166 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_telephone.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      415 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_time.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)       87 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_whitelist.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      215 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_word.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6216 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/test_ru_inverse_normalization.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     6236 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/test_ru_normalization.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     2083 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/utils.py
-drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-04-26 20:26:24.587200 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/
--rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/__init__.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_cardinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_date.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1486 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_decimal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1492 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_electronic.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_fraction.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_measure.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1483 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_money.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_ordinal.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1491 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_telephone.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_time.py
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1481 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_word.py
--rwxrwxr-x   0 eharper   (1000) eharper   (1000)      619 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/py_cprheader.txt
--rw-rw-r--   0 eharper   (1000) eharper   (1000)     1008 2022-04-26 19:36:18.000000 nemo_toolkit-1.8.2/tests/test_data_dir.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.039029 nemo_toolkit-1.9.0/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11356 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/LICENSE
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2153 2022-06-03 19:32:19.039029 nemo_toolkit-1.9.0/PKG-INFO
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12526 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/README.rst
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.943029 nemo_toolkit-1.9.0/nemo/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      874 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.943029 nemo_toolkit-1.9.0/nemo/collections/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.943029 nemo_toolkit-1.9.0/nemo/collections/asr/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      922 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.943029 nemo_toolkit-1.9.0/nemo/collections/asr/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3578 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_ctm_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    38079 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_label.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6146 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_label_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    47486 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_text.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    34518 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_text_dali.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    17939 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_text_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5664 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/feature_to_label.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1206 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/data/feature_to_label_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.943029 nemo_toolkit-1.9.0/nemo/collections/asr/losses/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      879 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/losses/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2362 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/losses/angularloss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2695 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/losses/ctc.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6989 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/losses/lattice_losses.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.943029 nemo_toolkit-1.9.0/nemo/collections/asr/losses/pt_losses/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      689 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/losses/pt_losses/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11415 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/losses/pt_losses/contrastive.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11393 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/losses/rnnt.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.943029 nemo_toolkit-1.9.0/nemo/collections/asr/metrics/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/metrics/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    29647 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/metrics/rnnt_wer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/metrics/rnnt_wer_bpe.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11763 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/metrics/wer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10566 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/metrics/wer_bpe.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/models/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1293 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5361 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/asr_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    32972 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/classification_models.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    22983 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/clustering_diarizer.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1659 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1331 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/aligner_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3161 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/asr_models_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3421 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/classification_models_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1296 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/k2_sequence_models_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12828 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/matchboxnet_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    19689 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/quartznet_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    22699 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/ctc_bpe_models.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    34786 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/ctc_models.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    16348 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/k2_aligner_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8202 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/k2_sequence_models.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    22583 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/label_models.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    22066 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/rnnt_bpe_models.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    42469 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/rnnt_models.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15526 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/models/ssl_models.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/modules/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1559 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    26393 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/audio_preprocessing.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4440 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/beam_search_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    13445 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/conformer_encoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    34053 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/conv_asr.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9509 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/graph_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3416 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/lstm_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6591 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/rnn_encoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    46949 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/rnnt.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11315 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/rnnt_abstract.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    13955 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/modules/wav2vec_modules.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1897 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/features.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3428 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/autograd.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6962 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/classes.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3676 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/grad_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6260 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/graph_compilers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10346 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/graph_decoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12130 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/map_loss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5493 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/ml_loss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4866 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/topologies.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9241 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/mixins/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      839 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/mixins/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7648 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/mixins/asr_adapter_mixins.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18614 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/mixins/mixins.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      693 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      782 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8560 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/rnnt.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12848 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_numpy.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9576 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_pytorch.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1194 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15598 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/cpu_rnnt.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.947029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1194 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11243 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18797 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt_kernel.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12486 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/reduce.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1727 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/global_constants.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3788 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/rnnt_helper.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/spec_augment/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      746 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/spec_augment/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11697 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/spec_augment/spec_aug_numba.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1330 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2886 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/feature_loader.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15286 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/features.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    38635 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/perturb.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10999 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/segment.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7469 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/conformer_modules.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    47339 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/jasper.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12886 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/multi_head_attention.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    50962 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/rnnt_beam_decoding.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    47484 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/rnnt_greedy_decoding.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5193 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/spectr_augment.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7258 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/ssl_quantizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6347 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/subsampling.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/tdnn_attention.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      847 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/activations.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3292 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/asr_module_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    33032 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/decoder_timestamps_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    48454 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/diarization_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    40152 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/nmesc_clustering.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3386 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/numba_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5863 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/rnnt_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    24913 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/speaker_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    46770 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/streaming_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3762 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/transcribe_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    44102 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/vad_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/common/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      946 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/common/callbacks/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      688 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/callbacks/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3997 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/callbacks/callbacks.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/common/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      674 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/data/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6839 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/data/dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12727 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/data/vocabs.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/common/losses/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1146 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2181 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/aggregator.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2719 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/bce_logits_loss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5369 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/cross_entropy.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1777 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/mse_loss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3487 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/multi_similarity_loss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4573 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/smoothed_cross_entropy.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3108 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/losses/spanning_loss.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.951029 nemo_toolkit-1.9.0/nemo/collections/common/metrics/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      867 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/common/metrics/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7320 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/common/metrics/classification_accuracy.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3532 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/metrics/global_average_loss_metric.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3558 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/metrics/perplexity.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/common/parts/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      902 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3301 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/adapter_modules.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2222 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/multi_layer_perceptron.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      806 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/patch_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8093 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/cleaners.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18255 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/collections.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3957 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/manifest.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7885 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/parsers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1012 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/ptl_overrides.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    20507 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/rnn.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3026 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/transformer_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1790 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/common/parts/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1364 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6302 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/aggregate_tokenizer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3233 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/bytelevel_tokenizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    25682 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/char_tokenizer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2724 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/chinese_tokenizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11242 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/column_coder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2956 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/en_ja_tokenizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4159 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/fairseq_tokenizer.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/huggingface/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      699 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/huggingface/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10598 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/huggingface/auto_tokenizer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1537 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/indic_tokenizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1597 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/moses_tokenizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9288 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/regex_tokenizer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    13770 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/sentencepiece_tokenizer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6901 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/tabular_tokenizer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1398 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/tokenizer_spec.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2475 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/word_tokenizer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2605 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/youtokentome_tokenizer.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/cv/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      912 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/cv/datasets/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      699 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/datasets/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4475 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/datasets/mnist_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/cv/losses/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      667 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/losses/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1902 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/losses/nll_loss.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/cv/models/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      694 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/models/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4870 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/models/mnist_lenet5.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/cv/modules/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      665 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/modules/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3381 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/cv/modules/lenet5.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/nlp/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      921 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1942 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/common/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      711 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/common/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4206 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/common/sequence_to_sequence_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/data_utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      681 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/data_utils/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18798 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/data_utils/data_preprocessing.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      967 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.955029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8942 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/assistant_data_processor.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2010 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/data_processor.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6156 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/design_data_processor.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4446 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/mellon_qa_data_processor.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5723 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/ms_marco_data_processor.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    24457 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/sgd_data_processor.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1064 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10826 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_bert_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1393 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11997 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_gpt_classification_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6054 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_gpt_generation_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3269 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_nearest_neighbour_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6165 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_s2s_generation_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    20458 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_sgd_bert_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    13117 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_zero_shot_intent_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      942 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2216 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/assistant_input_example.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1948 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/design_input_example.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1261 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/input_example.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1329 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/mellon_qa_input_example.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1601 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/ms_marco_input_example.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    20377 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/sgd_input_example.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      769 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    13356 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/evaluate.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10802 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/prediction_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7971 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/schema.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/entity_linking/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      708 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/entity_linking/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4723 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/entity_linking/entity_linking_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      699 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15465 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/data_processors.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    21656 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/glue_benchmark_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    19440 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/gpt_ptune_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9941 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/t5_ptune_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/information_retrieval/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      742 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/information_retrieval/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11066 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/information_retrieval/information_retrieval_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1232 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11111 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6833 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_descriptor.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5038 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6488 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_descriptor.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      968 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11078 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/l2r_lm_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    16799 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/lm_bert_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.959029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      890 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/Makefile
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1109 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4604 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/bart_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2899 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/base_dataset_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7854 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/bert_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2657 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/blendable_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5204 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/data_samplers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    29883 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/dataset_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    22652 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/gpt_dataset.py
+-rwxrwxr-x   0 eharper   (1000) eharper   (1000)    17135 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/gpt_prompt_learning_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    27118 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/helpers.cpp
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18914 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/indexed_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2582 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/lm_adapted_t5_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9729 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/megatron_batch_samplers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2736 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/megatron_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3866 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/request_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11942 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/t5_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12270 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/sentence_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/machine_translation/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      755 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/machine_translation/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    19249 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/machine_translation/machine_translation_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    49825 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/machine_translation/preproc_mt_data.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/question_answering_squad/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/question_answering_squad/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18239 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/question_answering_squad/qa_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    26029 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/question_answering_squad/qa_squad_processing.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text2sparql/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      701 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text2sparql/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5974 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text2sparql/text2sparql_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_classification/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      757 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_classification/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2578 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_classification/ptune_text_classification_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12536 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_classification/text_classification_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      917 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3364 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/constants.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    24934 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/decoder_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9876 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/tagger_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11947 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/test_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10631 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization_as_tagging/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      779 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization_as_tagging/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15095 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization_as_tagging/bert_example.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8163 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization_as_tagging/tagging.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4122 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization_as_tagging/thutmose_tagger_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14940 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization_as_tagging/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    84004 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/punctuation_capitalization_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18289 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/punctuation_capitalization_infer_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    62261 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/punctuation_capitalization_tarred_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    13473 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/token_classification_dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5061 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/token_classification_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/data/zero_shot_intent_recognition/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      784 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/zero_shot_intent_recognition/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12144 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/data/zero_shot_intent_recognition/zero_shot_intent_dataset.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/losses/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      681 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/losses/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10084 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/losses/sgd_loss.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      895 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10625 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/classification_report.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7165 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/dialogue_metrics.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3486 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/sequence_perplexity.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14948 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/sgd_metrics.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2077 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.963029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1031 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    29176 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_gpt_classification_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18328 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_gpt_generation_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9939 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_nearest_neighbour_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14979 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_s2s_generation_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    20752 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_zero_shot_intent_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    27409 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/intent_slot_classification_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    26971 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/sgdqa_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      947 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    23679 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    17562 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/duplex_tagger.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12676 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/duplex_tn.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1182 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2640 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/enc_dec_nlp_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/entity_linking/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      706 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/entity_linking/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6740 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/entity_linking/entity_linking_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/glue_benchmark/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      697 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/glue_benchmark/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11270 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/glue_benchmark/glue_benchmark_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2168 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/glue_benchmark/metrics_for_glue.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      800 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8249 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/base_ir_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5524 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/bert_dpr_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3368 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/bert_joint_ir_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/intent_slot_classification/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      911 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/intent_slot_classification/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    19361 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/intent_slot_classification/intent_slot_classification_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18367 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/intent_slot_classification/multi_label_intent_slot_classification_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      926 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11471 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/bert_lm_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      971 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10544 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron/bert_model.py
+-rwxrwxr-x   0 eharper   (1000) eharper   (1000)     7567 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron/gpt_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1938 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_bart_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3033 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_base_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    23475 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_bert_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    25964 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_finetune_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3753 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_glue_model.py
+-rwxrwxr-x   0 eharper   (1000) eharper   (1000)    38464 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_gpt_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    30513 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_gpt_prompt_learning_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    44588 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_lm_encoder_decoder_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    20270 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_ptune_t5_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8129 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_t5_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11996 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/transformer_lm_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      808 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    20166 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/megatron_nmt_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18753 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/mt_enc_dec_bottleneck_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5782 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/mt_enc_dec_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    64985 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/mt_enc_dec_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    17433 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/nlp_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/question_answering/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      687 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/question_answering/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    17410 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/question_answering/qa_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text2sparql/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      698 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text2sparql/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10438 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text2sparql/text2sparql_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_classification/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      721 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_classification/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12217 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_classification/text_classification_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_normalization_as_tagging/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      731 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_normalization_as_tagging/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    19105 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_normalization_as_tagging/thutmose_tagger.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      999 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15777 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/punctuation_capitalization_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    67529 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/punctuation_capitalization_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    21076 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/token_classification_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.967029 nemo_toolkit-1.9.0/nemo/collections/nlp/models/zero_shot_intent_recognition/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      723 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/zero_shot_intent_recognition/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12848 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/models/zero_shot_intent_recognition/zero_shot_intent_model.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.971029 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1166 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.971029 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1708 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3647 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/bert_module.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2905 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/classifier.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2099 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/decoder_module.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1440 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/encoder_module.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4150 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/gpt_module.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.971029 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1187 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1256 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/albert.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1258 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/bert.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1237 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/camembert.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1332 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/distilbert.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1887 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/gpt2.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3387 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/huggingface_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4367 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/huggingface_encoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5764 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/huggingface_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1230 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/roberta.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9328 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/lm_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.971029 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      749 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5650 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/clip_grads.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2458 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/fused_bias_dropout_add.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2215 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/fused_bias_gelu.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1702 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/fused_layer_norm.py
+-rwxrwxr-x   0 eharper   (1000) eharper   (1000)    24140 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/language_model.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      756 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/layer_type.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6144 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_decoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5963 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_encoder_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6124 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_encoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12504 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_init.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7364 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_transformer_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6923 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_transformer_encoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8520 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12735 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/module.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14822 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/retrieval_token_level_encoder_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14862 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/retrieval_transformer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2280 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/rotary_pos_embedding.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    16509 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/token_level_encoder_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    61302 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/transformer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10346 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3288 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/prompt_encoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7323 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/prompt_table.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2950 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/sequence_classifier.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2746 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/sequence_regression.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3227 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/sequence_token_classifier.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3293 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/t5_prompt_encoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7045 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/text_generation_server.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    38574 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/text_generation_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6176 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/token_classifier.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9240 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/tokenizer_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1188 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5302 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/bridge_encoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6712 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/perceiver_encoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5048 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/reduction_encoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5956 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/text_generation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9484 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12598 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_bottleneck.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9310 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_decoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6910 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_encoders.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    40354 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_generators.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11622 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_modules.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7895 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/dialogue_state_tracking/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/dialogue_state_tracking/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7653 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_decoder.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2643 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_encoder.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/nlp/parts/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      685 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/parts/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    29459 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/parts/nlp_overrides.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4525 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/nlp/parts/utils_funcs.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/tts/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      682 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/tts/helpers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      655 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/helpers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    19336 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/helpers/helpers.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/tts/losses/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      708 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/losses/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3070 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/losses/aligner_loss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5560 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/losses/fastpitchloss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4380 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/losses/hifigan_losses.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9869 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/losses/stftlosses.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3827 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/losses/tacotron2loss.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1991 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/losses/waveglowloss.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/tts/models/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1392 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9129 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/aligner.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12056 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/base.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    23835 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/fastpitch.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18499 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/hifigan.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    30408 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/mixer_tts.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    16428 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/tacotron2.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6521 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/two_stages.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15492 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/univnet.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10720 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/models/waveglow.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/tts/modules/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      901 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7024 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/aligner.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12234 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/fastpitch.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    15910 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/hifigan_modules.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8379 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/mixer_tts.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11119 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/submodules.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    18403 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/tacotron2.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9197 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/transformer.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    23269 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/univnet_modules.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11083 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/modules/waveglow.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/collections/tts/torch/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    38892 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/data.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      686 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/de_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2843 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/en_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10475 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/g2ps.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2973 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/helpers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1540 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/tts_data_types.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    13991 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/collections/tts/torch/tts_tokenizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1019 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/constants.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.975029 nemo_toolkit-1.9.0/nemo/core/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      673 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/core/classes/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1180 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/classes/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    43729 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/classes/common.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3361 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/classes/dataset.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7593 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/classes/exportable.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      905 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/classes/loss.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/core/classes/mixins/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      934 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/classes/mixins/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2814 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/classes/mixins/access_mixins.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3314 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/classes/mixins/adapter_mixin_strategies.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    22585 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/classes/mixins/adapter_mixins.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    58974 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/classes/modelPT.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2513 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/classes/module.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/core/config/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1582 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      918 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/base_config.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5028 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/hydra_runner.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6927 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/modelPT.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9394 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/optimizers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1478 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/pytorch.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3575 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/pytorch_lightning.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8149 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/config/schedulers.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/core/connectors/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      652 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/connectors/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    24332 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/connectors/save_restore_connector.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/core/neural_types/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      797 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/neural_types/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3980 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/neural_types/axes.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1343 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/neural_types/comparison.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    10053 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/neural_types/elements.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9499 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/neural_types/neural_type.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/core/optim/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1230 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/optim/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8725 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/optim/adafactor.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    34336 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/optim/lr_scheduler.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5714 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/optim/novograd.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    16961 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/core/optim/optimizer_with_main_params.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7189 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/optim/optimizers.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/core/utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      661 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/utils/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2214 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/utils/k2_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2281 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/utils/neural_type_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5719 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/core/utils/numba_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1400 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/package_info.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      954 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14601 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/app_state.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5605 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/arguments.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3117 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/cloud.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12528 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/config_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.979029 nemo_toolkit-1.9.0/nemo/utils/decorators/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      786 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/decorators/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2353 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/decorators/deprecated.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1047 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/decorators/experimental.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2947 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/decorators/port_docs.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1629 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/distributed.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6654 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/env_var_parsing.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1385 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/exceptions.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    42936 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/exp_manager.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9154 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo/utils/export_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo/utils/formatters/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/formatters/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5339 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/formatters/base.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2834 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/formatters/colors.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1537 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/formatters/utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1478 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/get_rank.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2504 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/lightning_logger_patch.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1452 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/metaclasses.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    21570 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/model_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    16740 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/nemo_logging.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4567 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo/utils/timers.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      942 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1255 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3413 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3694 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2758 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1709 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2773 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4016 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3686 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1743 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2192 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2096 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8284 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1485 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/whitelist.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1590 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2092 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2556 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1639 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2585 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2446 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1930 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize_final.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1255 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12771 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/clean_eval_data.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      626 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/currency.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       32 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      121 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/electronic/server_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      263 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/electronic/symbols.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       41 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/magnitudes.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1476 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/measurements.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       85 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/months.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       62 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/hundred.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      109 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      261 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/thousands.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       78 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/zero.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/ordinals/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/ordinals/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      105 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/ordinals/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       14 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/ordinals/teen.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.983029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/time/time_suffix.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       88 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/time/time_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/time/time_zone.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      157 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/whitelist.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5378 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5589 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4043 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3970 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      962 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3691 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4584 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1878 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1334 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/punctuation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5903 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5147 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5389 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1579 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1355 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1227 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1770 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2850 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2461 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1998 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      916 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2308 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1599 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2157 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1665 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2811 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2867 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1894 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1497 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1440 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1268 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       90 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/currency_plural.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       78 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/currency_singular.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       77 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      117 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/electronic/server_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       36 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/electronic/symbols.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      269 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/measurements_plural.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      249 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/measurements_singular.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       88 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/months.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       82 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      239 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/hundreds.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      108 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       93 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      206 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/twenties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/zero.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      280 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      473 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/hundreds.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1192 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      312 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      556 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/twenties.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.987029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      103 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/time/time_suffix.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      423 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/time/time_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       23 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/whitelist.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8325 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2656 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5079 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4126 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3831 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4786 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4328 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1305 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/punctuation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5392 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6059 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5339 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1548 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1326 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      864 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1783 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2265 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3016 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2088 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2279 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1600 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1759 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1361 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2799 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2839 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1865 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1468 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1411 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1268 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       77 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      120 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/electronic/server_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      126 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/electronic/symbols.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      737 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/fractions.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/measurements/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/measurements/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      122 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/measurements/magnitudes.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      391 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/measurements/measurements.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/money/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/money/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      674 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/money/currency_major.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       60 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/money/currency_minor.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       87 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/months.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       68 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       10 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/hundreds.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       57 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      236 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/thousands.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      146 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      470 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/ties_unique.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        8 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/zero.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      318 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/digits_root_change.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       51 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/firsts.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/key_nouns.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       43 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/second.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.991029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/roman/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/roman/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/roman/digits_large.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/roman/hundreds_large.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/roman/ties_large.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        0 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/suppletive.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.995029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/hour_to_night.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      255 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/hours.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      129 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/hours_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      881 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/minutes.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      353 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/minutes_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        8 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/time_suffix_am.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/time_suffix_pm.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      300 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/whitelist.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7004 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/graph_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.995029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11998 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2716 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5296 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4497 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3457 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3502 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5899 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3573 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1408 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/punctuation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3810 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5699 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5598 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1536 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1334 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      864 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.995029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1791 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2658 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3702 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1775 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2058 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2682 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1630 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3317 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1373 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2441 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3060 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1873 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1497 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1440 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6279 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/inverse_normalize.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.995029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.995029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1988 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1651 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2690 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/decimals.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1686 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1711 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1624 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1810 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1816 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3099 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5842 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1658 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/whitelist.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1885 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1309 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2044 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1331 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1461 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1326 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1567 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1347 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1893 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2817 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1865 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4892 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/run_evaluate.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1255 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      105 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/currency.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       35 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      113 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/electronic/server_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      213 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/electronic/symbols.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       40 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/magnitudes.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/math/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/math/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       82 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/math/symbols.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2692 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/measurements.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      120 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/months.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       71 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        5 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/hundred.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      172 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       54 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/thousands.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       63 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        8 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/zero.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       85 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/digit.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      356 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/hours.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      129 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/hours_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/hours_to_night.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1789 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/minutes.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      335 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/minutes_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       61 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/time_suffix.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/time_zone.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        0 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/whitelist.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5816 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/graph_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:18.999029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6508 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6379 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5170 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3833 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2501 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3769 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2934 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1627 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1339 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/punctuation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1889 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4578 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5624 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1585 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1361 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      843 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1774 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2849 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2455 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2000 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1876 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2805 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1605 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1512 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1391 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3152 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3070 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1901 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1524 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1467 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      943 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8172 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/data_loader_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      118 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       84 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/electronic/server_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      258 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/electronic/symbols.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      542 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/fractions.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/measure/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/measure/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1198 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/measure/measurements.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      139 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/measure/suppletive.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/money/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/money/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      396 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/money/currency.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/money/currency_minor_plural.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/money/currency_minor_singular.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/months/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/months/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      147 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/months/abbr_to_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      230 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/months/numbers.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       59 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       27 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/ones.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      119 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/quantities.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      109 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       81 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/zero.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/ordinals/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/ordinals/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       93 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/ordinals/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       70 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/ordinals/thousands.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      139 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/ordinals/ties.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.003029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       53 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/time/hour_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       67 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/time/hour_to_night.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      336 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/time/minute_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/time/time_zone.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       89 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/whitelist.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7770 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5997 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3832 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3311 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2340 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7219 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7422 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2116 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3815 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4095 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7372 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2925 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1427 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1317 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1848 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2873 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2549 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3675 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3144 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2243 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3493 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2417 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1965 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5632 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3770 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2006 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/verbalize_final.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1231 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12763 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/clean_eval_data.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/address/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/address/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      161 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/address/address_word.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      648 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/address/state.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      257 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/day.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      141 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/month_abbr.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       86 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/month_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      234 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/month_number.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      128 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/year_suffix.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      142 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      254 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/electronic/symbol.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/measure/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/measure/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       71 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/measure/math_operation.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1407 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/measure/unit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      544 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/measure/unit_alternatives.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      595 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/currency_major.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       26 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/currency_minor_plural.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       24 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/currency_minor_singular.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       15 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/per_unit.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.007029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/__init__.py
+-rwxrwxr-x   0 eharper   (1000) eharper   (1000)   325078 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/cardinal_number_name.far
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       62 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      142 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/fraction.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/hundred.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       30 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/quantity_abbr.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      109 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      261 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/thousand.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       69 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/ty.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        7 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/zero.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.011029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/ordinal/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/ordinal/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      105 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/ordinal/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       14 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/ordinal/teen.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.011029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/roman/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/roman/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    35561 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/roman/female.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       82 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/roman/key_word.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    20334 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/roman/male.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    72815 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/roman/roman_to_spoken.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      720 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/suppletive.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.011029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/telephone/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/telephone/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       19 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/telephone/ip_prompt.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       38 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/telephone/ssn_prompt.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       56 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/telephone/telephone_prompt.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.011029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       84 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/time/suffix.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      116 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/time/zone.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.011029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      520 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/alternatives.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      155 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/alternatives_all_format.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)   175151 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/asr.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      263 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/lj_speech.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      225 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/symbol.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    36522 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/tts.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7324 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/graph_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.011029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2184 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/abbreviation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6230 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14954 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5619 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3840 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2515 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11240 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9648 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2626 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2241 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/punctuation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4019 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/range.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4540 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/roman.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5651 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/serial.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5806 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5314 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8825 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12356 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify_lm.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    12797 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify_with_audio.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6209 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2531 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1643 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1561 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/abbreviation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3240 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3741 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2909 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3626 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3838 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4086 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2858 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2227 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/roman.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2487 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3752 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3990 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2279 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1697 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1627 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      682 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/dates/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/dates/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      115 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/dates/months.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      189 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       73 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/electronic/server_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      300 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/electronic/symbols.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/fractions/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/fractions/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       28 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/fractions/ordinal_exceptions.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      224 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/fractions/powers_of_ten.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      137 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/fractions/powers_of_ten_fem.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/measures/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/measures/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      228 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/measures/measurements.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       54 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/measures/measurements_plural_fem.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      332 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/measures/measurements_plural_masc.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/money/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/money/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      390 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/money/currency_major.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       44 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/money/currency_minor.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      173 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/money/currency_plural_fem.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      441 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/money/currency_plural_masc.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       64 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      111 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/hundreds.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       52 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/quantities.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      108 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       72 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      141 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/twenties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        6 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/zero.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      137 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      471 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/hundreds.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      200 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/teen.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      165 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/ties.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      295 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/twenties.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/roman/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/roman/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/roman/digit.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/roman/hundreds.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       46 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/roman/ties.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.015029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       19 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/afternoon_times.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       27 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/alt_minutes.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       37 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/evening_times.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       53 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/hour_to_12.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      128 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/hour_to_24.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       67 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/hour_to_night.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      336 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/minute_to.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       60 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/morning_times.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      150 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/time_suffix.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       63 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/time_zone.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      532 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/whitelist.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8466 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/graph_utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.019029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7980 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4513 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5873 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/decimals.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3633 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5819 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6593 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9090 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7615 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5947 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8998 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7473 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2926 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1442 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1140 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.019029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2514 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3415 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3822 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/decimals.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3840 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8523 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5305 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7249 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3077 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1638 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9173 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3588 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2001 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    17396 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/normalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    17953 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/normalize_with_audio.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.019029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2435 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/alphabet.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.019029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.019029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/currency/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/currency/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1420 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/currency/currency_plural.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1085 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/currency/currency_singular.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.019029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/electronic/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/electronic/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       47 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/electronic/domain.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      290 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/electronic/server_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      668 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/electronic/symbols.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      275 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/latin_to_cyrillic.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9277 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/measurements.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.019029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/months/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/months/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      239 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/months/abbr.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1541 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/months/abbr_to_name.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      214 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/months/numbers.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.023029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      969 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/1_cardinals_nominative.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      911 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/2_cardinals_genitive.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      933 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/3_cardinals_dative.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      913 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/4_cardinals_accusative.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1048 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/5_cardinals_instrumental.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      951 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/6_cardinals_prepositional.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      549 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_alternatives.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      710 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_nominative_case.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      565 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/decimal_delimiter.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1026 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/decimal_endings.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      119 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/digits_nominative_case.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      430 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/ordinal_endings.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    21537 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/ordinals.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      537 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/quantity.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.023029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      469 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/increment_hour_cardinal.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      611 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/increment_hour_ordinal.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      828 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/minutes_to_hour.tsv
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       62 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/time_convert.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.031029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3206 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/g.fst
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    69495 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/universal_thousands_punct.far
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)  7085564 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/util_arithmetic.far
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    14099 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/util_byte.far
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1005 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/whitelist.tsv
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.031029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6933 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6128 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4584 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/decimals.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4911 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7057 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     4112 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6746 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/number_names.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3065 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3380 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5368 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     7271 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/tokenize_and_classify.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3159 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1427 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/word.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1304 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.031029 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2006 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1612 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2304 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1685 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1874 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1577 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1898 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2230 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2993 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/verbalize.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2054 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/verbalize_final.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5055 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/run_evaluate.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     5130 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/token_parser.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.031029 nemo_toolkit-1.9.0/nemo_toolkit.egg-info/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2153 2022-06-03 19:32:18.000000 nemo_toolkit-1.9.0/nemo_toolkit.egg-info/PKG-INFO
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    76017 2022-06-03 19:32:18.000000 nemo_toolkit-1.9.0/nemo_toolkit.egg-info/SOURCES.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        1 2022-06-03 19:32:18.000000 nemo_toolkit-1.9.0/nemo_toolkit.egg-info/dependency_links.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)        1 2022-06-03 16:45:32.000000 nemo_toolkit-1.9.0/nemo_toolkit.egg-info/not-zip-safe
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3033 2022-06-03 19:32:18.000000 nemo_toolkit-1.9.0/nemo_toolkit.egg-info/requires.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       32 2022-06-03 19:32:18.000000 nemo_toolkit-1.9.0/nemo_toolkit.egg-info/top_level.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1325 2022-06-03 19:32:19.039029 nemo_toolkit-1.9.0/setup.cfg
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9442 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/setup.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.031029 nemo_toolkit-1.9.0/tests/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/__init__.py
+-rwxrwxr-x   0 eharper   (1000) eharper   (1000)     4386 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/check_copyright_header.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     8277 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/conftest.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.035029 nemo_toolkit-1.9.0/tests/core/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3917 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/test_config_utils.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    19386 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/test_exp_manager.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    11315 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/test_fileio.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     9537 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/test_neural_types.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    32351 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/core/test_optimizers_schedulers.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    25530 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/test_save_restore.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6123 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/test_serialization.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)    39357 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/core/test_typecheck.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3583 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/manualtest_model_downloads.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.035029 nemo_toolkit-1.9.0/tests/nemo_text_processing/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.035029 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2710 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2697 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2706 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2715 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2710 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2707 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2701 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1784 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_normalization_with_audio.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2368 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2713 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2697 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2713 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2698 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.035029 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2060 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_address.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2802 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3710 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2698 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2708 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1978 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2051 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_math.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2699 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2768 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1754 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_normalization_with_audio.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2726 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2138 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_punctuation.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2056 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_range.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2092 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_roman.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2074 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_serial.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1554 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_special_text.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2744 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2715 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     3576 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2765 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.035029 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      623 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2722 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2709 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2718 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2736 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2004 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2728 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2713 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1730 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_normalization_with_audio.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2719 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2733 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2718 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2731 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2780 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.039029 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1486 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1492 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1483 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1491 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1491 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1481 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_word.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.039029 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/__init__.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.039029 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      972 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1712 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal_normalize_with_audio.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      458 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_date.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1003 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_decimal.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      527 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_electronic.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      788 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_measure.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      567 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_money.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2913 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_ordinal.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      166 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_telephone.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      415 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_time.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)       87 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_whitelist.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      215 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_word.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6216 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/test_ru_inverse_normalization.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     6236 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/test_ru_normalization.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     2083 2022-06-03 16:42:08.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/utils.py
+drwxrwxr-x   0 eharper   (1000) eharper   (1000)        0 2022-06-03 19:32:19.039029 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)      610 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/__init__.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_cardinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_date.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1486 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_decimal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1492 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_electronic.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1489 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_fraction.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_measure.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1483 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_money.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1487 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_ordinal.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1491 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_telephone.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1480 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_time.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1491 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_whitelist.py
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1481 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_word.py
+-rwxrwxr-x   0 eharper   (1000) eharper   (1000)      619 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/py_cprheader.txt
+-rw-rw-r--   0 eharper   (1000) eharper   (1000)     1008 2022-06-03 16:41:58.000000 nemo_toolkit-1.9.0/tests/test_data_dir.py
```

### Comparing `nemo_toolkit-1.8.2/LICENSE` & `nemo_toolkit-1.9.0/LICENSE`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/PKG-INFO` & `nemo_toolkit-1.9.0/PKG-INFO`

 * *Files 8% similar despite different names*

```diff
@@ -1,20 +1,19 @@
 Metadata-Version: 2.1
 Name: nemo_toolkit
-Version: 1.8.2
+Version: 1.9.0
 Summary: NeMo - a toolkit for Conversational AI
 Home-page: https://github.com/nvidia/nemo
 Download-URL: https://github.com/NVIDIA/NeMo/releases
 Author: NVIDIA
 Author-email: nemo-toolkit@nvidia.com
 Maintainer: NVIDIA
 Maintainer-email: nemo-toolkit@nvidia.com
 License: Apache2
 Keywords: deep learning,machine learning,gpu,NLP,NeMo,nvidia,pytorch,torch,tts,speech,language
-Platform: UNKNOWN
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research
 Classifier: Intended Audience :: Information Technology
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Image Recognition
@@ -27,15 +26,15 @@
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Environment :: Console
 Classifier: Natural Language :: English
 Classifier: Operating System :: OS Independent
 Description-Content-Type: text/markdown
 Provides-Extra: test
-Provides-Extra: text_processing
+Provides-Extra: nemo_text_processing
 Provides-Extra: core
 Provides-Extra: common
 Provides-Extra: asr
 Provides-Extra: cv
 Provides-Extra: nlp
 Provides-Extra: tts
 Provides-Extra: all
@@ -46,9 +45,7 @@
 **NeMo Core** provides common APIs all modules and models have to implement.
 
 **NeMo Collections**
 
 * ASR - collection of modules and models for building speech recognition networks
 * TTS - collection of modules and models for building speech synthesis networks
 * NLP - collection of modules and models for building NLP networks
-
-
```

### Comparing `nemo_toolkit-1.8.2/README.rst` & `nemo_toolkit-1.9.0/README.rst`

 * *Files 2% similar despite different names*

```diff
@@ -64,15 +64,15 @@
     * `Text classification <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/text_classification.html>`_
     * `Joint Intent and Slot Classification <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/joint_intent_slot.html>`_    
     * `Question answering <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/question_answering.html>`_
     * `GLUE benchmark <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/glue_benchmark.html>`_
     * `Information retrieval <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/information_retrieval.html>`_
     * `Entity Linking <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/entity_linking.html>`_
     * `Dialogue State Tracking <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/sgd_qa.html>`_   
-    * `Prompt Tuning <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/megatron_finetuning.html#prompt-tuning>`_
+    * `Prompt Tuning <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/prompt_learning.html>`_
     * `NGC collection of pre-trained NLP models. <https://ngc.nvidia.com/catalog/collections/nvidia:nemo_nlp>`_
 * `Speech synthesis (TTS) <https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/tts/intro.html#>`_
     * Spectrogram generation: Tacotron2, GlowTTS, TalkNet, FastPitch, FastSpeech2, Mixer-TTS, Mixer-TTS-X
     * Vocoders: WaveGlow, SqueezeWave, UniGlow, MelGAN, HiFiGAN, UnivNet
     * End-to-end speech generation: FastPitch_HifiGan_E2E, FastSpeech2_HifiGan_E2E
     * `NGC collection of pre-trained TTS models. <https://ngc.nvidia.com/catalog/collections/nvidia:nemo_tts>`_
 * `Tools <https://github.com/NVIDIA/NeMo/tree/main/tools>`_
@@ -198,33 +198,33 @@
 ~~~~~~~~~~~~
 Megatron GPT training requires NVIDIA Apex to be installed.
 
 .. code-block:: bash
 
     git clone https://github.com/NVIDIA/apex
     cd apex
-    git checkout 8cc91ceaa8faa64451d90e11b8ad4732393b32aa
+    git checkout 9263bc8c6c16555bd55dd759f1a1b8c0cd187d10
     pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" --global-option="--fast_layer_norm" ./
 
 Docker containers:
 ~~~~~~~~~~~~~~~~~~
 To build a nemo container with Dockerfile from a branch, please run 
 
 .. code-block:: bash
 
     DOCKER_BUILDKIT=1 docker build -f Dockerfile -t nemo:latest .
 
 
-If you chose to work with main branch, we recommend using NVIDIA's PyTorch container version 22.03-py3 and then installing from GitHub.
+If you chose to work with main branch, we recommend using NVIDIA's PyTorch container version 22.04-py3 and then installing from GitHub.
 
 .. code-block:: bash
 
     docker run --gpus all -it --rm -v <nemo_github_folder>:/NeMo --shm-size=8g \
     -p 8888:8888 -p 6006:6006 --ulimit memlock=-1 --ulimit \
-    stack=67108864 --device=/dev/snd nvcr.io/nvidia/pytorch:22.03-py3
+    stack=67108864 --device=/dev/snd nvcr.io/nvidia/pytorch:22.04-py3
 
 Examples
 --------
 
 Many examples can be found under `"Examples" <https://github.com/NVIDIA/NeMo/tree/stable/examples>`_ folder.
```

### Comparing `nemo_toolkit-1.8.2/nemo/__init__.py` & `nemo_toolkit-1.9.0/nemo/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_ctm_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_ctm_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_label.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_label.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 import os
 from typing import Dict, List, Optional, Union
 
 import braceexpand
 import torch
 import webdataset as wd
 
+from nemo.collections.asr.data.audio_to_text import expand_audio_filepaths
 from nemo.collections.asr.parts.preprocessing.segment import available_formats as valid_sf_formats
 from nemo.collections.common.parts.preprocessing import collections
 from nemo.core.classes import Dataset, IterableDataset
 from nemo.core.neural_types import AudioSignal, LabelsType, LengthsType, NeuralType, RegressionValuesType
 from nemo.utils import logging
 
 # List of valid file formats (prioritized by order of importance)
@@ -528,59 +529,20 @@
         for label_id, label in enumerate(self.labels):
             self.label2id[label] = label_id
             self.id2label[label_id] = label
 
         for idx in range(len(self.labels[:5])):
             logging.debug(" label id {} and its mapped label {}".format(idx, self.id2label[idx]))
 
-        valid_shard_strategies = ['scatter', 'replicate']
-        if shard_strategy not in valid_shard_strategies:
-            raise ValueError(f"`shard_strategy` must be one of {valid_shard_strategies}")
-
-        if isinstance(audio_tar_filepaths, str):
-            # Replace '(' and '[' with '{'
-            brace_keys_open = ['(', '[', '<', '_OP_']
-            for bkey in brace_keys_open:
-                if bkey in audio_tar_filepaths:
-                    audio_tar_filepaths = audio_tar_filepaths.replace(bkey, "{")
-
-            # Replace ')' and ']' with '}'
-            brace_keys_close = [')', ']', '>', '_CL_']
-            for bkey in brace_keys_close:
-                if bkey in audio_tar_filepaths:
-                    audio_tar_filepaths = audio_tar_filepaths.replace(bkey, "}")
-
-        # Check for distributed and partition shards accordingly
-        if world_size > 1:
-            if isinstance(audio_tar_filepaths, str):
-                # Brace expand
-                audio_tar_filepaths = list(braceexpand.braceexpand(audio_tar_filepaths))
-
-            if shard_strategy == 'scatter':
-                logging.info("All tarred dataset shards will be scattered evenly across all nodes.")
-
-                if len(audio_tar_filepaths) % world_size != 0:
-                    logging.warning(
-                        f"Number of shards in tarred dataset ({len(audio_tar_filepaths)}) is not divisible "
-                        f"by number of distributed workers ({world_size})."
-                    )
-
-                begin_idx = (len(audio_tar_filepaths) // world_size) * global_rank
-                end_idx = begin_idx + (len(audio_tar_filepaths) // world_size)
-                audio_tar_filepaths = audio_tar_filepaths[begin_idx:end_idx]
-                logging.info(
-                    "Partitioning tarred dataset: process (%d) taking shards [%d, %d)", global_rank, begin_idx, end_idx
-                )
-
-            elif shard_strategy == 'replicate':
-                logging.info("All tarred dataset shards will be replicated across all nodes.")
-
-            else:
-                raise ValueError(f"Invalid shard strategy ! Allowed values are : {valid_shard_strategies}")
-
+        audio_tar_filepaths = expand_audio_filepaths(
+            audio_tar_filepaths=audio_tar_filepaths,
+            shard_strategy=shard_strategy,
+            world_size=world_size,
+            global_rank=global_rank,
+        )
         # Put together WebDataset
         self._dataset = wd.WebDataset(urls=audio_tar_filepaths, nodesplitter=None)
 
         if shuffle_n > 0:
             self._dataset = self._dataset.shuffle(shuffle_n)
         else:
             logging.info("WebDataset will not shuffle files within the tar files.")
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_label_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_label_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_text_dali.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_text_dali.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/audio_to_text_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_text_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/feature_to_label.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/feature_to_label.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/data/feature_to_label_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/feature_to_label_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/losses/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/losses/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/losses/angularloss.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/losses/angularloss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/losses/ctc.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/losses/ctc.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/losses/lattice_losses.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/losses/lattice_losses.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/losses/pt_losses/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/losses/pt_losses/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/losses/pt_losses/contrastive.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/losses/pt_losses/contrastive.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/losses/rnnt.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/losses/rnnt.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/metrics/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/metrics/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/metrics/rnnt_wer.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/metrics/rnnt_wer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/metrics/rnnt_wer_bpe.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/metrics/rnnt_wer_bpe.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/metrics/wer.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/metrics/wer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/metrics/wer_bpe.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/metrics/wer_bpe.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/asr_model.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/asr_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/classification_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/classification_models.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/clustering_diarizer.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/clustering_diarizer.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,14 @@
 
 import json
 import os
 import pickle as pkl
 import shutil
 import tarfile
 import tempfile
-from collections import defaultdict
 from copy import deepcopy
 from typing import List, Optional
 
 import torch
 from omegaconf import DictConfig, OmegaConf
 from pytorch_lightning.utilities import rank_zero_only
 from tqdm import tqdm
@@ -321,36 +320,39 @@
     def _extract_embeddings(self, manifest_file: str):
         """
         This method extracts speaker embeddings from segments passed through manifest_file
         Optionally you may save the intermediate speaker embeddings for debugging or any use. 
         """
         logging.info("Extracting embeddings for Diarization")
         self._setup_spkr_test_data(manifest_file)
-        self.embeddings = defaultdict(list)
+        self.embeddings = {}
         self._speaker_model = self._speaker_model.to(self._device)
         self._speaker_model.eval()
         self.time_stamps = {}
 
-        all_embs = []
+        all_embs = torch.empty([0])
         for test_batch in tqdm(self._speaker_model.test_dataloader()):
             test_batch = [x.to(self._device) for x in test_batch]
             audio_signal, audio_signal_len, labels, slices = test_batch
             with autocast():
                 _, embs = self._speaker_model.forward(input_signal=audio_signal, input_signal_length=audio_signal_len)
                 emb_shape = embs.shape[-1]
                 embs = embs.view(-1, emb_shape)
-                all_embs.extend(embs.cpu().detach().numpy())
+                all_embs = torch.cat((all_embs, embs.cpu().detach()), dim=0)
             del test_batch
 
         with open(manifest_file, 'r', encoding='utf-8') as manifest:
             for i, line in enumerate(manifest.readlines()):
                 line = line.strip()
                 dic = json.loads(line)
                 uniq_name = get_uniqname_from_filepath(dic['audio_filepath'])
-                self.embeddings[uniq_name].extend([all_embs[i]])
+                if uniq_name in self.embeddings:
+                    self.embeddings[uniq_name] = torch.cat((self.embeddings[uniq_name], all_embs[i].view(1, -1)))
+                else:
+                    self.embeddings[uniq_name] = all_embs[i].view(1, -1)
                 if uniq_name not in self.time_stamps:
                     self.time_stamps[uniq_name] = []
                 start = dic['offset']
                 end = start + dic['duration']
                 stamp = '{:.3f} {:.3f} '.format(start, end)
                 self.time_stamps[uniq_name].append(stamp)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/aligner_config.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/aligner_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/asr_models_config.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/asr_models_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/classification_models_config.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/classification_models_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/k2_sequence_models_config.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/k2_sequence_models_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/matchboxnet_config.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/matchboxnet_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/configs/quartznet_config.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/configs/quartznet_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/ctc_bpe_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/ctc_bpe_models.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -30,197 +30,14 @@
 
 __all__ = ['EncDecCTCModelBPE']
 
 
 class EncDecCTCModelBPE(EncDecCTCModel, ASRBPEMixin):
     """Encoder decoder CTC-based models with Byte Pair Encoding."""
 
-    @classmethod
-    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
-        """
-        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
-
-        Returns:
-            List of available pre-trained models.
-        """
-        results = []
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_citrinet_256",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256/versions/1.0.0rc1/files/stt_en_citrinet_256.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_citrinet_512",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512/versions/1.0.0rc1/files/stt_en_citrinet_512.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_citrinet_1024",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024/versions/1.0.0rc1/files/stt_en_citrinet_1024.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_citrinet_256_gamma_0_25",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_256_gamma_0_25.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_citrinet_512_gamma_0_25",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_512_gamma_0_25.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_citrinet_1024_gamma_0_25",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_1024_gamma_0_25.nemo",
-        )
-
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_es_citrinet_512",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_citrinet_512",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_citrinet_512/versions/1.0.0/files/stt_es_citrinet_512.nemo",
-        )
-
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_de_citrinet_1024",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_citrinet_1024",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_citrinet_1024/versions/1.3.2/files/stt_de_citrinet_1024.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_fr_citrinet_1024_gamma_0_25",
-            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_citrinet_1024_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_citrinet_1024_gamma_0_25/versions/1.5/files/stt_fr_citrinet_1024_gamma_0_25.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_fr_no_hyphen_citrinet_1024_gamma_0_25",
-            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_citrinet_1024_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_citrinet_1024_gamma_0_25/versions/1.5/files/stt_fr_no_hyphen_citrinet_1024_gamma_0_25.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_es_citrinet_1024_gamma_0_25",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_citrinet_1024_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_citrinet_1024_gamma_0_25/versions/1.8.0/files/stt_es_citrinet_1024_gamma_0_25.nemo",
-        )
-
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_conformer_ctc_small",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small/versions/1.6.0/files/stt_en_conformer_ctc_small.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_conformer_ctc_medium",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium/versions/1.6.0/files/stt_en_conformer_ctc_medium.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_conformer_ctc_large",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large/versions/1.6.0/files/stt_en_conformer_ctc_large.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_conformer_ctc_small_ls",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small_ls",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small_ls/versions/1.0.0/files/stt_en_conformer_ctc_small_ls.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_conformer_ctc_medium_ls",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium_ls",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium_ls/versions/1.0.0/files/stt_en_conformer_ctc_medium_ls.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_conformer_ctc_large_ls",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large_ls",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large_ls/versions/1.0.0/files/stt_en_conformer_ctc_large_ls.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_fr_conformer_ctc_large",
-            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_conformer_ctc_large",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_conformer_ctc_large/versions/1.5.1/files/stt_fr_conformer_ctc_large.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_fr_no_hyphen_conformer_ctc_large",
-            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_conformer_ctc_large",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_conformer_ctc_large/versions/1.5.1/files/stt_fr_no_hyphen_conformer_ctc_large.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_de_conformer_ctc_large",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_conformer_ctc_large",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_conformer_ctc_large/versions/1.5.0/files/stt_de_conformer_ctc_large.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_es_conformer_ctc_large",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_conformer_ctc_large",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_conformer_ctc_large/versions/1.8.0/files/stt_es_conformer_ctc_large.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_hi_conformer_ctc_medium",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_hi_conformer_ctc_medium",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_hi_conformer_ctc_medium/versions/1.6.0/files/stt_hi_conformer_ctc_medium.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_mr_conformer_ctc_medium",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_mr_conformer_ctc_medium",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_mr_conformer_ctc_medium/versions/1.6.0/files/stt_mr_conformer_ctc_medium.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_enes_conformer_ctc_large",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_enes_conformer_ctc_large",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_enes_conformer_ctc_large/versions/1.0.0/files/stt_enes_conformer_ctc_large.nemo",
-        )
-        results.append(model)
-
-        return results
-
     def __init__(self, cfg: DictConfig, trainer=None):
         # Convert to Hydra 1.0 compatible DictConfig
         cfg = model_utils.convert_model_config_to_dict_config(cfg)
         cfg = model_utils.maybe_update_config_version(cfg)
 
         if 'tokenizer' not in cfg:
             raise ValueError("`cfg` must have `tokenizer` config to create a tokenizer !")
@@ -450,7 +267,190 @@
 
         # Update config
         OmegaConf.set_struct(self._cfg.decoder, False)
         self._cfg.decoder = decoder_config
         OmegaConf.set_struct(self._cfg.decoder, True)
 
         logging.info(f"Changed tokenizer to {self.decoder.vocabulary} vocabulary.")
+
+    @classmethod
+    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
+        """
+        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
+
+        Returns:
+            List of available pre-trained models.
+        """
+        results = []
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_citrinet_256",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256/versions/1.0.0rc1/files/stt_en_citrinet_256.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_citrinet_512",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512/versions/1.0.0rc1/files/stt_en_citrinet_512.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_citrinet_1024",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024/versions/1.0.0rc1/files/stt_en_citrinet_1024.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_citrinet_256_gamma_0_25",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_256_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_256_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_256_gamma_0_25.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_citrinet_512_gamma_0_25",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_512_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_512_gamma_0_25.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_citrinet_1024_gamma_0_25",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_en_citrinet_1024_gamma_0_25.nemo",
+        )
+
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_es_citrinet_512",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_citrinet_512",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_citrinet_512/versions/1.0.0/files/stt_es_citrinet_512.nemo",
+        )
+
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_de_citrinet_1024",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_citrinet_1024",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_citrinet_1024/versions/1.3.2/files/stt_de_citrinet_1024.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_fr_citrinet_1024_gamma_0_25",
+            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_citrinet_1024_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_citrinet_1024_gamma_0_25/versions/1.5/files/stt_fr_citrinet_1024_gamma_0_25.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_fr_no_hyphen_citrinet_1024_gamma_0_25",
+            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_citrinet_1024_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_citrinet_1024_gamma_0_25/versions/1.5/files/stt_fr_no_hyphen_citrinet_1024_gamma_0_25.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_es_citrinet_1024_gamma_0_25",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_citrinet_1024_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_citrinet_1024_gamma_0_25/versions/1.8.0/files/stt_es_citrinet_1024_gamma_0_25.nemo",
+        )
+
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_conformer_ctc_small",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small/versions/1.6.0/files/stt_en_conformer_ctc_small.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_conformer_ctc_medium",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium/versions/1.6.0/files/stt_en_conformer_ctc_medium.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_conformer_ctc_large",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large/versions/1.6.0/files/stt_en_conformer_ctc_large.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_conformer_ctc_small_ls",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_small_ls",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_small_ls/versions/1.0.0/files/stt_en_conformer_ctc_small_ls.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_conformer_ctc_medium_ls",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_medium_ls",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_medium_ls/versions/1.0.0/files/stt_en_conformer_ctc_medium_ls.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_conformer_ctc_large_ls",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_conformer_ctc_large_ls",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_ctc_large_ls/versions/1.0.0/files/stt_en_conformer_ctc_large_ls.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_fr_conformer_ctc_large",
+            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_conformer_ctc_large",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_conformer_ctc_large/versions/1.5.1/files/stt_fr_conformer_ctc_large.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_fr_no_hyphen_conformer_ctc_large",
+            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_fr_conformer_ctc_large",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_conformer_ctc_large/versions/1.5.1/files/stt_fr_no_hyphen_conformer_ctc_large.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_de_conformer_ctc_large",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_conformer_ctc_large",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_conformer_ctc_large/versions/1.5.0/files/stt_de_conformer_ctc_large.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_es_conformer_ctc_large",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_conformer_ctc_large",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_conformer_ctc_large/versions/1.8.0/files/stt_es_conformer_ctc_large.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_hi_conformer_ctc_medium",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_hi_conformer_ctc_medium",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_hi_conformer_ctc_medium/versions/1.6.0/files/stt_hi_conformer_ctc_medium.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_mr_conformer_ctc_medium",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_mr_conformer_ctc_medium",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_mr_conformer_ctc_medium/versions/1.6.0/files/stt_mr_conformer_ctc_medium.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_enes_conformer_ctc_large",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_enes_conformer_ctc_large",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_enes_conformer_ctc_large/versions/1.0.0/files/stt_enes_conformer_ctc_large.nemo",
+        )
+        results.append(model)
+
+        return results
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/ctc_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/ctc_models.py`

 * *Files 4% similar despite different names*

```diff
@@ -36,132 +36,14 @@
 
 __all__ = ['EncDecCTCModel']
 
 
 class EncDecCTCModel(ASRModel, ExportableEncDecModel, ASRModuleMixin):
     """Base class for encoder decoder CTC-based models."""
 
-    @classmethod
-    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
-        """
-        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
-
-        Returns:
-            List of available pre-trained models.
-        """
-        results = []
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="QuartzNet15x5Base-En",
-            description="QuartzNet15x5 model trained on six datasets: LibriSpeech, Mozilla Common Voice (validated clips from en_1488h_2019-12-10), WSJ, Fisher, Switchboard, and NSC Singapore English. It was trained with Apex/Amp optimization level O1 for 600 epochs. The model achieves a WER of 3.79% on LibriSpeech dev-clean, and a WER of 10.05% on dev-other. Please visit https://ngc.nvidia.com/catalog/models/nvidia:nemospeechmodels for further details.",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/QuartzNet15x5Base-En.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_quartznet15x5/versions/1.0.0rc1/files/stt_en_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_en_jasper10x5dr",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_jasper10x5dr",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_jasper10x5dr/versions/1.0.0rc1/files/stt_en_jasper10x5dr.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_ca_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_ca_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_ca_quartznet15x5/versions/1.0.0rc1/files/stt_ca_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_it_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_it_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_it_quartznet15x5/versions/1.0.0rc1/files/stt_it_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_fr_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_fr_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_quartznet15x5/versions/1.0.0rc1/files/stt_fr_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_es_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_quartznet15x5/versions/1.0.0rc1/files/stt_es_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_de_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_quartznet15x5/versions/1.0.0rc1/files/stt_de_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_pl_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_pl_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_pl_quartznet15x5/versions/1.0.0rc1/files/stt_pl_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_ru_quartznet15x5",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_ru_quartznet15x5",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_ru_quartznet15x5/versions/1.0.0rc1/files/stt_ru_quartznet15x5.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_zh_citrinet_512",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_512",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_512/versions/1.0.0rc1/files/stt_zh_citrinet_512.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_zh_citrinet_1024_gamma_0_25",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_1024_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_zh_citrinet_1024_gamma_0_25.nemo",
-        )
-
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_zh_citrinet_1024_gamma_0_25",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_1024_gamma_0_25",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_zh_citrinet_1024_gamma_0_25.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="stt_zh_conformer_transducer_large",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_conformer_transducer_large",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_conformer_transducer_large/versions/1.8.0/files/stt_zh_conformer_transducer_large.nemo",
-        )
-        results.append(model)
-
-        model = PretrainedModelInfo(
-            pretrained_model_name="asr_talknet_aligner",
-            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:asr_talknet_aligner",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/asr_talknet_aligner/versions/1.0.0rc1/files/qn5x5_libri_tts_phonemes.nemo",
-        )
-        results.append(model)
-
-        return results
-
     def __init__(self, cfg: DictConfig, trainer: Trainer = None):
         # Get global rank and total number of GPU workers for IterableDataset partitioning, if applicable
         # Global_rank and local_rank is set by LightningModule in Lightning 1.2.0
         self.world_size = 1
         if trainer is not None:
             self.world_size = trainer.world_size
 
@@ -207,14 +89,17 @@
             dist_sync_on_step=True,
             log_prediction=self._cfg.get("log_prediction", False),
         )
 
         # Setup optional Optimization flags
         self.setup_optimization_flags()
 
+        # Adapter modules setup (from ASRAdapterModelMixin)
+        self.setup_adapters()
+
     @torch.no_grad()
     def transcribe(
         self,
         paths2audio_files: List[str],
         batch_size: int = 4,
         logprobs: bool = False,
         return_hypotheses: bool = False,
@@ -718,21 +603,117 @@
             'num_workers': config.get('num_workers', min(batch_size, os.cpu_count() - 1)),
             'pin_memory': True,
         }
 
         temporary_datalayer = self._setup_dataloader_from_config(config=DictConfig(dl_config))
         return temporary_datalayer
 
-    def load_state_dict(self, state_dict, strict=True):
-        """Stopgap measure to keep old checkpoints working before full model deprecation.
+    @classmethod
+    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
+        """
+        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
 
-        This override fiddles with the state_dict in order to keep functionality from old checkpoints after the
-        switch from torch_stft. It will be removed when the TalkNet Aligner model is deprecated.
+        Returns:
+            List of available pre-trained models.
         """
-        # TODO: Remove this function once TalkNet Aligner is deprecated in 1.9.0
-        if 'preprocessor.featurizer.stft.forward_basis' in state_dict:
-            logging.warning("Loading old checkpoint, defaulting to hann window.")
-            window_dim = state_dict['preprocessor.featurizer.stft.forward_basis'].shape[-1]
-            state_dict['preprocessor.featurizer.window'] = torch.hann_window(window_dim)
-            del state_dict['preprocessor.featurizer.stft.forward_basis']
-            del state_dict['preprocessor.featurizer.stft.inverse_basis']
-        super().load_state_dict(state_dict, strict=strict)
+        results = []
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="QuartzNet15x5Base-En",
+            description="QuartzNet15x5 model trained on six datasets: LibriSpeech, Mozilla Common Voice (validated clips from en_1488h_2019-12-10), WSJ, Fisher, Switchboard, and NSC Singapore English. It was trained with Apex/Amp optimization level O1 for 600 epochs. The model achieves a WER of 3.79% on LibriSpeech dev-clean, and a WER of 10.05% on dev-other. Please visit https://ngc.nvidia.com/catalog/models/nvidia:nemospeechmodels for further details.",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/QuartzNet15x5Base-En.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_quartznet15x5/versions/1.0.0rc1/files/stt_en_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_en_jasper10x5dr",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_jasper10x5dr",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_jasper10x5dr/versions/1.0.0rc1/files/stt_en_jasper10x5dr.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_ca_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_ca_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_ca_quartznet15x5/versions/1.0.0rc1/files/stt_ca_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_it_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_it_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_it_quartznet15x5/versions/1.0.0rc1/files/stt_it_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_fr_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_fr_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_fr_quartznet15x5/versions/1.0.0rc1/files/stt_fr_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_es_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_es_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_es_quartznet15x5/versions/1.0.0rc1/files/stt_es_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_de_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_de_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_de_quartznet15x5/versions/1.0.0rc1/files/stt_de_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_pl_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_pl_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_pl_quartznet15x5/versions/1.0.0rc1/files/stt_pl_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_ru_quartznet15x5",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_ru_quartznet15x5",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_ru_quartznet15x5/versions/1.0.0rc1/files/stt_ru_quartznet15x5.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_zh_citrinet_512",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_512",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_512/versions/1.0.0rc1/files/stt_zh_citrinet_512.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_zh_citrinet_1024_gamma_0_25",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_1024_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_zh_citrinet_1024_gamma_0_25.nemo",
+        )
+
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_zh_citrinet_1024_gamma_0_25",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_zh_citrinet_1024_gamma_0_25",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_citrinet_1024_gamma_0_25/versions/1.0.0/files/stt_zh_citrinet_1024_gamma_0_25.nemo",
+        )
+        results.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="asr_talknet_aligner",
+            description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:asr_talknet_aligner",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/asr_talknet_aligner/versions/1.0.0rc1/files/qn5x5_libri_tts_phonemes.nemo",
+        )
+        results.append(model)
+
+        return results
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/k2_aligner_model.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/k2_aligner_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/k2_sequence_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/k2_sequence_models.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/label_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/label_models.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import copy
 import itertools
+from math import ceil
 from typing import Dict, List, Optional, Union
 
 import librosa
 import numpy as np
 import torch
 from omegaconf import DictConfig
 from omegaconf.omegaconf import open_dict
@@ -102,14 +103,18 @@
             self.loss = AngularSoftmaxLoss(scale=scale, margin=margin)
         else:
             logging.info("loss is Softmax-CrossEntropy")
             self.loss = CELoss()
         self.task = None
         self._accuracy = TopKClassificationAccuracy(top_k=[1])
         self.labels = None
+        if hasattr(self._cfg, 'spec_augment') and self._cfg.spec_augment is not None:
+            self.spec_augmentation = EncDecSpeakerLabelModel.from_config_dict(self._cfg.spec_augment)
+        else:
+            self.spec_augmentation = None
 
     @staticmethod
     def extract_labels(data_layer_config):
         labels = set()
         manifest_filepath = data_layer_config.get('manifest_filepath', None)
         if manifest_filepath is None:
             logging.warning("No manifest_filepath was provided, no labels got extracted!")
@@ -117,15 +122,15 @@
         manifest_filepaths = convert_to_config_list(data_layer_config['manifest_filepath'])
 
         for manifest_filepath in itertools.chain.from_iterable(manifest_filepaths):
             collection = ASRSpeechLabel(
                 manifests_files=manifest_filepath,
                 min_duration=data_layer_config.get("min_duration", None),
                 max_duration=data_layer_config.get("max_duration", None),
-                index_by_file_id=False,
+                index_by_file_id=True,
             )
             labels.update(collection.uniq_labels)
         labels = list(sorted(labels))
         logging.warning(f"Total number of {len(labels)} found in all the manifest files.")
         return labels
 
     def __setup_dataloader_from_config(self, config: Optional[Dict]):
@@ -190,14 +195,31 @@
 
     def setup_training_data(self, train_data_layer_config: Optional[Union[DictConfig, Dict]]):
         self.labels = self.extract_labels(train_data_layer_config)
         train_data_layer_config['labels'] = self.labels
         if 'shuffle' not in train_data_layer_config:
             train_data_layer_config['shuffle'] = True
         self._train_dl = self.__setup_dataloader_from_config(config=train_data_layer_config)
+        # Need to set this because if using an IterableDataset, the length of the dataloader is the total number
+        # of samples rather than the number of batches, and this messes up the tqdm progress bar.
+        # So we set the number of steps manually (to the correct number) to fix this.
+        if 'is_tarred' in train_data_layer_config and train_data_layer_config['is_tarred']:
+            # We also need to check if limit_train_batches is already set.
+            # If it's an int, we assume that the user has set it to something sane, i.e. <= # training batches,
+            # and don't change it. Otherwise, adjust batches accordingly if it's a float (including 1.0).
+            if self._trainer is not None and isinstance(self._trainer.limit_train_batches, float):
+                self._trainer.limit_train_batches = int(
+                    self._trainer.limit_train_batches
+                    * ceil((len(self._train_dl.dataset) / self.world_size) / train_data_layer_config['batch_size'])
+                )
+            elif self._trainer is None:
+                logging.warning(
+                    "Model Trainer was not set before constructing the dataset, incorrect number of "
+                    "training batches will be used. Please set the trainer and rebuild the dataset."
+                )
 
     def setup_validation_data(self, val_data_layer_config: Optional[Union[DictConfig, Dict]]):
         val_data_layer_config['labels'] = self.labels
         self._validation_dl = self.__setup_dataloader_from_config(config=val_data_layer_config)
 
     def setup_test_data(self, test_data_layer_params: Optional[Union[DictConfig, Dict]]):
         if hasattr(self, 'dataset'):
@@ -225,25 +247,28 @@
     @property
     def output_types(self) -> Optional[Dict[str, NeuralType]]:
         return {
             "logits": NeuralType(('B', 'D'), LogitsType()),
             "embs": NeuralType(('B', 'D'), AcousticEncodedRepresentation()),
         }
 
-    @typecheck()
     def forward_for_export(self, processed_signal, processed_signal_len):
         encoded, length = self.encoder(audio_signal=processed_signal, length=processed_signal_len)
         logits, embs = self.decoder(encoder_output=encoded, length=length)
         return logits, embs
 
     @typecheck()
     def forward(self, input_signal, input_signal_length):
         processed_signal, processed_signal_len = self.preprocessor(
             input_signal=input_signal, length=input_signal_length,
         )
+
+        if self.spec_augmentation is not None and self.training:
+            processed_signal = self.spec_augmentation(input_spec=processed_signal, length=processed_signal_len)
+
         encoded, length = self.encoder(audio_signal=processed_signal, length=processed_signal_len)
         logits, embs = self.decoder(encoder_output=encoded, length=length)
         return logits, embs
 
     # PTL-specific methods
     def training_step(self, batch, batch_idx):
         audio_signal, audio_signal_len, labels, _ = batch
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/rnnt_bpe_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/rnnt_bpe_models.py`

 * *Files 0% similar despite different names*

```diff
@@ -56,15 +56,15 @@
             location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_512/versions/1.6.0/files/stt_en_contextnet_512.nemo",
         )
         results.append(model)
 
         model = PretrainedModelInfo(
             pretrained_model_name="stt_en_contextnet_1024",
             description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_1024",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_1024/versions/1.6.0/files/stt_en_contextnet_1024.nemo",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_1024/versions/1.9.0/files/stt_en_contextnet_1024.nemo",
         )
         results.append(model)
 
         model = PretrainedModelInfo(
             pretrained_model_name="stt_en_contextnet_256_mls",
             description="For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_contextnet_256_mls",
             location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_contextnet_256_mls/versions/1.0.0/files/stt_en_contextnet_256_mls.nemo",
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/rnnt_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/rnnt_models.py`

 * *Files 1% similar despite different names*

```diff
@@ -38,25 +38,14 @@
 from nemo.utils import logging
 from nemo.utils.export_utils import augment_filename
 
 
 class EncDecRNNTModel(ASRModel, ASRModuleMixin, Exportable):
     """Base class for encoder decoder RNNT-based models."""
 
-    @classmethod
-    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
-        """
-        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
-
-        Returns:
-            List of available pre-trained models.
-        """
-        result = []
-        return result
-
     def __init__(self, cfg: DictConfig, trainer: Trainer = None):
         # Get global rank and total number of GPU workers for IterableDataset partitioning, if applicable
         # Global_rank and local_rank is set by LightningModule in Lightning 1.2.0
         self.world_size = 1
         if trainer is not None:
             self.world_size = trainer.world_size
 
@@ -113,19 +102,23 @@
         # Setup fused Joint step if flag is set
         if self.joint.fuse_loss_wer or (
             self.decoding.joint_fused_batch_size is not None and self.decoding.joint_fused_batch_size > 0
         ):
             self.joint.set_loss(self.loss)
             self.joint.set_wer(self.wer)
 
+        # Setup optimization normalization (if provided in config)
         self.setup_optim_normalization()
 
         # Setup optional Optimization flags
         self.setup_optimization_flags()
 
+        # Setup encoder adapters (from ASRAdapterModelMixin)
+        self.setup_adapters()
+
     def setup_optim_normalization(self):
         """
         Helper method to setup normalization of certain parts of the model prior to the optimization step.
 
         Supported pre-optimization normalizations are as follows:
 
         .. code-block:: yaml
@@ -933,7 +926,26 @@
         decoder_exp, decoder_descr = decoder_joint.export(
             augment_filename(output, 'Decoder-Joint'),
             # TODO: propagate from export()
             input_example=None,
             **kwargs,
         )
         return encoder_exp + decoder_exp, encoder_descr + decoder_descr
+
+    @classmethod
+    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
+        """
+        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
+
+        Returns:
+            List of available pre-trained models.
+        """
+        results = []
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="stt_zh_conformer_transducer_large",
+            description="For details about this model, please visit https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_zh_conformer_transducer_large",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_zh_conformer_transducer_large/versions/1.8.0/files/stt_zh_conformer_transducer_large.nemo",
+        )
+        results.append(model)
+
+        return results
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/models/ssl_models.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/models/ssl_models.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,21 +19,22 @@
 from pytorch_lightning import Trainer
 
 from nemo.collections.asr.data import audio_to_text_dataset
 from nemo.collections.asr.parts.mixins import ASRModuleMixin
 from nemo.collections.asr.parts.preprocessing.perturb import process_augmentations
 from nemo.core.classes import ModelPT
 from nemo.core.classes.common import PretrainedModelInfo, typecheck
+from nemo.core.classes.mixins import AccessMixin
 from nemo.core.neural_types import AudioSignal, LengthsType, NeuralType, SpectrogramType, VoidType
 from nemo.utils import logging
 
 __all__ = ['SpeechEncDecSelfSupervisedModel']
 
 
-class SpeechEncDecSelfSupervisedModel(ModelPT, ASRModuleMixin):
+class SpeechEncDecSelfSupervisedModel(ModelPT, ASRModuleMixin, AccessMixin):
     """Base class for encoder-decoder models used for self-supervised encoder pre-training"""
 
     @classmethod
     def list_available_models(cls) -> Optional[PretrainedModelInfo]:
         """
         This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
 
@@ -78,14 +79,17 @@
 
         # Feature penalty for preprocessor encodings (for Wav2Vec training)
         if "feature_penalty" in self._cfg:
             self.feat_pen, self.pen_factor = 0.0, self._cfg.feature_penalty
         else:
             self.feat_pen, self.pen_factor = None, None
 
+        if "access" in self._cfg:
+            set_access_cfg(self._cfg.access)
+
     def _setup_dataloader_from_config(self, config: Optional[Dict]):
         if 'augmentor' in config:
             augmentor = process_augmentations(config['augmentor'])
         else:
             augmentor = None
 
         # Automatically inject args from model config to dataloader config
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,20 +16,21 @@
     AudioToMelSpectrogramPreprocessor,
     AudioToMFCCPreprocessor,
     CropOrPadSpectrogramAugmentation,
     MaskedPatchAugmentation,
     SpectrogramAugmentation,
 )
 from nemo.collections.asr.modules.beam_search_decoder import BeamSearchDecoderWithLM
-from nemo.collections.asr.modules.conformer_encoder import ConformerEncoder
+from nemo.collections.asr.modules.conformer_encoder import ConformerEncoder, ConformerEncoderAdapter
 from nemo.collections.asr.modules.conv_asr import (
     ConvASRDecoder,
     ConvASRDecoderClassification,
     ConvASRDecoderReconstruction,
     ConvASREncoder,
+    ConvASREncoderAdapter,
     ECAPAEncoder,
     ParallelConvASREncoder,
     SpeakerDecoder,
 )
 from nemo.collections.asr.modules.graph_decoder import ViterbiDecoderWithGraph
 from nemo.collections.asr.modules.lstm_decoder import LSTMDecoder
 from nemo.collections.asr.modules.rnn_encoder import RNNEncoder
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/audio_preprocessing.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/audio_preprocessing.py`

 * *Files 2% similar despite different names*

```diff
@@ -142,32 +142,27 @@
                 Defaults to 1e-5
             pad_to (int): Ensures that the output size of the time dimension is
                 a multiple of pad_to.
                 Defaults to 16
             frame_splicing (int): Defaults to 1
             exact_pad (bool): If True, sets stft center to False and adds padding, such that num_frames = audio_length
                 // hop_length. Defaults to False.
-            stft_exact_pad (bool): If True, uses pytorch_stft and convolutions with
-                padding such that num_frames = num_samples / hop_length. If False,
-                stft_conv will be used to determine how stft will be performed.
-                Defaults to False. TODO:This feature is deprecated and will be removed in 1.1.0
-            stft_conv (bool): If True, uses pytorch_stft and convolutions. If
-                False, uses torch.stft. TODO:This feature is deprecated and will be removed in 1.1.0
-                Defaults to False
             pad_value (float): The value that shorter mels are padded with.
                 Defaults to 0
             mag_power (float): The power that the linear spectrogram is raised to
                 prior to multiplication with mel basis.
                 Defaults to 2 for a power spec
             rng : Random number generator
             nb_augmentation_prob (float) : Probability with which narrowband augmentation would be applied to
                 samples in the batch.
                 Defaults to 0.0
             nb_max_freq (int) : Frequency above which all frequencies will be masked for narrowband augmentation.
                 Defaults to 4000
+            stft_exact_pad: Deprecated argument, kept for compatibility with older checkpoints.
+            stft_conv: Deprecated argument, kept for compatibility with older checkpoints.
         """
 
     def save_to(self, save_path: str):
         pass
 
     @classmethod
     def restore_from(cls, restore_path: str):
@@ -216,21 +211,21 @@
         log=True,
         log_zero_guard_type="add",
         log_zero_guard_value=2 ** -24,
         dither=1e-5,
         pad_to=16,
         frame_splicing=1,
         exact_pad=False,
-        stft_exact_pad=False,
-        stft_conv=False,
         pad_value=0,
         mag_power=2.0,
         rng=None,
         nb_augmentation_prob=0.0,
         nb_max_freq=4000,
+        stft_exact_pad=False,  # Deprecated arguments; kept for config compatibility
+        stft_conv=False,  # Deprecated arguments; kept for config compatibility
     ):
         super().__init__(n_window_size, n_window_stride)
 
         self._sample_rate = sample_rate
         if window_size and n_window_size:
             raise ValueError(f"{self} received both window_size and " f"n_window_size. Only one should be specified.")
         if window_stride and n_window_stride:
@@ -256,21 +251,21 @@
             log=log,
             log_zero_guard_type=log_zero_guard_type,
             log_zero_guard_value=log_zero_guard_value,
             dither=dither,
             pad_to=pad_to,
             frame_splicing=frame_splicing,
             exact_pad=exact_pad,
-            stft_exact_pad=stft_exact_pad,
-            stft_conv=stft_conv,
             pad_value=pad_value,
             mag_power=mag_power,
             rng=rng,
             nb_augmentation_prob=nb_augmentation_prob,
             nb_max_freq=nb_max_freq,
+            stft_exact_pad=stft_exact_pad,  # Deprecated arguments; kept for config compatibility
+            stft_conv=stft_conv,  # Deprecated arguments; kept for config compatibility
         )
 
     def get_features(self, input_signal, length):
         return self.featurizer(input_signal, length)
 
     @property
     def filter_banks(self):
@@ -675,21 +670,21 @@
     log: bool = True
     log_zero_guard_type: str = "add"
     log_zero_guard_value: float = 2 ** -24
     dither: float = 1e-5
     pad_to: int = 16
     frame_splicing: int = 1
     exact_pad: bool = False
-    stft_exact_pad: bool = False
-    stft_conv: bool = False
     pad_value: int = 0
     mag_power: float = 2.0
     rng: Optional[str] = None
     nb_augmentation_prob: float = 0.0
     nb_max_freq: int = 4000
+    stft_exact_pad: bool = False  # Deprecated argument, kept for compatibility with older checkpoints.
+    stft_conv: bool = False  # Deprecated argument, kept for compatibility with older checkpoints.
 
 
 @dataclass
 class AudioToMFCCPreprocessorConfig:
     _target_: str = 'nemo.collections.asr.modules.AudioToMFCCPreprocessor'
     sample_rate: int = 16000
     window_size: float = 0.02
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/beam_search_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/beam_search_decoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/conformer_encoder.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/conformer_encoder.py`

 * *Files 26% similar despite different names*

```diff
@@ -10,24 +10,26 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import math
 from collections import OrderedDict
+from typing import List, Optional
 
 import torch
 import torch.distributed
 import torch.nn as nn
 
 from nemo.collections.asr.parts.submodules.conformer_modules import ConformerLayer
 from nemo.collections.asr.parts.submodules.multi_head_attention import PositionalEncoding, RelPositionalEncoding
-from nemo.collections.asr.parts.submodules.subsampling import ConvSubsampling
+from nemo.collections.asr.parts.submodules.subsampling import ConvSubsampling, StackingSubsampling
 from nemo.core.classes.common import typecheck
 from nemo.core.classes.exportable import Exportable
+from nemo.core.classes.mixins import adapter_mixins
 from nemo.core.classes.module import NeuralModule
 from nemo.core.neural_types import AcousticEncodedRepresentation, LengthsType, NeuralType, SpectrogramType
 
 __all__ = ['ConformerEncoder']
 
 
 class ConformerEncoder(NeuralModule, Exportable):
@@ -145,26 +147,31 @@
             self.xscale = math.sqrt(d_model)
         else:
             self.xscale = None
 
         if subsampling_conv_channels == -1:
             subsampling_conv_channels = d_model
         if subsampling and subsampling_factor > 1:
-            self.pre_encode = ConvSubsampling(
-                subsampling=subsampling,
-                subsampling_factor=subsampling_factor,
-                feat_in=feat_in,
-                feat_out=d_model,
-                conv_channels=subsampling_conv_channels,
-                activation=nn.ReLU(),
-            )
-            self._feat_out = d_model
+            if subsampling == 'stacking':
+                self.pre_encode = StackingSubsampling(
+                    subsampling_factor=subsampling_factor, feat_in=feat_in, feat_out=d_model
+                )
+            else:
+                self.pre_encode = ConvSubsampling(
+                    subsampling=subsampling,
+                    subsampling_factor=subsampling_factor,
+                    feat_in=feat_in,
+                    feat_out=d_model,
+                    conv_channels=subsampling_conv_channels,
+                    activation=nn.ReLU(),
+                )
         else:
             self.pre_encode = nn.Linear(feat_in, d_model)
-            self._feat_out = d_model
+
+        self._feat_out = d_model
 
         if not untie_biases and self_attention_model == "rel_pos":
             d_head = d_model // n_heads
             pos_bias_u = nn.Parameter(torch.Tensor(n_heads, d_head))
             pos_bias_v = nn.Parameter(torch.Tensor(n_heads, d_head))
             nn.init.zeros_(pos_bias_u)
             nn.init.zeros_(pos_bias_v)
@@ -243,18 +250,19 @@
         if length is None:
             length = audio_signal.new_full(
                 audio_signal.size(0), max_audio_length, dtype=torch.int32, device=self.seq_range.device
             )
 
         audio_signal = torch.transpose(audio_signal, 1, 2)
 
-        if isinstance(self.pre_encode, ConvSubsampling):
-            audio_signal, length = self.pre_encode(audio_signal, length)
-        else:
+        if isinstance(self.pre_encode, nn.Linear):
             audio_signal = self.pre_encode(audio_signal)
+        else:
+            audio_signal, length = self.pre_encode(audio_signal, length)
+
         audio_signal, pos_emb = self.pos_enc(audio_signal)
         # adjust size
         max_audio_length = audio_signal.size(1)
         # Create the self-attention and padding masks
 
         pad_mask = self.make_pad_mask(max_audio_length, length)
         att_mask = pad_mask.unsqueeze(1).repeat([1, max_audio_length, 1])
@@ -298,7 +306,37 @@
         return mask
 
     def enable_pad_mask(self, on=True):
         # On inference, user may chose to disable pad mask
         mask = self.use_pad_mask
         self.use_pad_mask = on
         return mask
+
+
+class ConformerEncoderAdapter(ConformerEncoder, adapter_mixins.AdapterModuleMixin):
+
+    # Higher level forwarding
+    def add_adapter(self, name: str, cfg: dict):
+        for conformer_layer in self.layers:  # type: adapter_mixins.AdapterModuleMixin
+            conformer_layer.add_adapter(name, cfg)
+
+    def is_adapter_available(self) -> bool:
+        return any([conformer_layer.is_adapter_available() for conformer_layer in self.layers])
+
+    def set_enabled_adapters(self, name: Optional[str] = None, enabled: bool = True):
+        for conformer_layer in self.layers:  # type: adapter_mixins.AdapterModuleMixin
+            conformer_layer.set_enabled_adapters(name=name, enabled=enabled)
+
+    def get_enabled_adapters(self) -> List[str]:
+        names = set([])
+        for conformer_layer in self.layers:  # type: adapter_mixins.AdapterModuleMixin
+            names.update(conformer_layer.get_enabled_adapters())
+
+        names = sorted(list(names))
+        return names
+
+
+"""
+Register any additional information
+"""
+if adapter_mixins.get_registered_adapter(ConformerEncoder) is None:
+    adapter_mixins.register_adapter(base_class=ConformerEncoder, adapter_class=ConformerEncoderAdapter)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/conv_asr.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/conv_asr.py`

 * *Files 4% similar despite different names*

```diff
@@ -33,14 +33,15 @@
     AttentivePoolLayer,
     StatsPoolLayer,
     TDNNModule,
     TDNNSEModule,
 )
 from nemo.core.classes.common import typecheck
 from nemo.core.classes.exportable import Exportable
+from nemo.core.classes.mixins import adapter_mixins
 from nemo.core.classes.module import NeuralModule
 from nemo.core.neural_types import (
     AcousticEncodedRepresentation,
     LengthsType,
     LogitsType,
     LogprobsType,
     NeuralType,
@@ -848,14 +849,54 @@
             pool = F.normalize(pool, p=2, dim=1)
 
         out = self.final(pool)
 
         return out, embs[-1].squeeze(-1)
 
 
+class ConvASREncoderAdapter(ConvASREncoder, adapter_mixins.AdapterModuleMixin):
+
+    # Higher level forwarding
+    def add_adapter(self, name: str, cfg: dict):
+        for jasper_block in self.encoder:  # type: adapter_mixins.AdapterModuleMixin
+            cfg = self._update_adapter_cfg_input_dim(jasper_block, cfg)
+            jasper_block.add_adapter(name, cfg)
+
+    def is_adapter_available(self) -> bool:
+        return any([jasper_block.is_adapter_available() for jasper_block in self.encoder])
+
+    def set_enabled_adapters(self, name: Optional[str] = None, enabled: bool = True):
+        for jasper_block in self.encoder:  # type: adapter_mixins.AdapterModuleMixin
+            jasper_block.set_enabled_adapters(name=name, enabled=enabled)
+
+    def get_enabled_adapters(self) -> List[str]:
+        names = set([])
+        for jasper_block in self.encoder:  # type: adapter_mixins.AdapterModuleMixin
+            names.update(jasper_block.get_enabled_adapters())
+
+        names = sorted(list(names))
+        return names
+
+    def _update_adapter_cfg_input_dim(self, block: JasperBlock, cfg):
+        if 'in_features' in cfg:
+            in_planes = cfg['in_features']
+
+            if in_planes != block.planes:
+                logging.info(f"Updating Adapter input dim from {in_planes} to {block.planes}")
+                in_planes = block.planes
+
+            cfg['in_features'] = in_planes
+            return cfg
+        else:
+            raise ValueError(
+                f"Failed to infer the input dimension of the Adapter cfg. Provided config : \n"
+                f"{OmegaConf.to_yaml(cfg)}"
+            )
+
+
 @dataclass
 class JasperEncoderConfig:
     filters: int = MISSING
     repeat: int = MISSING
     kernel: List[int] = MISSING
     stride: List[int] = MISSING
     dilation: List[int] = MISSING
@@ -903,7 +944,14 @@
 class ConvASRDecoderClassificationConfig:
     _target_: str = 'nemo.collections.asr.modules.ConvASRDecoderClassification'
     feat_in: int = MISSING
     num_classes: int = MISSING
     init_mode: Optional[str] = "xavier_uniform"
     return_logits: bool = True
     pooling_type: str = 'avg'
+
+
+"""
+Register any additional information
+"""
+if adapter_mixins.get_registered_adapter(ConvASREncoder) is None:
+    adapter_mixins.register_adapter(base_class=ConvASREncoder, adapter_class=ConvASREncoderAdapter)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/graph_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/graph_decoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/lstm_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/lstm_decoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/rnn_encoder.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/rnn_encoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -157,18 +157,18 @@
         if length is None:
             length = audio_signal.new_full(
                 audio_signal.size(0), max_audio_length, dtype=torch.int32, device=self.seq_range.device
             )
 
         audio_signal = torch.transpose(audio_signal, 1, 2)
 
-        if isinstance(self.pre_encode, ConvSubsampling) or isinstance(self.pre_encode, StackingSubsampling):
-            audio_signal, length = self.pre_encode(audio_signal, length)
-        else:
+        if isinstance(self.pre_encode, nn.Linear):
             audio_signal = self.pre_encode(audio_signal)
+        else:
+            audio_signal, length = self.pre_encode(audio_signal, length)
 
         for lth, layer in enumerate(self.layers):
             audio_signal = layer(audio_signal)
             if isinstance(audio_signal, tuple):
                 audio_signal, _ = audio_signal
 
         audio_signal = torch.transpose(audio_signal, 1, 2)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/rnnt.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/rnnt.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/rnnt_abstract.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/rnnt_abstract.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/modules/wav2vec_modules.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/modules/wav2vec_modules.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/features.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/features.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/autograd.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/autograd.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/classes.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/classes.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/grad_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/grad_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/graph_compilers.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/graph_compilers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/graph_decoders.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/graph_decoders.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/map_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/map_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/ml_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/ml_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/topologies.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/topologies.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/k2/utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/k2/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/mixins/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/entity_linking/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,8 +8,8 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.asr.parts.mixins.mixins import ASRBPEMixin, ASRModuleMixin, DiarizationMixin
+from nemo.collections.nlp.data.entity_linking.entity_linking_dataset import EntityLinkingDataset
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/mixins/mixins.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/mixins/mixins.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,14 +14,15 @@
 
 import os
 from abc import ABC, abstractmethod
 from typing import List
 
 from omegaconf import DictConfig, OmegaConf, open_dict
 
+from nemo.collections.asr.parts.mixins.asr_adapter_mixins import ASRAdapterModelMixin
 from nemo.collections.asr.parts.utils import asr_module_utils
 from nemo.collections.common import tokenizers
 from nemo.utils import logging
 
 
 class ASRBPEMixin(ABC):
     """ ASR BPE Mixin class that sets up a Tokenizer via a config
@@ -358,15 +359,15 @@
         # clean up the old aggregate artifacts as well
         if hasattr(self, 'artifacts'):
             for akey in list(self.artifacts.keys()):
                 if akey.startswith('tokenizer.' + self.AGGREGATE_TOKENIZERS_DICT_PREFIX + '.'):
                     self.artifacts.pop(akey)
 
 
-class ASRModuleMixin(ABC):
+class ASRModuleMixin(ASRAdapterModelMixin):
     """
     ASRModuleMixin is a mixin class added to ASR models in order to add methods that are specific
     to a particular instantiation of a module inside of an ASRModel.
 
     Each method should first check that the module is present within the subclass, and support additional
     functionality if the corresponding module is present.
     """
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/rnnt.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/rnnt.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_numpy.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_numpy.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_pytorch.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/rnnt_pytorch.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/cpu_rnnt.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cpu_utils/cpu_rnnt.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt_kernel.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/gpu_rnnt_kernel.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/reduce.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/cuda_utils/reduce.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/global_constants.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/global_constants.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/rnnt_loss/utils/rnnt_helper.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/rnnt_loss/utils/rnnt_helper.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/spec_augment/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/spec_augment/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/numba/spec_augment/spec_aug_numba.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/numba/spec_augment/spec_aug_numba.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,22 +9,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from nemo.collections.asr.parts.preprocessing.feature_loader import ExternalFeatureLoader
-from nemo.collections.asr.parts.preprocessing.features import (
-    STFT,
-    FeaturizerFactory,
-    FilterbankFeatures,
-    STFTExactPad,
-    STFTPatch,
-    WaveformFeaturizer,
-)
+from nemo.collections.asr.parts.preprocessing.features import FeaturizerFactory, FilterbankFeatures, WaveformFeaturizer
 from nemo.collections.asr.parts.preprocessing.perturb import (
     AudioAugmentor,
     AugmentationDataset,
     GainPerturbation,
     ImpulsePerturbation,
     NoisePerturbation,
     Perturbation,
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/feature_loader.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/feature_loader.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/features.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/features.py`

 * *Files 14% similar despite different names*

```diff
@@ -32,21 +32,16 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 # This file contains code artifacts adapted from https://github.com/ryanleary/patter
 import math
 import random
 
 import librosa
-import numpy as np
 import torch
 import torch.nn as nn
-import torch.nn.functional as F
-from librosa.util import tiny
-from torch.autograd import Variable
-from torch_stft import STFT
 
 from nemo.collections.asr.parts.preprocessing.perturb import AudioAugmentor
 from nemo.collections.asr.parts.preprocessing.segment import AudioSegment
 from nemo.utils import logging
 
 CONSTANT = 1e-5
 
@@ -139,64 +134,14 @@
         pass
 
     @classmethod
     def from_config(cls, input_cfg, perturbation_configs=None):
         return WaveformFeaturizer.from_config(input_cfg, perturbation_configs=perturbation_configs)
 
 
-# Create helper class to patch forward func for use with AMP
-class STFTPatch(STFT):
-    def forward(self, input_data):
-        return super().transform(input_data)[0]
-
-
-# Create helper class for STFT that yields num_frames = num_samples // hop_length
-class STFTExactPad(STFTPatch):
-    """adapted from Prem Seetharaman's https://github.com/pseeth/pytorch-stft"""
-
-    def __init__(self, *params, **kw_params):
-        super().__init__(*params, **kw_params)
-        self.pad_amount = (self.filter_length - self.hop_length) // 2
-
-    def inverse(self, magnitude, phase):
-        recombine_magnitude_phase = torch.cat([magnitude * torch.cos(phase), magnitude * torch.sin(phase)], dim=1)
-
-        inverse_transform = F.conv_transpose1d(
-            recombine_magnitude_phase,
-            Variable(self.inverse_basis, requires_grad=False),
-            stride=self.hop_length,
-            padding=0,
-        )
-
-        if self.window is not None:
-            window_sum = librosa.filters.window_sumsquare(
-                window=self.window,
-                n_frames=magnitude.size(-1),
-                hop_length=self.hop_length,
-                win_length=self.win_length,
-                n_fft=self.filter_length,
-                dtype=np.float32,
-            )
-            # remove modulation effects
-            approx_nonzero_indices = torch.from_numpy(np.where(window_sum > tiny(window_sum))[0])
-            window_sum = torch.autograd.Variable(torch.from_numpy(window_sum), requires_grad=False).to(
-                magnitude.device
-            )
-            inverse_transform[..., approx_nonzero_indices] /= window_sum[approx_nonzero_indices]
-
-            # scale by hop ratio
-            inverse_transform *= self.filter_length / self.hop_length
-
-        inverse_transform = inverse_transform[..., self.pad_amount :]
-        inverse_transform = inverse_transform[..., : -self.pad_amount :]
-        inverse_transform = inverse_transform.squeeze(1)
-
-        return inverse_transform
-
-
 class FilterbankFeatures(nn.Module):
     """Featurizer that converts wavs to Mel Spectrograms.
     See AudioToMelSpectrogramPreprocessor for args.
     """
 
     def __init__(
         self,
@@ -220,29 +165,25 @@
         exact_pad=False,
         pad_value=0,
         mag_power=2.0,
         use_grads=False,
         rng=None,
         nb_augmentation_prob=0.0,
         nb_max_freq=4000,
-        # Deprecated arguments; kept for config compatibility
-        stft_exact_pad=False,  # TODO: Remove this in 1.1.0
-        stft_conv=False,  # TODO: Remove this in 1.1.0
+        stft_exact_pad=False,  # Deprecated arguments; kept for config compatibility
+        stft_conv=False,  # Deprecated arguments; kept for config compatibility
     ):
         super().__init__()
         if stft_conv or stft_exact_pad:
             logging.warning(
                 "Using torch_stft is deprecated and has been removed. The values have been forcibly set to False "
                 "for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True "
                 "as needed."
             )
-            stft_conv = False
-            stft_exact_pad = False
-
-        if (exact_pad or stft_exact_pad) and n_window_stride % 2 == 1:
+        if exact_pad and n_window_stride % 2 == 1:
             raise NotImplementedError(
                 f"{self} received exact_pad == True, but hop_size was odd. If audio_length % hop_size == 0. Then the "
                 "returned spectrogram would not be of length audio_length // hop_size. Please use an even hop_size."
             )
         self.log_zero_guard_value = log_zero_guard_value
         if (
             n_window_size is None
@@ -258,47 +199,36 @@
             )
         logging.info(f"PADDING: {pad_to}")
 
         self.win_length = n_window_size
         self.hop_length = n_window_stride
         self.n_fft = n_fft or 2 ** math.ceil(math.log2(self.win_length))
         self.stft_pad_amount = (self.n_fft - self.hop_length) // 2 if exact_pad else None
-        self.stft_exact_pad = stft_exact_pad
-        self.stft_conv = stft_conv
 
-        if stft_conv:
-            logging.info("STFT using conv")
-            if stft_exact_pad:
-                logging.info("STFT using exact pad")
-                self.stft = STFTExactPad(self.n_fft, self.hop_length, self.win_length, window)
-            else:
-                self.stft = STFTPatch(self.n_fft, self.hop_length, self.win_length, window)
-        else:
-            logging.info("STFT using torch")
-            if exact_pad:
-                logging.info("STFT using exact pad")
-            torch_windows = {
-                'hann': torch.hann_window,
-                'hamming': torch.hamming_window,
-                'blackman': torch.blackman_window,
-                'bartlett': torch.bartlett_window,
-                'none': None,
-            }
-            window_fn = torch_windows.get(window, None)
-            window_tensor = window_fn(self.win_length, periodic=False) if window_fn else None
-            self.register_buffer("window", window_tensor)
-            self.stft = lambda x: torch.stft(
-                x,
-                n_fft=self.n_fft,
-                hop_length=self.hop_length,
-                win_length=self.win_length,
-                center=False if exact_pad else True,
-                window=self.window.to(dtype=torch.float),
-                return_complex=False,
-            )
+        if exact_pad:
+            logging.info("STFT using exact pad")
+        torch_windows = {
+            'hann': torch.hann_window,
+            'hamming': torch.hamming_window,
+            'blackman': torch.blackman_window,
+            'bartlett': torch.bartlett_window,
+            'none': None,
+        }
+        window_fn = torch_windows.get(window, None)
+        window_tensor = window_fn(self.win_length, periodic=False) if window_fn else None
+        self.register_buffer("window", window_tensor)
+        self.stft = lambda x: torch.stft(
+            x,
+            n_fft=self.n_fft,
+            hop_length=self.hop_length,
+            win_length=self.win_length,
+            center=False if exact_pad else True,
+            window=self.window.to(dtype=torch.float),
+            return_complex=False,
+        )
 
         self.normalize = normalize
         self.log = log
         self.dither = dither
         self.frame_splicing = frame_splicing
         self.nfilt = nfilt
         self.preemph = preemph
@@ -363,19 +293,16 @@
                     f"log_zero_guard_type parameter. It must be either a "
                     f"number, 'tiny', or 'eps'"
                 )
         else:
             return self.log_zero_guard_value
 
     def get_seq_len(self, seq_len):
-        if isinstance(self.stft, STFT):
-            pad_amount = self.stft.pad_amount * 2
-        else:
-            # Assuming that center is True is stft_pad_amount = 0
-            pad_amount = self.stft_pad_amount * 2 if self.stft_pad_amount is not None else self.n_fft // 2 * 2
+        # Assuming that center is True is stft_pad_amount = 0
+        pad_amount = self.stft_pad_amount * 2 if self.stft_pad_amount is not None else self.n_fft // 2 * 2
         seq_len = torch.floor((seq_len + pad_amount - self.n_fft) / self.hop_length) + 1
         return seq_len.to(dtype=torch.long)
 
     @property
     def filter_banks(self):
         return self.fb
 
@@ -396,20 +323,19 @@
             x = torch.cat((x[:, 0].unsqueeze(1), x[:, 1:] - self.preemph * x[:, :-1]), dim=1)
 
         # disable autocast to get full range of stft values
         with torch.cuda.amp.autocast(enabled=False):
             x = self.stft(x)
 
         # torch returns real, imag; so convert to magnitude
-        if not self.stft_conv:
-            # guard is needed for sqrt if grads are passed through
-            guard = 0 if not self.use_grads else CONSTANT
-            if x.dtype in [torch.cfloat, torch.cdouble]:
-                x = torch.view_as_real(x)
-            x = torch.sqrt(x.pow(2).sum(-1) + guard)
+        # guard is needed for sqrt if grads are passed through
+        guard = 0 if not self.use_grads else CONSTANT
+        if x.dtype in [torch.cfloat, torch.cdouble]:
+            x = torch.view_as_real(x)
+        x = torch.sqrt(x.pow(2).sum(-1) + guard)
 
         if self.training and self.nb_augmentation_prob > 0.0:
             for idx in range(x.shape[0]):
                 if self._rng.random() < self.nb_augmentation_prob:
                     x[idx, self._nb_max_fft_bin :, :] = 0.0
 
         # get power spectrum
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/perturb.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/perturb.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/preprocessing/segment.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/preprocessing/segment.py`

 * *Files 3% similar despite different names*

```diff
@@ -39,22 +39,20 @@
 import librosa
 import numpy as np
 import soundfile as sf
 
 from nemo.utils import logging
 
 # TODO @blisc: Perhaps refactor instead of import guarding
-HAVE_KALDI_PYDUB = True
+HAVE_PYDUB = True
 try:
-    from kaldiio.matio import read_kaldi
-    from kaldiio.utils import open_like_kaldi
     from pydub import AudioSegment as Audio
     from pydub.exceptions import CouldntDecodeError
 except ModuleNotFoundError:
-    HAVE_KALDI_PYDUB = False
+    HAVE_PYDUB = False
 
 
 available_formats = sf.available_formats()
 sf_supported_formats = ["." + i.lower() for i in available_formats.keys()]
 
 
 class AudioSegment(object):
@@ -152,26 +150,16 @@
                         samples = f.read(dtype=dtype)
                 samples = samples.transpose()
             except RuntimeError as e:
                 logging.error(
                     f"Loading {audio_file} via SoundFile raised RuntimeError: `{e}`. "
                     f"NeMo will fallback to loading via pydub."
                 )
-        elif HAVE_KALDI_PYDUB and isinstance(audio_file, str) and audio_file.strip()[-1] == "|":
-            f = open_like_kaldi(audio_file, "rb")
-            sample_rate, samples = read_kaldi(f)
-            if offset > 0:
-                samples = samples[int(offset * sample_rate) :]
-            if duration > 0:
-                samples = samples[: int(duration * sample_rate)]
-            if not int_values:
-                abs_max_value = np.abs(samples).max()
-                samples = np.array(samples, dtype=np.float) / abs_max_value
 
-        if HAVE_KALDI_PYDUB and samples is None:
+        if HAVE_PYDUB and samples is None:
             try:
                 samples = Audio.from_file(audio_file)
                 sample_rate = samples.frame_rate
                 if offset > 0:
                     # pydub does things in milliseconds
                     seconds = offset * 1000
                     samples = samples[int(seconds) :]
@@ -179,15 +167,15 @@
                     seconds = duration * 1000
                     samples = samples[: int(seconds)]
                 samples = np.array(samples.get_array_of_samples())
             except CouldntDecodeError as err:
                 logging.error(f"Loading {audio_file} via pydub raised CouldntDecodeError: `{err}`.")
 
         if samples is None:
-            libs = "soundfile, kaldiio, and pydub" if HAVE_KALDI_PYDUB else "soundfile"
+            libs = "soundfile, and pydub" if HAVE_PYDUB else "soundfile"
             raise Exception(f"Your audio file {audio_file} could not be decoded. We tried using {libs}.")
 
         return cls(samples, sample_rate, target_sr=target_sr, trim=trim, orig_sr=orig_sr)
 
     @classmethod
     def segment_from_file(cls, audio_file, target_sr=None, n_segments=0, trim=False, orig_sr=None):
         """Grabs n_segments number of samples from audio_file randomly from the
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/conformer_modules.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/conformer_modules.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,19 +17,22 @@
 from torch.nn import LayerNorm
 
 from nemo.collections.asr.parts.submodules.multi_head_attention import (
     MultiHeadAttention,
     RelPositionMultiHeadAttention,
 )
 from nemo.collections.asr.parts.utils.activations import Swish
+from nemo.core.classes.mixins import AccessMixin
+from nemo.core.classes.mixins.adapter_mixins import AdapterModuleMixin
+from nemo.utils import logging
 
 __all__ = ['ConformerConvolution', 'ConformerFeedForward', 'ConformerLayer']
 
 
-class ConformerLayer(torch.nn.Module):
+class ConformerLayer(torch.nn.Module, AdapterModuleMixin, AccessMixin):
     """A single block of the Conformer encoder.
 
     Args:
         d_model (int): input dimension of MultiheadAttentionMechanism and PositionwiseFeedForward
         d_ff (int): hidden dimension of PositionwiseFeedForward
         n_heads (int): number of heads for multi-head attention
         conv_kernel_size (int): kernel size for depthwise convolution in convolution module
@@ -114,14 +117,22 @@
         residual = residual + self.dropout(x)
 
         x = self.norm_feed_forward2(residual)
         x = self.feed_forward2(x)
         residual = residual + self.dropout(x) * self.fc_factor
 
         x = self.norm_out(residual)
+
+        if self.is_adapter_available():
+            # Call the adapters
+            x = self.forward_enabled_adapters(x)
+
+        if self.is_access_enabled():
+            self.register_accessible_tensor(tensor=x)
+
         return x
 
 
 class ConformerConvolution(nn.Module):
     """The convolution module for the Conformer model.
     Args:
         d_model (int): hidden dimension
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/jasper.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/jasper.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,35 +18,30 @@
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torch import Tensor
 from torch.nn.init import _calculate_correct_fan
 from torch.nn.modules.utils import _single
 
-from nemo.collections.asr.parts.utils.activations import Swish
+from nemo.collections.common.parts.utils import activation_registry
+from nemo.core.classes.mixins import AccessMixin
+from nemo.core.classes.mixins.adapter_mixins import AdapterModuleMixin
 from nemo.utils import logging
 
 try:
     from pytorch_quantization import calib
     from pytorch_quantization import nn as quant_nn
     from pytorch_quantization import quant_modules
     from pytorch_quantization.tensor_quant import QuantDescriptor
 
     PYTORCH_QUANTIZATION_AVAILABLE = True
 except ImportError:
     PYTORCH_QUANTIZATION_AVAILABLE = False
 
-jasper_activations = {
-    "hardtanh": nn.Hardtanh,
-    "relu": nn.ReLU,
-    "selu": nn.SELU,
-    "swish": Swish,
-    "silu": nn.SiLU,
-    "gelu": nn.GELU,
-}
+jasper_activations = activation_registry
 
 
 def tds_uniform_(tensor, mode='fan_in'):
     """
     Uniform Initialization from the paper [Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions](https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2460.pdf)
     Normalized to -
 
@@ -559,15 +554,15 @@
         """
         if hasattr(self, 'context_window'):
             logging.info(f"Changing Squeeze-Excitation context window from {self.context_window} to {context_window}")
 
         self.context_window = context_window
 
 
-class JasperBlock(nn.Module):
+class JasperBlock(nn.Module, AdapterModuleMixin, AccessMixin):
     """
     Constructs a single "Jasper" block. With modified parameters, also constructs other blocks for models
     such as `QuartzNet` and `Citrinet`.
 
     - For `Jasper`    : `separable` flag should be False
     - For `QuartzNet` : `separable` flag should be True
     - For `Citrinet`  : `separable` flag and `se` flag should be True
@@ -719,14 +714,16 @@
             kernel_size = compute_new_kernel_size(kernel_size, kernel_size_factor)
 
         if future_context < 0:
             padding_val = get_same_padding(kernel_size[0], stride[0], dilation[0])
         else:
             padding_val = get_asymtric_padding(kernel_size[0], stride[0], dilation[0], future_context)
 
+        self.inplanes = inplanes
+        self.planes = planes
         self.conv_mask = conv_mask
         self.separable = separable
         self.residual_mode = residual_mode
         self.se = se
         self.quantize = quantize
 
         inplanes_loop = inplanes
@@ -1027,14 +1024,31 @@
                     else:
                         out = out + res_out
                 else:
                     out = torch.max(out, res_out)
 
         # compute the output
         out = self.mout(out)
+
+        # Support ASR Adapters
+        if self.is_adapter_available():
+            # Check for all available and enabled adapters
+            adapter_names = self.get_enabled_adapters()
+
+            if len(adapter_names) > 0:
+                out = out.transpose(1, 2)  # (B, T, C)
+
+                # Call the adapters
+                out = self.forward_enabled_adapters(out)
+
+                out = out.transpose(1, 2)  # (B, C, T)
+
+        if self.is_access_enabled():
+            self.register_accessible_tensor(tensor=out)
+
         if self.res is not None and self.dense_residual:
             return xs + [out], lens
 
         return [out], lens
 
 
 class ParallelBlock(nn.Module):
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/multi_head_attention.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/multi_head_attention.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/rnnt_beam_decoding.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/rnnt_beam_decoding.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/rnnt_greedy_decoding.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/rnnt_greedy_decoding.py`

 * *Files identical despite different names*

```diff
@@ -243,15 +243,15 @@
         Returns:
             packed list containing batch number of sentences (Hypotheses).
         """
         # Preserve decoder and joint training state
         decoder_training_state = self.decoder.training
         joint_training_state = self.joint.training
 
-        with torch.no_grad():
+        with torch.inference_mode():
             # Apply optional preprocessing
             encoder_output = encoder_output.transpose(1, 2)  # (B, T, D)
 
             self.decoder.eval()
             self.joint.eval()
 
             hypotheses = []
@@ -424,15 +424,15 @@
         Returns:
             packed list containing batch number of sentences (Hypotheses).
         """
         # Preserve decoder and joint training state
         decoder_training_state = self.decoder.training
         joint_training_state = self.joint.training
 
-        with torch.no_grad():
+        with torch.inference_mode():
             # Apply optional preprocessing
             encoder_output = encoder_output.transpose(1, 2)  # (B, T, D)
             logitlen = encoded_lengths
 
             self.decoder.eval()
             self.joint.eval()
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/spectr_augment.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/spectr_augment.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/ssl_quantizers.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/ssl_quantizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/subsampling.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/subsampling.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,15 +29,15 @@
     def __init__(self, subsampling_factor, feat_in, feat_out):
         super(StackingSubsampling, self).__init__()
         self.subsampling_factor = subsampling_factor
         self.proj_out = torch.nn.Linear(subsampling_factor * feat_in, feat_out)
 
     def forward(self, x, lengths):
         b, t, h = x.size()
-        pad_size = self.subsampling_factor - (t % self.subsampling_factor)
+        pad_size = (self.subsampling_factor - (t % self.subsampling_factor)) % self.subsampling_factor
         x = torch.nn.functional.pad(x, (0, 0, 0, pad_size))
         _, t, _ = x.size()
         x = torch.reshape(x, (b, t // self.subsampling_factor, h * self.subsampling_factor))
         x = self.proj_out(x)
         lengths = torch.div(lengths + pad_size, self.subsampling_factor, rounding_mode='floor')
         return x, lengths
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/submodules/tdnn_attention.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/submodules/tdnn_attention.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/activations.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/activations.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/asr_module_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/asr_module_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/decoder_timestamps_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/decoder_timestamps_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -586,19 +586,14 @@
         cfg.preprocessor.dither = 0.0
         cfg.preprocessor.pad_to = 0
         cfg.preprocessor.normalize = "None"
 
         preprocessor = nemo_asr.models.EncDecCTCModelBPE.from_config_dict(cfg.preprocessor)
         preprocessor.to(asr_model.device)
 
-        if cfg.preprocessor.normalize != "per_feature":
-            logging.error(
-                "Only EncDecCTCModelBPE models trained with per_feature normalization are supported currently"
-            )
-
         # Disable config overwriting
         OmegaConf.set_struct(cfg.preprocessor, True)
 
         onset_delay = (
             math.ceil(((self.total_buffer_in_secs - self.chunk_len_in_sec) / 2) / self.model_stride_in_secs) + 1
         )
         mid_delay = math.ceil(
@@ -666,15 +661,15 @@
                     logging.info(
                         f"Running beam-search decoder with LM {self.ctc_decoder_params['pretrained_language_model']}"
                     )
                     log_prob = log_prob.unsqueeze(0).cpu().numpy()[0]
                     hyp_words, word_ts = self.run_pyctcdecode(log_prob, onset_delay_in_sec=onset_delay_in_sec)
                 else:
                     logits_len = torch.from_numpy(np.array([len(greedy_predictions_list)]))
-                    greedy_predictions_list = greedy_predictions_list[onset_delay:-mid_delay]
+                    greedy_predictions_list = greedy_predictions_list[onset_delay:]
                     greedy_predictions = torch.from_numpy(np.array(greedy_predictions_list)).unsqueeze(0)
                     text, char_ts, word_ts = werbpe_ts.ctc_decoder_predictions_tensor_with_ts(
                         self.model_stride_in_secs, greedy_predictions, predictions_len=logits_len
                     )
                     hyp_words, word_ts = text[0].split(), word_ts[0]
 
                 word_ts = self.align_decoder_delay(word_ts, self.decoder_delay_in_sec)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/diarization_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/diarization_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -534,15 +534,19 @@
             sentence['text'] += word.strip() + ' '
 
             self.add_json_to_dict(riva_dict, word, stt_sec, end_sec, speaker)
             audacity_label_words.append(self.get_audacity_label(word, stt_sec, end_sec, speaker))
             total_riva_dict[uniq_id] = riva_dict
             prev_speaker = speaker
 
+        # note that we need to add the very last sentence.
+        sentence['text'] = sentence['text'].strip()
+        sentences.append(sentence)
         gecko_dict['monologues'].append({'speaker': {'name': None, 'id': speaker}, 'terms': terms_list})
+
         riva_dict['transcription'] = ' '.join(word_seq_list)
         self.write_and_log(uniq_id, riva_dict, audacity_label_words, gecko_dict, sentences)
         return total_riva_dict
 
     def get_realignment_ranges(self, k, word_seq_len):
         """
         Calculate word ranges for realignment operation.
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/nmesc_clustering.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/speaker_utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,676 +1,611 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+import json
+import math
+import os
+from copy import deepcopy
 
-# Copyright (c) 2007-2020 The scikit-learn developers.
+import numpy as np
+import omegaconf
+import soundfile as sf
+import torch
+from pyannote.core import Annotation, Segment, Timeline
+from pyannote.metrics.diarization import DiarizationErrorRate
+from tqdm import tqdm
 
-# BSD 3-Clause License
+from nemo.collections.asr.parts.utils.nmesc_clustering import COSclustering
+from nemo.utils import logging
 
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
-# This file is part of https://github.com/scikit-learn/scikit-learn/blob/114616d9f6ce9eba7c1aacd3d4a254f868010e25/sklearn/manifold/_spectral_embedding.py and
-# https://github.com/tango4j/Auto-Tuning-Spectral-Clustering.
+"""
+This file contains all the utility functions required for speaker embeddings part in diarization scripts
+"""
 
-from collections import Counter
 
-import numpy as np
-import torch
-from sklearn.cluster._kmeans import k_means
-from sklearn.metrics.pairwise import cosine_similarity
-from sklearn.preprocessing import MinMaxScaler
+def get_uniqname_from_filepath(filepath):
+    "return base name from provided filepath"
+    if type(filepath) is str:
+        basename = os.path.basename(filepath).rsplit('.', 1)[0]
+        return basename
+    else:
+        raise TypeError("input must be filepath string")
 
-from nemo.utils import logging
 
-scaler = MinMaxScaler(feature_range=(0, 1))
+def audio_rttm_map(manifest):
+    """
+    This function creates AUDIO_RTTM_MAP which is used by all diarization components to extract embeddings,
+    cluster and unify time stamps
+    input: manifest file that contains keys audio_filepath, rttm_filepath if exists, text, num_speakers if known and uem_filepath if exists
 
-try:
-    from torch.linalg import eigh as eigh
+    returns:
+    AUDIO_RTTM_MAP (dict) : A dictionary with keys of uniq id, which is being used to map audio files and corresponding rttm files
+    """
 
-    TORCH_EIGN = True
+    AUDIO_RTTM_MAP = {}
+    with open(manifest, 'r') as inp_file:
+        lines = inp_file.readlines()
+        logging.info("Number of files to diarize: {}".format(len(lines)))
+        for line in lines:
+            line = line.strip()
+            dic = json.loads(line)
 
-except ImportError:
-    TORCH_EIGN = False
-    from scipy.linalg import eigh as eigh
+            meta = {
+                'audio_filepath': dic['audio_filepath'],
+                'rttm_filepath': dic.get('rttm_filepath', None),
+                'duration': dic.get('duration', None),
+                'text': dic.get('text', None),
+                'num_speakers': dic.get('num_speakers', None),
+                'uem_filepath': dic.get('uem_filepath', None),
+                'ctm_filepath': dic.get('ctm_filepath', None),
+            }
 
-    logging.warning("Using eigen decomposition from scipy, upgrade torch to 1.9 or higher for faster clustering")
+            uniqname = get_uniqname_from_filepath(filepath=meta['audio_filepath'])
 
+            if uniqname not in AUDIO_RTTM_MAP:
+                AUDIO_RTTM_MAP[uniqname] = meta
+            else:
+                raise KeyError(
+                    "file {} is already part AUDIO_RTTM_Map, it might be duplicated".format(meta['audio_filepath'])
+                )
+
+    return AUDIO_RTTM_MAP
+
+
+def parse_scale_configs(window_lengths_in_sec, shift_lengths_in_sec, multiscale_weights):
+    """
+    Check whether multiscale parameters are provided correctly. window_lengths_in_sec, shift_lengfhs_in_sec and
+    multiscale_weights should be all provided in omegaconf.listconfig.ListConfig type. In addition, the scales
+    should be provided in descending order, from the longest scale to the base scale (the shortest).
+
+    Example:
+        Single-scale setting:
+            parameters.window_length_in_sec=1.5
+            parameters.shift_length_in_sec=0.75
+            parameters.multiscale_weights=null
+
+        Multiscale setting (base scale - window_length 0.5 s and shift_length 0.25):
+            parameters.window_length_in_sec=[1.5,1.0,0.5]
+            parameters.shift_length_in_sec=[0.75,0.5,0.25]
+            parameters.multiscale_weights=[0.33,0.33,0.33]
+    """
+    checkFloatConfig = [type(var) == float for var in (window_lengths_in_sec, shift_lengths_in_sec)]
+    checkListConfig = [
+        type(var) == type(omegaconf.listconfig.ListConfig([]))
+        for var in (window_lengths_in_sec, shift_lengths_in_sec, multiscale_weights)
+    ]
+    if all(checkListConfig) or all(checkFloatConfig):
+
+        # If bare floating numbers are provided, convert them to list format.
+        if all(checkFloatConfig):
+            window_lengths, shift_lengths, multiscale_weights = (
+                [window_lengths_in_sec],
+                [shift_lengths_in_sec],
+                [1.0],
+            )
+        else:
+            window_lengths, shift_lengths, multiscale_weights = (
+                window_lengths_in_sec,
+                shift_lengths_in_sec,
+                multiscale_weights,
+            )
+
+        length_check = (
+            len(set([len(window_lengths), len(shift_lengths), len(multiscale_weights)])) == 1
+            and len(multiscale_weights) > 0
+        )
+        scale_order_check = (
+            window_lengths == sorted(window_lengths)[::-1] and shift_lengths == sorted(shift_lengths)[::-1]
+        )
 
-def isGraphFullyConnected(affinity_mat):
-    return getTheLargestComponent(affinity_mat, 0).sum() == affinity_mat.shape[0]
+        # Check whether window lengths are longer than shift lengths
+        if len(window_lengths) > 1:
+            shift_length_check = all([w > s for w, s in zip(window_lengths, shift_lengths)]) == True
+        else:
+            shift_length_check = window_lengths[0] > shift_lengths[0]
 
+        multiscale_args_dict = {}
+        if all([length_check, scale_order_check, shift_length_check]) == True:
+            if len(window_lengths) > 1:
+                multiscale_args_dict['scale_dict'] = {
+                    k: (w, s) for k, (w, s) in enumerate(zip(window_lengths, shift_lengths))
+                }
+            else:
+                multiscale_args_dict['scale_dict'] = {0: (window_lengths[0], shift_lengths[0])}
+            multiscale_args_dict['multiscale_weights'] = multiscale_weights
+            return multiscale_args_dict
+        else:
+            raise ValueError('Multiscale parameters are not properly setup.')
 
-def getTheLargestComponent(affinity_mat, seg_index):
+    elif any(checkListConfig):
+        raise ValueError(
+            'You must provide list config for all three parameters: window, shift and multiscale weights.'
+        )
+    else:
+        return None
+
+
+def get_embs_and_timestamps(multiscale_embeddings_and_timestamps, multiscale_args_dict):
     """
-    Find the largest affinity_mat connected components for each given node.
-    This is for checking whether the affinity_mat is fully connected.
+    The embeddings and timestamps in multiscale_embeddings_and_timestamps dictionary are
+    indexed by scale index. This function rearranges the extracted speaker embedding and
+    timestamps by unique ID to make the further processing more convenient.
+
+    Args:
+        multiscale_embeddings_and_timestamps (dict):
+            Dictionary of embeddings and timestamps for each scale.
+        multiscale_args_dict (dict):
+            Dictionary of scale information: window, shift and multiscale weights.
+
+    Returns:
+        embs_and_timestamps (dict)
+            A dictionary containing embeddings and timestamps of each scale, indexed by unique ID.
     """
-    num_of_segments = affinity_mat.shape[0]
+    embs_and_timestamps = {
+        uniq_id: {'multiscale_weights': [], 'scale_dict': {}}
+        for uniq_id in multiscale_embeddings_and_timestamps[0][0].keys()
+    }
+    for scale_idx in sorted(multiscale_args_dict['scale_dict'].keys()):
+        embeddings, time_stamps = multiscale_embeddings_and_timestamps[scale_idx]
+        for uniq_id in embeddings.keys():
+            embs_and_timestamps[uniq_id]['multiscale_weights'] = (
+                torch.tensor(multiscale_args_dict['multiscale_weights']).unsqueeze(0).half()
+            )
+            assert len(embeddings[uniq_id]) == len(time_stamps[uniq_id])
+            embs_and_timestamps[uniq_id]['scale_dict'][scale_idx] = {
+                'embeddings': embeddings[uniq_id],
+                'time_stamps': time_stamps[uniq_id],
+            }
+
+    return embs_and_timestamps
+
+
+def get_contiguous_stamps(stamps):
+    """
+    Return contiguous time stamps
+    """
+    lines = deepcopy(stamps)
+    contiguous_stamps = []
+    for i in range(len(lines) - 1):
+        start, end, speaker = lines[i].split()
+        next_start, next_end, next_speaker = lines[i + 1].split()
+        if float(end) > float(next_start):
+            avg = str((float(next_start) + float(end)) / 2.0)
+            lines[i + 1] = ' '.join([avg, next_end, next_speaker])
+            contiguous_stamps.append(start + " " + avg + " " + speaker)
+        else:
+            contiguous_stamps.append(start + " " + end + " " + speaker)
+    start, end, speaker = lines[-1].split()
+    contiguous_stamps.append(start + " " + end + " " + speaker)
+    return contiguous_stamps
+
+
+def merge_stamps(lines):
+    """
+    merge time stamps of same speaker
+    """
+    stamps = deepcopy(lines)
+    overlap_stamps = []
+    for i in range(len(stamps) - 1):
+        start, end, speaker = stamps[i].split()
+        next_start, next_end, next_speaker = stamps[i + 1].split()
+        if float(end) == float(next_start) and speaker == next_speaker:
+            stamps[i + 1] = ' '.join([start, next_end, next_speaker])
+        else:
+            overlap_stamps.append(start + " " + end + " " + speaker)
 
-    connected_nodes = np.zeros(num_of_segments).astype(np.bool)
-    nodes_to_explore = np.zeros(num_of_segments).astype(np.bool)
+    start, end, speaker = stamps[-1].split()
+    overlap_stamps.append(start + " " + end + " " + speaker)
 
-    nodes_to_explore[seg_index] = True
-    for k in range(num_of_segments):
-        last_num_component = connected_nodes.sum()
-        np.logical_or(connected_nodes, nodes_to_explore, out=connected_nodes)
-        if last_num_component >= connected_nodes.sum():
-            break
-        indices = np.where(nodes_to_explore)[0]
-        nodes_to_explore.fill(False)
-        for i in indices:
-            neighbors = affinity_mat[i]
-            np.logical_or(nodes_to_explore, neighbors, out=nodes_to_explore)
-    return connected_nodes
+    return overlap_stamps
 
 
-def getKneighborsConnections(affinity_mat, p_value):
+def labels_to_pyannote_object(labels, uniq_name=''):
     """
-    Binarize top-p values for each row from the given affinity matrix.
+    converts labels to pyannote object to calculate DER and for visualization
     """
-    binarized_affinity_mat = np.zeros_like(affinity_mat)
-    for i, line in enumerate(affinity_mat):
-        sorted_idx = np.argsort(line)
-        sorted_idx = sorted_idx[::-1]
-        indices = sorted_idx[:p_value]
-        binarized_affinity_mat[indices, i] = 1
-    return binarized_affinity_mat
+    annotation = Annotation(uri=uniq_name)
+    for label in labels:
+        start, end, speaker = label.strip().split()
+        start, end = float(start), float(end)
+        annotation[Segment(start, end)] = speaker
 
+    return annotation
 
-def getAffinityGraphMat(affinity_mat_raw, p_value):
+
+def uem_timeline_from_file(uem_file, uniq_name=''):
     """
-    Calculate a binarized graph matrix and
-    symmetrize the binarized graph matrix.
+    outputs pyannote timeline segments for uem file
+
+     <UEM> file format
+     UNIQ_SPEAKER_ID CHANNEL START_TIME END_TIME
     """
-    X = getKneighborsConnections(affinity_mat_raw, p_value)
-    symm_affinity_mat = 0.5 * (X + X.T)
-    return symm_affinity_mat
+    timeline = Timeline(uri=uniq_name)
+    with open(uem_file, 'r') as f:
+        lines = f.readlines()
+        for line in lines:
+            line = line.strip()
+            speaker_id, channel, start_time, end_time = line.split()
+            timeline.add(Segment(float(start_time), float(end_time)))
 
+    return timeline
 
-def getMinimumConnection(mat, max_N, n_list):
+
+def labels_to_rttmfile(labels, uniq_id, out_rttm_dir):
     """
-    Generate connections until fully connect all the nodes in the graph.
-    If graph is not fully connected, it might generate an inaccurate results.
+    write rttm file with uniq_id name in out_rttm_dir with time_stamps in labels
     """
-    p_value = 1
-    affinity_mat = getAffinityGraphMat(mat, p_value)
-    for i, p_value in enumerate(n_list):
-        fully_connected = isGraphFullyConnected(affinity_mat)
-        affinity_mat = getAffinityGraphMat(mat, p_value)
-        if fully_connected or p_value > max_N:
-            break
+    filename = os.path.join(out_rttm_dir, uniq_id + '.rttm')
+    with open(filename, 'w') as f:
+        for line in labels:
+            line = line.strip()
+            start, end, speaker = line.split()
+            duration = float(end) - float(start)
+            start = float(start)
+            log = 'SPEAKER {} 1   {:.3f}   {:.3f} <NA> <NA> {} <NA> <NA>\n'.format(uniq_id, start, duration, speaker)
+            f.write(log)
 
-    return affinity_mat, p_value
+    return filename
 
 
-def getRepeatedList(mapping_argmat, score_mat_size):
+def rttm_to_labels(rttm_filename):
     """
-    Count the numbers in the mapping dictionary and create lists that contain
-    repeated indices to be used for creating the repeated affinity matrix for
-    fusing the affinity values.
+    prepares time stamps label list from rttm file
     """
-    count_dict = dict(Counter(mapping_argmat))
-    repeat_list = []
-    for k in range(score_mat_size):
-        if k in count_dict:
-            repeat_list.append(count_dict[k])
-        else:
-            repeat_list.append(0)
-    return repeat_list
+    labels = []
+    with open(rttm_filename, 'r') as f:
+        for line in f.readlines():
+            rttm = line.strip().split()
+            start, end, speaker = float(rttm[3]), float(rttm[4]) + float(rttm[3]), rttm[7]
+            labels.append('{} {} {}'.format(start, end, speaker))
+    return labels
 
 
-def get_argmin_mat(uniq_scale_dict):
+def write_cluster_labels(base_scale_idx, lines_cluster_labels, out_rttm_dir):
     """
-    Calculate the mapping between the base scale and other scales. A segment from a longer scale is
-    repeatedly mapped to a segment from a shorter scale or the base scale.
 
+    Write cluster labels that are generated from clustering into a file.
     Args:
-        uniq_scale_dict (dict) :
-            Dictionary of embeddings and timestamps for each scale.
-
-    Returns:
-        session_scale_mapping_dict (dict) :
-            Dictionary containing argmin arrays indexed by scale index.
+        base_scale_idx (int): The base scale index which is the highest scale index.
+        lines_cluster_labels (list): The start and end time-stamps of each segment with the predicted cluster label.
+        out_rttm_dir (str): The path where output rttm files are saved.
     """
-    scale_list = sorted(list(uniq_scale_dict.keys()))
-    segment_anchor_dict = {}
-    for scale_idx in scale_list:
-        time_stamp_list = uniq_scale_dict[scale_idx]['time_stamps']
-        time_stamps_float = np.array([[float(x.split()[0]), float(x.split()[1])] for x in time_stamp_list])
-        segment_anchor_dict[scale_idx] = np.mean(time_stamps_float, axis=1)
-
-    base_scale_idx = max(scale_list)
-    base_scale_anchor = segment_anchor_dict[base_scale_idx]
-    session_scale_mapping_dict = {}
-    for scale_idx in scale_list:
-        curr_scale_anchor = segment_anchor_dict[scale_idx]
-        curr_mat = np.tile(curr_scale_anchor, (base_scale_anchor.shape[0], 1))
-        base_mat = np.tile(base_scale_anchor, (curr_scale_anchor.shape[0], 1)).T
-        argmin_mat = np.argmin(np.abs(curr_mat - base_mat), axis=1)
-        session_scale_mapping_dict[scale_idx] = argmin_mat
-    return session_scale_mapping_dict
+    out_label_name = os.path.join(
+        out_rttm_dir, '../speaker_outputs', f'subsegments_scale{base_scale_idx}_cluster.label'
+    )
+    with open(out_label_name, 'w') as f:
+        for clus_label_line in lines_cluster_labels:
+            f.write(clus_label_line)
 
 
-def getMultiScaleCosAffinityMatrix(uniq_embs_and_timestamps):
+def perform_clustering(embs_and_timestamps, AUDIO_RTTM_MAP, out_rttm_dir, clustering_params):
     """
-    Calculate cosine similarity values among speaker embeddings for each scale then
-    apply multiscale weights to calculate the fused similarity matrix.
+    performs spectral clustering on embeddings with time stamps generated from VAD output
 
     Args:
-        uniq_embs_and_timestamps: (dict)
-            The dictionary containing embeddings, timestamps and multiscale weights.
-            If uniq_embs_and_timestamps contains only one scale, single scale diarization 
-            is performed.
+        embs_and_timestamps (dict): This dictionary contains the following items indexed by unique IDs.
+            'embeddings' : Embeddings with key as unique_id
+            'time_stamps' : Time stamps list for each audio recording
+        AUDIO_RTTM_MAP (dict): AUDIO_RTTM_MAP for mapping unique id with audio file path and rttm path
+        out_rttm_dir (str): Path to write predicted rttms
+        clustering_params (dict): clustering parameters provided through config that contains max_num_speakers (int),
+        oracle_num_speakers (bool), max_rp_threshold(float), sparse_search_volume(int) and enhance_count_threshold (int)
 
     Returns:
-        fused_sim_d (np.array):
-            This function generates an ffinity matrix that is obtained by calculating
-            the weighted sum of the affinity matrices from the different scales.
-        base_scale_emb (np.array):
-            The base scale embedding (the embeddings from the finest scale)
-    """
-    uniq_scale_dict = uniq_embs_and_timestamps['scale_dict']
-    base_scale_idx = max(uniq_scale_dict.keys())
-    base_scale_emb = np.array(uniq_scale_dict[base_scale_idx]['embeddings'])
-    multiscale_weights = uniq_embs_and_timestamps['multiscale_weights']
-    score_mat_list, repeated_mat_list = [], []
-
-    session_scale_mapping_dict = get_argmin_mat(uniq_scale_dict)
-    for scale_idx in sorted(uniq_scale_dict.keys()):
-        mapping_argmat = session_scale_mapping_dict[scale_idx]
-        score_mat = getCosAffinityMatrix(uniq_scale_dict[scale_idx]['embeddings'])
-        score_mat_list.append(score_mat)
-        repeat_list = getRepeatedList(mapping_argmat, score_mat.shape[0])
-        repeated_mat = np.repeat(np.repeat(score_mat, repeat_list, axis=0), repeat_list, axis=1)
-        repeated_mat_list.append(repeated_mat)
-
-    fused_sim_d = np.average(np.array(repeated_mat_list), weights=multiscale_weights, axis=0)
-    return fused_sim_d, base_scale_emb
-
-
-def addAnchorEmb(emb, anchor_sample_n, anchor_spk_n, sigma):
-    """
-    Add randomly generated synthetic embeddings to make eigen analysis more stable.
-    We refer to these embeddings as anchor embeddings.
-
-    emb (np.array):
-        The input embedding from the emebedding extractor.
-
-    anchor_sample_n (int):
-        The number of embedding samples per speaker.
-        anchor_sample_n = 10 is recommended.
-
-    anchor_spk_n (int):
-        The number of speakers for synthetic embedding.
-        anchor_spk_n = 3 is recommended.
-
-    sigma (int):
-        The amplitude of synthetic noise for each embedding vector.
-        If sigma value is too small, under-counting could happen.
-        If sigma value is too large, over-counting could happen.
-        sigma = 50 is recommended.
-
-    """
-    emb_dim = emb.shape[1]
-    std_org = np.std(emb, axis=0)
-    new_emb_list = []
-    for _ in range(anchor_spk_n):
-        emb_m = np.tile(np.random.randn(1, emb_dim), (anchor_sample_n, 1))
-        emb_noise = np.random.randn(anchor_sample_n, emb_dim).T
-        emb_noise = np.dot(np.diag(std_org), emb_noise / np.max(np.abs(emb_noise))).T
-        emb_gen = emb_m + sigma * emb_noise
-        new_emb_list.append(emb_gen)
-
-    new_emb_list.append(emb)
-    new_emb_np = np.vstack(new_emb_list)
-    return new_emb_np
-
-
-def getEnhancedSpeakerCount(emb, cuda, random_test_count=5, anchor_spk_n=3, anchor_sample_n=10, sigma=50):
-    """
-    Calculate the number of speakers using NME analysis with anchor embeddings.
-    """
-    est_num_of_spk_list = []
-    for seed in range(random_test_count):
-        np.random.seed(seed)
-        emb_aug = addAnchorEmb(emb, anchor_sample_n, anchor_spk_n, sigma)
-        mat = getCosAffinityMatrix(emb_aug)
-        nmesc = NMESC(
-            mat,
-            max_num_speaker=emb.shape[0],
-            max_rp_threshold=0.25,
-            sparse_search=True,
-            sparse_search_volume=30,
-            fixed_thres=None,
-            NME_mat_size=300,
+        all_reference (list[uniq_name,Annotation]): reference annotations for score calculation
+        all_hypothesis (list[uniq_name,Annotation]): hypothesis annotations for score calculation
+
+    """
+    all_hypothesis = []
+    all_reference = []
+    no_references = False
+    max_num_speakers = clustering_params['max_num_speakers']
+    lines_cluster_labels = []
+
+    cuda = True
+    if not torch.cuda.is_available():
+        logging.warning("cuda=False, using CPU for Eigen decompostion. This might slow down the clustering process.")
+        cuda = False
+
+    for uniq_id, value in tqdm(AUDIO_RTTM_MAP.items()):
+        if clustering_params.oracle_num_speakers:
+            num_speakers = value.get('num_speakers', None)
+            if num_speakers is None:
+                raise ValueError("Provided option as oracle num of speakers but num_speakers in manifest is null")
+        else:
+            num_speakers = None
+
+        cluster_labels = COSclustering(
+            uniq_embs_and_timestamps=embs_and_timestamps[uniq_id],
+            oracle_num_speakers=num_speakers,
+            max_num_speaker=max_num_speakers,
+            enhanced_count_thres=clustering_params.enhanced_count_thres,
+            max_rp_threshold=clustering_params.max_rp_threshold,
+            sparse_search_volume=clustering_params.sparse_search_volume,
             cuda=cuda,
         )
-        est_num_of_spk, _ = nmesc.NMEanalysis()
-        est_num_of_spk_list.append(est_num_of_spk)
 
-    ctt = Counter(est_num_of_spk_list)
-    oracle_num_speakers = max(ctt.most_common(1)[0][0] - anchor_spk_n, 1)
-    return oracle_num_speakers
+        base_scale_idx = max(embs_and_timestamps[uniq_id]['scale_dict'].keys())
+        lines = embs_and_timestamps[uniq_id]['scale_dict'][base_scale_idx]['time_stamps']
+        assert len(cluster_labels) == len(lines)
+        for idx, label in enumerate(cluster_labels):
+            tag = 'speaker_' + str(label)
+            lines[idx] += tag
+        a = get_contiguous_stamps(lines)
+        labels = merge_stamps(a)
+        if out_rttm_dir:
+            labels_to_rttmfile(labels, uniq_id, out_rttm_dir)
+            lines_cluster_labels.extend([f'{uniq_id} {seg_line}\n' for seg_line in lines])
+        hypothesis = labels_to_pyannote_object(labels, uniq_name=uniq_id)
+        all_hypothesis.append([uniq_id, hypothesis])
+
+        rttm_file = value.get('rttm_filepath', None)
+        if rttm_file is not None and os.path.exists(rttm_file) and not no_references:
+            ref_labels = rttm_to_labels(rttm_file)
+            reference = labels_to_pyannote_object(ref_labels, uniq_name=uniq_id)
+            all_reference.append([uniq_id, reference])
+        else:
+            no_references = True
+            all_reference = []
 
+    if out_rttm_dir:
+        write_cluster_labels(base_scale_idx, lines_cluster_labels, out_rttm_dir)
 
-def getCosAffinityMatrix(emb):
-    """
-    Calculate cosine similarity values among speaker embeddings.
-    """
-    sim_d = cosine_similarity(emb)
-    scaler.fit(sim_d)
-    sim_d = scaler.transform(sim_d)
-    return sim_d
+    return all_reference, all_hypothesis
 
 
-def getLaplacian(X):
+def score_labels(AUDIO_RTTM_MAP, all_reference, all_hypothesis, collar=0.25, ignore_overlap=True):
     """
-    Calculate a laplacian matrix from an affinity matrix X.
-    """
-    X[np.diag_indices(X.shape[0])] = 0
-    A = X
-    D = np.sum(np.abs(A), axis=1)
-    D = np.diag(D)
-    L = D - A
-    return L
-
-
-def eigDecompose(laplacian, cuda, device=None):
-    if TORCH_EIGN:
-        if cuda:
-            if device is None:
-                device = torch.cuda.current_device()
-            laplacian = torch.from_numpy(laplacian).float().to(device)
-        else:
-            laplacian = torch.from_numpy(laplacian).float()
-        lambdas, diffusion_map = eigh(laplacian)
-        lambdas = lambdas.cpu().numpy()
-        diffusion_map = diffusion_map.cpu().numpy()
-    else:
-        lambdas, diffusion_map = eigh(laplacian)
+    calculates DER, CER, FA and MISS
 
-    return lambdas, diffusion_map
+    Args:
+    AUDIO_RTTM_MAP : Dictionary containing information provided from manifestpath
+    all_reference (list[uniq_name,Annotation]): reference annotations for score calculation
+    all_hypothesis (list[uniq_name,Annotation]): hypothesis annotations for score calculation
 
+    Returns:
+    metric (pyannote.DiarizationErrorRate): Pyannote Diarization Error Rate metric object. This object contains detailed scores of each audiofile.
+    mapping (dict): Mapping dict containing the mapping speaker label for each audio input
 
-def getLamdaGaplist(lambdas):
-    lambdas = np.real(lambdas)
-    return list(lambdas[1:] - lambdas[:-1])
-
-
-def estimateNumofSpeakers(affinity_mat, max_num_speaker, is_cuda=False):
-    """
-    Estimate the number of speakers using eigen decompose on laplacian Matrix.
-    affinity_mat: (array)
-        NxN affitnity matrix
-    max_num_speaker: (int)
-        Maximum number of clusters to consider for each session
-    is_cuda: (bool)
-        if cuda availble eigh decomposition would be computed on GPUs
-    """
-    laplacian = getLaplacian(affinity_mat)
-    lambdas, _ = eigDecompose(laplacian, is_cuda)
-    lambdas = np.sort(lambdas)
-    lambda_gap_list = getLamdaGaplist(lambdas)
-    num_of_spk = np.argmax(lambda_gap_list[: min(max_num_speaker, len(lambda_gap_list))]) + 1
-    return num_of_spk, lambdas, lambda_gap_list
-
-
-class _SpectralClustering:
-    def __init__(self, n_clusters=8, random_state=0, n_init=10, p_value=10, n_jobs=None, cuda=False):
-        self.n_clusters = n_clusters
-        self.random_state = random_state
-        self.n_init = n_init
-        self.p_value = p_value
-        self.affinity_matrix_ = None
-        self.cuda = cuda
-
-    def predict(self, X):
-        if X.shape[0] != X.shape[1]:
-            raise ValueError("The affinity matrix is not a square matrix.")
-
-        self.affinity_matrix_ = X
-        labels = self.clusterSpectralEmbeddings(self.affinity_matrix_, n_init=self.n_init, cuda=self.cuda)
-        return labels
-
-    def clusterSpectralEmbeddings(self, affinity, n_init=10, cuda=False):
-        spectral_emb = self.getSpectralEmbeddings(affinity, n_spks=self.n_clusters, drop_first=False, cuda=cuda)
-        _, labels, _ = k_means(spectral_emb, self.n_clusters, random_state=self.random_state, n_init=n_init)
-        return labels
-
-    def getSpectralEmbeddings(self, affinity_mat, n_spks=8, drop_first=True, cuda=False):
-        if not isGraphFullyConnected(affinity_mat):
-            logging.warning("Graph is not fully connected and the clustering result might not be accurate.")
-
-        laplacian = getLaplacian(affinity_mat)
-        lambdas_, diffusion_map_ = eigDecompose(laplacian, cuda)
-        diffusion_map = diffusion_map_[:, :n_spks]
-        embedding = diffusion_map.T[n_spks::-1]
-        return embedding[:n_spks].T
-
-
-class NMESC:
-    """
-    Normalized Maximum Eigengap based Spectral Clustering (NME-SC)
-    uses Eigengap analysis to get an estimated p-value for
-    affinity binarization and an estimated number of speakers.
-
-    p_value (also referred to as p_neighbors) is for taking
-    top p number of affinity values and convert those to 1 while
-    convert the rest of values to 0.
-
-    p_value can be also tuned on a development set without performing
-    NME-analysis.
-
-    Reference: Auto-Tuning Spectral Clustering for Speaker Diarization
-    Using Normalized Maximum Eigengap (https://arxiv.org/abs/2003.02405)
-
-    Parameters:
-        Please refer to def __init__()
-
-    Methods:
-        NMEanalysis():
-            Performs NME-analysis to estimate p_value and the number of speakers.
-
-        subsampleAffinityMat(NME_mat_size):
-            Subsamples the number of speakers to reduce the computational load.
-
-        getPvalueList():
-            Generates a list contains p-values that need to be examined.
-
-        getEigRatio(p_neighbors):
-            calculates g_p, which is a ratio between p_neighbors and the maximum eigengap.
-
-        getLamdaGaplist(lambdas):
-            Calculates lambda gap values from an array contains ambda values.
-
-        estimateNumofSpeakers(affinity_mat):
-            Estimates the number of speakers using lambda gap list.
-
-    """
-
-    def __init__(
-        self,
-        mat,
-        max_num_speaker=10,
-        max_rp_threshold=0.250,
-        sparse_search=True,
-        sparse_search_volume=30,
-        use_subsampling_for_NME=True,
-        fixed_thres=None,
-        cuda=False,
-        NME_mat_size=512,
-    ):
-        """
-        Parameters:
-            mat: (numpy.array)
-                Cosine similarity matrix calculated from speaker embeddings.
-
-            max_num_speaker: (int)
-                Maximum number of speakers for estimating number of speakers.
-                Shows stable performance under 20.
-
-            max_rp_threshold: (float)
-                Limits the range of parameter search.
-                Clustering performance can vary depending on this range.
-                Default is 0.25.
-
-            sparse_search: (bool)
-                To increase the speed of parameter estimation, sparse_search=True
-                limits the number of p_values we search.
-
-            sparse_search_volume: (int)
-                The number of p_values we search during NME analysis.
-                Default is 30. The lower the value, the faster NME-analysis becomes.
-                Lower than 20 might cause a poor parameter estimation.
-
-            use_subsampling_for_NME: (bool)
-                Use subsampling to reduce the calculational complexity.
-                Default is True.
-
-            fixed_thres: (float or None)
-                A fixed threshould can be used instead of estimating the
-                threshold with NME analysis. If fixed_thres is float,
-                it skips NME analysis part.
-
-            cuda: (bool)
-                Use cuda for Eigen decomposition if cuda=True.
-
-            NME_mat_size: (int)
-                Targeted size of matrix for NME analysis.
-
-
-        """
-        self.max_num_speaker = max_num_speaker
-        self.max_rp_threshold = max_rp_threshold
-        self.use_subsampling_for_NME = use_subsampling_for_NME
-        self.NME_mat_size = NME_mat_size
-        self.sparse_search = sparse_search
-        self.sparse_search_volume = sparse_search_volume
-        self.fixed_thres = fixed_thres
-        self.cuda = cuda
-        self.eps = 1e-10
-        self.max_N = None
-        self.mat = mat
-        self.p_value_list = []
-
-    def NMEanalysis(self):
-        """
-        Subsample the input matrix to reduce the computational load.
-        """
-        if self.use_subsampling_for_NME:
-            subsample_ratio = self.subsampleAffinityMat(self.NME_mat_size)
-
-        # Scans p_values and find a p_value that generates
-        # the smallest g_p value.
-        eig_ratio_list, est_spk_n_dict = [], {}
-        self.p_value_list = self.getPvalueList()
-        for p_value in self.p_value_list:
-            est_num_of_spk, g_p = self.getEigRatio(p_value)
-            est_spk_n_dict[p_value] = est_num_of_spk
-            eig_ratio_list.append(g_p)
-
-        index_nn = np.argmin(eig_ratio_list)
-        rp_p_value = self.p_value_list[index_nn]
-        affinity_mat = getAffinityGraphMat(self.mat, rp_p_value)
-
-        # Checks whether affinity graph is fully connected.
-        # If not, it adds minimum number of connections to make it fully connected.
-        if not isGraphFullyConnected(affinity_mat):
-            affinity_mat, rp_p_value = getMinimumConnection(self.mat, self.max_N, self.p_value_list)
-
-        p_hat_value = int(subsample_ratio * rp_p_value)
-        est_num_of_spk = est_spk_n_dict[rp_p_value]
-        return est_num_of_spk, p_hat_value
-
-    def subsampleAffinityMat(self, NME_mat_size):
-        """
-        Perform Subsampling of affinity matrix.
-        This subsampling is for calculational complexity, not for performance.
-        The smaller NME_mat_size is,
-            - the bigger the chance of missing a speaker.
-            - the faster p-value estimation speed (based on eigen decomposition).
-
-        Recommended NME_mat_size is 250~750.
-        However, if there are speakers who speak for very short period of time in the recording,
-        this subsampling might make the system miss the underrepresented speaker.
-        Use this with caution.
-
-        Parameters:
-            NME_mat_size: (int)
-                Targeted matrix size
-
-        Returns:
-            subsample_ratio : (float)
-                The ratio between NME_mat_size and the original matrix size
-
-        """
-        subsample_ratio = int(max(1, self.mat.shape[0] / NME_mat_size))
-        self.mat = self.mat[::subsample_ratio, ::subsample_ratio]
-        return subsample_ratio
-
-    def getEigRatio(self, p_neighbors):
-        """
-        For a given p_neighbors value,
-        calculates g_p, which is a ratio
-        between p_neighbors and the maximum eigengap.
-
-        For more details: https://arxiv.org/abs/2003.02405
-
-        Parameters:
-            p_neighbors: (int)
-                Determines how many binary graph connections we want to keep for each row.
-
-        Returns:
-            est_num_of_spk: (int)
-                Estimated number of speakers
-
-            g_p: (float)
-                The ratio between p_neighbors value and the maximum eigen gap value.
-        """
-
-        affinity_mat = getAffinityGraphMat(self.mat, p_neighbors)
-        est_num_of_spk, lambdas, lambda_gap_list = estimateNumofSpeakers(affinity_mat, self.max_num_speaker, self.cuda)
-        arg_sorted_idx = np.argsort(lambda_gap_list[: self.max_num_speaker])[::-1]
-        max_key = arg_sorted_idx[0]
-        max_eig_gap = lambda_gap_list[max_key] / (max(lambdas) + self.eps)
-        g_p = (p_neighbors / self.mat.shape[0]) / (max_eig_gap + self.eps)
-
-        return est_num_of_spk, g_p
-
-    def getPvalueList(self):
-        """
-        Generates a p-value (p_neighbour) list for searching.
-        """
-        if self.fixed_thres:
-            p_value_list = [int(self.mat.shape[0] * self.fixed_thres)]
-            self.max_N = p_value_list[0]
-        else:
-            self.max_N = int(self.mat.shape[0] * self.max_rp_threshold)
-            if self.sparse_search:
-                N = min(self.max_N, self.sparse_search_volume)
-                p_value_list = list(np.linspace(1, self.max_N, N, endpoint=True).astype(int))
-            else:
-                p_value_list = list(range(1, self.max_N))
+    < Caveat >
+    Unlike md-eval.pl, "no score" collar in pyannote.metrics is the maximum length of
+    "no score" collar from left to right. Therefore, if 0.25s is applied for "no score"
+    collar in md-eval.pl, 0.5s should be applied for pyannote.metrics.
+
+    """
+    metric = None
+    if len(all_reference) == len(all_hypothesis):
+        metric = DiarizationErrorRate(collar=2 * collar, skip_overlap=ignore_overlap)
+
+        mapping_dict = {}
+        for (reference, hypothesis) in zip(all_reference, all_hypothesis):
+            ref_key, ref_labels = reference
+            _, hyp_labels = hypothesis
+            uem = AUDIO_RTTM_MAP[ref_key].get('uem_filepath', None)
+            if uem is not None:
+                uem = uem_timeline_from_file(uem_file=uem, uniq_name=ref_key)
+            metric(ref_labels, hyp_labels, uem=uem, detailed=True)
+            mapping_dict[ref_key] = metric.optimal_mapping(ref_labels, hyp_labels)
+
+        DER = abs(metric)
+        CER = metric['confusion'] / metric['total']
+        FA = metric['false alarm'] / metric['total']
+        MISS = metric['missed detection'] / metric['total']
+
+        logging.info(
+            "Cumulative Results for collar {} sec and ignore_overlap {}: \n FA: {:.4f}\t MISS {:.4f}\t \
+                Diarization ER: {:.4f}\t, Confusion ER:{:.4f}".format(
+                collar, ignore_overlap, FA, MISS, DER, CER
+            )
+        )
 
-        return p_value_list
+        return metric, mapping_dict
+    else:
+        logging.warning(
+            "check if each ground truth RTTMs were present in provided manifest file. Skipping calculation of Diariazation Error Rate"
+        )
 
-    # emb,
+        return None
 
 
-def COSclustering(
-    uniq_embs_and_timestamps=None,
-    oracle_num_speakers=None,
-    max_num_speaker=8,
-    min_samples_for_NMESC=6,
-    enhanced_count_thres=80,
-    max_rp_threshold=0.25,
-    sparse_search_volume=30,
-    fixed_thres=None,
-    cuda=False,
-):
+def write_rttm2manifest(AUDIO_RTTM_MAP, manifest_file):
     """
-    Clustering method for speaker diarization based on cosine similarity.
+    writes manifest file based on rttm files (or vad table out files). This manifest file would be used by 
+    speaker diarizer to compute embeddings and cluster them. This function also takes care of overlap time stamps
 
-    Parameters:
-        uniq_embs_and_timestamps: (dict)
-            The dictionary containing embeddings, timestamps and multiscale weights.
-            If uniq_embs_and_timestamps contains only one scale, single scale diarization 
-            is performed.
-
-        oracle_num_speaker: (int or None)
-            Oracle number of speakers if known else None
-
-        max_num_speaker: (int)
-            Maximum number of clusters to consider for each session
-
-        min_samples_for_NMESC: (int)
-            Minimum number of samples required for NME clustering, this avoids
-            zero p_neighbour_lists. If the input has fewer segments than min_samples,
-            it is directed to the enhanced speaker counting mode.
-
-        enhanced_count_thres: (int)
-            For short audio recordings under 60 seconds, clustering algorithm cannot
-            accumulate enough amount of speaker profile for each cluster.
-            Thus, getEnhancedSpeakerCount() employs anchor embeddings (dummy representations)
-            to mitigate the effect of cluster sparsity.
-            enhanced_count_thres = 80 is recommended.
-
-        max_rp_threshold: (float)
-            Limits the range of parameter search.
-            Clustering performance can vary depending on this range.
-            Default is 0.25.
-
-        sparse_search_volume: (int)
-            The number of p_values we search during NME analysis.
-            Default is 30. The lower the value, the faster NME-analysis becomes.
-            Lower than 20 might cause a poor parameter estimation.
-
-        fixed_thres: (float)
-            If fixed_thres value is provided, NME-analysis process will be skipped.
-            This value should be optimized on a development set to obtain a quality result.
-            Default is None and performs NME-analysis to estimate the threshold.
+    Args:
+    AUDIO_RTTM_MAP: dict containing keys to uniqnames, that contains audio filepath and rttm_filepath as its contents,
+    these are used to extract oracle vad timestamps.
+    manifest (str): path to write manifest file
 
     Returns:
-        Y: (List[int])
-            Speaker label for each segment.
+    manifest (str): path to write manifest file
     """
-    # Get base-scale embedding from uniq_embs_and_timestamps.
-    uniq_scale_dict = uniq_embs_and_timestamps['scale_dict']
-    emb = np.array(uniq_scale_dict[max(uniq_scale_dict.keys())]['embeddings'])
-
-    if emb.shape[0] == 1:
-        return np.array([0])
-    elif emb.shape[0] <= max(enhanced_count_thres, min_samples_for_NMESC) and oracle_num_speakers is None:
-        est_num_of_spk_enhanced = getEnhancedSpeakerCount(emb, cuda)
-    else:
-        est_num_of_spk_enhanced = None
-
-    if oracle_num_speakers:
-        max_num_speaker = oracle_num_speakers
 
-    mat, emb = getMultiScaleCosAffinityMatrix(uniq_embs_and_timestamps)
-
-    nmesc = NMESC(
-        mat,
-        max_num_speaker=max_num_speaker,
-        max_rp_threshold=max_rp_threshold,
-        sparse_search=True,
-        sparse_search_volume=sparse_search_volume,
-        fixed_thres=fixed_thres,
-        NME_mat_size=300,
-        cuda=cuda,
-    )
+    with open(manifest_file, 'w') as outfile:
+        for key in AUDIO_RTTM_MAP:
+            rttm_filename = AUDIO_RTTM_MAP[key]['rttm_filepath']
+            if rttm_filename and os.path.exists(rttm_filename):
+                f = open(rttm_filename, 'r')
+            else:
+                raise FileNotFoundError(
+                    "Requested to construct manifest from rttm with oracle VAD option or from NeMo VAD but received filename as {}".format(
+                        rttm_filename
+                    )
+                )
+
+            audio_path = AUDIO_RTTM_MAP[key]['audio_filepath']
+            if AUDIO_RTTM_MAP[key].get('duration', None):
+                max_duration = AUDIO_RTTM_MAP[key]['duration']
+            else:
+                sound = sf.SoundFile(audio_path)
+                max_duration = sound.frames / sound.samplerate
 
-    if emb.shape[0] > min_samples_for_NMESC:
-        est_num_of_spk, p_hat_value = nmesc.NMEanalysis()
-        affinity_mat = getAffinityGraphMat(mat, p_hat_value)
-    else:
-        affinity_mat = mat
+            lines = f.readlines()
+            time_tup = (-1, -1)
+            for line in lines:
+                vad_out = line.strip().split()
+                if len(vad_out) > 3:
+                    start, dur, _ = float(vad_out[3]), float(vad_out[4]), vad_out[7]
+                else:
+                    start, dur, _ = float(vad_out[0]), float(vad_out[1]), vad_out[2]
+                start, dur = float("{:.3f}".format(start)), float("{:.3f}".format(dur))
+
+                if start == 0 and dur == 0:  # No speech segments
+                    continue
+                else:
+
+                    if time_tup[0] >= 0 and start > time_tup[1]:
+                        dur2 = float("{:.3f}".format(time_tup[1] - time_tup[0]))
+                        if time_tup[0] < max_duration and dur2 > 0:
+                            meta = {
+                                "audio_filepath": audio_path,
+                                "offset": time_tup[0],
+                                "duration": dur2,
+                                "label": 'UNK',
+                            }
+                            json.dump(meta, outfile)
+                            outfile.write("\n")
+                        else:
+                            logging.warning(
+                                "RTTM label has been truncated since start is greater than duration of audio file"
+                            )
+                        time_tup = (start, start + dur)
+                    else:
+                        if time_tup[0] == -1:
+                            end_time = start + dur
+                            if end_time > max_duration:
+                                end_time = max_duration
+                            time_tup = (start, end_time)
+                        else:
+                            end_time = max(time_tup[1], start + dur)
+                            if end_time > max_duration:
+                                end_time = max_duration
+                            time_tup = (min(time_tup[0], start), end_time)
+            dur2 = float("{:.3f}".format(time_tup[1] - time_tup[0]))
+            if time_tup[0] < max_duration and dur2 > 0:
+                meta = {"audio_filepath": audio_path, "offset": time_tup[0], "duration": dur2, "label": 'UNK'}
+                json.dump(meta, outfile)
+                outfile.write("\n")
+            else:
+                logging.warning("RTTM label has been truncated since start is greater than duration of audio file")
+            f.close()
+    return manifest_file
 
-    if oracle_num_speakers:
-        est_num_of_spk = oracle_num_speakers
-    elif est_num_of_spk_enhanced:
-        est_num_of_spk = est_num_of_spk_enhanced
 
-    spectral_model = _SpectralClustering(n_clusters=est_num_of_spk, cuda=cuda)
-    Y = spectral_model.predict(affinity_mat)
+def segments_manifest_to_subsegments_manifest(
+    segments_manifest_file: str,
+    subsegments_manifest_file: str = None,
+    window: float = 1.5,
+    shift: float = 0.75,
+    min_subsegment_duration: float = 0.05,
+):
+    """
+    Generate subsegments manifest from segments manifest file
+    Args
+    input:
+        segments_manifest file (str): path to segments manifest file, typically from VAD output
+        subsegments_manifest_file (str): path to output subsegments manifest file (default (None) : writes to current working directory)
+        window (float): window length for segments to subsegments length
+        shift (float): hop length for subsegments shift
+        min_subsegments_duration (float): exclude subsegments smaller than this duration value
+
+    output:
+        returns path to subsegment manifest file
+    """
+    if subsegments_manifest_file is None:
+        pwd = os.getcwd()
+        subsegments_manifest_file = os.path.join(pwd, 'subsegments.json')
+
+    with open(segments_manifest_file, 'r') as segments_manifest, open(
+        subsegments_manifest_file, 'w'
+    ) as subsegments_manifest:
+        segments = segments_manifest.readlines()
+        for segment in segments:
+            segment = segment.strip()
+            dic = json.loads(segment)
+            audio, offset, duration, label = dic['audio_filepath'], dic['offset'], dic['duration'], dic['label']
+            subsegments = get_subsegments(offset=offset, window=window, shift=shift, duration=duration)
+
+            for subsegment in subsegments:
+                start, dur = subsegment
+                if dur > min_subsegment_duration:
+                    meta = {"audio_filepath": audio, "offset": start, "duration": dur, "label": label}
+                    json.dump(meta, subsegments_manifest)
+                    subsegments_manifest.write("\n")
+
+    return subsegments_manifest_file
+
+
+def get_subsegments(offset: float, window: float, shift: float, duration: float):
+    """
+    return subsegments from a segment of audio file
+    Args
+    input:
+        offset (float): start time of audio segment
+        window (float): window length for segments to subsegments length
+        shift (float): hop length for subsegments shift
+        duration (float): duration of segment
+    output:
+        subsegments (List[tuple[float, float]]): subsegments generated for the segments as list of tuple of start and duration of each subsegment
+    """
+    subsegments = []
+    start = offset
+    slice_end = start + duration
+    base = math.ceil((duration - window) / shift)
+    slices = 1 if base < 0 else base + 1
+    for slice_id in range(slices):
+        end = start + window
+        if end > slice_end:
+            end = slice_end
+        subsegments.append((start, end - start))
+        start = offset + (slice_id + 1) * shift
+
+    return subsegments
+
+
+def embedding_normalize(embs, use_std=False, eps=1e-10):
+    """
+    mean and l2 length normalize the input speaker embeddings
+    input:
+        embs: embeddings of shape (Batch,emb_size)
+    output:
+        embs: normalized embeddings of shape (Batch,emb_size)
+    """
+    embs = embs - embs.mean(axis=0)
+    if use_std:
+        embs = embs / (embs.std(axis=0) + eps)
+    embs_l2_norm = np.expand_dims(np.linalg.norm(embs, ord=2, axis=-1), axis=1)
+    embs = embs / embs_l2_norm
 
-    return Y
+    return embs
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/numba_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/numba_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/rnnt_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/rnnt_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/streaming_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/streaming_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/transcribe_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/transcribe_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/asr/parts/utils/vad_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/parts/utils/vad_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -9,18 +9,20 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import glob
 import json
+import math
+import multiprocessing
 import os
 import shutil
 from itertools import repeat
-from multiprocessing import Pool
+from typing import Dict, Tuple
 
 import IPython.display as ipd
 import librosa
 import matplotlib.pyplot as plt
 import numpy as np
 import pandas as pd
 import torch
@@ -42,21 +44,21 @@
 
 
 """
 This file contains all the utility functions required for voice activity detection. 
 """
 
 
-def prepare_manifest(config):
+def prepare_manifest(config: dict) -> str:
     """
     Perform VAD on long audio snippet might cause CUDA out of memory issue. 
     Automatically split manifest entry by split_duration to avoid the potential memory issue.
     """
-    if 'prepared_manfiest_vad_input' in config and config['prepared_manfiest_vad_input']:
-        manifest_vad_input = config['prepared_manfiest_vad_input']
+    if 'prepared_manifest_vad_input' in config and config['prepared_manifest_vad_input']:
+        manifest_vad_input = config['prepared_manifest_vad_input']
     else:
         manifest_vad_input = "manifest_vad_input.json"
 
     # input_list is a list of variable ['audio_filepath': i, "offset": xxx, "duration": xxx])
     if type(config['input']) == str:
         input_list = []
         with open(config['input'], 'r', encoding='utf-8') as manifest:
@@ -65,15 +67,15 @@
     elif type(config['input']) == list:
         input_list = config['input']
     else:
         raise ValueError(
             "The input for manifest preparation would either be a string of the filepath to manifest or a list of {'audio_filepath': i, 'offset': 0, 'duration': null} "
         )
 
-    p = Pool(processes=config['num_workers'])
+    p = multiprocessing.Pool(processes=config['num_workers'])
     args_func = {
         'label': 'infer',
         'split_duration': config['split_duration'],
         'window_length_in_sec': config['window_length_in_sec'],
     }
 
     results = p.starmap(write_vad_infer_manifest, zip(input_list, repeat(args_func)))
@@ -88,33 +90,34 @@
             for r in res:
                 json.dump(r, fout)
                 fout.write('\n')
                 fout.flush()
     return manifest_vad_input
 
 
-def write_vad_infer_manifest(file, args_func):
+def write_vad_infer_manifest(file: dict, args_func: dict) -> list:
     """
     Used by prepare_manifest.
-    Given a list of files, write them to manifest for dataloader with restrictions.
+    Given a list of files, split them with maximum split_duration and write them to the manifest.
     Args:
-        files (json) : file to be processed
-        label (str): label for audio snippet.
-        split_duration (float): max duration of each audio clip (each line in json)
-        window_length_in_sec (float) : length of window for generating the frame. Used for taking care of joint. 
+        files (dict) : file to be processed
+        args_func:
+            label (str): label for audio snippet.y
+            split_duration (float): max duration of each audio clip (each line in json)
+            window_length_in_sec (float) : length of window for generating the frame. Used for taking care of joint. 
     Returns:
         res (list) : list of generated metadata line of json for file
     """
     res = []
     label = args_func['label']
     split_duration = args_func['split_duration']
     window_length_in_sec = args_func['window_length_in_sec']
     filepath = file['audio_filepath']
-    in_duration = file['duration']
-    in_offset = file['offset']
+    in_duration = file.get('duration', None)
+    in_offset = file.get('offset', 0)
 
     try:
         sr = 16000
         x, _sr = librosa.load(filepath, sr=sr, offset=in_offset, duration=in_duration)
         duration = librosa.get_duration(y=x, sr=sr)
         left = duration
         current_offset = in_offset
@@ -161,18 +164,18 @@
     except Exception as e:
         err_file = "error.log"
         with open(err_file, 'w', encoding='utf-8') as fout:
             fout.write(filepath + ":" + str(e))
     return res
 
 
-def get_vad_stream_status(data):
+def get_vad_stream_status(data: list) -> list:
     """
     Generate a list of status for each snippet in manifest. A snippet should be in single, start, next or end status. 
-    Used for concatenate to full audio file.
+    Used for concatenating to full audio file.
     Args:
         data (list): list of filepath of audio snippet
     Returns:
         status (list): list of status of each snippet.
     """
     if len(data) == 1:
         return ['single']
@@ -191,401 +194,538 @@
             elif data[i] == data[i - 1] and data[i] != data[i + 1]:
                 status[i] = 'end'
             else:
                 status[i] = 'single'
     return status
 
 
+def load_tensor_from_file(filepath: str) -> Tuple[torch.Tensor, str]:
+    """
+    Load torch.Tensor and the name from file
+    """
+    frame = []
+    with open(filepath, "r", encoding='utf-8') as f:
+        for line in f.readlines():
+            frame.append(float(line))
+
+    name = filepath.split("/")[-1].rsplit(".", 1)[0]
+    return torch.tensor(frame), name
+
+
 def generate_overlap_vad_seq(
-    frame_pred_dir, smoothing_method, overlap, window_length_in_sec, shift_length_in_sec, num_workers, out_dir=None
-):
+    frame_pred_dir: str,
+    smoothing_method: str,
+    overlap: float,
+    window_length_in_sec: float,
+    shift_length_in_sec: float,
+    num_workers: int,
+    out_dir: str = None,
+) -> str:
     """
-    Gnerate predictions with overlapping input windows/segments. Then a smoothing filter is applied to decide the label for a frame spanned by multiple windows. 
+    Generate predictions with overlapping input windows/segments. Then a smoothing filter is applied to decide the label for a frame spanned by multiple windows. 
     Two common smoothing filters are supported: majority vote (median) and average (mean).
+    This function uses multiprocessing to speed up. 
     Args:
         frame_pred_dir (str): Directory of frame prediction file to be processed.
         smoothing_method (str): median or mean smoothing filter.
         overlap (float): amounts of overlap of adjacent windows.
         window_length_in_sec (float): length of window for generating the frame.
         shift_length_in_sec (float): amount of shift of window for generating the frame.
         out_dir (str): directory of generated predictions.
         num_workers(float): number of process for multiprocessing
     Returns:
-        overlap_out_dir(str): directory of generate predictions.
+        overlap_out_dir(str): directory of the generated predictions.
     """
 
-    p = Pool(processes=num_workers)
+    p = multiprocessing.Pool(processes=num_workers)
     frame_filepathlist = glob.glob(frame_pred_dir + "/*.frame")
     if out_dir:
         overlap_out_dir = out_dir
     else:
         overlap_out_dir = frame_pred_dir + "/overlap_smoothing_output" + "_" + smoothing_method + "_" + str(overlap)
 
     if not os.path.exists(overlap_out_dir):
         os.mkdir(overlap_out_dir)
 
     per_args = {
-        "out_dir": overlap_out_dir,
-        "smoothing_method": smoothing_method,
         "overlap": overlap,
         "window_length_in_sec": window_length_in_sec,
         "shift_length_in_sec": shift_length_in_sec,
+        "out_dir": overlap_out_dir,
+        "smoothing_method": smoothing_method,
     }
+
     p.starmap(generate_overlap_vad_seq_per_file, zip(frame_filepathlist, repeat(per_args)))
     p.close()
     p.join()
 
     return overlap_out_dir
 
 
-def generate_overlap_vad_seq_per_file(frame_filepath, per_args):
+@torch.jit.script
+def generate_overlap_vad_seq_per_tensor(
+    frame: torch.Tensor, per_args: Dict[str, float], smoothing_method: str
+) -> torch.Tensor:
     """
     Use generated frame prediction (generated by shifting window of shift_length_in_sec (10ms)) to generate prediction with overlapping input window/segments
-    See discription in generate_overlap_vad_seq.
+    See description in generate_overlap_vad_seq.
+    Use this for single instance pipeline. 
     """
-    try:
-        smoothing_method = per_args['smoothing_method']
-        overlap = per_args['overlap']
-        window_length_in_sec = per_args['window_length_in_sec']
-        shift_length_in_sec = per_args['shift_length_in_sec']
-        out_dir = per_args['out_dir']
-
-        frame = np.loadtxt(frame_filepath)
-        name = os.path.basename(frame_filepath).split(".frame")[0] + "." + smoothing_method
-        overlap_filepath = os.path.join(out_dir, name)
-
-        shift = int(shift_length_in_sec / 0.01)  # number of units of shift
-        seg = int((window_length_in_sec / 0.01 + 1))  # number of units of each window/segment
-
-        jump_on_target = int(seg * (1 - overlap))  # jump on target generated sequence
-        jump_on_frame = int(jump_on_target / shift)  # jump on input frame sequence
-
-        if jump_on_frame < 1:
-            raise ValueError(
-                f"Note we jump over frame sequence to generate overlapping input segments. \n \
-            Your input makes jump_on_fram={jump_on_frame} < 1 which is invalid because it cannot jump and will stuck.\n \
-            Please try different window_length_in_sec, shift_length_in_sec and overlap choices. \n \
-            jump_on_target = int(seg * (1 - overlap)) \n \
-            jump_on_frame  = int(jump_on_frame/shift) "
-            )
-
-        target_len = int(len(frame) * shift)
+    # This function will be refactor for vectorization but this is okay for now
 
-        if smoothing_method == 'mean':
-            preds = np.zeros(target_len)
-            pred_count = np.zeros(target_len)
-
-            for i, og_pred in enumerate(frame):
-                if i % jump_on_frame != 0:
-                    continue
-                start = i * shift
-                end = start + seg
-                preds[start:end] = preds[start:end] + og_pred
-                pred_count[start:end] = pred_count[start:end] + 1
-
-            preds = preds / pred_count
-            last_non_zero_pred = preds[pred_count != 0][-1]
-            preds[pred_count == 0] = last_non_zero_pred
-
-        elif smoothing_method == 'median':
-            preds = [[] for _ in range(target_len)]
-            for i, og_pred in enumerate(frame):
-                if i % jump_on_frame != 0:
-                    continue
-
-                start = i * shift
-                end = start + seg
-                for j in range(start, end):
-                    if j <= target_len - 1:
-                        preds[j].append(og_pred)
-
-            preds = np.array([np.median(l) for l in preds])
-            nan_idx = np.isnan(preds)
-            last_non_nan_pred = preds[~nan_idx][-1]
-            preds[nan_idx] = last_non_nan_pred
-
-        else:
-            raise ValueError("smoothing_method should be either mean or median")
+    overlap = per_args['overlap']
+    window_length_in_sec = per_args['window_length_in_sec']
+    shift_length_in_sec = per_args['shift_length_in_sec']
+    frame_len = per_args.get('frame_len', 0.01)
 
-        round_final = np.round(preds, 4)
-        np.savetxt(overlap_filepath, round_final, delimiter='\n')
-        return overlap_filepath
+    shift = int(shift_length_in_sec / frame_len)  # number of units of shift
+    seg = int((window_length_in_sec / frame_len + 1))  # number of units of each window/segment
 
-    except Exception as e:
-        raise (e)
+    jump_on_target = int(seg * (1 - overlap))  # jump on target generated sequence
+    jump_on_frame = int(jump_on_target / shift)  # jump on input frame sequence
 
+    if jump_on_frame < 1:
+        raise ValueError(
+            f"Note we jump over frame sequence to generate overlapping input segments. \n \
+        Your input makes jump_on_frame={jump_on_frame} < 1 which is invalid because it cannot jump and will stuck.\n \
+        Please try different window_length_in_sec, shift_length_in_sec and overlap choices. \n \
+        jump_on_target = int(seg * (1 - overlap)) \n \
+        jump_on_frame  = int(jump_on_frame/shift) "
+        )
 
-def generate_vad_segment_table(
-    vad_pred_dir, postprocessing_params, shift_length_in_sec, num_workers, out_dir=None, threshold=None
-):
-    """
-    Convert frame level prediction to speech segment in start and end times format.
-    And save to csv file  in rttm-like format
-            0, 10, speech
-            17,18, speech
-    Args:
-        vad_pred_dir (str): directory of prediction files to be processed.
-        postprocessing_params (dict): dictionary of thresholds for prediction score. See details in binarization and filtering.
-        shift_length_in_sec (float): amount of shift of window for generating the frame.
-        out_dir (str): output dir of generated table/csv file.
-        num_workers(float): number of process for multiprocessing
-    Returns:
-        table_out_dir(str): directory of generate table.
-    """
+    target_len = int(len(frame) * shift)
 
-    p = Pool(processes=num_workers)
-    suffixes = ("frame", "mean", "median")
-    vad_pred_filepath_list = [os.path.join(vad_pred_dir, x) for x in os.listdir(vad_pred_dir) if x.endswith(suffixes)]
+    if smoothing_method == 'mean':
+        preds = torch.zeros(target_len)
+        pred_count = torch.zeros(target_len)
+
+        for i, og_pred in enumerate(frame):
+            if i % jump_on_frame != 0:
+                continue
+            start = i * shift
+            end = start + seg
+            preds[start:end] = preds[start:end] + og_pred
+            pred_count[start:end] = pred_count[start:end] + 1
+
+        preds = preds / pred_count
+        last_non_zero_pred = preds[pred_count != 0][-1]
+        preds[pred_count == 0] = last_non_zero_pred
+
+    elif smoothing_method == 'median':
+        preds = [torch.empty(0) for _ in range(target_len)]
+        for i, og_pred in enumerate(frame):
+            if i % jump_on_frame != 0:
+                continue
+
+            start = i * shift
+            end = start + seg
+            for j in range(start, end):
+                if j <= target_len - 1:
+                    preds[j] = torch.cat((preds[j], og_pred.unsqueeze(0)), 0)
+
+        preds = torch.stack([torch.nanquantile(l, q=0.5) for l in preds])
+        nan_idx = torch.isnan(preds)
+        last_non_nan_pred = preds[~nan_idx][-1]
+        preds[nan_idx] = last_non_nan_pred
 
-    if out_dir:
-        table_out_dir = out_dir
     else:
-        table_out_dir_name = "table_output_tmp_"
-        for key in postprocessing_params:
-            table_out_dir_name = table_out_dir_name + str(key) + str(postprocessing_params[key]) + "_"
-
-        table_out_dir = os.path.join(vad_pred_dir, table_out_dir_name)
+        raise ValueError("smoothing_method should be either mean or median")
 
-    if not os.path.exists(table_out_dir):
-        os.mkdir(table_out_dir)
+    return preds
 
-    per_args = {"shift_length_in_sec": shift_length_in_sec, "out_dir": table_out_dir}
 
-    per_args = {**per_args, **postprocessing_params}
+def generate_overlap_vad_seq_per_file(frame_filepath: str, per_args: dict) -> str:
+    """
+    A wrapper for generate_overlap_vad_seq_per_tensor.
+    """
 
-    p.starmap(generate_vad_segment_table_per_file, zip(vad_pred_filepath_list, repeat(per_args)))
-    p.close()
-    p.join()
+    out_dir = per_args['out_dir']
+    smoothing_method = per_args['smoothing_method']
+    frame, name = load_tensor_from_file(frame_filepath)
 
-    return table_out_dir
+    per_args_float: Dict[str, float] = {}
+    for i in per_args:
+        if type(per_args[i]) == float or type(per_args[i]) == int:
+            per_args_float[i] = per_args[i]
+
+    preds = generate_overlap_vad_seq_per_tensor(frame, per_args_float, smoothing_method)
+
+    overlap_filepath = os.path.join(out_dir, name + "." + smoothing_method)
+    with open(overlap_filepath, "w", encoding='utf-8') as f:
+        for pred in preds:
+            f.write(f"{pred:.4f}\n")
+
+    return overlap_filepath
+
+
+@torch.jit.script
+def merge_overlap_segment(segments: torch.Tensor) -> torch.Tensor:
+    """
+    Merged the given overlapped segments.
+    For example:
+    torch.Tensor([[0, 1.5], [1, 3.5]]) -> torch.Tensor([0, 3.5])
+    """
+    if (
+        segments.shape == torch.Size([0])
+        or segments.shape == torch.Size([0, 2])
+        or segments.shape == torch.Size([1, 2])
+    ):
+        return segments
+
+    segments = segments[segments[:, 0].sort()[1]]
+    merge_boundary = segments[:-1, 1] >= segments[1:, 0]
+    head_padded = torch.nn.functional.pad(merge_boundary, [1, 0], mode='constant', value=0.0)
+    head = segments[~head_padded, 0]
+    tail_padded = torch.nn.functional.pad(merge_boundary, [0, 1], mode='constant', value=0.0)
+    tail = segments[~tail_padded, 1]
+    merged = torch.stack((head, tail), dim=1)
+    return merged
 
 
-def generate_vad_segment_table_per_file(pred_filepath, per_args):
+@torch.jit.script
+def filter_short_segments(segments: torch.Tensor, threshold: float) -> torch.Tensor:
     """
-    See discription in generate_overlap_vad_seq.
+    Remove segments which duration is smaller than a threshold.
+    For example,
+    torch.Tensor([[0, 1.5], [1, 3.5], [4, 7]]) and threshold = 2.0
+    -> 
+    torch.Tensor([[1, 3.5], [4, 7]])
     """
-    shift_length_in_sec = per_args['shift_length_in_sec']
-    out_dir = per_args['out_dir']
+    return segments[segments[:, 1] - segments[:, 0] >= threshold]
 
-    name = pred_filepath.split("/")[-1].rsplit(".", 1)[0]
-    sequence = np.loadtxt(pred_filepath)
 
-    speech_segments = binarization(sequence, per_args)
-    speech_segments = filtering(speech_segments, per_args)
+def percentile(data: torch.Tensor, perc: int) -> float:
+    """
+    Calculate percentile given data
+    """
+    size = len(data)
+    return float(sorted(data)[int(math.ceil((size * perc) / 100)) - 1])
 
-    seg_speech_table = pd.DataFrame(speech_segments, columns=['start', 'end'])
-    seg_speech_table = seg_speech_table.sort_values('start', ascending=True)
-    seg_speech_table['dur'] = seg_speech_table['end'] - seg_speech_table['start'] + shift_length_in_sec
-    seg_speech_table['vad'] = 'speech'
 
-    save_name = name + ".txt"
-    save_path = os.path.join(out_dir, save_name)
-    seg_speech_table.to_csv(save_path, columns=['start', 'dur', 'vad'], sep='\t', index=False, header=False)
-    return save_path
+def cal_vad_onset_offset(
+    scale: str, onset: float, offset: float, sequence: torch.Tensor = None
+) -> Tuple[float, float]:
+    """
+    Calculate onset and offset threshold given different scale.
+    """
+    if scale == "absolute":
+        mini = 0
+        maxi = 1
+    elif scale == "relative":
+        mini = min(sequence)
+        maxi = max(sequence)
+    elif scale == "percentile":
+        mini = percentile(sequence, 1)
+        maxi = percentile(sequence, 99)
+
+    onset = mini + onset * (maxi - mini)
+    offset = mini + offset * (maxi - mini)
+    return float(onset), float(offset)
 
 
-def binarization(sequence, per_args):
+@torch.jit.script
+def binarization(sequence: torch.Tensor, per_args: Dict[str, float]) -> torch.Tensor:
     """
     Binarize predictions to speech and non-speech
 
     Reference
     Paper: Gregory Gelly and Jean-Luc Gauvain. "Minimum Word Error Training of RNN-based Voice Activity Detection", InterSpeech 2015. 
     Implementation: https://github.com/pyannote/pyannote-audio/blob/master/pyannote/audio/utils/signal.py 
 
     Args:
-        sequence (list) : A list of frame level predictions.
+        sequence (torch.Tensor) : A tensor of frame level predictions.
         per_args:
             onset (float): onset threshold for detecting the beginning and end of a speech 
             offset (float): offset threshold for detecting the end of a speech. 
             pad_onset (float): adding durations before each speech segment
             pad_offset (float): adding durations after each speech segment;
             shift_length_in_sec (float): amount of shift of window for generating the frame.
     
     Returns:
-        speech_segments(set): Set of speech segment in (start, end) format. 
+        speech_segments(torch.Tensor): A tensor of speech segment in torch.Tensor([[start1, end1], [start2, end2]]) format. 
     """
     shift_length_in_sec = per_args.get('shift_length_in_sec', 0.01)
 
     onset = per_args.get('onset', 0.5)
     offset = per_args.get('offset', 0.5)
-    pad_onset = per_args.get('pad_onset', 0)
-    pad_offset = per_args.get('pad_offset', 0)
-
-    onset, offset = cal_vad_onset_offset(per_args.get('scale', 'absolute'), onset, offset, sequence)
+    pad_onset = per_args.get('pad_onset', 0.0)
+    pad_offset = per_args.get('pad_offset', 0.0)
 
     speech = False
-    speech_segments = set()  # {(start1, end1), (start2, end2)}
+    start = 0.0
+    i = 0
+
+    speech_segments = torch.empty(0)
+
     for i in range(1, len(sequence)):
         # Current frame is speech
         if speech:
             # Switch from speech to non-speech
             if sequence[i] < offset:
                 if i * shift_length_in_sec + pad_offset > max(0, start - pad_onset):
-                    speech_segments.add((max(0, start - pad_onset), i * shift_length_in_sec + pad_offset))
+                    new_seg = torch.tensor(
+                        [max(0, start - pad_onset), i * shift_length_in_sec + pad_offset]
+                    ).unsqueeze(0)
+                    speech_segments = torch.cat((speech_segments, new_seg), 0)
+
                 start = i * shift_length_in_sec
                 speech = False
 
         # Current frame is non-speech
         else:
             # Switch from non-speech to speech
             if sequence[i] > onset:
                 start = i * shift_length_in_sec
                 speech = True
 
     # if it's speech at the end, add final segment
     if speech:
-        speech_segments.add((max(0, start - pad_onset), i * shift_length_in_sec + pad_offset))
+        new_seg = torch.tensor([max(0, start - pad_onset), i * shift_length_in_sec + pad_offset]).unsqueeze(0)
+        speech_segments = torch.cat((speech_segments, new_seg), 0)
 
     # Merge the overlapped speech segments due to padding
     speech_segments = merge_overlap_segment(speech_segments)  # not sorted
-
     return speech_segments
 
 
-def filtering(speech_segments, per_args):
+@torch.jit.script
+def remove_segments(original_segments: torch.Tensor, to_be_removed_segments: torch.Tensor) -> torch.Tensor:
+    """
+    Remove speech segments list in to_be_removed_segments from original_segments.
+    For example, 
+    remove torch.Tensor([[start2, end2],[start4, end4]]) from torch.Tensor([[start1, end1],[start2, end2],[start3, end3], [start4, end4]]),
+    -> 
+    torch.Tensor([[start1, end1],[start3, end3]])
+    """
+    for y in to_be_removed_segments:
+        original_segments = original_segments[original_segments.eq(y).all(dim=1).logical_not()]
+    return original_segments
+
+
+@torch.jit.script
+def get_gap_segments(segments: torch.Tensor) -> torch.Tensor:
+    """
+    Get the gap segments. 
+    For example,
+    torch.Tensor([[start1, end1], [start2, end2], [start3, end3]]) -> torch.Tensor([[end1, start2], [end2, start3]])
+    """
+    segments = segments[segments[:, 0].sort()[1]]
+    return torch.column_stack((segments[:-1, 1], segments[1:, 0]))
+
+
+@torch.jit.script
+def filtering(speech_segments: torch.Tensor, per_args: Dict[str, float]) -> torch.Tensor:
+
     """
     Filter out short non_speech and speech segments.
 
     Reference
     Paper: Gregory Gelly and Jean-Luc Gauvain. "Minimum Word Error Training of RNN-based Voice Activity Detection", InterSpeech 2015. 
     Implementation: https://github.com/pyannote/pyannote-audio/blob/master/pyannote/audio/utils/signal.py 
     Args:
-        speech_segments (set): A set of speech segment in (start, end) format.  {(start1, end1), (start2, end2)}
+        speech_segments (torch.Tensor):  A tensor of speech segment in torch.Tensor([[start1, end1], [start2, end2]]) format. 
         per_args:
             min_duration_on (float): threshold for small non_speech deletion
             min_duration_off (float): threshold for short speech segment deletion
-            filter_speech_first (boolean): Whether to perform short speech segment deletion first.
+            filter_speech_first (float): Whether to perform short speech segment deletion first. Use 1.0 to represent True. 
 
     Returns:
-        speech_segments(set): Filtered set of speech segment in (start, end) format.  {(start1, end1), (start2, end2)}
+        speech_segments(torch.Tensor): A tensor of filtered speech segment in torch.Tensor([[start1, end1], [start2, end2]]) format. 
     """
+    if speech_segments.shape == torch.Size([0]):
+        return speech_segments
+
     min_duration_on = per_args.get('min_duration_on', 0.0)
     min_duration_off = per_args.get('min_duration_off', 0.0)
-    filter_speech_first = per_args.get('filter_speech_first', True)
+    filter_speech_first = per_args.get('filter_speech_first', 1.0)
 
-    if filter_speech_first:
+    if filter_speech_first == 1.0:
         # Filter out the shorter speech segments
         if min_duration_on > 0.0:
             speech_segments = filter_short_segments(speech_segments, min_duration_on)
         # Filter out the shorter non-speech segments and return to be as speech segments
         if min_duration_off > 0.0:
             # Find non-speech segments
             non_speech_segments = get_gap_segments(speech_segments)
             # Find shorter non-speech segments
-            short_non_speech_segments = non_speech_segments - filter_short_segments(
-                non_speech_segments, min_duration_off
+            short_non_speech_segments = remove_segments(
+                non_speech_segments, filter_short_segments(non_speech_segments, min_duration_off)
             )
             # Return shorter non-speech segments to be as speech segments
-            speech_segments.update(short_non_speech_segments)
+            speech_segments = torch.cat((speech_segments, short_non_speech_segments), 0)
+
             # Merge the overlapped speech segments
             speech_segments = merge_overlap_segment(speech_segments)
     else:
         if min_duration_off > 0.0:
             # Find non-speech segments
             non_speech_segments = get_gap_segments(speech_segments)
             # Find shorter non-speech segments
-            short_non_speech_segments = non_speech_segments - filter_short_segments(
-                non_speech_segments, min_duration_off
+            short_non_speech_segments = remove_segments(
+                non_speech_segments, filter_short_segments(non_speech_segments, min_duration_off)
             )
-            # Return shorter non-speech segments to be as speech segments
-            speech_segments.update(short_non_speech_segments)
+
+            speech_segments = torch.cat((speech_segments, short_non_speech_segments), 0)
+
             # Merge the overlapped speech segments
             speech_segments = merge_overlap_segment(speech_segments)
         if min_duration_on > 0.0:
             speech_segments = filter_short_segments(speech_segments, min_duration_on)
+
     return speech_segments
 
 
-def filter_short_segments(segments, threshold):
+def prepare_gen_segment_table(sequence: torch.Tensor, per_args: dict) -> Tuple[str, dict]:
     """
-    Remove segments which duration is smaller than a threshold.
+    Preparing for generating segment table. 
     """
-    res = set()
-    for seg in segments:
-        if seg[1] - seg[0] >= threshold:
-            res.add(seg)
-    return res
+    out_dir = per_args.get('out_dir', None)
+
+    # calculate onset offset based on scale selection
+    per_args['onset'], per_args['offset'] = cal_vad_onset_offset(
+        per_args.get('scale', 'absolute'), per_args['onset'], per_args['offset'], sequence
+    )
+
+    # cast 'filter_speech_first' for torch.jit.script
+    if 'filter_speech_first' in per_args:
+        if per_args['filter_speech_first']:
+            per_args['filter_speech_first'] = 1.0
+        else:
+            per_args['filter_speech_first'] = 0.0
 
+    per_args_float: Dict[str, float] = {}
+    for i in per_args:
+        if type(per_args[i]) == float or type(per_args[i]) == int:
+            per_args_float[i] = per_args[i]
 
-def get_gap_segments(segments):
+    return out_dir, per_args_float
+
+
+@torch.jit.script
+def generate_vad_segment_table_per_tensor(sequence: torch.Tensor, per_args: Dict[str, float]) -> torch.Tensor:
     """
-    Get the gap segments. {(start1, end1), (start2, end2), (start3, end3)} -> {(end1, start2), (end2, start3)}
+    See description in generate_overlap_vad_seq.
+    Use this for single instance pipeline. 
     """
-    segments = [list(i) for i in segments]
-    segments.sort(key=lambda x: x[0])
-    gap_segments = set()
-    for i in range(len(segments) - 1):
-        gap_segments.add((segments[i][1], segments[i + 1][0]))
-    return gap_segments
+
+    shift_length_in_sec = per_args['shift_length_in_sec']
+    speech_segments = binarization(sequence, per_args)
+    speech_segments = filtering(speech_segments, per_args)
+
+    if speech_segments.shape == torch.Size([0]):
+        return speech_segments
+
+    speech_segments, _ = torch.sort(speech_segments, 0)
+
+    dur = speech_segments[:, 1:2] - speech_segments[:, 0:1] + shift_length_in_sec
+    speech_segments = torch.column_stack((speech_segments, dur))
+
+    return speech_segments
 
 
-def merge_overlap_segment(segments):
+def generate_vad_segment_table_per_file(pred_filepath: str, per_args: dict) -> str:
     """
-    Merged the overlapped segemtns {(0, 1.5), (1, 3.5), } -> {(0, 3.5), }
+    A wrapper for generate_vad_segment_table_per_tensor
     """
-    segments = [list(i) for i in segments]
-    segments.sort(key=lambda x: x[0])
-    merged = []
-    for segment in segments:
-        if not merged or merged[-1][1] < segment[0]:
-            merged.append(segment)
-        else:
-            merged[-1][1] = max(merged[-1][1], segment[1])
+    sequence, name = load_tensor_from_file(pred_filepath)
+    out_dir, per_args_float = prepare_gen_segment_table(sequence, per_args)
 
-    merged_set = set([tuple(t) for t in merged])
-    return merged_set
+    preds = generate_vad_segment_table_per_tensor(sequence, per_args_float)
+    save_name = name + ".txt"
+    save_path = os.path.join(out_dir, save_name)
 
+    if preds.shape == torch.Size([0]):
+        with open(save_path, "w", encoding='utf-8') as fp:
+            fp.write(f"0 0 speech\n")
+
+    else:
+        with open(save_path, "w", encoding='utf-8') as fp:
+            for i in preds:
+                fp.write(f"{i[0]:.4f} {i[2]:.4f} speech\n")
 
-def cal_vad_onset_offset(scale, onset, offset, sequence=None):
+    return save_path
+
+
+def generate_vad_segment_table(
+    vad_pred_dir: str, postprocessing_params: dict, shift_length_in_sec: float, num_workers: int, out_dir: str = None,
+) -> str:
     """
-    Calculate onset and offset threshold given different scale.
+    Convert frame level prediction to speech segment in start and end times format.
+    And save to csv file  in rttm-like format
+            0, 10, speech
+            17,18, speech
+    Args:
+        vad_pred_dir (str): directory of prediction files to be processed.
+        postprocessing_params (dict): dictionary of thresholds for prediction score. See details in binarization and filtering.
+        shift_length_in_sec (float): amount of shift of window for generating the frame.
+        out_dir (str): output dir of generated table/csv file.
+        num_workers(float): number of process for multiprocessing
+    Returns:
+        table_out_dir(str): directory of the generated table.
     """
-    if scale == "absolute":
-        mini = 0
-        maxi = 1
-    elif scale == "relative":
-        mini = np.nanmin(sequence)
-        maxi = np.nanmax(sequence)
-    elif scale == "percentile":
-        mini = np.nanpercentile(sequence, 1)
-        maxi = np.nanpercentile(sequence, 99)
 
-    onset = mini + onset * (maxi - mini)
-    offset = mini + offset * (maxi - mini)
-    return onset, offset
+    p = multiprocessing.Pool(processes=num_workers)
+    suffixes = ("frame", "mean", "median")
+    vad_pred_filepath_list = [os.path.join(vad_pred_dir, x) for x in os.listdir(vad_pred_dir) if x.endswith(suffixes)]
+
+    if out_dir:
+        table_out_dir = out_dir
+    else:
+        table_out_dir_name = "table_output_tmp_"
+        for key in postprocessing_params:
+            table_out_dir_name = table_out_dir_name + str(key) + str(postprocessing_params[key]) + "_"
+
+        table_out_dir = os.path.join(vad_pred_dir, table_out_dir_name)
 
+    if not os.path.exists(table_out_dir):
+        os.mkdir(table_out_dir)
+
+    per_args = {
+        "shift_length_in_sec": shift_length_in_sec,
+        "out_dir": table_out_dir,
+    }
+    per_args = {**per_args, **postprocessing_params}
 
-def vad_construct_pyannote_object_per_file(vad_table_filepath, groundtruth_RTTM_file):
+    p.starmap(generate_vad_segment_table_per_file, zip(vad_pred_filepath_list, repeat(per_args)))
+    p.close()
+    p.join()
+
+    return table_out_dir
+
+
+def vad_construct_pyannote_object_per_file(
+    vad_table_filepath: str, groundtruth_RTTM_file: str
+) -> Tuple[Annotation, Annotation]:
     """
-    Construct pyannote object for evaluation.
+    Construct a Pyannote object for evaluation.
     Args:
         vad_table_filepath(str) : path of vad rttm-like table.
         groundtruth_RTTM_file(str): path of groundtruth rttm file.
     Returns:
         reference(pyannote.Annotation): groundtruth
-        hypothesise(pyannote.Annotation): prediction
+        hypothesis(pyannote.Annotation): prediction
     """
 
-    pred = pd.read_csv(vad_table_filepath, sep="\t", header=None)
+    pred = pd.read_csv(vad_table_filepath, sep=" ", header=None)
     label = pd.read_csv(groundtruth_RTTM_file, sep=" ", delimiter=None, header=None)
     label = label.rename(columns={3: "start", 4: "dur", 7: "speaker"})
 
     # construct reference
     reference = Annotation()
     for index, row in label.iterrows():
         reference[Segment(row['start'], row['start'] + row['dur'])] = row['speaker']
 
     # construct hypothsis
     hypothesis = Annotation()
     for index, row in pred.iterrows():
-        hypothesis[Segment(row[0], row[0] + row[1])] = 'Speech'
+        hypothesis[Segment(float(row[0]), float(row[0]) + float(row[1]))] = 'Speech'
     return reference, hypothesis
 
 
-def get_parameter_grid(params):
+def get_parameter_grid(params: dict) -> list:
     """
     Get the parameter grid given a dictionary of parameters.
     """
     has_filter_speech_first = False
     if 'filter_speech_first' in params:
         filter_speech_first = params['filter_speech_first']
         has_filter_speech_first = True
@@ -596,81 +736,101 @@
     if has_filter_speech_first:
         for i in params_grid:
             i['filter_speech_first'] = filter_speech_first
     return params_grid
 
 
 def vad_tune_threshold_on_dev(
-    params, vad_pred, groundtruth_RTTM, result_file="res", vad_pred_method="frame", focus_metric="DetER"
-):
+    params: dict,
+    vad_pred: str,
+    groundtruth_RTTM: str,
+    result_file: str = "res",
+    vad_pred_method: str = "frame",
+    focus_metric: str = "DetER",
+    shift_length_in_sec: float = 0.01,
+    num_workers: int = 20,
+) -> Tuple[dict, dict]:
     """
     Tune thresholds on dev set. Return best thresholds which gives the lowest detection error rate (DetER) in thresholds.
     Args:
-        params (dict): dictionary of parameter to be tuned on.
+        params (dict): dictionary of parameters to be tuned on.
         vad_pred_method (str): suffix of prediction file. Use to locate file. Should be either in "frame", "mean" or "median".
-        vad_pred_dir (str): directory of vad predictions or a file contains the paths of them
-        groundtruth_RTTM_dir (str): directory of groundtruch rttm files or a file contains the paths of them.
+        groundtruth_RTTM_dir (str): directory of ground-truth rttm files or a file contains the paths of them.
         focus_metric (str): metrics we care most when tuning threshold. Should be either in "DetER", "FA", "MISS"
     Returns:
-        best_threhsold (float): threshold that gives lowest DetER.
+        best_threshold (float): threshold that gives lowest DetER.
     """
     min_score = 100
     all_perf = {}
     try:
         check_if_param_valid(params)
     except:
         raise ValueError("Please check if the parameters are valid")
 
     paired_filenames, groundtruth_RTTM_dict, vad_pred_dict = pred_rttm_map(vad_pred, groundtruth_RTTM, vad_pred_method)
     metric = detection.DetectionErrorRate()
     params_grid = get_parameter_grid(params)
 
     for param in params_grid:
-        # perform binarization, filtering accoring to param and write to rttm-like table
-        vad_table_dir = generate_vad_segment_table(vad_pred, param, shift_length_in_sec=0.01, num_workers=20)
+        for i in param:
+            if type(param[i]) == np.float64 or type(param[i]) == np.int64:
+                param[i] = float(param[i])
+        try:
+            # Generate speech segments by performing binarization on the VAD prediction according to param.
+            # Filter speech segments according to param and write the result to rttm-like table.
+            vad_table_dir = generate_vad_segment_table(
+                vad_pred, param, shift_length_in_sec=shift_length_in_sec, num_workers=num_workers
+            )
+            # add reference and hypothesis to metrics
+            for filename in paired_filenames:
+                groundtruth_RTTM_file = groundtruth_RTTM_dict[filename]
+                vad_table_filepath = os.path.join(vad_table_dir, filename + ".txt")
+                reference, hypothesis = vad_construct_pyannote_object_per_file(
+                    vad_table_filepath, groundtruth_RTTM_file
+                )
+                metric(reference, hypothesis)  # accumulation
 
-        # add reference and hypothesis to metrics
-        for filename in paired_filenames:
-            groundtruth_RTTM_file = groundtruth_RTTM_dict[filename]
-            vad_table_filepath = os.path.join(vad_table_dir, filename + ".txt")
-            reference, hypothesis = vad_construct_pyannote_object_per_file(vad_table_filepath, groundtruth_RTTM_file)
-            metric(reference, hypothesis)  # accumulation
+            # delete tmp table files
+            shutil.rmtree(vad_table_dir, ignore_errors=True)
 
-        # delete tmp table files
-        shutil.rmtree(vad_table_dir, ignore_errors=True)
+            report = metric.report(display=False)
+            DetER = report.iloc[[-1]][('detection error rate', '%')].item()
+            FA = report.iloc[[-1]][('false alarm', '%')].item()
+            MISS = report.iloc[[-1]][('miss', '%')].item()
 
-        report = metric.report(display=False)
-        DetER = report.iloc[[-1]][('detection error rate', '%')].item()
-        FA = report.iloc[[-1]][('false alarm', '%')].item()
-        MISS = report.iloc[[-1]][('miss', '%')].item()
+            assert (
+                focus_metric == "DetER" or focus_metric == "FA" or focus_metric == "MISS"
+            ), "Metric we care most should be only in 'DetER', 'FA' or 'MISS'!"
+            all_perf[str(param)] = {'DetER (%)': DetER, 'FA (%)': FA, 'MISS (%)': MISS}
+            logging.info(f"parameter {param}, {all_perf[str(param)] }")
 
-        assert (
-            focus_metric == "DetER" or focus_metric == "FA" or focus_metric == "MISS"
-        ), "Metric we care most should be only in 'DetER', 'FA'or 'MISS'!"
-        all_perf[str(param)] = {'DetER (%)': DetER, 'FA (%)': FA, 'MISS (%)': MISS}
-        logging.info(f"parameter {param}, {all_perf[str(param)] }")
+            score = all_perf[str(param)][focus_metric + ' (%)']
 
-        score = all_perf[str(param)][focus_metric + ' (%)']
+            del report
+            metric.reset()  # reset internal accumulator
 
-        del report
-        metric.reset()  # reset internal accumulator
+            # save results for analysis
+            with open(result_file + ".txt", "a", encoding='utf-8') as fp:
+                fp.write(f"{param}, {all_perf[str(param)] }\n")
 
-        # save results for analysis
-        with open(result_file + ".txt", "a", encoding='utf-8') as fp:
-            fp.write(f"{param}, {all_perf[str(param)] }\n")
+            if score < min_score:
+                best_threshold = param
+                optimal_scores = all_perf[str(param)]
+                min_score = score
+            print("Current best", best_threshold, optimal_scores)
 
-        if score < min_score:
-            best_threhsold = param
-            optimal_scores = all_perf[str(param)]
-            min_score = score
+        except RuntimeError as e:
+            print(f"Pass {param}, with error {e}")
+        except pd.errors.EmptyDataError as e1:
+            print(f"Pass {param}, with error {e1}")
 
-    return best_threhsold, optimal_scores
+    return best_threshold, optimal_scores
 
 
-def check_if_param_valid(params):
+def check_if_param_valid(params: dict) -> bool:
     """
     Check if the parameters are valid.
     """
     for i in params:
         if i == "filter_speech_first":
             if not type(params["filter_speech_first"]) == bool:
                 raise ValueError("Invalid inputs! filter_speech_first should be either True or False!")
@@ -678,24 +838,24 @@
             continue
         elif i == "pad_offset":
             continue
         else:
             for j in params[i]:
                 if not j >= 0:
                     raise ValueError(
-                        "Invalid inputs! All float parameters excpet pad_onset and pad_offset should be larger than 0!"
+                        "Invalid inputs! All float parameters except pad_onset and pad_offset should be larger than 0!"
                     )
 
     if not (all(i <= 1 for i in params['onset']) and all(i <= 1 for i in params['offset'])):
         raise ValueError("Invalid inputs! The onset and offset thresholds should be in range [0, 1]!")
 
     return True
 
 
-def pred_rttm_map(vad_pred, groundtruth_RTTM, vad_pred_method="frame"):
+def pred_rttm_map(vad_pred: str, groundtruth_RTTM: str, vad_pred_method: str = "frame") -> Tuple[set, dict, dict]:
     """
     Find paired files in vad_pred and groundtruth_RTTM
     """
     groundtruth_RTTM_dict = {}
     if os.path.isfile(groundtruth_RTTM):
         with open(groundtruth_RTTM, "r", encoding='utf-8') as fp:
             groundtruth_RTTM_files = fp.read().splitlines()
@@ -713,121 +873,128 @@
     if os.path.isfile(vad_pred):
         with open(vad_pred, "r", encoding='utf-8') as fp:
             vad_pred_files = fp.read().splitlines()
     elif os.path.isdir(vad_pred):
         vad_pred_files = glob.glob(os.path.join(vad_pred, "*." + vad_pred_method))
     else:
         raise ValueError(
-            "vad_pred should either be a directory contains vad pred files or a file contains paths to them!"
+            "vad_pred should either be a directory containing vad pred files or a file contains paths to them!"
         )
     for f in vad_pred_files:
         filename = os.path.basename(f).rsplit(".", 1)[0]
         vad_pred_dict[filename] = f
 
     paired_filenames = groundtruth_RTTM_dict.keys() & vad_pred_dict.keys()
     return paired_filenames, groundtruth_RTTM_dict, vad_pred_dict
 
 
 def plot(
-    path2audio_file,
-    path2_vad_pred,
-    path2ground_truth_label=None,
-    offset=0,
-    duration=None,
-    threshold=None,
-    per_args=None,
-):
+    path2audio_file: str,
+    path2_vad_pred: str,
+    path2ground_truth_label: str = None,
+    offset: float = 0,
+    duration: float = None,
+    threshold: float = None,
+    per_args: dict = None,
+) -> ipd.Audio:
     """
     Plot VAD outputs for demonstration in tutorial
     Args:
         path2audio_file (str):  path to audio file.
         path2_vad_pred (str): path to vad prediction file,
         path2ground_truth_label(str): path to groundtruth label file.
         threshold (float): threshold for prediction score (from 0 to 1).
+        per_args(dict): a dict that stores the thresholds for postprocessing.
     """
     plt.figure(figsize=[20, 2])
     FRAME_LEN = 0.01
 
     audio, sample_rate = librosa.load(path=path2audio_file, sr=16000, mono=True, offset=offset, duration=duration)
     dur = librosa.get_duration(y=audio, sr=sample_rate)
 
     time = np.arange(offset, offset + dur, FRAME_LEN)
-    frame = np.loadtxt(path2_vad_pred)
-    frame = frame[int(offset / FRAME_LEN) : int((offset + dur) / FRAME_LEN)]
+    frame, _ = load_tensor_from_file(path2_vad_pred)
+    frame_snippet = frame[int(offset / FRAME_LEN) : int((offset + dur) / FRAME_LEN)]
 
-    len_pred = len(frame)
+    len_pred = len(frame_snippet)
     ax1 = plt.subplot()
     ax1.plot(np.arange(audio.size) / sample_rate, audio, 'gray')
     ax1.set_xlim([0, int(dur) + 1])
     ax1.tick_params(axis='y', labelcolor='b')
     ax1.set_ylabel('Signal')
     ax1.set_ylim([-1, 1])
     ax2 = ax1.twinx()
 
-    prob = frame
     if threshold and per_args:
         raise ValueError("threshold and per_args cannot be used at same time!")
     if not threshold and not per_args:
         raise ValueError("One and only one of threshold and per_args must have been used!")
 
     if threshold:
-        pred = np.where(prob >= threshold, 1, 0)
+        pred_snippet = np.where(frame_snippet >= threshold, 1, 0)
     if per_args:
-        speech_segments = binarization(prob, per_args)
-        speech_segments = filtering(speech_segments, per_args)
-        pred = gen_pred_from_speech_segments(speech_segments, prob)
+        _, per_args_float = prepare_gen_segment_table(
+            frame, per_args
+        )  # take whole frame here for calculating onset and offset
+        speech_segments = generate_vad_segment_table_per_tensor(frame, per_args_float)
+        pred = gen_pred_from_speech_segments(speech_segments, frame)
+        pred_snippet = pred[int(offset / FRAME_LEN) : int((offset + dur) / FRAME_LEN)]
 
     if path2ground_truth_label:
         label = extract_labels(path2ground_truth_label, time)
         ax2.plot(np.arange(len_pred) * FRAME_LEN, label, 'r', label='label')
 
-    ax2.plot(np.arange(len_pred) * FRAME_LEN, pred, 'b', label='pred')
-    ax2.plot(np.arange(len_pred) * FRAME_LEN, prob, 'g--', label='speech prob')
+    ax2.plot(np.arange(len_pred) * FRAME_LEN, pred_snippet, 'b', label='pred')
+    ax2.plot(np.arange(len_pred) * FRAME_LEN, frame_snippet, 'g--', label='speech prob')
     ax2.tick_params(axis='y', labelcolor='r')
     ax2.legend(loc='lower right', shadow=True)
     ax2.set_ylabel('Preds and Probas')
     ax2.set_ylim([-0.1, 1.1])
     return ipd.Audio(audio, rate=16000)
 
 
-def gen_pred_from_speech_segments(speech_segments, prob, shift_length_in_sec=0.01):
+def gen_pred_from_speech_segments(
+    speech_segments: torch.Tensor, prob: float, shift_length_in_sec: float = 0.01
+) -> np.array:
     """
     Generate prediction arrays like 000111000... from speech segments {[0,1][2,4]} 
     """
     pred = np.zeros(prob.shape)
     speech_segments = [list(i) for i in speech_segments]
     speech_segments.sort(key=lambda x: x[0])
 
     for seg in speech_segments:
         start = int(seg[0] / shift_length_in_sec)
         end = int(seg[1] / shift_length_in_sec)
         pred[start:end] = 1
     return pred
 
 
-def extract_labels(path2ground_truth_label, time):
+def extract_labels(path2ground_truth_label: str, time: list) -> list:
     """
-    Extract groundtruth label for given time period.
+    Extract ground-truth label for given time period.
     path2ground_truth_label (str): path of groundtruth label file 
-    time (list) : a list of array represent time period.
+    time (list) : a list of array representing time period.
     """
 
     data = pd.read_csv(path2ground_truth_label, sep=" ", delimiter=None, header=None)
     data = data.rename(columns={3: "start", 4: "dur", 7: "speaker"})
     labels = []
     for pos in time:
         line = data[(data["start"] <= pos) & (data["start"] + data["dur"] > pos)]
         if len(line) >= 1:
             labels.append(1)
         else:
             labels.append(0)
     return labels
 
 
-def generate_vad_frame_pred(vad_model, window_length_in_sec, shift_length_in_sec, manifest_vad_input, out_dir):
+def generate_vad_frame_pred(
+    vad_model, window_length_in_sec: float, shift_length_in_sec: float, manifest_vad_input: str, out_dir: str
+) -> str:
     """
     Generate VAD frame level prediction and write to out_dir
     """
     time_unit = int(window_length_in_sec / shift_length_in_sec)
     trunc = int(time_unit / 2)
     trunc_l = time_unit - trunc
     all_len = 0
@@ -864,15 +1031,15 @@
         del test_batch
         if status[i] == 'end' or status[i] == 'single':
             logging.debug(f"Overall length of prediction of {data[i]} is {all_len}!")
             all_len = 0
     return out_dir
 
 
-def init_vad_model(model_path):
+def init_vad_model(model_path: str):
     """
     Initiate VAD model with model path
     """
     if model_path.endswith('.nemo'):
         logging.info(f"Using local VAD model from {model_path}")
         vad_model = EncDecClassificationModel.restore_from(restore_path=model_path)
     elif model_path.endswith('.ckpt'):
@@ -954,21 +1121,21 @@
 
         logging.info(
             f"Finish stitch segmented ASR output to {stitched_output_manifest}, the speech segments info has been stored in directory {speech_segments_tensor_dir}"
         )
         return stitched_output_manifest
 
 
-def contruct_manfiest_eval(
+def construct_manifest_eval(
     input_manifest: str, stitched_output_manifest: str, aligned_vad_asr_output_manifest: str = "vad_asr_out.json"
 ) -> str:
 
     """
     Generate aligned manifest for evaluation.
-    Because some pure noise samples might not appears in stitched_output_manifest.
+    Because some pure noise samples might not appear in stitched_output_manifest.
     """
     stitched_output = dict()
     for line in open(stitched_output_manifest, 'r', encoding='utf-8'):
         file = json.loads(line)
         stitched_output[file["audio_filepath"]] = file
 
     out = []
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/callbacks/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/callbacks/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/callbacks/callbacks.py` & `nemo_toolkit-1.9.0/nemo/collections/common/callbacks/callbacks.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/data/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/data/dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/common/data/dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/data/vocabs.py` & `nemo_toolkit-1.9.0/nemo/collections/common/data/vocabs.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/aggregator.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/aggregator.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/bce_logits_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/bce_logits_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/cross_entropy.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/cross_entropy.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/mse_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/mse_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/multi_similarity_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/multi_similarity_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/smoothed_cross_entropy.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/smoothed_cross_entropy.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/losses/spanning_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/common/losses/spanning_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/metrics/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/metrics/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/metrics/classification_accuracy.py` & `nemo_toolkit-1.9.0/nemo/collections/common/metrics/classification_accuracy.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/metrics/global_average_loss_metric.py` & `nemo_toolkit-1.9.0/nemo/collections/common/metrics/global_average_loss_metric.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/metrics/perplexity.py` & `nemo_toolkit-1.9.0/nemo/collections/common/metrics/perplexity.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,10 +8,11 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+from nemo.collections.common.parts.adapter_modules import LinearAdapter, LinearAdapterConfig
 from nemo.collections.common.parts.multi_layer_perceptron import MultiLayerPerceptron
 from nemo.collections.common.parts.transformer_utils import *
 from nemo.collections.common.parts.utils import *
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/multi_layer_perceptron.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/multi_layer_perceptron.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/patch_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/patch_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/cleaners.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/cleaners.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/collections.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/collections.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/manifest.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/manifest.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/preprocessing/parsers.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/preprocessing/parsers.py`

 * *Files 15% similar despite different names*

```diff
@@ -171,15 +171,57 @@
             )
         except Exception:
             return None
 
         return text
 
 
-NAME_TO_PARSER = frozendict.frozendict({'base': CharParser, 'en': ENCharParser})
+class RUCharParser(CharParser):
+    """Incorporates russian-specific parsing logic."""
+
+    PUNCTUATION_TO_REPLACE = frozendict.frozendict({'+': 'плюс', 'ё': 'е'})
+
+    def __init__(self, *args, **kwargs):
+        """Creates cyrillic-specific mapping char parser.
+        This class overrides normalizing implementation.
+        Args:
+            *args: Positional args to pass to `CharParser` constructor.
+            **kwargs: Key-value args to pass to `CharParser` constructor.
+        """
+
+        super().__init__(*args, **kwargs)
+
+        self._table = self.__make_trans_table()
+
+    def __make_trans_table(self):
+        punctuation = string.punctuation
+
+        for char in self.PUNCTUATION_TO_REPLACE:
+            punctuation = punctuation.replace(char, '')
+
+        for label in self._labels:
+            punctuation = punctuation.replace(label, '')
+
+        table = str.maketrans(punctuation, ' ' * len(punctuation))
+
+        return table
+
+    def _normalize(self, text: str) -> Optional[str]:
+        # noinspection PyBroadException
+        try:
+            text = cleaners.clean_text(
+                string=text, table=self._table, punctuation_to_replace=self.PUNCTUATION_TO_REPLACE,
+            )
+        except Exception:
+            return None
+
+        return text
+
+
+NAME_TO_PARSER = frozendict.frozendict({'base': CharParser, 'en': ENCharParser, 'ru': RUCharParser})
 
 
 def make_parser(labels: Optional[List[str]] = None, name: str = 'base', **kwargs,) -> CharParser:
     """Creates parser from labels, set of arguments and concise parser name.
 
     Args:
         labels: List of labels to allocate indexes for. If set to
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/ptl_overrides.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/ptl_overrides.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/rnn.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/rnn.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/transformer_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/transformer_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/parts/utils.py` & `nemo_toolkit-1.9.0/nemo/collections/common/parts/utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -12,16 +12,27 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import math
 import os
 from typing import List
 
+import torch.nn as nn
+
 __all__ = ['if_exist', '_compute_softmax']
 
+activation_registry = {
+    "hardtanh": nn.Hardtanh,
+    "relu": nn.ReLU,
+    "selu": nn.SELU,
+    "swish": nn.SiLU,
+    "silu": nn.SiLU,
+    "gelu": nn.GELU,
+}
+
 
 def if_exist(outfold: str, files: List[str]):
     """
     Returns true if all given files exist in the given folder
     Args:
         outfold: folder path
         files: list of file names relative to outfold
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/aggregate_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/aggregate_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/bytelevel_tokenizers.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/bytelevel_tokenizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/char_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/char_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/chinese_tokenizers.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/chinese_tokenizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/column_coder.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/column_coder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/en_ja_tokenizers.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/en_ja_tokenizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/fairseq_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/fairseq_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/huggingface/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/huggingface/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/huggingface/auto_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/huggingface/auto_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/indic_tokenizers.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/indic_tokenizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/moses_tokenizers.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/moses_tokenizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/regex_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/regex_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/sentencepiece_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/sentencepiece_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/tabular_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/tabular_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/tokenizer_spec.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/tokenizer_spec.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/word_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/word_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/common/tokenizers/youtokentome_tokenizer.py` & `nemo_toolkit-1.9.0/nemo/collections/common/tokenizers/youtokentome_tokenizer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/datasets/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/datasets/mnist_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/datasets/mnist_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/losses/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/losses/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/losses/nll_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/losses/nll_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/models/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/models/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/models/mnist_lenet5.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/models/mnist_lenet5.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/modules/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/modules/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/cv/modules/lenet5.py` & `nemo_toolkit-1.9.0/nemo/collections/cv/modules/lenet5.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/data_utils/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/data_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/data_utils/data_preprocessing.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/data_utils/data_preprocessing.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -8,14 +8,13 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.data_processor import DialogueSGDDataProcessor
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.dialogue_bert_dataset import (
-    DialogueBERTDataset,
-    DialogueSGDBERTDataset,
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_bert_dataset import DialogueBERTDataset
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_gpt_classification_dataset import (
+    DialogueGPTClassificationDataset,
 )
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.dialogue_gpt_dataset import DialogueGPTDataset
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.schema import Schema
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_sgd_bert_dataset import DialogueSGDBERTDataset
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_zero_shot_intent_dataset import DialogueZeroShotIntentDataset
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/data_processor.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/sgd_data_processor.py`

 * *Files 10% similar despite different names*

```diff
@@ -13,141 +13,164 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """
 This file contains code artifacts adapted from the original implementation:
 https://github.com/google-research/google-research/blob/master/schema_guided_dst/baseline/data_utils.py
 """
-
 import collections
 import json
 import os
 import pickle
-from typing import Dict, List
-
-import numpy as np
+import re
+from typing import List
 
-from nemo.collections.nlp.data.data_utils.data_preprocessing import DataProcessor
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.input_example import DialogueInputExample
+from nemo.collections.nlp.data.dialogue.data_processor.data_processor import DialogueDataProcessor
+from nemo.collections.nlp.data.dialogue.input_example.input_example import DialogueInputExample
+from nemo.collections.nlp.data.dialogue.sgd.schema import Schema
 from nemo.utils import logging
+from nemo.utils.get_rank import is_global_rank_zero
 
-__all__ = ['DialogueDataProcessor', 'DialogueSGDDataProcessor']
+__all__ = ['DialogueSGDDataProcessor']
 
 FILE_RANGES = {
     "sgd_single_domain": {"train": range(1, 44), "dev": range(1, 8), "test": range(1, 12)},
     "sgd_multi_domain": {"train": range(44, 128), "dev": range(8, 21), "test": range(12, 35)},
     "sgd_all": {"train": range(1, 128), "dev": range(1, 21), "test": range(1, 35)},
     "sgd_all_single": {"train": range(1, 128), "dev": range(1, 8), "test": range(1, 12)},
     "multiwoz": {"train": range(1, 18), "dev": range(1, 3), "test": range(1, 3)},
     "debug_sample": {"train": range(1, 2), "dev": range(1, 2), "test": range(1, 2)},
 }
 
 
-class DialogueDataProcessor(DataProcessor):
-    """
-    Base class for Data Processing for all data sources
-
-    Data Processor is designed to be Model-independent (but Data-dependent) so that
-        - Encourages experimentation with a variety of models \
-            (BERT-style; GPT-style; T5-style), \
-            which have different tokenization/preprocessing requirements
-        - Facilitates experiments with a variety of data sources, 
-           as data is processed into a common format
-        
-    Roles 
-        1. Processes raw files into Dialogue Input Examples. 
-        2. Keeps all possibly relevant information from the raw files, which 
-            the Dataset class can then determine which labels to use
-    
-    """
-
-    def __init__(self):
-        raise NotImplementedError()
-
-    # common interface for Data Processor
-    def get_train_examples(self):
-        """Gets a collection of `InputExample`s for the train set."""
-        raise NotImplementedError()
+class DialogueSGDDataProcessor(DialogueDataProcessor):
+    """Data Processor for SGD dialogues.
 
-    def get_dev_examples(self):
-        """Gets a collection of `InputExample`s for the dev set."""
-        raise NotImplementedError()
+    More information at https://arxiv.org/abs/1909.05855
 
-    def get_test_examples(self):
-        """Gets a collection of `InputExample`s for the test set."""
-        raise NotImplementedError()
+    ***Downloading the dataset***
+        #   git clone https://github.com/google-research-datasets/dstc8-schema-guided-dialogue.git
 
+    ***Data format***
+    SGD data comes with a JSON schema file and dialogue files for each dataset split. 
+
+    In the following we will show an example for a service entry in the schema file.
+    * service_name
+    * description
+    * slots
+        * name
+        * description
+        * is_categorical
+        * possible values
+    * intents
+        * name
+        * description
+        * required_slots (not used)
+        * is_transactional (not used)
+        * optional_slots (not used)
+        * result_slots (not used)
+
+
+    In the following we will show an example for a dialogue. 
+    * dialogue_id
+    * services
+    * turns
+        * frames
+            * actions
+                * act
+                * slot
+                * values
+            * service
+            * slots
+                * exclusive_end
+                * slot
+                * start
+            * state
+                * active_intent
+                * requeste_slots
+                * slot_values 
+        * speaker - [USER, SYSTEM]
+        * utterance
 
-class DialogueSGDDataProcessor(DialogueDataProcessor):
-    """Data Processor for SGD dialogues."""
+    """
 
     def __init__(
-        self,
-        task_name: str,
-        data_dir: str,
-        dialogues_example_dir: str,
-        tokenizer: object,
-        schemas: object,
-        schema_config: Dict[str, int],
-        subsample: bool = False,
+        self, data_dir: str, dialogues_example_dir: str, tokenizer: object, cfg=None,
     ):
         """
         Constructs DialogueSGDDataProcessor
         Args:
-            task_name: task name, e.g. "sgd_single_domain"
             data_dir: path to data directory
             dialogues_example_dir: path to store processed dialogue examples
             tokenizer: tokenizer object
-            schemas: schema object 
-            schema_config: schema configuration
-            subsample: whether to balance positive and negative samples in dataset
+            cfg: cfg container for dataset
         """
         self.data_dir = data_dir
+        self.cfg = cfg
+
+        self._task_name = self.cfg.task_name  # e.g. "sgd_single_domain"
+        self._subsample = self.cfg.subsample
 
-        self._task_name = task_name
-        self.schemas = schemas
-        self.schema_config = schema_config
-
-        train_file_range = FILE_RANGES[task_name]["train"]
-        dev_file_range = FILE_RANGES[task_name]["dev"]
-        test_file_range = FILE_RANGES[task_name]["test"]
+        all_schema_json_paths = []
+        for dataset_split in ['train', 'test', 'dev']:
+            all_schema_json_paths.append(os.path.join(self.cfg.data_dir, dataset_split, "schema.json"))
+        self.schemas = Schema(all_schema_json_paths)
+
+        self.schema_config = {
+            "MAX_NUM_CAT_SLOT": self.cfg.max_num_cat_slot,
+            "MAX_NUM_NONCAT_SLOT": self.cfg.max_num_noncat_slot,
+            "MAX_NUM_VALUE_PER_CAT_SLOT": self.cfg.max_value_per_cat_slot,
+            "MAX_NUM_INTENT": self.cfg.max_num_intent,
+            "NUM_TASKS": self.cfg.num_tasks,
+            "MAX_SEQ_LENGTH": self.cfg.max_seq_length,
+        }
+
+        train_file_range = FILE_RANGES[self._task_name]["train"]
+        dev_file_range = FILE_RANGES[self._task_name]["dev"]
+        test_file_range = FILE_RANGES[self._task_name]["test"]
 
         self._file_ranges = {
             "train": train_file_range,
             "dev": dev_file_range,
             "test": test_file_range,
         }
 
         self._seen_services = {
             "train": set(),
             "dev": set(),
             "test": set(),
         }
 
         self._tokenizer = tokenizer
-        self._subsample = subsample
+
         self._dialogues_example_dir = dialogues_example_dir
 
         self.dial_files = {}
 
         # slots_relation_list.np would contain the candidate list of slots for each (service, slot) which would be
         # looked into when a switch between two services happens in the dialogue and we can not find any value for a slot in the current user utterance.
         # This file would get generated from the dialogues in the training set.
-        self.slots_relation_file = os.path.join(dialogues_example_dir, f"{task_name}_train_slots_relation_list.np")
+        self.slots_relation_file = os.path.join(
+            dialogues_example_dir, f"{self._task_name}_train_slots_relation_list.np"
+        )
         for dataset in ["train", "dev", "test"]:
             # Process dialogue files
-            dial_file = f"{task_name}_{dataset}_examples.json"
+            dial_file = f"{self._task_name}_{dataset}_examples.json"
             dial_file = os.path.join(dialogues_example_dir, dial_file)
-            self.dial_files[(task_name, dataset)] = dial_file
+            self.dial_files[(self._task_name, dataset)] = dial_file
 
-            dialog_paths = DialogueSGDDataProcessor.get_dialogue_files(data_dir, dataset, task_name)
+            dialog_paths = DialogueSGDDataProcessor.get_dialogue_files(data_dir, dataset, self._task_name)
             dialogs = DialogueSGDDataProcessor.load_dialogues(dialog_paths)
             for dialog in dialogs:
                 self._seen_services[dataset].update(set(dialog['services']))
 
+        if is_global_rank_zero():
+            overwrite_dial_files = not self.cfg.use_cache
+            self.save_dialog_examples(overwrite_dial_files=overwrite_dial_files)
+
     def save_dialog_examples(self, overwrite_dial_files: bool):
         """
         Preprocesses dialogues and saves to disk.
         Args:
             overwrite_dial_files: whether or not to overwrite saved file if already exists
         """
         for dataset in ["train", "dev", "test"]:
@@ -204,15 +227,14 @@
             )
         dial_file = self.dial_files[(self._task_name, dataset_split)]
         logging.info(f"Loading dialogue examples from {dial_file}.")
 
         with open(dial_file, "rb") as f:
             dial_examples = json.load(f)
             dial_examples = [DialogueInputExample(i) for i in dial_examples]
-
         if not os.path.exists(self.slots_relation_file):
             raise ValueError(
                 f"Slots relation file {self.slots_relation_file} does not exist. It is needed for the carry-over mechanism of state tracker for switches between services."
             )
         if os.path.getsize(self.slots_relation_file) > 0:
             with open(self.slots_relation_file, "rb") as f:
                 self.schemas._slots_relation_list = pickle.load(f)
@@ -289,21 +311,26 @@
         prev_states = {}
         examples = []
         for turn_idx, turn in enumerate(dialog["turns"]):
             # Generate an example for every frame in every user turn.
             if turn["speaker"] == "USER":
                 user_utterance = turn["utterance"]
                 user_frames = {f["service"]: f for f in turn["frames"]}
-                if turn_idx > 0:
-                    system_turn = dialog["turns"][turn_idx - 1]
+                if self.cfg.system_utterance == 'prev_turn':
+                    if turn_idx > 0:
+                        system_turn = dialog["turns"][turn_idx - 1]
+                        system_utterance = system_turn["utterance"]
+                        system_frames = {f["service"]: f for f in system_turn["frames"]}
+                    else:
+                        system_utterance = ""
+                        system_frames = {}
+                else:  # takes the system utterance of the next turn
+                    system_turn = dialog["turns"][turn_idx + 1]
                     system_utterance = system_turn["utterance"]
                     system_frames = {f["service"]: f for f in system_turn["frames"]}
-                else:
-                    system_utterance = ""
-                    system_frames = {}
 
                 turn_id = "{}-{}-{:02d}".format(dataset_split, dialog_id, turn_idx)
                 turn_examples, prev_states, slot_carryover_values = self._create_examples_from_turn(
                     turn_id,
                     system_utterance,
                     user_utterance,
                     system_frames,
@@ -340,14 +367,35 @@
         state_update = dict(current_state)
         for slot, values in current_state.items():
             if slot in prev_state and prev_state[slot][0] in values:
                 # Remove the slot from state if its value didn't change.
                 state_update.pop(slot)
         return state_update
 
+    @staticmethod
+    def convert_camelcase_to_lower(label):
+        """Converts camelcase to lowercase with spaces e.g. 'HelloWorld' --> 'hello world'"""
+        if label.lower() == "none":
+            return "none"
+        label = label.split("_")[0]
+        tokens = re.findall('[A-Z][^A-Z]*', label)
+        return ' '.join([token.lower() for token in tokens])
+
+    def preprocess_intent(self, intent, schemas, service):
+        if self.cfg.preprocess_intent_function == 'default':
+            return intent
+        elif self.cfg.preprocess_intent_function == 'lowercase':
+            return DialogueSGDDataProcessor.convert_camelcase_to_lower(intent)
+        elif self.cfg.preprocess_intent_function == 'description':
+            return schemas.get_service_schema(service).intent_descriptions[intent]
+        else:
+            raise ValueError(
+                'Only default, lowercase and description are allowed for model.dataset.preprocess_intent_function for SGD task'
+            )
+
     def _create_examples_from_turn(
         self,
         turn_id: int,
         system_utterance: str,
         user_utterance: str,
         system_frames: dict,
         user_frames: dict,
@@ -398,23 +446,27 @@
                 "example_id": example_id,
                 "example_id_num": example_id_num,
                 "utterance": user_utterance,
                 "system_utterance": system_utterance,
                 "system_slots": {slot["slot"]: slot for slot in system_frame["slots"]}
                 if system_frame is not None
                 else None,
+                "system_actions": system_frame["actions"] if system_frame is not None else None,
                 "labels": {
                     "service": service,
-                    "intent": intent,
+                    "intent": self.preprocess_intent(intent, schemas, service),
                     "slots": {slot: state[slot] for slot in state_update},
                 },
                 "label_positions": {"slots": {slot["slot"]: slot for slot in user_frames[service]["slots"]}},
                 "possible_labels": {
                     "service": schemas.services,
-                    "intent": schemas.get_service_schema(service).intents,
+                    "intent": [
+                        self.preprocess_intent(intent, schemas, service)
+                        for intent in schemas.get_service_schema(service).intents
+                    ],
                     "slots": {
                         slot: schemas.get_service_schema(service).get_categorical_slot_values(slot)
                         if slot in categorical_slots
                         else []
                         for slot in all_possible_slots
                     },
                 },
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/dialogue_bert_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_sgd_bert_dataset.py`

 * *Files 26% similar despite different names*

```diff
@@ -16,294 +16,42 @@
 """
 This file contains code artifacts adapted from the original implementation:
 https://github.com/google-research/google-research/blob/master/schema_guided_dst
 """
 
 import os
 import re
-from typing import Dict, List, Optional
+from typing import List
 
 import numpy as np
 
-from nemo.collections.nlp.data.data_utils import get_stats
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.input_example import SGDInputExample
-from nemo.core.classes import Dataset
-from nemo.core.neural_types import ChannelType, LabelsType, MaskType, NeuralType
-from nemo.utils import logging
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_dataset import DialogueDataset
+from nemo.collections.nlp.data.dialogue.input_example.sgd_input_example import SGDInputExample
 
-__all__ = ['DialogueSGDBERTDataset', 'DialogueBERTDataset']
+__all__ = ['DialogueSGDBERTDataset']
 
 
-class DialogueBERTDataset(Dataset):
-
-    """
-    Creates a dataset to use for the task of joint intent
-    and slot classification with pretrained model.
-
-    For a dataset to use during inference without labels, see
-    IntentSlotDataset.
-    """
-
-    @property
-    def output_types(self) -> Optional[Dict[str, NeuralType]]:
-        """Returns definitions of module output ports.
-               """
-        return {
-            'input_ids': NeuralType(('B', 'T'), ChannelType()),
-            'segment_ids': NeuralType(('B', 'T'), ChannelType()),
-            'input_mask': NeuralType(('B', 'T'), MaskType()),
-            'loss_mask': NeuralType(('B', 'T'), MaskType()),
-            'subtokens_mask': NeuralType(('B', 'T'), MaskType()),
-            'intent_labels': NeuralType(('B'), LabelsType()),
-            'slot_labels': NeuralType(('B', 'T'), LabelsType()),
-        }
-
-    def __init__(self, dataset_split: str, dialogues_processor: object, tokenizer, cfg):
-        """
-        Args:
-            dataset_split: dataset split
-            dialogues_processor: Data generator for dialogues
-            tokenizer: tokenizer to split text into sub-word tokens
-            cfg: config dict for dataset
-        """
-        self.cfg = cfg
-        self.all_possible_labels = dialogues_processor.intents
-        self.label_to_label_id = {self.all_possible_labels[i]: i for i in range(len(self.all_possible_labels))}
-        self.all_possible_slots = dialogues_processor.slots
-        self.slot_name_to_slot_id = {self.all_possible_slots[i]: i for i in range(len(self.all_possible_slots))}
-        self.empty_slot_name = self.all_possible_slots[-1]
-
-        self.features = dialogues_processor.get_dialog_examples(dataset_split)
-        self.features = self.features if self.cfg.num_samples == -1 else self.features[: self.cfg.num_samples]
-
-        queries = [feature.data["utterance"] for feature in self.features]
-        if self.cfg.do_lowercase:
-            queries = [query.lower() for query in queries]
-        intents = [self.label_to_label_id[feature.data["labels"]["intent"]] for feature in self.features]
-        word_level_slots = [self.convert_slot_position_to_slot_ids(feature.data) for feature in self.features]
-
-        features = DialogueBERTDataset.get_features(
-            queries,
-            self.cfg.max_seq_length,
-            tokenizer,
-            pad_label=self.cfg.pad_label,
-            word_level_slots=word_level_slots,
-            ignore_extra_tokens=self.cfg.ignore_extra_tokens,
-            ignore_start_end=self.cfg.ignore_start_end,
-        )
-
-        self.all_input_ids = features[0]
-        self.all_segment_ids = features[1]
-        self.all_input_mask = features[2]
-        self.all_loss_mask = features[3]
-        self.all_subtokens_mask = features[4]
-        self.all_slots = features[5]
-        self.all_intents = intents
-
-    def convert_slot_position_to_slot_ids(self, feature):
-        slot_ids = [self.slot_name_to_slot_id[self.empty_slot_name] for i in range(len(feature["utterance"].split()))]
-        slot_name_to_positions = feature["label_positions"]["slots"]
-
-        for slot_name in slot_name_to_positions:
-            slot_id = self.slot_name_to_slot_id[slot_name]
-            start = slot_name_to_positions[slot_name]["start"]
-            exclusive_end = slot_name_to_positions[slot_name]["exclusive_end"]
-            for to_replace_position in range(start, min(exclusive_end, len(slot_ids))):
-                slot_ids[to_replace_position] = slot_id
-
-        return slot_ids
-
-    def __len__(self):
-        return len(self.all_input_ids)
-
-    def __getitem__(self, idx):
-        return (
-            np.array(self.all_input_ids[idx]),
-            np.array(self.all_segment_ids[idx]),
-            np.array(self.all_input_mask[idx], dtype=np.long),
-            np.array(self.all_loss_mask[idx]),
-            np.array(self.all_subtokens_mask[idx]),
-            self.all_intents[idx],
-            np.array(self.all_slots[idx]),
-        )
-
-    @staticmethod
-    def truncate_and_pad(
-        max_seq_length,
-        ignore_start_end,
-        with_label,
-        pad_label,
-        tokenizer,
-        all_slots,
-        all_subtokens,
-        all_input_mask,
-        all_loss_mask,
-        all_subtokens_mask,
-        all_input_ids,
-        all_segment_ids,
-    ):
-
-        too_long_count = 0
-
-        for i, subtokens in enumerate(all_subtokens):
-            if len(subtokens) > max_seq_length:
-                subtokens = [tokenizer.cls_token] + subtokens[-max_seq_length + 1 :]
-                all_input_mask[i] = [1] + all_input_mask[i][-max_seq_length + 1 :]
-                all_loss_mask[i] = [1 - ignore_start_end] + all_loss_mask[i][-max_seq_length + 1 :]
-                all_subtokens_mask[i] = [0] + all_subtokens_mask[i][-max_seq_length + 1 :]
-
-                if with_label:
-                    all_slots[i] = [pad_label] + all_slots[i][-max_seq_length + 1 :]
-                too_long_count += 1
-
-            all_input_ids.append([tokenizer.tokens_to_ids(t) for t in subtokens])
-
-            if len(subtokens) < max_seq_length:
-                extra = max_seq_length - len(subtokens)
-                all_input_ids[i] = all_input_ids[i] + [0] * extra
-                all_loss_mask[i] = all_loss_mask[i] + [0] * extra
-                all_subtokens_mask[i] = all_subtokens_mask[i] + [0] * extra
-                all_input_mask[i] = all_input_mask[i] + [0] * extra
-
-                if with_label:
-                    all_slots[i] = all_slots[i] + [pad_label] * extra
-
-            all_segment_ids.append([0] * max_seq_length)
-
-        logging.info(f'{too_long_count} are longer than {max_seq_length}')
-        return (
-            all_slots,
-            all_subtokens,
-            all_input_mask,
-            all_loss_mask,
-            all_subtokens_mask,
-            all_input_ids,
-            all_segment_ids,
-        )
-
-    @staticmethod
-    def get_features(
-        queries,
-        max_seq_length,
-        tokenizer,
-        pad_label=128,
-        word_level_slots=None,
-        ignore_extra_tokens=False,
-        ignore_start_end=False,
-    ):
-        """
-        Convert queries (utterance, intent label and slot labels) to BERT input format 
-        """
-
-        all_subtokens = []
-        all_loss_mask = []
-        all_subtokens_mask = []
-        all_segment_ids = []
-        all_input_ids = []
-        all_input_mask = []
-        sent_lengths = []
-        all_slots = []
-
-        with_label = word_level_slots is not None
-
-        for i, query in enumerate(queries):
-            words = query.strip().split()
-            subtokens = [tokenizer.cls_token]
-            loss_mask = [1 - ignore_start_end]
-            subtokens_mask = [0]
-            if with_label:
-                slots = [pad_label]
-
-            for j, word in enumerate(words):
-                word_tokens = tokenizer.text_to_tokens(word)
-
-                # to handle emojis that could be neglected during tokenization
-                if len(word.strip()) > 0 and len(word_tokens) == 0:
-                    word_tokens = [tokenizer.ids_to_tokens(tokenizer.unk_id)]
-
-                subtokens.extend(word_tokens)
-                # mask all sub-word tokens except the first token in a word
-                # use the label for the first sub-word token as the label for the entire word to eliminate need for disambiguation
-                loss_mask.append(1)
-                loss_mask.extend([int(not ignore_extra_tokens)] * (len(word_tokens) - 1))
-
-                subtokens_mask.append(1)
-                subtokens_mask.extend([0] * (len(word_tokens) - 1))
-
-                if with_label:
-                    slots.extend([word_level_slots[i][j]] * len(word_tokens))
-
-            subtokens.append(tokenizer.sep_token)
-            loss_mask.append(1 - ignore_start_end)
-            subtokens_mask.append(0)
-            sent_lengths.append(len(subtokens))
-            all_subtokens.append(subtokens)
-            all_loss_mask.append(loss_mask)
-            all_subtokens_mask.append(subtokens_mask)
-            all_input_mask.append([1] * len(subtokens))
-            if with_label:
-                slots.append(pad_label)
-                all_slots.append(slots)
-        max_seq_length_data = max(sent_lengths)
-        max_seq_length = min(max_seq_length, max_seq_length_data) if max_seq_length > 0 else max_seq_length_data
-        logging.info(f'Setting max length to: {max_seq_length}')
-        get_stats(sent_lengths)
-
-        # truncate and pad samples
-        (
-            all_slots,
-            all_subtokens,
-            all_input_mask,
-            all_loss_mask,
-            all_subtokens_mask,
-            all_input_ids,
-            all_segment_ids,
-        ) = DialogueBERTDataset.truncate_and_pad(
-            max_seq_length,
-            ignore_start_end,
-            with_label,
-            pad_label,
-            tokenizer,
-            all_slots,
-            all_subtokens,
-            all_input_mask,
-            all_loss_mask,
-            all_subtokens_mask,
-            all_input_ids,
-            all_segment_ids,
-        )
-
-        # log examples for debugging
-        logging.debug("*** Some Examples of Processed Data ***")
-        for i in range(min(len(all_input_ids), 5)):
-            logging.debug("i: %s" % (i))
-            logging.debug("subtokens: %s" % " ".join(list(map(str, all_subtokens[i]))))
-            logging.debug("loss_mask: %s" % " ".join(list(map(str, all_loss_mask[i]))))
-            logging.debug("input_mask: %s" % " ".join(list(map(str, all_input_mask[i]))))
-            logging.debug("subtokens_mask: %s" % " ".join(list(map(str, all_subtokens_mask[i]))))
-            if with_label:
-                logging.debug("slots_label: %s" % " ".join(list(map(str, all_slots[i]))))
-
-        return (all_input_ids, all_segment_ids, all_input_mask, all_loss_mask, all_subtokens_mask, all_slots)
-
-
-class DialogueSGDBERTDataset(Dataset):
+class DialogueSGDBERTDataset(DialogueDataset):
     '''
     Dataset Class 
         1. Performs Model-dependent (but Data-independent) operations (tokenization etc)
         2. This can allow the same model preprocessing for multiple datasources
         3. Users can configurate which labels to use for modelling 
             (e.g. intent classification, slot filling or both together etc)
     '''
 
     def __init__(self, dataset_split: str, dialogues_processor: object, tokenizer, schemas, schema_config, cfg):
         """ Constructor
         Args:
             dataset_split: dataset split
             dialogues_processor: Data generator for SGD dialogues
+            tokenizer: tokenizer
+            schemas: SGD schema for domain, intent and slots
+            schema_config: config dict for schemas
+            cfg: cfg container for dataset
         """
         self.dataset_split = dataset_split
         self.tokenizer = tokenizer
         self.schemas = schemas
         self.schema_config = schema_config
         self.dialogues_processor = dialogues_processor
         self.cfg = cfg
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/dialogue_gpt_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/dataset/dialogue_gpt_classification_dataset.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,49 +9,52 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""
-This file contains code artifacts adapted from the original implementation:
-https://github.com/google-research/google-research/blob/master/schema_guided_dst
-"""
-
 import copy
 import random
 import re
 from collections import defaultdict
 
 import torch
 
-from nemo.core.classes import Dataset
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_dataset import DialogueDataset
+from nemo.utils import logging
 
 
-class DialogueGPTDataset(Dataset):
+class DialogueGPTClassificationDataset(DialogueDataset):
     '''
+    Designed for classification tasks such as intent/domain classification as well as slot tagging
+
     Dataset Class 
         1. Performs Model-dependent (but Data-independent) operations (tokenization etc)
         2. This can allow the same model preprocessing for multiple datasources
         3. Users can configurate which labels to use for modelling 
             (e.g. intent classification, slot filling or both together etc)
-        
     '''
 
     def __init__(self, dataset_split: str, dialogues_processor: object, tokenizer, cfg):
         """ Constructor
         Args:
             dataset_split: dataset split
             dialogues_processor: Data generator for SGD dialogues
+            tokenizer: tokenizer
+            cfg: cfg container for dataset
         """
         self.cfg = cfg
 
         if self.cfg.target_template == "with_slots" and self.cfg.eval_mode != "generation":
-            raise ValueError("slot-filling is not supported by eval_mode {}".format(self.cfg.eval_mode))
+            raise ValueError(
+                "slot-filling is not supported by eval_mode {}, please set model.dataset.eval_mode=generation instead".format(
+                    self.cfg.eval_mode
+                )
+            )
         if self.cfg.target_template != "with_slots" and self.cfg.field == "slots":
             raise ValueError("please set model.dataset.target_template='with_slots' if model.dataset.field='slots'")
         self.label_type = self.cfg.field
         if self.cfg.target_template == "with_description":
             self.label_to_description = defaultdict(str)
         self.all_possible_labels = set()
         self.tokenizer = tokenizer
@@ -121,18 +124,20 @@
         if not slots:
             return "None"
         return ", ".join(
             ["{}({})".format(slot, value if isinstance(value, str) else value[0]) for slot, value in slots.items()]
         )
 
     def format_target(self, target, slots=None):
-        # this function formats the back part of the training ex, after the base_template
-        # for instance, "restaurant" in  "<utterance> service: restaurant"
-        # or "set alarm\nslots: <slot_name1>(<slot_value1>), <slot_name1>(<slot_value1>)" in \
-        # "<utterance>\nintent: set alarm\nslots: <slot_name1>(<slot_value1>), <slot_name1>(<slot_value1>)"
+        """
+        Formats the back part of the training example, after the base_template
+        for instance, "restaurant" in  "<utterance> service: restaurant"
+        or "set alarm\nslots: <slot_name1>(<slot_value1>), <slot_name1>(<slot_value1>)" in \
+        "<utterance>\nintent: set alarm\nslots: <slot_name1>(<slot_value1>), <slot_name1>(<slot_value1>)"
+        """
         if self.cfg.target_template == "with_description":
             return target + ' (' + self.label_to_description[target] + ')'
         elif self.cfg.target_template == "default":
             return target
         elif self.cfg.target_template == "with_slots" and slots is not None and self.cfg.field == "intent":
             return target + '\nslots: ' + self.linearize_slots(slots)
         elif self.cfg.target_template == "with_slots" and slots is not None and self.cfg.field == "slots":
@@ -148,16 +153,16 @@
             utterance = ex["utterance"]
             label = ex["labels"][self.label_type]
             slots = ex["labels"]["slots"] if self.cfg.target_template == "with_slots" else None
             lm_feature = self.format_prompt(utterance) + ' ' + self.format_target(label, slots=slots)
             feature_len = self.get_n_tokens_in_sentence(lm_feature)
             max_sample_length = max(max_sample_length, feature_len)
             lm_features.append(lm_feature)
-        print("max feature length per sample with label: ", max_sample_length)
-        print(
+        logging.info("max feature length per sample with label: ".format(max_sample_length))
+        logging.info(
             "please adjust max seq len to at least {} * ({} + 1) = {} but not too much more for efficiency".format(
                 max_sample_length, self.cfg.few_shot, max_sample_length * (1 + self.cfg.few_shot)
             )
         )
         return lm_features
 
     def format_prompt(self, utterance, few_shot=0, idx=None):
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/evaluate.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/evaluate.py`

 * *Files 1% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 import collections
 import glob
 import json
 import os
 
 import numpy as np
 
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.metrics import (
+from nemo.collections.nlp.metrics.sgd_metrics import (
     ACTIVE_INTENT_ACCURACY,
     JOINT_CAT_ACCURACY,
     JOINT_GOAL_ACCURACY,
     JOINT_NONCAT_ACCURACY,
     NAN_VAL,
     REQUESTED_SLOTS_F1,
     REQUESTED_SLOTS_PRECISION,
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/input_example.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/input_example/sgd_input_example.py`

 * *Files 1% similar despite different names*

```diff
@@ -16,66 +16,56 @@
 """
 This file contains code artifacts adapted from the original implementation:
 https://github.com/google-research/google-research/blob/master/schema_guided_dst/baseline/data_utils.py
 """
 
 from typing import List
 
+from nemo.collections.nlp.data.dialogue.input_example.input_example import DialogueInputExample
 from nemo.utils import logging
 
 __all__ = [
-    'DialogueInputExample',
-    'SGDInputExample',
     'SGDInputExample',
     'STR_DONTCARE',
     'STATUS_OFF',
     'STATUS_ACTIVE',
     'STATUS_DONTCARE',
 ]
 
 
-class DialogueInputExample(object):
-    """
-    Generic Dialogue Input Example
-    Uses data: dict as a flexible interface to support various input types.
-    This ranges from classification labels, to complex nested labels such as those in SGD
+class DialogueSGDInputExample(DialogueInputExample):
 
-    {
-        "utterance": <utterance>,
-        "labels": { 
-            "intent": <intent>,
-            "slots": { ... },
-        }
-    }
     """
+    Template for DialogueSGDInputExample
 
-    def __init__(self, data: dict):
-        self.data = data
+    Meant as a descriptor rather than to be instantiated
 
-    def __repr__(self):
-        return self.data
+    Please instantiate using the base class 'DialogueInputExample' 
 
-    def __str__(self):
-        return self.data
-
-
-class DialogueSGDInputExample(DialogueInputExample):
-
-    """
     {
         "example_id": <example_id>,
         "example_id_num": <example_id_num>,
         "utterance": <utterance>,
         "system_utterance": <system_utterance>,
         "system_slots": None or {
                     "<slot-name1>": {
                         "exclusive_end": 46,
                         "slot": "restaurant_name",
                         "start": 34
             },
+        "system_actions": None or [{
+                "act": "INFORM",
+                "canonical_values": [
+                  "2019-03-02"
+                ],
+                "slot": "date",
+                "values": [
+                  "March 2nd"
+                ]
+              }, ...]
         "labels": {
             "service": <service>,
             "intent": <intent>,
             "slots": {
                 #only non-empty slots
                 #most slot values are list of length 1 
                 #but there are some of length 2 as both are accepted
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/metrics.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/sgd_metrics.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/prediction_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/prediction_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 """
 
 import json
 import os
 from collections import OrderedDict, defaultdict
 from typing import Dict, List, Optional
 
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.input_example import (
+from nemo.collections.nlp.data.dialogue.input_example.sgd_input_example import (
     STATUS_ACTIVE,
     STATUS_DONTCARE,
     STR_DONTCARE,
 )
 from nemo.utils import logging
 
 REQ_SLOT_THRESHOLD = 0.5
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/schema.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/sgd/schema.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/entity_linking/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_normalization_as_tagging/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.data.entity_linking.entity_linking_dataset import EntityLinkingDataset
+
+from nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger import ThutmoseTaggerModel
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/entity_linking/entity_linking_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/entity_linking/entity_linking_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/data_processors.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/data_processors.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/glue_benchmark_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/glue_benchmark_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/gpt_ptune_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/gpt_ptune_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/glue_benchmark/t5_ptune_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/glue_benchmark/t5_ptune_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/information_retrieval/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/information_retrieval/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/information_retrieval/information_retrieval_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/information_retrieval/information_retrieval_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_descriptor.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/intent_slot_classification_descriptor.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_descriptor.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/intent_slot_classification/multi_label_intent_slot_classification_descriptor.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/l2r_lm_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/l2r_lm_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/lm_bert_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/lm_bert_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/Makefile` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/Makefile`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -10,10 +10,10 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from nemo.collections.nlp.data.language_modeling.megatron.bert_dataset import BertDataset
 from nemo.collections.nlp.data.language_modeling.megatron.gpt_dataset import GPTDataset
-from nemo.collections.nlp.data.language_modeling.megatron.gpt_prompt_tuning_dataset import GPTPromptTuningDataset
+from nemo.collections.nlp.data.language_modeling.megatron.gpt_prompt_learning_dataset import GPTPromptLearningDataset
 from nemo.collections.nlp.data.language_modeling.megatron.indexed_dataset import IndexedDataset, MMapIndexedDataset
 from nemo.collections.nlp.data.language_modeling.megatron.t5_dataset import T5Dataset
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/bart_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/bart_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/base_dataset_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/base_dataset_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/bert_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/bert_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/blendable_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/blendable_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/data_samplers.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/data_samplers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/dataset_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/dataset_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/gpt_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/gpt_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/helpers.cpp` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/helpers.cpp`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/indexed_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/indexed_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/lm_adapted_t5_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/lm_adapted_t5_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/megatron_batch_samplers.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/megatron_batch_samplers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/megatron_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/megatron_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/request_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/request_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/megatron/t5_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/megatron/t5_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/language_modeling/sentence_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/language_modeling/sentence_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/machine_translation/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/machine_translation/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/machine_translation/machine_translation_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/machine_translation/machine_translation_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/machine_translation/preproc_mt_data.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/machine_translation/preproc_mt_data.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/question_answering_squad/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/question_answering_squad/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/question_answering_squad/qa_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/question_answering_squad/qa_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/question_answering_squad/qa_squad_processing.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/question_answering_squad/qa_squad_processing.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text2sparql/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text2sparql/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text2sparql/text2sparql_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text2sparql/text2sparql_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_classification/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_classification/ptune_text_classification_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_classification/ptune_text_classification_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_classification/text_classification_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_classification/text_classification_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/constants.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/constants.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/decoder_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/decoder_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/tagger_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/tagger_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/test_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/test_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/text_normalization/utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/text_normalization/utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -52,15 +52,15 @@
     written = re.sub("³", "3", written)
     return written
 
 
 def convert_fraction(written: str):
     """
     converts fraction to standard form, e.g "½" -> "1/2", "1 ½" -> "1 1/2"
-    
+
     Args:
         written: written form
     Returns:
         written: modified form
     """
     written = re.sub(" ½", " 1/2", written)
     written = re.sub(" ⅓", " 1/3", written)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/punctuation_capitalization_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/punctuation_capitalization_dataset.py`

 * *Files 5% similar despite different names*

```diff
@@ -792,15 +792,17 @@
             dataset. If ``-1``, use all dataset. Useful for testing.
         tokens_in_batch (:obj:`int`, `optional`, defaults to :obj:`5000`): number of tokens in a batch including
             paddings and special tokens ([CLS], [SEP], [UNK]). This class :meth:`__getitem__` method returns not
             samples but ready batches. Number of samples in a batch is adjusted for input sequences lengths. If input
             sequences are short, then a batch will contain more samples. Before packing into batches, samples are
             sorted by number of tokens they contain. Sorting allows to reduce number of pad tokens in a batch
             significantly. Regular PyTorch data loader shuffling will only permute batches with changing their content.
-            Proper shuffling is achieved via calling method :meth:`repack_batches_with_shuffle` every epoch.
+            Proper shuffling is achieved via calling method :meth:`repack_batches_with_shuffle` every epoch. If
+            parameter ``number_of_batches_is_multiple_of`` is greater than 1, some batches may be split into smaller
+            pieces.
         pad_label (:obj:`str`, `optional`, defaults to :obj:`'O'`): pad value to use for labels. It's also the neutral
             label both for punctuation and capitalization.
         punct_label_ids (:obj:`Dict[str, int]`, `optional`): dict to map punctuation labels to label ids. For dev set,
             use label ids generated during training to support cases when not all labels are present in the dev set.
             For training, it is recommended to set ``punct_label_ids`` to ``None`` or load from cache.
         capit_label_ids (:obj:`Dict[str, int]`, `optional`): same ``punct_label_ids`` for capitalization labels.
         ignore_extra_tokens (:obj:`bool`, `optional`, defaults to :obj:`False`): whether to compute loss on
@@ -835,20 +837,28 @@
         add_masks_and_segment_ids_to_batch (:obj:`bool`, `optional`, defaults to :obj:`True`): whether to add
             ``'loss_mask'``, ``'input_mask'``, ``'segment_ids'`` items to a batch. Useful for creation of tarred
             dataset and can NOT be used during model training and inference.
         verbose (:obj:`bool`, `optional`, defaults to :obj:`True`): whether to show data examples, label stats and
             other useful information.
         n_jobs (:obj:`int`, `optional`, defaults to :obj:`0`): number of workers used for tokenization, encoding
             labels, creating "first token in word" mask, and clipping. If ``n_jobs <= 0`` data preparation is performed
-            without multiprocessing. By default ``n_jobs`` is equal to the number of CPUs.
+            without multiprocessing. By default ``n_jobs`` is ``0``.
 
             .. warning::
                 There can be deadlocking problems with some tokenizers (e.g. SentencePiece, HuggingFace AlBERT)
                 if ``n_jobs > 0``.
-
+        number_of_batches_is_multiple_of (:obj:`int`, `optional`, defaults to :obj:`1`): number of batches in the
+            dataset is made divisible by ``number_of_batches_is_multiple_of``. If ``number_of_batches_is_multiple_of``
+            is greater than 1, then several batches are split in parts until number of batches
+            is divisible by ``number_of_batches_is_multiple_of``. If there is no enough queries in the dataset to
+            create enough batches, then a warning is printed. This parameter is useful for dev and validation datasets
+            if multiple GPUs are used. The problem is that if number of batches is not evenly divisible by number of
+            GPUs, then some queries may be processed several times and metrics will be distorted.
+        batch_shuffling_random_seed (:obj:`int`, defaults to :obj:`int`): a random seed used for batches repacking and
+            shuffling.
         tokenization_progress_queue (:obj:`multiprocessing.Queue`, `optional`): a queue for reporting tokenization
             progress. Useful for creation of tarred dataset
         batch_mark_up_progress_queue (:obj:`multiprocessing.Queue`, `optional`): a queue for reporting progress in
             deciding which samples batches will contain. Useful for creation of tarred dataset
         batch_building_progress_queue (:obj:`multiprocessing.Queue`, `optional`): a queue for reporting progress in
             batch creation (stacking and padding). Useful for creation of tarred dataset
     """
@@ -884,14 +894,16 @@
         get_label_frequencies: bool = False,
         label_info_save_dir: Optional[Union[str, os.PathLike]] = None,
         punct_label_vocab_file: Optional[Union[str, os.PathLike]] = None,
         capit_label_vocab_file: Optional[Union[str, os.PathLike]] = None,
         add_masks_and_segment_ids_to_batch: bool = True,
         verbose: bool = True,
         n_jobs: Optional[int] = 0,
+        number_of_batches_is_multiple_of: int = 1,
+        batch_shuffling_random_seed: int = 42,
         tokenization_progress_queue: Optional[mp.Queue] = None,
         batch_mark_up_progress_queue: Optional[mp.Queue] = None,
         batch_building_progress_queue: Optional[mp.Queue] = None,
     ) -> None:
         """ Initializes BertPunctuationCapitalizationDataset. """
         if isinstance(punct_label_ids, DictConfig):
             punct_label_ids = OmegaConf.to_container(punct_label_ids)
@@ -902,54 +914,55 @@
             labels_file,
             punct_label_ids,
             capit_label_ids,
             punct_label_vocab_file,
             capit_label_vocab_file,
             num_samples,
             use_cache,
+            number_of_batches_is_multiple_of,
         )
         if punct_label_vocab_file is not None:
             punct_label_vocab_file = Path(punct_label_vocab_file).expanduser()
             punct_label_ids = load_label_ids(punct_label_vocab_file)
         if capit_label_vocab_file is not None:
             capit_label_vocab_file = Path(capit_label_vocab_file).expanduser()
             capit_label_ids = load_label_ids(capit_label_vocab_file)
-        text_file, labels_file = Path(text_file).expanduser(), Path(labels_file).expanduser()
+        self.text_file, self.labels_file = Path(text_file).expanduser(), Path(labels_file).expanduser()
         if label_info_save_dir is None:
-            self.label_info_save_dir = text_file.parent
+            self.label_info_save_dir = self.text_file.parent
         else:
             self.label_info_save_dir = Path(label_info_save_dir).expanduser()
 
         self.tokens_in_batch = tokens_in_batch
         self.tokenizer = tokenizer
         self.pad_label = pad_label
         self.ignore_extra_tokens = ignore_extra_tokens
         self.ignore_start_end = ignore_start_end
         self.add_masks_and_segment_ids_to_batch = add_masks_and_segment_ids_to_batch
         self.verbose = verbose
         self.batch_mark_up_progress_queue = batch_mark_up_progress_queue
         self.batch_building_progress_queue = batch_building_progress_queue
 
         master_device = is_global_rank_zero()
-        self.features_pkl = self._get_path_to_pkl_features(text_file, cache_dir, max_seq_length, num_samples)
+        self.features_pkl = self._get_path_to_pkl_features(self.text_file, cache_dir, max_seq_length, num_samples)
         features = None
         if master_device and not (self.features_pkl.is_file() and use_cache):
             if verbose:
-                logging.info(f'Processing {text_file}')
-            res = self._read_dataset(text_file, labels_file, num_samples)
+                logging.info(f'Processing {self.text_file}')
+            res = self._read_dataset(self.text_file, self.labels_file, num_samples)
             text_lines, punct_label_lines, capit_label_lines, punct_unique_labels, capit_unique_labels = res
             if punct_label_ids:
                 self._check_label_ids_vs_unique_labels(
-                    punct_label_ids, punct_unique_labels, 'punct', 'punctuation', labels_file
+                    punct_label_ids, punct_unique_labels, 'punct', 'punctuation', self.labels_file
                 )
             else:
                 punct_label_ids = create_label_ids(punct_unique_labels, self.pad_label)
             if capit_label_ids:
                 self._check_label_ids_vs_unique_labels(
-                    capit_label_ids, capit_unique_labels, 'capit', 'capitalzation', labels_file
+                    capit_label_ids, capit_unique_labels, 'capit', 'capitalzation', self.labels_file
                 )
             else:
                 capit_label_ids = create_label_ids(capit_unique_labels, self.pad_label)
             features = _get_features(
                 text_lines,
                 punct_label_lines,
                 capit_label_lines,
@@ -982,14 +995,16 @@
                 tokenization_progress_queue.put(len(features[0]))
             if self.verbose:
                 logging.info(f'Features restored from {self.features_pkl}')
             features = features[:-2]
 
         self.input_ids, self.subtokens_mask, self.punct_labels, self.capit_labels = features
         self.punct_label_ids, self.capit_label_ids = punct_label_ids, capit_label_ids
+        self.number_of_batches_is_multiple_of = number_of_batches_is_multiple_of
+        self.batch_shuffling_random_state = np.random.RandomState(batch_shuffling_random_seed)
         self.batches = self._pack_into_batches(
             self.input_ids, self.subtokens_mask, self.punct_labels, self.capit_labels
         )
 
         if get_label_frequencies:
             self.punct_label_frequencies = self._calculate_and_save_label_frequencies(self.punct_labels, 'punct')
             self.capit_label_frequencies = self._calculate_and_save_label_frequencies(self.capit_labels, 'capit')
@@ -1017,14 +1032,15 @@
         labels_file: Union[str, os.PathLike],
         punct_label_ids: Optional[Dict[str, int]],
         capit_label_ids: Optional[Dict[str, int]],
         punct_label_vocab_file: Union[str, os.PathLike],
         capit_label_vocab_file: Union[str, os.PathLike],
         num_samples: int,
         use_cache: bool,
+        number_of_batches_is_multiple_of: int,
     ) -> None:
         if torch.distributed.is_initialized() and torch.distributed.get_world_size() > 1 and not use_cache:
             raise ValueError(
                 f"If you already created process group and the world size is greater than 1, then `use_cache` "
                 f"parameter has to `True`. Only master process prepares features and if `use_cache=False`, then "
                 f"other processes will not be able to obtain features. Alternatively, you may set `use_cache=False` "
                 f"and set up data before spawning processes. Use `cache_dir` dataset directory with "
@@ -1073,27 +1089,32 @@
                     f'which is passed in parameter `capit_label_vocab_file`',
                 )
         if num_samples == 0:
             raise ValueError(
                 f"Parameter `num_samples` has to be positive or negative whereas `num_samples={num_samples}`. "
                 f"Negative `num_samples` is for using all samples in a dataset."
             )
+        if number_of_batches_is_multiple_of < 1 or not isinstance(number_of_batches_is_multiple_of, int):
+            raise ValueError(
+                f"Parameter `number_of_batches_is_multiple_of` has to be positive integer whereas "
+                f"{number_of_batches_is_multiple_of} is given."
+            )
 
     def _check_label_ids_loaded_from_pkl(
         self,
         parameter_punct_label_ids: Dict[str, int],
         parameter_capit_label_ids: Dict[str, int],
         pkl_punct_label_ids: Any,
         pkl_capit_label_ids: Any,
         punct_label_vocab_file: Optional[Path],
         capit_label_vocab_file: Optional[Path],
     ) -> None:
         if not isinstance(pkl_punct_label_ids, dict):
             raise ValueError(
-                f"Punctuation label ids loaded from features file {self.features_pkl} has wrong type "
+                f"Punctuation label ids loaded from features file {self.features_pkl} have wrong type "
                 f"{type(pkl_punct_label_ids)}"
             )
         if parameter_punct_label_ids is not None:
             if parameter_punct_label_ids != pkl_punct_label_ids:
                 raise_not_equal_labels_error(
                     first_labels=parameter_punct_label_ids,
                     second_labels=pkl_punct_label_ids,
@@ -1166,14 +1187,104 @@
         if len(dataset) == 0:
             raise ValueError(f"Dataset loaded from files {text_file} and {labels_file} is empty.")
         if num_samples > 0:
             dataset = dataset[:num_samples]
         text_lines, punct_labels_lines, capit_labels_lines = zip(*dataset)
         return text_lines, punct_labels_lines, capit_labels_lines, punct_unique_labels, capit_unique_labels
 
+    @staticmethod
+    def calc_batch_seq_length(queries: List[np.ndarray], length_is_multiple_of: int) -> int:
+        return ceil(max([len(elem) for elem in queries]) / length_is_multiple_of) * length_is_multiple_of
+
+    def _adjust_number_of_batches(
+        self,
+        input_ids: List[np.ndarray],
+        batch_beginnings: List[int],
+        batch_sizes: List[int],
+        batch_seq_lengths: List[int],
+    ) -> Tuple[List[int], List[int], List[int]]:
+        """
+        If length of ``batch_sizes`` list is not divisible by ``self.number_of_batches_is_multiple_of``, then
+        one or several batches are split into parts until number of batches is divisible by
+        ``self.number_of_batches_is_multiple_of``.
+
+        The method selects a batch and tries to slice smaller batches with 8 elements each from the batch. If
+        the batch cannot be sliced any further and there are still not enough batches, then the next batch from dataset
+        is selected.
+
+        If slicing batches of size 8 is not enough, then batches of size 1 are created.
+
+        If dataset is too small to create enough batches, then a warning is shown.
+
+        Args:
+            input_ids: tokenized queries of the dataset. `input_ids` are expected to be sorted by length in ascending
+                order.
+            batch_beginnings: indices of first elements of batches created inside :meth:`_mark_up_batches` method.
+                Expected to be sorted in ascending order.
+            batch_sizes: sizes of batches created inside :meth:`_mark_up_batches` method.
+            batch_seq_lengths: lengths of elements in batch after padding created inside :meth:`_mark_up_batches`
+                method.
+
+        Returns:
+            batch_beginnings: a list of indices in ``input_ids`` of first samples of every batch
+            batch_sizes: a list of numbers of samples in batches
+            batch_seq_lengths: a list of sequence lengths after padding for every batch
+        """
+        batch_beginnings, batch_sizes = batch_beginnings.copy(), batch_sizes.copy()
+        batch_seq_lengths = batch_seq_lengths.copy()
+        num_missing_batches = (
+            self.number_of_batches_is_multiple_of - len(batch_sizes) % self.number_of_batches_is_multiple_of
+        )
+        if num_missing_batches == 0:
+            return batch_beginnings, batch_sizes, batch_seq_lengths
+        if sum(batch_sizes) - len(batch_sizes) < num_missing_batches:
+            logging.warning(
+                f"Unable to achieve number of batches multiple of {self.number_of_batches_is_multiple_of} because "
+                f"dataset in files '{self.text_file}' and '{self.labels_file}' contains not enough queries "
+                f"({sum(batch_sizes)}) or queries in the dataset are too long. Dataset will have "
+                f"{len(batch_sizes)} batches instead. For validation or test dataset if multiple GPUs are used "
+                f"this will lead to distorted metrics because some batches will be processed several times. "
+                f"To fix this problem you may try to tweak (increase) parameter `tokens_in_batch`, though result is "
+                f"not guaranteed."
+            )
+            return batch_beginnings, batch_sizes, batch_seq_lengths
+        num_cut = 0
+        for ss in [8, 1]:  # ss - split_size
+            old_num_batches = len(batch_sizes)
+            # Starting from the last batch because its size is likely to be not multiple of 8. Thus number of
+            # batches which size is not multiple of 8 can be reduced by 1.
+            original_batch_index = old_num_batches - 1
+            while original_batch_index >= 0 and num_cut < num_missing_batches:
+                bs, bb = batch_sizes[original_batch_index], batch_beginnings[original_batch_index]
+                rb = 0  # an index of sliced first element of sliced batch in original batch (relative beginning)
+                if rb < bs - ss:
+                    while rb < bs - ss and num_cut < num_missing_batches:
+                        batch_sizes.append(ss)
+                        batch_beginnings.append(bb + rb)
+                        batch_seq_lengths.append(
+                            self.calc_batch_seq_length(input_ids[bb + rb : bb + rb + ss], length_is_multiple_of=8)
+                        )
+                        rb += ss
+                        num_cut += 1
+                    assert len(input_ids[bb + rb : bb + bs]) > 0
+                    batch_sizes[original_batch_index] = bs - rb
+                    batch_beginnings[original_batch_index] = bb + rb
+                    batch_seq_lengths[original_batch_index] = self.calc_batch_seq_length(
+                        input_ids[bb + rb : bb + bs], length_is_multiple_of=8
+                    )
+                original_batch_index -= 1
+            # Keeping order of batches.
+            batch_beginnings, batch_sizes, batch_seq_lengths = map(
+                list, zip(*sorted(zip(batch_beginnings, batch_sizes, batch_seq_lengths), key=lambda x: x[0]))
+            )
+        assert len(batch_beginnings) % self.number_of_batches_is_multiple_of == 0
+        assert len(batch_sizes) % self.number_of_batches_is_multiple_of == 0
+        assert len(batch_seq_lengths) % self.number_of_batches_is_multiple_of == 0
+        return batch_beginnings, batch_sizes, batch_seq_lengths
+
     def _mark_up_batches(self, input_ids: List[np.ndarray]) -> Tuple[List[int], List[int], List[int]]:
         """
         Computes indices of first samples in batch, batch sizes, seq lengths for batches. ``input_ids`` has to be
         sorted by number of tokens in ascending order.
 
         Batches are marked up with respect to following conditions:
             - total number of tokens in batch including paddings is less or equal to ``self.tokens_in_batch``
@@ -1204,45 +1315,50 @@
             current_max_length = max(current_max_length, ceil(len(inp) / 8) * 8)
             if current_max_length * (i + 1 - start) > self.tokens_in_batch:
                 batch_size = (i - start) // 8 * 8
                 if batch_size == 0:
                     if i > start:
                         batch_size = i - start
                         logging.warning(
-                            f"Could not create batch with multiple of 8 size. Probably there is a too long sequence in "
-                            f"the dataset. current_max_length={current_max_length}. Batch size will be reduced to "
-                            f"{batch_size}. tokens_in_batch={self.tokens_in_batch}. The batch includes sequences from "
+                            f"Could not create batch with multiple of 8 size. Probably, there is a too long sequence "
+                            f"in the dataset or parameter `tokens_in_batch` is too small. Current length of sequences "
+                            f"in batch is {current_max_length}. Batch size will be reduced to {batch_size}. "
+                            f"tokens_in_batch={self.tokens_in_batch}. The batch includes sequences from "
                             f"{start} to {i - 1}."
                         )
                     else:
                         logging.warning(
                             f"Input sequence number {i - 1} is too long. Could not fit it into batch with "
                             f"{self.tokens_in_batch} tokens. Sequence number {i - 1} will not be added to batches."
                         )
                         start = i
                         current_max_length = ceil(len(inp) / 8) * 8
                         continue
-                seq_length = ceil(max([len(inp) for inp in input_ids[start : start + batch_size]]) / 8) * 8
+                seq_length = self.calc_batch_seq_length(input_ids[start : start + batch_size], length_is_multiple_of=8)
                 batch_beginnings.append(start)
                 batch_sizes.append(batch_size)
                 batch_seq_lengths.append(seq_length)
                 start += batch_size
-                current_max_length = ceil(max([len(inp) for inp in input_ids[start : i + 1]]) / 8) * 8
+                current_max_length = self.calc_batch_seq_length(input_ids[start : i + 1], length_is_multiple_of=8)
             if self.batch_mark_up_progress_queue is not None:
                 progress_made += 1
                 if progress_made >= BATCH_MARK_UP_PROGRESS_REPORT_PERIOD:
                     self.batch_mark_up_progress_queue.put(progress_made)
                     progress_made = 0
         if start < len(input_ids):
-            seq_length = ceil(max([len(inp) for inp in input_ids[start:]]) / 8) * 8
+            seq_length = self.calc_batch_seq_length(input_ids[start:], length_is_multiple_of=8)
             batch_beginnings.append(start)
             batch_sizes.append(len(input_ids) - start)
             batch_seq_lengths.append(seq_length)
             if self.batch_mark_up_progress_queue is not None:
                 self.batch_mark_up_progress_queue.put(progress_made)
+        if len(batch_beginnings) % self.number_of_batches_is_multiple_of:
+            batch_beginnings, batch_sizes, batch_seq_lengths = self._adjust_number_of_batches(
+                input_ids, batch_beginnings, batch_sizes, batch_seq_lengths
+            )
         assert sum(batch_sizes) == len(input_ids)
         for i in range(len(batch_beginnings) - 1):
             assert batch_beginnings[i] + batch_sizes[i] == batch_beginnings[i + 1]
             assert batch_seq_lengths[i] >= max(
                 [len(inp) for inp in input_ids[batch_beginnings[i] : batch_beginnings[i] + batch_sizes[i]]]
             )
         return batch_beginnings, batch_sizes, batch_seq_lengths
@@ -1286,15 +1402,15 @@
               - ``'segment_ids'``: a ``np.int8`` numpy array;
               - ``'input_mask'``: a boolean numpy array;
               - ``'loss_mask'``: a boolean numpy array.
 
             The values of a batch dictionary are numpy arrays of identical shape.
         """
         zipped = list(zip(input_ids, subtokens_mask, punct_labels, capit_labels))
-        random.shuffle(zipped)
+        self.batch_shuffling_random_state.shuffle(zipped)
         input_ids, subtokens_mask, punct_labels, capit_labels = zip(*sorted(zipped, key=lambda x: x[0].shape[0]))
         batch_beginnings, batch_sizes, batch_seq_lengths = self._mark_up_batches(input_ids)
         batches = []
         if self.batch_building_progress_queue is None:
             inp_iterator = tqdm(
                 zip(batch_beginnings, batch_sizes, batch_seq_lengths),
                 total=len(batch_beginnings),
@@ -1335,15 +1451,15 @@
             if self.batch_building_progress_queue is not None:
                 progress_made += size
                 if progress_made >= BATCH_BUILDING_PROGRESS_REPORT_PERIOD:
                     self.batch_building_progress_queue.put(progress_made)
                     progress_made = 0
         if self.batch_building_progress_queue is not None:
             self.batch_building_progress_queue.put(progress_made)
-        random.shuffle(batches)
+        self.batch_shuffling_random_state.shuffle(batches)
         return batches
 
     def repack_batches_with_shuffle(self) -> None:
         """A function for proper shuffling of a dataset. Pytorch data loader shuffing will only permute batches."""
         logging.info("Shuffling training dataset")
         self.batches = self._pack_into_batches(
             self.input_ids, self.subtokens_mask, self.punct_labels, self.capit_labels
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/punctuation_capitalization_infer_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/punctuation_capitalization_infer_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/punctuation_capitalization_tarred_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/punctuation_capitalization_tarred_dataset.py`

 * *Files 0% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 import inspect
 import json
 import multiprocessing as mp
 import os
 import pickle
 import re
 import shutil
+import tempfile
 from collections import deque
 from pathlib import Path
 from typing import Any, Callable, Dict, Iterator, List, Optional, Set, Tuple, Type, Union
 
 import numpy as np
 import torch
 import webdataset as wds
@@ -156,44 +157,52 @@
         tokenizer_name,
         tokenizer_model=None if tokenizer_model is None else str(tokenizer_model),
         vocab_file=None if vocab_file is None else str(vocab_file),
         merges_file=None if merges_file is None else str(merges_file),
         special_tokens=special_tokens,
         use_fast=use_fast_tokenizer,
     )
-    tmp_text = output_dir / f'tmp_text_{fragment_idx}.txt'
-    tmp_labels = output_dir / f'tmp_labels_{fragment_idx}.txt'
-    with text_file.open() as tf, labels_file.open() as lf, tmp_text.open('w') as otf, tmp_labels.open('w') as olf:
-        tf.seek(text_start_pos)
-        lf.seek(label_start_pos)
-        for _ in range(lines_per_dataset_fragment):
-            text_line = tf.readline()
-            if not text_line:
-                break
-            otf.write(text_line)
-            olf.write(lf.readline())
-    dataset = BertPunctuationCapitalizationDataset(
-        tmp_text,
-        tmp_labels,
-        max_seq_length,
-        tokenizer,
-        tokens_in_batch=tokens_in_batch,
-        pad_label=pad_label,
-        punct_label_ids=punct_label_ids,
-        capit_label_ids=capit_label_ids,
-        n_jobs=0,
-        use_cache=False,
-        add_masks_and_segment_ids_to_batch=False,
-        verbose=False,
-        tokenization_progress_queue=tokenization_progress_queue,
-        batch_mark_up_progress_queue=batch_mark_up_progress_queue,
-        batch_building_progress_queue=batch_building_progress_queue,
-    )
-    tmp_text.unlink()
-    tmp_labels.unlink()
+    tmp_text: Optional[str] = None
+    tmp_labels: Optional[str] = None
+    try:
+        otfd, tmp_text = tempfile.mkstemp(suffix='.txt', prefix=f'text_{fragment_idx}_', dir=output_dir, text=True)
+        olfd, tmp_labels = tempfile.mkstemp(suffix='.txt', prefix=f'labels_{fragment_idx}_', dir=output_dir, text=True)
+        with text_file.open() as tf, labels_file.open() as lf, os.fdopen(otfd, 'w') as otf, os.fdopen(
+            olfd, 'w'
+        ) as olf:
+            tf.seek(text_start_pos)
+            lf.seek(label_start_pos)
+            for _ in range(lines_per_dataset_fragment):
+                text_line = tf.readline()
+                if not text_line:
+                    break
+                otf.write(text_line)
+                olf.write(lf.readline())
+        dataset = BertPunctuationCapitalizationDataset(
+            tmp_text,
+            tmp_labels,
+            max_seq_length,
+            tokenizer,
+            tokens_in_batch=tokens_in_batch,
+            pad_label=pad_label,
+            punct_label_ids=punct_label_ids,
+            capit_label_ids=capit_label_ids,
+            n_jobs=0,
+            use_cache=False,
+            add_masks_and_segment_ids_to_batch=False,
+            verbose=False,
+            tokenization_progress_queue=tokenization_progress_queue,
+            batch_mark_up_progress_queue=batch_mark_up_progress_queue,
+            batch_building_progress_queue=batch_building_progress_queue,
+        )
+    finally:
+        if tmp_text is not None and os.path.exists(tmp_text):
+            os.remove(tmp_text)
+        if tmp_labels is not None and os.path.exists(tmp_labels):
+            os.remove(tmp_labels)
     dataset.features_pkl.unlink()
     tar_ctr = 0
     current_file_name = output_dir / TAR_FRAGMENT_TMPL_IN_PROGRESS.format(fragment_idx=fragment_idx, file_idx=tar_ctr)
     current_num_batches = 0
     sink = wds.TarWriter(str(current_file_name))
     progress_made = 0
     for batch_i, batch in enumerate(dataset):
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/token_classification_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/token_classification_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/token_classification/token_classification_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/token_classification/token_classification_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/zero_shot_intent_recognition/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/zero_shot_intent_recognition/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/data/zero_shot_intent_recognition/zero_shot_intent_dataset.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/zero_shot_intent_recognition/zero_shot_intent_dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/losses/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/losses/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/losses/sgd_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/losses/sgd_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/metrics/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,8 +9,9 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from nemo.collections.nlp.metrics.classification_report import ClassificationReport, MultiLabelClassificationReport
+from nemo.collections.nlp.metrics.dialogue_metrics import DialogueClassificationMetrics
 from nemo.collections.nlp.metrics.sequence_perplexity import SequencePerplexity
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/metrics/classification_report.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/classification_report.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/metrics/sequence_perplexity.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/metrics/sequence_perplexity.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -8,28 +8,30 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.dialogue_state_tracking_sgdqa.sgdqa_model import SGDQAModel
+
 from nemo.collections.nlp.models.duplex_text_normalization import (
     DuplexDecoderModel,
     DuplexTaggerModel,
     DuplexTextNormalizationModel,
 )
 from nemo.collections.nlp.models.entity_linking.entity_linking_model import EntityLinkingModel
 from nemo.collections.nlp.models.glue_benchmark.glue_benchmark_model import GLUEModel
 from nemo.collections.nlp.models.information_retrieval import BertDPRModel, BertJointIRModel
 from nemo.collections.nlp.models.intent_slot_classification import (
     IntentSlotClassificationModel,
     MultiLabelIntentSlotClassificationModel,
 )
+from nemo.collections.nlp.models.language_modeling import MegatronGPTPromptLearningModel
 from nemo.collections.nlp.models.language_modeling.bert_lm_model import BERTLMModel
 from nemo.collections.nlp.models.language_modeling.transformer_lm_model import TransformerLMModel
 from nemo.collections.nlp.models.machine_translation import MTEncDecModel
 from nemo.collections.nlp.models.question_answering.qa_model import QAModel
 from nemo.collections.nlp.models.text2sparql.text2sparql_model import Text2SparqlModel
 from nemo.collections.nlp.models.text_classification import TextClassificationModel
+from nemo.collections.nlp.models.text_normalization_as_tagging import ThutmoseTaggerModel
 from nemo.collections.nlp.models.token_classification import PunctuationCapitalizationModel, TokenClassificationModel
 from nemo.collections.nlp.models.zero_shot_intent_recognition import ZeroShotIntentModel
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_generative/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,9 +8,11 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.dialogue_state_tracking_generative.dialogue_gpt_model import DialogueGPTModel
-from nemo.collections.nlp.models.dialogue_state_tracking_generative.dialogue_metrics import IntentSlotMetrics
+from nemo.collections.nlp.models.dialogue.dialogue_gpt_classification_model import DialogueGPTClassificationModel
+from nemo.collections.nlp.models.dialogue.dialogue_zero_shot_intent_model import DialogueZeroShotIntentModel
+from nemo.collections.nlp.models.dialogue.intent_slot_classification_model import IntentSlotClassificationModel
+from nemo.collections.nlp.models.dialogue.sgdqa_model import SGDQAModel
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_generative/dialogue_gpt_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_gpt_classification_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,60 +9,48 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-'''
-This file contains code artifacts adapted from the original implementation:
-https://github.com/google-research/google-research/blob/master/schema_guided_dst/baseline/train_and_predict.py
-'''
-
 import collections
 import os
 import random
 from typing import Dict, Optional, Union
 
 import numpy as np
 import torch
 from omegaconf import DictConfig
 from pytorch_lightning import Trainer
 from torch.utils.data import DataLoader
 from transformers import AutoModelWithLMHead
 
-from nemo.collections.nlp.data.dialogue_state_tracking_generative import (
-    DialogueGPTDataset,
-    DialogueSGDDataProcessor,
-    Schema,
-)
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.assistant_data_processor import (
-    DialogueAssistantDataProcessor,
-)
+from nemo.collections.nlp.data.dialogue import DialogueGPTClassificationDataset, DialogueSGDDataProcessor
+from nemo.collections.nlp.data.dialogue.data_processor.assistant_data_processor import DialogueAssistantDataProcessor
+from nemo.collections.nlp.data.dialogue.data_processor.design_data_processor import DialogueDesignDataProcessor
 from nemo.collections.nlp.metrics.classification_report import ClassificationReport
-from nemo.collections.nlp.models.dialogue_state_tracking_generative.dialogue_metrics import IntentSlotMetrics
+from nemo.collections.nlp.metrics.dialogue_metrics import DialogueClassificationMetrics
 from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel
 from nemo.collections.nlp.models.nlp_model import NLPModel
 from nemo.core.classes.common import PretrainedModelInfo
 from nemo.utils import logging
-from nemo.utils.get_rank import is_global_rank_zero
-
-__all__ = ['DialogueGPTModel']
 
-NUM_TASKS = 1  # focussing on intent currently 6  # number of multi-head tasks
+__all__ = ['DialogueGPTClassificationModel']
 
 
-class DialogueGPTModel(NLPModel):
+class DialogueGPTClassificationModel(NLPModel):
     def __init__(
         self, cfg: DictConfig, trainer: Trainer = None,
     ):
 
         self.cfg = cfg
+        self.eval_mode = cfg.dataset.eval_mode
         self.data_prepared = False
-
+        self.epoch_number = 0
         super().__init__(cfg=cfg, trainer=trainer, no_lm_init=True)
 
         if self.cfg.library == "huggingface":
             self.language_model = AutoModelWithLMHead.from_pretrained(cfg.language_model.pretrained_model_name)
             self.language_model.resize_token_embeddings(len(self.tokenizer.tokenizer))
         elif self.cfg.library == "megatron":
             self.language_model = MegatronGPTModel.restore_from(cfg.language_model.lm_checkpoint, trainer=trainer)
@@ -97,16 +85,14 @@
 
         self.all_existing_labels = set(self.label_to_ids.keys())
 
         self.token_to_words = {}
         self.classification_report = ClassificationReport(
             num_classes=len(self.label_to_ids) + 1, mode='micro', label_ids=self.label_to_ids, dist_sync_on_step=True
         )
-        self.eval_mode = cfg.eval_mode
-        self.cfg = cfg
 
     def training_step(self, batch, batch_idx):
 
         (
             input_ids,
             attn_masks,
             labels,
@@ -171,25 +157,27 @@
         for output in outputs:
             generated_field += output["generated_field"]
             ground_truth_field += output["ground_truth_field"]
             inputs += output["input"]
 
         with_slots = self.cfg.dataset.target_template == "with_slots"
 
-        generated_labels, generated_slots = IntentSlotMetrics.split_label_and_slots(
+        generated_labels, generated_slots = DialogueClassificationMetrics.split_label_and_slots(
             generated_field, with_slots=with_slots
         )
-        ground_truth_labels, ground_truth_slots = IntentSlotMetrics.split_label_and_slots(
+        ground_truth_labels, ground_truth_slots = DialogueClassificationMetrics.split_label_and_slots(
             ground_truth_field, with_slots=with_slots
         )
 
         os.makedirs(self.cfg.dataset.dialogues_example_dir, exist_ok=True)
-        filename = os.path.join(self.cfg.dataset.dialogues_example_dir, f"{mode}_predictions.jsonl")
+        filename = os.path.join(
+            self.cfg.dataset.dialogues_example_dir, f"{mode}_predictions_epoch{self.epoch_number}.jsonl"
+        )
 
-        IntentSlotMetrics.save_predictions(
+        DialogueClassificationMetrics.save_predictions(
             filename,
             generated_labels,
             generated_slots,
             ground_truth_labels,
             ground_truth_slots,
             generated_field,
             ground_truth_field,
@@ -207,29 +195,38 @@
         ).to(self.classification_report.device)
 
         tp, fn, fp, _ = self.classification_report(generated_field_ids, ground_truth_field_ids)
 
         precision, recall, f1, report = self.classification_report.compute()
         self.classification_report.reset()
 
-        slot_precision, slot_recall, slot_f1, slot_joint_goal_accuracy = IntentSlotMetrics.get_slot_filling_metrics(
-            generated_slots, ground_truth_slots
-        )
+        (
+            slot_precision,
+            slot_recall,
+            slot_f1,
+            slot_joint_goal_accuracy,
+        ) = DialogueClassificationMetrics.get_slot_filling_metrics(generated_slots, ground_truth_slots)
 
         logging.info(report)
 
         self.log('{}_precision'.format(self.cfg.dataset.field), precision)
         self.log('{}_f1'.format(self.cfg.dataset.field), f1)
         self.log('{}_recall'.format(self.cfg.dataset.field), recall)
         self.log('{}_{}_accuracy'.format(mode, self.cfg.dataset.field), label_acc * 100)
         self.log('slot_precision', slot_precision)
         self.log('slot_recall', slot_recall)
         self.log('slot_f1', slot_f1)
         self.log('slot_joint_goal_accuracy', slot_joint_goal_accuracy)
 
+        if mode == 'val':
+            self.epoch_number += 1
+            if self.cfg.save_model:
+                filename = '{}/epoch-{}-model.bin'.format(self.cfg.dataset.dialogues_example_dir, self.epoch_number)
+                torch.save(self.language_model.state_dict(), filename)
+
     def test_step(self, batch, batch_idx):
         return self.eval_step_helper(batch=batch, mode='test')
 
     # for inference only
     def predict_step(self, batch, batch_idx, dataloader_idx=None):
         # return self(batch)
         raise NotImplementedError()
@@ -582,43 +579,31 @@
         """
         Preprocessed schema and dialogues and caches this
         """
         if self.data_prepared:
             return
 
         if self._cfg.dataset.task == 'sgd':
-            schema_config = {
-                "MAX_NUM_CAT_SLOT": self._cfg.dataset.max_num_cat_slot,
-                "MAX_NUM_NONCAT_SLOT": self._cfg.dataset.max_num_noncat_slot,
-                "MAX_NUM_VALUE_PER_CAT_SLOT": self._cfg.dataset.max_value_per_cat_slot,
-                "MAX_NUM_INTENT": self._cfg.dataset.max_num_intent,
-                "NUM_TASKS": NUM_TASKS,
-                "MAX_SEQ_LENGTH": self._cfg.dataset.max_seq_length,
-            }
-            all_schema_json_paths = []
-            for dataset_split in ['train', 'test', 'dev']:
-                all_schema_json_paths.append(os.path.join(self._cfg.dataset.data_dir, dataset_split, "schema.json"))
-            schemas = Schema(all_schema_json_paths)
-
             self.dialogues_processor = DialogueSGDDataProcessor(
-                task_name=self._cfg.dataset.task_name,
                 data_dir=self._cfg.dataset.data_dir,
                 dialogues_example_dir=self._cfg.dataset.dialogues_example_dir,
                 tokenizer=self.tokenizer,
-                schemas=schemas,
-                schema_config=schema_config,
-                subsample=self._cfg.dataset.subsample,
-            )
-            if is_global_rank_zero():
-                overwrite_dial_files = not self._cfg.dataset.use_cache
-                self.dialogues_processor.save_dialog_examples(overwrite_dial_files=overwrite_dial_files)
-        elif self._cfg.dataset.task == 'assistant':
+                cfg=self._cfg.dataset,
+            )
+        elif self._cfg.dataset.task in ['assistant', "zero_shot"]:
             self.dialogues_processor = DialogueAssistantDataProcessor(
-                data_dir=self._cfg.dataset.data_dir, tokenizer=self.tokenizer,
+                data_dir=self._cfg.dataset.data_dir, tokenizer=self.tokenizer, cfg=self._cfg.dataset
             )
+        elif self._cfg.dataset.task == 'design':
+            self.dialogues_processor = DialogueDesignDataProcessor(
+                data_dir=self._cfg.dataset.data_dir, tokenizer=self.tokenizer, cfg=self._cfg.dataset,
+            )
+        else:
+            raise ValueError("Only sgd, assistant, zero_shot, design supported for Dialogue GPT Classification Model")
+
         self.data_prepared = True
 
     def update_data_dirs(self, data_dir: str, dialogues_example_dir: str):
         """
         Update data directories
 
         Args:
@@ -653,15 +638,15 @@
     def _setup_dataloader_from_config(self, cfg: DictConfig, split: str) -> DataLoader:
         dataset_cfg = self._cfg.dataset
         data_dir = dataset_cfg.data_dir
 
         if not os.path.exists(data_dir):
             raise FileNotFoundError(f"Data directory is not found at: {data_dir}.")
 
-        dataset = DialogueGPTDataset(
+        dataset = DialogueGPTClassificationDataset(
             dataset_split=split,
             dialogues_processor=self.dialogues_processor,
             tokenizer=self.dialogues_processor._tokenizer,
             cfg=dataset_cfg,
         )
 
         dl = torch.utils.data.DataLoader(
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_sgdqa/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/common/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,16 +1,15 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.dialogue_state_tracking_generative.dialogue_gpt_model import DialogueGPTModel
-from nemo.collections.nlp.models.dialogue_state_tracking_sgdqa.sgdqa_model import SGDQAModel
+from nemo.collections.nlp.data.common.sequence_to_sequence_dataset import SequenceToSequenceDataset
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/dialogue_state_tracking_sgdqa/sgdqa_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/sgdqa_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,44 +15,44 @@
 
 '''
 This file contains code artifacts adapted from the original implementation:
 https://github.com/google-research/google-research/blob/master/schema_guided_dst/baseline/train_and_predict.py
 '''
 
 import os
-from typing import Dict, List, Optional
+from typing import List, Optional
 
 import torch
-from omegaconf import DictConfig, OmegaConf
+from omegaconf import DictConfig
 from pytorch_lightning import Trainer
 from torch.utils.data import DataLoader
 
-from nemo.collections.nlp.data.dialogue_state_tracking_generative import (
-    DialogueSGDBERTDataset,
-    DialogueSGDDataProcessor,
-    Schema,
-)
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.evaluate import evaluate, get_in_domain_services
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.prediction_utils import write_predictions_to_file
+from nemo.collections.nlp.data.dialogue import DialogueSGDBERTDataset, DialogueSGDDataProcessor
+from nemo.collections.nlp.data.dialogue.sgd.evaluate import evaluate, get_in_domain_services
+from nemo.collections.nlp.data.dialogue.sgd.prediction_utils import write_predictions_to_file
 from nemo.collections.nlp.losses import SGDDialogueStateLoss
 from nemo.collections.nlp.models.nlp_model import NLPModel
 from nemo.collections.nlp.modules import SGDDecoder, SGDEncoder
 from nemo.collections.nlp.parts.utils_funcs import tensor2list
 from nemo.core.classes.common import PretrainedModelInfo, typecheck
-from nemo.core.neural_types import NeuralType
 from nemo.utils import logging
-from nemo.utils.get_rank import is_global_rank_zero
 
 __all__ = ['SGDQAModel']
 
-NUM_TASKS = 6  # number of multi-head tasks
-
 
 class SGDQAModel(NLPModel):
-    """Dialogue State Tracking Model SGD-QA"""
+    """
+    Dialogue State Tracking Model SGD-QA (https://arxiv.org/abs/2105.08049)
+
+    The SGD-QA model is a fast multi-pass schema-guided state-tracking model, that is trained on the Google schema-guided state tracking dataset (https://arxiv.org/abs/1909.05855).
+    The model takes dialogue as input and outputs the dialogue state, which includes slot-value pairs. 
+    The model consists of two components: a neural natural language understanding model (NLU), and a rule-based state tracker.
+    The NLU takes in a dialogue turn and different schema (entity) information options and outputs their match score. The state tracker takes the highest rated entities and composes
+    the dialogue state across turns.
+    """
 
     @property
     def output_module(self):
         return self.decoder
 
     def __init__(self, cfg: DictConfig, trainer: Trainer = None):
         self.data_prepared = False
@@ -503,41 +503,22 @@
 
     def prepare_data(self):
         """
         Preprocessed schema and dialogues and caches this
         """
         if self.data_prepared:
             return
-        schema_config = {
-            "MAX_NUM_CAT_SLOT": self._cfg.dataset.max_num_cat_slot,
-            "MAX_NUM_NONCAT_SLOT": self._cfg.dataset.max_num_noncat_slot,
-            "MAX_NUM_VALUE_PER_CAT_SLOT": self._cfg.dataset.max_value_per_cat_slot,
-            "MAX_NUM_INTENT": self._cfg.dataset.max_num_intent,
-            "NUM_TASKS": NUM_TASKS,
-            "MAX_SEQ_LENGTH": self._cfg.dataset.max_seq_length,
-        }
-        all_schema_json_paths = []
-        for dataset_split in ['train', 'test', 'dev']:
-            all_schema_json_paths.append(os.path.join(self._cfg.dataset.data_dir, dataset_split, "schema.json"))
-        schemas = Schema(all_schema_json_paths)
 
         self.dialogues_processor = DialogueSGDDataProcessor(
-            task_name=self._cfg.dataset.task_name,
             data_dir=self._cfg.dataset.data_dir,
             dialogues_example_dir=self._cfg.dataset.dialogues_example_dir,
             tokenizer=self.tokenizer,
-            schemas=schemas,
-            schema_config=schema_config,
-            subsample=self._cfg.dataset.subsample,
+            cfg=self._cfg.dataset,
         )
 
-        if is_global_rank_zero():
-            overwrite_dial_files = not self._cfg.dataset.use_cache
-            self.dialogues_processor.save_dialog_examples(overwrite_dial_files=overwrite_dial_files)
-
         self.data_prepared = True
 
     def update_data_dirs(self, data_dir: str, dialogues_example_dir: str):
         """
         Update data directories
 
         Args:
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/duplex_tagger.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/duplex_tagger.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/duplex_tn.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/duplex_tn.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/duplex_text_normalization/utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/duplex_text_normalization/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/enc_dec_nlp_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/enc_dec_nlp_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/entity_linking/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/entity_linking/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/entity_linking/entity_linking_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/entity_linking/entity_linking_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/glue_benchmark/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/glue_benchmark/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/glue_benchmark/glue_benchmark_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/glue_benchmark/glue_benchmark_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/glue_benchmark/metrics_for_glue.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/glue_benchmark/metrics_for_glue.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/base_ir_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/base_ir_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/bert_dpr_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/bert_dpr_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/information_retrieval/bert_joint_ir_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/information_retrieval/bert_joint_ir_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/intent_slot_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification/intent_slot_classification_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/intent_slot_classification/intent_slot_classification_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification/multi_label_intent_slot_classification_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/intent_slot_classification/multi_label_intent_slot_classification_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification_refactor/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -8,10 +8,9 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.intent_slot_classification_refactor.intent_slot_classification_model import (
-    IntentSlotClassificationModel,
-)
+from nemo.collections.nlp.models.machine_translation.mt_enc_dec_bottleneck_model import MTBottleneckModel
+from nemo.collections.nlp.models.machine_translation.mt_enc_dec_model import MTEncDecModel
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/intent_slot_classification_refactor/intent_slot_classification_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/intent_slot_classification_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,53 +17,44 @@
 
 import torch
 from omegaconf import DictConfig, OmegaConf
 from pytorch_lightning import Trainer
 from torch.utils.data import DataLoader
 
 from nemo.collections.common.losses import AggregatorLoss, CrossEntropyLoss
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.assistant_data_processor import (
-    DialogueAssistantDataProcessor,
-)
-from nemo.collections.nlp.data.dialogue_state_tracking_generative.sgd.dialogue_bert_dataset import DialogueBERTDataset
+from nemo.collections.nlp.data.dialogue.data_processor.assistant_data_processor import DialogueAssistantDataProcessor
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_bert_dataset import DialogueBERTDataset
 from nemo.collections.nlp.data.intent_slot_classification import IntentSlotDataDesc, IntentSlotInferenceDataset
 from nemo.collections.nlp.metrics.classification_report import ClassificationReport
-from nemo.collections.nlp.models.dialogue_state_tracking_generative.dialogue_metrics import IntentSlotMetrics
+from nemo.collections.nlp.metrics.dialogue_metrics import DialogueClassificationMetrics
 from nemo.collections.nlp.models.nlp_model import NLPModel
 from nemo.collections.nlp.modules.common import SequenceTokenClassifier
 from nemo.collections.nlp.parts.utils_funcs import tensor2list
 from nemo.core.classes import typecheck
 from nemo.core.classes.common import PretrainedModelInfo
-from nemo.core.neural_types import NeuralType
 from nemo.utils import logging
 
 
 class IntentSlotClassificationModel(NLPModel):
     def __init__(self, cfg: DictConfig, trainer: Trainer = None):
         """ Initializes BERT Joint Intent and Slot model.
         """
-        self.max_seq_length = cfg.language_model.max_seq_length
-
+        self.max_seq_length = cfg.dataset.max_seq_length
+        self.cfg = cfg
         # Check the presence of data_dir.
-        if not cfg.data_dir or not os.path.exists(cfg.data_dir):
-            # Disable setup methods.
-            IntentSlotClassificationModel._set_model_restore_state(is_being_restored=True)
+        if not cfg.dataset.data_dir or not os.path.exists(cfg.dataset.data_dir):
             # Set default values of data_desc.
             self._set_defaults_data_desc(cfg)
         else:
-            self.data_dir = cfg.data_dir
+            self.data_dir = cfg.dataset.data_dir
             # Update configuration of data_desc.
-            self._set_data_desc_to_cfg(cfg, cfg.data_dir, cfg.train_ds, cfg.validation_ds)
-
+            self._set_data_desc_to_cfg(cfg, cfg.dataset.data_dir, cfg.train_ds, cfg.validation_ds)
         # init superclass
         super().__init__(cfg=cfg, trainer=trainer)
 
-        # Enable setup methods.
-        IntentSlotClassificationModel._set_model_restore_state(is_being_restored=False)
-
         # Initialize Classifier.
         self._reconfigure_classifier()
 
     def _set_defaults_data_desc(self, cfg):
         """
         Method makes sure that cfg.data_desc params are set.
         If not, set's them to "dummy" defaults.
@@ -125,19 +116,19 @@
             logging.info(f'Labels: {label_ids}')
             logging.info(f'Labels mapping saved to : {out.name}')
 
     def _reconfigure_classifier(self):
         """ Method reconfigures the classifier depending on the settings of model cfg.data_desc """
 
         self.classifier = SequenceTokenClassifier(
-            hidden_size=self.bert_model.config.hidden_size,
+            hidden_size=self.hidden_size,
             num_intents=len(self.cfg.data_desc.intent_labels),
             num_slots=len(self.cfg.data_desc.slot_labels),
-            dropout=self.cfg.head.fc_dropout,
-            num_layers=self.cfg.head.num_output_layers,
+            dropout=self.cfg.classifier_head.fc_dropout,
+            num_layers=self.cfg.classifier_head.num_output_layers,
             log_softmax=False,
         )
 
         # define losses
         if self.cfg.class_balancing == 'weighted_loss':
             # You may need to increase the number of epochs for convergence when using weighted_loss
             self.intent_loss = CrossEntropyLoss(logits_ndim=2, weight=self.cfg.data_desc.intent_weights)
@@ -191,20 +182,20 @@
 
     @typecheck()
     def forward(self, input_ids, attention_mask, token_type_ids):
         """
         No special modification required for Lightning, define it as you normally would
         in the `nn.Module` in vanilla PyTorch.
         """
-        hidden_states = self.bert_model(
-            input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask
-        )
-        if isinstance(hidden_states, tuple):
-            hidden_states = hidden_states[0]
-
+        if self._cfg.tokenizer.get('library', '') == 'megatron':
+            hidden_states, _ = self.bert_model(input_ids, attention_mask, tokentype_ids=token_type_ids, lm_labels=None)
+        else:
+            hidden_states = self.bert_model(
+                input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask
+            )
         intent_logits, slot_logits = self.classifier(hidden_states=hidden_states)
         return intent_logits, slot_logits
 
     def training_step(self, batch, batch_idx):
         """
         Lightning calls this inside the training loop with the data from the training dataloader
         passed in as `batch`.
@@ -352,28 +343,31 @@
             all_generated_slots.append(processed_predicted_slots)
             all_ground_truth_slots.append(processed_ground_truth_slots)
             all_utterances.append(' '.join(utterance_tokens))
 
         os.makedirs(self.cfg.dataset.dialogues_example_dir, exist_ok=True)
         filename = os.path.join(self.cfg.dataset.dialogues_example_dir, "predictions.jsonl")
 
-        IntentSlotMetrics.save_predictions(
+        DialogueClassificationMetrics.save_predictions(
             filename,
             generated_labels,
             all_generated_slots,
             ground_truth_labels,
             all_ground_truth_slots,
             ['' for i in range(len(generated_labels))],
             ['' for i in range(len(generated_labels))],
             all_utterances,
         )
 
-        slot_precision, slot_recall, slot_f1, slot_joint_goal_accuracy = IntentSlotMetrics.get_slot_filling_metrics(
-            all_generated_slots, all_ground_truth_slots
-        )
+        (
+            slot_precision,
+            slot_recall,
+            slot_f1,
+            slot_joint_goal_accuracy,
+        ) = DialogueClassificationMetrics.get_slot_filling_metrics(all_generated_slots, all_ground_truth_slots)
 
         return slot_precision, slot_recall, slot_f1, slot_joint_goal_accuracy
 
     @staticmethod
     def join_tokens_containing_at_sign(utterance_tokens, slot_names):
         """
         assumes utterance contains only one @ sign
@@ -409,16 +403,16 @@
             for index, token in enumerate(utterance_tokens[:-1]):
                 if utterance_tokens[index + 1] == "@" or utterance_tokens[index - 1] == "@" or token == "@":
                     new_tokens[-1] += token
                 else:
                     new_tokens.append(token)
         else:
             raise ValueError(
-                "Difference of more than 3 ({}) encountered. please extend this method for utterance {} with slots {}".format(
-                    diff, utterance_tokens, slot_names
+                "Difference of more than 3 ({}, utterance has {}, predicted slots has {}) encountered. please extend this method for utterance {} with slots {}".format(
+                    diff, len(utterance_tokens), len(slot_names), utterance_tokens, slot_names
                 )
             )
 
         return new_tokens
 
     def validation_epoch_end(self, outputs):
         """
@@ -491,15 +485,15 @@
     def setup_validation_data(self, val_data_config: Optional[DictConfig]):
         self._validation_dl = self._setup_dataloader_from_config(cfg=val_data_config, dataset_split='dev')
 
     def setup_test_data(self, test_data_config: Optional[DictConfig]):
         self._test_dl = self._setup_dataloader_from_config(cfg=test_data_config, dataset_split='test')
 
     def _setup_dataloader_from_config(self, cfg: DictConfig, dataset_split: str):
-        data_processor = DialogueAssistantDataProcessor(self.data_dir, self.tokenizer)
+        data_processor = DialogueAssistantDataProcessor(self.data_dir, self.tokenizer, cfg=self.cfg.dataset)
 
         dataset = DialogueBERTDataset(
             dataset_split,
             data_processor,
             self.tokenizer,
             self.cfg.dataset,  # this is the model.dataset cfg, which is diff from train_ds cfg etc
         )
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/text2sparql/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,9 +8,8 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.language_modeling.bert_lm_model import BERTLMModel
-from nemo.collections.nlp.models.language_modeling.transformer_lm_model import TransformerLMModel
+from nemo.collections.nlp.models.text2sparql.text2sparql_model import Text2SparqlModel
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/bert_lm_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/bert_lm_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron/bert_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron/bert_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron/gpt_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron/gpt_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -98,17 +98,14 @@
         activations_checkpoint_method=None,
         activations_checkpoint_num_layers=1,
         layernorm_epsilon=1e-5,
         bias_gelu_fusion=True,
         persist_layer_norm=False,
         openai_gelu=False,
         onnx_safe=False,
-        use_soft_prompts=False,
-        num_prompt_tokens=10,
-        existing_prompt_tags=None,
     ):
 
         super(GPTModel, self).__init__()
 
         self.parallel_output = parallel_output
         self.pre_process = pre_process
         self.post_process = post_process
@@ -144,17 +141,14 @@
             activations_checkpoint_method=activations_checkpoint_method,
             activations_checkpoint_num_layers=activations_checkpoint_num_layers,
             layernorm_epsilon=layernorm_epsilon,
             bias_gelu_fusion=bias_gelu_fusion,
             persist_layer_norm=persist_layer_norm,
             openai_gelu=openai_gelu,
             onnx_safe=onnx_safe,
-            use_soft_prompts=use_soft_prompts,
-            num_prompt_tokens=num_prompt_tokens,
-            existing_prompt_tags=existing_prompt_tags,
         )
 
         self.initialize_word_embeddings(
             init_method=init_method_normal(init_method_std), vocab_size=vocab_size, hidden_size=hidden_size
         )
 
     def set_input_tensor(self, input_tensor):
@@ -163,29 +157,27 @@
 
     def forward(
         self,
         input_ids,
         position_ids,
         attention_mask,
         labels=None,
-        prompt_ids=None,
         token_type_ids=None,
         layer_past=None,
         get_key_value=False,
         forward_method_parallel_output=None,
         encoder_input=None,
         set_inference_key_value_memory=False,
         inference_max_sequence_len=None,
     ):
 
         lm_output = self.language_model(
             input_ids,
             position_ids,
             attention_mask,
-            prompt_ids=prompt_ids,
             layer_past=layer_past,
             get_key_value=get_key_value,
             encoder_input=encoder_input,
             set_inference_key_value_memory=set_inference_key_value_memory,
             inference_max_sequence_len=inference_max_sequence_len,
         )
 
@@ -221,13 +213,7 @@
 
         # Load word_embeddings.
         if self.post_process and not self.pre_process:
             self.word_embeddings.load_state_dict(state_dict[self._word_embeddings_for_head_key], strict=strict)
         if self._language_model_key in state_dict:
             state_dict = state_dict[self._language_model_key]
         self.language_model.load_state_dict(state_dict, strict=strict)
-
-    def _init_prompt_from_random(self, prompt_tag, prompt_id):
-        self.language_model._init_prompt_from_random(prompt_tag, prompt_id)
-
-    def _init_prompt_from_text(self, prompt_tag, prompt_id, init_token_ids):
-        self.language_model._init_prompt_from_text(prompt_tag, prompt_id, init_token_ids)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_bart_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_bart_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_base_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_base_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_bert_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_bert_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_glue_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_finetune_model.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,48 +8,65 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import torch
-from omegaconf.dictconfig import DictConfig
+from omegaconf import DictConfig, ListConfig
 from pytorch_lightning.trainer.trainer import Trainer
 
+from nemo.collections.common.data import ConcatDataset
 from nemo.collections.common.metrics.classification_accuracy import ExactStringPerCategoryMatchMetric
-from nemo.collections.nlp.data.glue_benchmark.glue_benchmark_dataset import (
-    TextToTextGLUEDataset,
-    TextToTextXNLIDataset,
-)
+from nemo.collections.nlp.data.common.sequence_to_sequence_dataset import SequenceToSequenceDataset
 from nemo.collections.nlp.models.language_modeling.megatron_t5_model import MegatronT5Model
 from nemo.collections.nlp.parts.nlp_overrides import GlobalBatchDataFetcher
-from nemo.utils import AppState, app_state, logging
+from nemo.utils import AppState, logging
 
 try:
     from apex.transformer import parallel_state
-    from apex.transformer.pipeline_parallel.utils import _reconfigure_microbatch_calculator
-    from apex.transformer.pipeline_parallel.utils import get_num_microbatches
+    from apex.transformer.pipeline_parallel.utils import _reconfigure_microbatch_calculator, get_num_microbatches
 
     HAVE_APEX = True
 except (ImportError, ModuleNotFoundError):
     HAVE_APEX = False
 
 
-__all__ = ['MegatronT5GLUEModel']
+__all__ = ['MegatronT5FinetuneModel']
 
 
-class MegatronT5GLUEModel(MegatronT5Model):
-    """GLUE Model that Inherits from MegatronT5Model instead."""
+class MegatronT5FinetuneModel(MegatronT5Model):
+    """Finetune Model that Inherits from MegatronT5Model instead."""
 
     def __init__(self, cfg: DictConfig, trainer: Trainer):
         super().__init__(cfg, trainer=trainer)
-        if hasattr(self.cfg, 'eval_languages'):
-            self.acc_metric = ExactStringPerCategoryMatchMetric(self.cfg.eval_languages)
+        self.val_metric = self.setup_metric(self.cfg.data.validation_ds)
+        if hasattr(self.cfg.data, "test_ds"):
+            self.test_metric = self.setup_metric(self.cfg.data.test_ds)
+
+    def setup_metric(self, data_cfg):
+        # XNLI
+        if hasattr(self.cfg, "eval_languages"):
+            metric = ExactStringPerCategoryMatchMetric(self.cfg.eval_languages)
+        # GLUE
+        elif hasattr(data_cfg, "task_name"):
+            metric = ExactStringPerCategoryMatchMetric()
+        # General Seq2seq finetuning
         else:
-            self.acc_metric = ExactStringPerCategoryMatchMetric()
+            if isinstance(data_cfg.src_file_name, ListConfig):
+                if hasattr(data_cfg, "names") and isinstance(data_cfg.names, ListConfig):
+                    metric = ExactStringPerCategoryMatchMetric(self.cfg.data.validation_ds.names)
+                else:
+                    metric = ExactStringPerCategoryMatchMetric(
+                        [str(i) for i in range(len(self.cfg.data.test_ds.src_file_name))]
+                    )
+            else:
+                metric = ExactStringPerCategoryMatchMetric()
+
+        return metric
 
     def setup(self, stage=None):
         # This is just to keep the parent class happy since we override its setup() method.
         self.init_consumed_samples = 0
         self.init_global_step = 0
         if stage == 'predict':
             return
@@ -159,25 +176,14 @@
             rampup_batch_size=None,
             global_batch_size=self.cfg.data.validation_ds.global_batch_size,
             micro_batch_size=self.cfg.data.validation_ds.micro_batch_size,
             data_parallel_size=parallel_state.get_data_parallel_world_size(),
         )
         return super().on_validation_epoch_start()
 
-    def on_test_epoch_start(self):
-        app_state = AppState()
-        _reconfigure_microbatch_calculator(
-            rank=app_state.global_rank,
-            rampup_batch_size=None,
-            global_batch_size=self.cfg.data.test_ds.global_batch_size,
-            micro_batch_size=self.cfg.data.test_ds.micro_batch_size,
-            data_parallel_size=parallel_state.get_data_parallel_world_size(),
-        )
-        return super().on_test_epoch_start()
-
     def on_validation_epoch_end(self):
         app_state = AppState()
         if hasattr(self, "_train_ds"):
             _reconfigure_microbatch_calculator(
                 rank=app_state.global_rank,
                 rampup_batch_size=None,
                 global_batch_size=self.cfg.data.train_ds.global_batch_size,
@@ -209,60 +215,76 @@
                 * parallel_state.get_data_parallel_world_size()
                 * get_num_microbatches(),
                 micro_batch_size=micro_batch_size,
                 data_parallel_size=parallel_state.get_data_parallel_world_size(),
             )
         return super().training_step(batch, batch_idx)
 
-    def inference_step(self, batch, batch_idx):
+    def inference_step(self, batch, batch_idx, mode, dataloader_idx=0):
         batch_has_lang_information = len(batch[0]) == 7
         # XNLI Batches have language information that need to be removed before calling the parent validation step.
         if batch_has_lang_information:
             processed_batch = []
             for micro_batch in batch:
                 micro_batch = {k: v for k, v in micro_batch.items() if k != 'lang'}
                 processed_batch.append(micro_batch)
         else:
             processed_batch = batch
 
         micro_batch_size = processed_batch[0]['text_enc'].size(0)
-
         # This should happen only on the last batch of the dataset.
         if micro_batch_size != self.cfg.data.validation_ds.micro_batch_size:
             app_state = AppState()
             _reconfigure_microbatch_calculator(
                 rank=app_state.global_rank,
                 rampup_batch_size=None,
                 global_batch_size=micro_batch_size
                 * parallel_state.get_data_parallel_world_size()
                 * get_num_microbatches(),
                 micro_batch_size=micro_batch_size,
                 data_parallel_size=parallel_state.get_data_parallel_world_size(),
             )
+
         # Call parent validation step to get the loss.
         loss = super().validation_step(processed_batch, batch_idx)
 
         # Remainder of the code is to run the decoding loop, and compute accuracies.
         if batch_has_lang_information:
             tokens_enc, _, _, labels, enc_mask, _, langs = self.process_global_batch(batch)
         else:
             tokens_enc, _, _, labels, enc_mask, _ = self.process_global_batch(batch)
 
-        predicted_token_ids, _ = self.decode(tokens_enc=tokens_enc, enc_mask=enc_mask, num_tokens_to_generate=10)
+        predicted_token_ids, _ = self.decode(tokens_enc=tokens_enc, enc_mask=enc_mask, num_tokens_to_generate=30)
 
         preds_text, labels_text = self.preds_and_labels_to_text(predicted_token_ids, labels)
 
         if not batch_has_lang_information:
-            langs = [None] * len(preds_text)
+            if (
+                mode == 'validation'
+                and hasattr(self.cfg.data.validation_ds, "names")
+                and isinstance(self.cfg.data.validation_ds.names, ListConfig)
+            ):
+                categories = [self.cfg.data.validation_ds.names[dataloader_idx]] * len(preds_text)
+            elif (
+                mode == 'test'
+                and hasattr(self.cfg.data.test_ds, "names")
+                and isinstance(self.cfg.data.test_ds.names, ListConfig)
+            ):
+                categories = [self.cfg.data.test_ds.names[dataloader_idx]] * len(preds_text)
+            else:
+                categories = [None] * len(preds_text)
+        else:
+            categories = langs
 
-        assert len(langs) == len(preds_text) == len(labels_text)
-        for _, (pred, label, lang) in enumerate(zip(preds_text, labels_text, langs)):
-            _ = self.acc_metric(pred, label, lang)
+        metric = self.val_metric if mode == 'validation' else self.test_metric
+        assert len(categories) == len(preds_text) == len(labels_text)
+        for _, (pred, label, category) in enumerate(zip(preds_text, labels_text, categories)):
+            _ = metric(pred, label, category)
 
-        return loss
+        return {'loss': loss, 'preds': preds_text, 'labels': labels_text, 'categories': categories}
 
     def preds_and_labels_to_text(self, preds, labels):
         preds = preds.cpu().numpy().tolist()
         labels = labels.cpu().numpy().tolist()
         preds_text, labels_text = [], []
         for _, (pred, label) in enumerate(zip(preds, labels)):
             if self.tokenizer.eos_id in pred:
@@ -278,37 +300,53 @@
             preds_text.append(pred)
             labels_text.append(label)
 
         return preds_text, labels_text
 
     def inference_epoch_end(self, outputs, mode):
         # Parent class will handle logging of the loss.
+        if not outputs:
+            return
+        if isinstance(outputs[0], dict):
+            outputs = [outputs]
+
+        for _, output in enumerate(outputs):
+            if mode == 'validation':
+                averaged_loss = super().validation_epoch_end([x['loss'] for x in output])
+            else:
+                averaged_loss = super().test_epoch_end([x['loss'] for x in output])
+
         if mode == 'validation':
-            averaged_loss = super().validation_epoch_end(outputs)
+            accuracy = self.val_metric.compute()
         else:
-            averaged_loss = super().test_epoch_end(outputs)
-        accuracy = self.acc_metric.compute()
+            accuracy = self.test_metric.compute()
         # Loss is logged in the parent epoch end class.
         self.log(f'{mode}_acc', accuracy['acc'])
-        if hasattr(self.cfg, 'eval_languages'):
-            for lang in self.cfg.eval_languages:
-                self.log(f'{lang}_acc', accuracy[lang])
-                logging.info(f"{mode} {lang} accuracy: {accuracy[lang]} total: {accuracy[lang+'_total']}")
         logging.info(f"{mode} accuracy: {accuracy['acc']}")
-        self.acc_metric.reset()
+
+        for k, v in accuracy.items():
+            if k != 'acc' and 'total' not in k:
+                logging.info(f"{mode} {k} accuracy: {v} total: {accuracy[k+'_total']}")
+                self.log(f'{mode}_{k}_acc', v)
+
+        if mode == 'validation':
+            self.val_metric.reset()
+        else:
+            self.test_metric.reset()
+
         return averaged_loss, accuracy['acc']
 
-    def validation_step(self, batch, batch_idx):
-        return self.inference_step(batch, batch_idx)
+    def validation_step(self, batch, batch_idx, dataloader_idx=0):
+        return self.inference_step(batch, batch_idx, 'validation', dataloader_idx)
 
     def validation_epoch_end(self, outputs):
         _ = self.inference_epoch_end(outputs, 'validation')
 
-    def test_step(self, batch, batch_idx):
-        return self.inference_step(batch, batch_idx)
+    def test_step(self, batch, batch_idx, dataloader_idx=0):
+        return self.inference_step(batch, batch_idx, 'test', dataloader_idx)
 
     def test_epoch_end(self, outputs):
         _ = self.inference_epoch_end(outputs, 'test')
 
     def build_data_loader(
         self,
         dataset,
@@ -331,17 +369,17 @@
             dataset, num_replicas=world_size, rank=rank, shuffle=shuffle
         )
         # This check makes sure the val_check_interval is less than the number of global batches.
         # Normally, PTL would do this check and properly account for gradient accumulation.
         # But now, it is implicit in the apex fwd/bwd functions and so we need to check for this somewhere.
         # The consequence of not doing this is that training loop will never run validation.
         # NOTE: Prog bar is also broken as a result of this.
-        global_batch_size_per_data_parallel_rank = global_batch_size // parallel_state.get_data_parallel_world_size()
+        global_batch_size_per_gpu = micro_batch_size * get_num_microbatches()
         if (
-            self.trainer.val_check_interval > (sampler.num_samples // global_batch_size_per_data_parallel_rank)
+            self.trainer.val_check_interval > (sampler.num_samples // global_batch_size_per_gpu)
             and check_validation_interval
         ):
             raise ValueError(
                 f"trainer.val_check_interval {self.trainer.val_check_interval} is > number of global batches {sampler.num_samples // global_batch_size}"
             )
 
         # Data loader. Note that batch size is the per GPU batch size.
@@ -363,72 +401,151 @@
             shuffle=self.cfg.data.train_ds.shuffle,
             num_workers=self.cfg.data.train_ds.num_workers,
             pin_memory=self.cfg.data.train_ds.pin_memory,
             drop_last=self.cfg.data.train_ds.drop_last,
             check_validation_interval=True,
         )
 
+    def setup_eval_data(self, datasets, data_cfg):
+        dataloaders = []
+        for dataset in datasets:
+            eval_dl = self.build_data_loader(
+                dataset,
+                micro_batch_size=data_cfg.micro_batch_size,
+                global_batch_size=data_cfg.global_batch_size,
+                shuffle=data_cfg.shuffle,
+                num_workers=data_cfg.num_workers,
+                pin_memory=data_cfg.pin_memory,
+                drop_last=data_cfg.drop_last,
+                check_validation_interval=False,
+            )
+            dataloaders.append(eval_dl)
+        return dataloaders
+
     def setup_validation_data(self):
-        self._validation_dl = self.build_data_loader(
-            self._validation_ds,
-            micro_batch_size=self.cfg.data.validation_ds.micro_batch_size,
-            global_batch_size=self.cfg.data.validation_ds.global_batch_size,
-            shuffle=self.cfg.data.validation_ds.shuffle,
-            num_workers=self.cfg.data.validation_ds.num_workers,
-            pin_memory=self.cfg.data.validation_ds.pin_memory,
-            drop_last=self.cfg.data.validation_ds.drop_last,
-            check_validation_interval=False,
-        )
+        self._validation_dl = self.setup_eval_data(self._validation_ds, self.cfg.data.validation_ds)
 
     def setup_test_data(self):
-        self._test_dl = self.build_data_loader(
-            self._test_ds,
-            micro_batch_size=self.cfg.data.test_ds.micro_batch_size,
-            global_batch_size=self.cfg.data.test_ds.global_batch_size,
-            shuffle=self.cfg.data.test_ds.shuffle,
-            num_workers=self.cfg.data.test_ds.num_workers,
-            pin_memory=self.cfg.data.test_ds.pin_memory,
-            drop_last=self.cfg.data.test_ds.drop_last,
-            check_validation_interval=False,
-        )
+        self._test_dl = self.setup_eval_data(self._test_ds, self.cfg.data.test_ds)
 
-    def _build_dataset(self, data_cfg):
-        if data_cfg.task_name == 'xnli':
-            dataset = TextToTextXNLIDataset(
-                data_cfg.file_path,
-                task_name=data_cfg.task_name,
+    def _build_train_dataset(self, data_cfg):
+        """Build the training dataset."""
+        if (
+            data_cfg.drop_last is False
+            and data_cfg.global_batch_size > data_cfg.micro_batch_size * parallel_state.get_data_parallel_world_size()
+        ):
+            raise ValueError(
+                f"Cannot use drop_last=False in your training data with gradient accumulation found grad acc of {data_cfg.global_batch_size // (data_cfg.micro_batch_size * parallel_state.get_data_parallel_world_size())} with global_batch_size {data_cfg.global_batch_size}, micro_batch_size {data_cfg.micro_batch_size}, data parallel size {parallel_state.get_data_parallel_world_size()}"
+            )
+        datasets = []
+        # Determine if we are using a single dataset or a list of datasets.
+        is_src_list_config = isinstance(data_cfg.src_file_name, ListConfig)
+        is_tgt_list_config = isinstance(data_cfg.tgt_file_name, ListConfig)
+
+        if (is_src_list_config and not is_tgt_list_config) or (is_tgt_list_config and not is_src_list_config):
+            raise ValueError("src_list and tgt_list must both be either a ListConfig or a string. ")
+        if is_src_list_config:
+            if len(data_cfg.src_file_name) != len(data_cfg.tgt_file_name):
+                raise ValueError("src_file_name and tgt_file_name must have the same number of elements. ")
+        else:
+            data_cfg.src_file_name = [data_cfg.src_file_name]
+            data_cfg.tgt_file_name = [data_cfg.tgt_file_name]
+
+        for src, tgt in zip(data_cfg.src_file_name, data_cfg.tgt_file_name):
+            dataset = SequenceToSequenceDataset(
+                src_file_name=src,
+                tgt_file_name=tgt,
                 tokenizer=self.tokenizer,
-                max_seq_length=data_cfg.max_seq_length,
-                lang_list=self.cfg.eval_languages,
+                max_src_seq_length=data_cfg.max_src_seq_length,
+                max_tgt_seq_length=data_cfg.max_tgt_seq_length,
             )
+            datasets.append(dataset)
+
+        if len(datasets) > 1:
+            dataset = ConcatDataset(
+                datasets=datasets,
+                sampling_technique=data_cfg.get('concat_sampling_technique', 'temperature'),
+                sampling_temperature=data_cfg.get('concat_sampling_temperature', 5),
+                sampling_probabilities=data_cfg.get(
+                    'concat_sampling_probabilities', [1 / len(datasets)] * len(datasets)
+                ),
+                global_rank=parallel_state.get_data_parallel_rank(),
+                world_size=parallel_state.get_data_parallel_world_size(),
+            )
+            return dataset
+        else:
+            return datasets[0]
+
+    def _build_eval_dataset(self, data_cfg, mode='train'):
+        """Build the evaluation dataset."""
+        if data_cfg.global_batch_size > data_cfg.micro_batch_size * parallel_state.get_data_parallel_world_size():
+            raise ValueError(
+                f'You are trying to use "implicit gradient accumulation" of {data_cfg.global_batch_size // (data_cfg.micro_batch_size * parallel_state.get_data_parallel_world_size())} in your validation/test datasets. This is not supported. Please set global_batch_size equal to micro_batch_size * data_parallel_world_size.'
+            )
+        datasets = []
+        # Determine if we are using a single dataset or a list of datasets.
+        is_src_list_config = isinstance(data_cfg.src_file_name, ListConfig)
+        is_tgt_list_config = isinstance(data_cfg.tgt_file_name, ListConfig)
+        is_names_list_config = False
+        if hasattr(data_cfg, "names"):
+            if isinstance(data_cfg.names, ListConfig):
+                is_names_list_config = True
+
+        if (is_src_list_config and not is_tgt_list_config) or (is_tgt_list_config and not is_src_list_config):
+            raise ValueError("src_list and tgt_list must both be either a ListConfig or a string. ")
+        if is_src_list_config:
+            if len(data_cfg.src_file_name) != len(data_cfg.tgt_file_name):
+                raise ValueError("src_file_name and tgt_file_name must have the same number of elements. ")
+            if is_names_list_config and len(data_cfg.names) != len(data_cfg.src_file_name):
+                raise ValueError(
+                    "If you are providing names for each src/tgt file, they must have the same number of elements."
+                )
         else:
-            dataset = TextToTextGLUEDataset(
-                data_cfg.file_path,
-                task_name=data_cfg.task_name,
+            data_cfg.src_file_name = [data_cfg.src_file_name]
+            data_cfg.tgt_file_name = [data_cfg.tgt_file_name]
+
+        for src, tgt in zip(data_cfg.src_file_name, data_cfg.tgt_file_name):
+            dataset = SequenceToSequenceDataset(
+                src_file_name=src,
+                tgt_file_name=tgt,
                 tokenizer=self.tokenizer,
-                max_seq_length=data_cfg.max_seq_length,
+                max_src_seq_length=data_cfg.max_src_seq_length,
+                max_tgt_seq_length=data_cfg.max_tgt_seq_length,
             )
-        return dataset
+            datasets.append(dataset)
+
+        if mode == 'train' and len(datasets) > 1:
+            if len(datasets) > 1:
+                dataset = ConcatDataset(
+                    datasets=datasets,
+                    sampling_technique=data_cfg.get('concat_sampling_technique', 'temperature'),
+                    sampling_temperature=data_cfg.get('concat_sampling_temperature', 5),
+                    sampling_probabilities=data_cfg.get(
+                        'concat_sampling_probabilities', [1 / len(datasets)] * len(datasets)
+                    ),
+                    global_rank=parallel_state.get_data_parallel_rank(),
+                    world_size=parallel_state.get_data_parallel_world_size(),
+                )
+            return dataset
+
+        return datasets
 
     def build_train_valid_test_datasets(self, stage):
-        logging.info('Building GLUE/XNLI datasets.')
+        logging.info('Building datasets ...')
         if stage != 'test':
-            self._validation_ds = self._build_dataset(self.cfg.data.validation_ds)
-            logging.info(f'Length of val dataset: {len(self._validation_ds)}')
+            self._validation_ds = self._build_eval_dataset(self.cfg.data.validation_ds, mode='validation')
 
-        if stage != 'validate':
+        if stage != 'validation':
             if hasattr(self.cfg.data, 'test_ds'):
-                self._test_ds = self._build_dataset(self.cfg.data.test_ds)
-                logging.info(f'Length of test dataset: {len(self._test_ds)}')
+                self._test_ds = self._build_eval_dataset(self.cfg.data.test_ds, mode='test')
 
-        if stage == 'validate' or stage == 'test':
+        if stage == 'validation' or stage == 'test':
             return
-        self._train_ds = self._build_dataset(self.cfg.data.train_ds)
-        logging.info(f'Length of train dataset: {len(self._train_ds)}')
-        logging.info(f'Finished building GLUE/XNLI datasets.')
+        self._train_ds = self._build_train_dataset(self.cfg.data.train_ds)
+        logging.info(f'Finished building datasets ...')
 
     def on_train_start(self) -> None:
         """PTL hook used to override DataFetcher with GlobalBatchDataFetcher """
         self.trainer.fit_loop._data_fetcher = GlobalBatchDataFetcher()
 
     def on_validation_start(self) -> None:
         """PTL hook used to override DataFetcher with GlobalBatchDataFetcher """
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_gpt_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_gpt_model.py`

 * *Files 22% similar despite different names*

```diff
@@ -10,71 +10,72 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import os
 import re
-from typing import Any, Dict, List, Optional, Union
+from typing import Any, List, Optional, Union
 
 import torch
-import torch.nn.functional as F
 from omegaconf.dictconfig import DictConfig
-from omegaconf.omegaconf import open_dict
 from pytorch_lightning.plugins.precision.native_amp import NativeMixedPrecisionPlugin
 from pytorch_lightning.trainer.trainer import Trainer
-from torch.utils.data import DataLoader, Dataset
 
 from nemo.collections.nlp.data.language_modeling.megatron.gpt_dataset import build_train_valid_test_datasets
-from nemo.collections.nlp.data.language_modeling.megatron.gpt_prompt_tuning_dataset import GPTPromptTuningDataset
 from nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers import (
     MegatronPretrainingBatchSampler,
     MegatronPretrainingRandomBatchSampler,
 )
 from nemo.collections.nlp.models.language_modeling.megatron.gpt_model import GPTModel
 from nemo.collections.nlp.models.nlp_model import NLPModel
 from nemo.collections.nlp.modules.common.megatron.clip_grads import clip_grad_norm_fp32
 from nemo.collections.nlp.modules.common.megatron.megatron_init import initialize_model_parallel_for_nemo
 from nemo.collections.nlp.modules.common.megatron.module import Float16Module
 from nemo.collections.nlp.modules.common.megatron.utils import (
     average_losses_across_data_parallel_group,
-    get_ltor_masks_and_position_ids,
     get_params_for_weight_decay_optimization,
 )
-from nemo.collections.nlp.modules.common.text_generation_utils import generate, get_computeprob_response
+from nemo.collections.nlp.modules.common.text_generation_utils import (
+    generate,
+    get_computeprob_response,
+    get_default_length_params,
+    get_default_sampling_params,
+    megatron_gpt_generate,
+)
 from nemo.collections.nlp.modules.common.tokenizer_utils import get_nmt_tokenizer
 from nemo.collections.nlp.modules.common.transformer.text_generation import (
     LengthParam,
     OutputType,
     SamplingParam,
     TextGeneration,
 )
 from nemo.collections.nlp.parts.nlp_overrides import GradScaler
 from nemo.collections.nlp.parts.utils_funcs import get_last_rank
 from nemo.core.classes.common import PretrainedModelInfo
 from nemo.core.optim import MainParamsOptimizerWrapper, prepare_lr_scheduler
 from nemo.utils import AppState, logging
 
 try:
-    from apex.transformer import parallel_state, tensor_parallel
+    from apex.transformer import parallel_state
     from apex.transformer.pipeline_parallel.schedules.common import build_model
     from apex.transformer.pipeline_parallel.schedules.fwd_bwd_pipelining_without_interleaving import (
         forward_backward_pipelining_without_interleaving,
     )
     from apex.transformer.pipeline_parallel.schedules.fwd_bwd_no_pipelining import forward_backward_no_pipelining
-    from apex.transformer.pipeline_parallel.utils import get_num_microbatches, _reconfigure_microbatch_calculator
+    from apex.transformer.pipeline_parallel.utils import get_num_microbatches
 
     HAVE_APEX = True
 except (ImportError, ModuleNotFoundError):
     HAVE_APEX = False
 
 
 class MegatronGPTModel(NLPModel, TextGeneration):
     """
-    Megatron GPT pretraining and prompt tuning
+    Megatron GPT pretraining
     """
 
     def __init__(self, cfg: DictConfig, trainer: Trainer):
         if not HAVE_APEX:
             raise ImportError(
                 "Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/NeMo#megatron-gpt."
             )
@@ -115,44 +116,14 @@
 
         self.padded_vocab_size = self._vocab_size_with_padding(
             orig_vocab_size=vocab_size,
             make_vocab_size_divisible_by=cfg.get('make_vocab_size_divisible_by', 128),
             tensor_model_parallel_size=cfg.get('tensor_model_parallel_size', 1),
         )
 
-        # Prompt tuning initialization
-        self.use_soft_prompts = self.cfg.get('use_soft_prompts', False)
-
-        if self.use_soft_prompts:
-            if self.cfg.get('pipeline_model_parallel_size', 1) > 1:
-                raise NotImplementedError("Prompt tuning is not yet supported for pipeline parallel > 1")
-
-            self.prompts_to_tune = set([])
-            self.prompt_table = set([])
-            self.next_prompt_id = 0
-            self.num_prompt_tokens = cfg.get('num_prompt_tokens', 100)
-
-            if self.cfg.get('existing_prompt_tags', None):
-                # Assign prompt tag ids if none were present in the config
-                if type(self.cfg.existing_prompt_tags[0]) == str:
-                    existing_prompt_tags = self.cfg.existing_prompt_tags
-                    num_prompt_tags = len(existing_prompt_tags)
-                    existing_prompt_tags = [
-                        (existing_prompt_tags[tag_id], tag_id + 1) for tag_id in range(num_prompt_tags)
-                    ]
-
-                    with open_dict(self.cfg):
-                        self.cfg.existing_prompt_tags = existing_prompt_tags
-
-                # Fill table with prev tuned prompt tags and their ids
-                self.prompt_table = set(self.cfg.existing_prompt_tags)
-
-                # Get max prompt id from table for starting point of new prompt ids
-                self.next_prompt_id = max(self.prompt_table, key=lambda x: x[1])[1]
-
         # TODO: Not sure how to use lists of modules with PTL.
         # This means we can only use pipeline parallelism without the interleaved schedule.
         self.model = build_model(model_provider_func=self.model_provider_func, wrap_with_ddp=False)[0]
 
         self.setup_optimizer_param_groups()
 
         self.megatron_amp_o2 = cfg.get('megatron_amp_O2', False)
@@ -204,24 +175,21 @@
             hidden_dropout=self.cfg.get('hidden_dropout', 0.1),
             precision=self.cfg.get('precision', 16),
             fp32_residual_connection=self.cfg.get('fp32_residual_connection', False),
             activations_checkpoint_method=self.cfg.get('activations_checkpoint_method', None),
             activations_checkpoint_num_layers=self.cfg.get('activations_checkpoint_num_layers', 1),
             layernorm_epsilon=self.cfg.get('layernorm_epsilon', 1e-5),
             onnx_safe=self.cfg.get('onnx_safe', False),
-            use_soft_prompts=self.cfg.get('use_soft_prompts', False),
-            num_prompt_tokens=self.cfg.get('num_prompt_tokens', 100),
-            existing_prompt_tags=self.cfg.get('existing_prompt_tags', None),
             persist_layer_norm=self.cfg.get('persist_layer_norm', False),
         )
 
         return model
 
-    def forward(self, tokens, text_position_ids, attention_mask, labels, prompt_ids=None):
-        output_tensor = self.model(tokens, text_position_ids, attention_mask, labels=labels, prompt_ids=prompt_ids,)
+    def forward(self, tokens, text_position_ids, attention_mask, labels):
+        output_tensor = self.model(tokens, text_position_ids, attention_mask, labels=labels)
         return output_tensor
 
     def setup_optimizer_param_groups(self):
         """ModelPT override. Optimizer will get self._optimizer_param_groups"""
         self._optimizer_param_groups = get_params_for_weight_decay_optimization([self.model])
 
     def training_step(self, batch, batch_idx):
@@ -233,22 +201,17 @@
             Microbatches are then moved to GPU during the pipeline.
             The list of microbatches is then piped through the pipeline using Apex fwd/bwd functions.
         """
 
         # we zero grads here because we also call backward in the apex fwd/bwd functions
         self._optimizer.zero_grad()
 
-        if self.use_soft_prompts:
-            # The micro batches are already prepared for apex by the prompt tuning dataclass
-            batch_for_pipeline = batch
-            tensor_shape = [len(batch_for_pipeline[0][0]), self.cfg.micro_batch_size, self.cfg.hidden_size]
-        else:
-            # we prepare the micro batches for the apex fwd/bwd function
-            batch_for_pipeline = self.process_global_batch(batch)
-            tensor_shape = [self.cfg.encoder_seq_length, self.cfg.micro_batch_size, self.cfg.hidden_size]
+        # we prepare the micro batches for the apex fwd/bwd function
+        batch_for_pipeline = self.process_global_batch(batch)
+        tensor_shape = [self.cfg.encoder_seq_length, self.cfg.micro_batch_size, self.cfg.hidden_size]
 
         if self.cfg.get('pipeline_model_parallel_size', 1) > 1:
 
             losses_reduced_per_micro_batch = forward_backward_pipelining_without_interleaving(
                 forward_step_func=self.get_forward_output_and_loss_func(),
                 batch=batch_for_pipeline,
                 model=self.model,
@@ -407,77 +370,49 @@
                 else:
                     grad = word_embeddings_weight.grad
                 torch.distributed.all_reduce(grad, group=parallel_state.get_embedding_group())
 
     def get_forward_output_and_loss_func(self):
         def fwd_output_and_loss_func(batch, model):
             batch = [x.cuda(non_blocking=True) for x in batch]
-
-            if self.use_soft_prompts:
-                tokens, labels, loss_mask, attention_mask, position_ids, prompt_ids = batch
-                output_tensor = model(tokens, position_ids, attention_mask, labels, prompt_ids=prompt_ids)
-            else:
-                tokens, labels, loss_mask, attention_mask, position_ids = batch
-                attention_mask = attention_mask[0:1]
-                output_tensor = model(tokens, position_ids, attention_mask, labels)
+            tokens, labels, loss_mask, attention_mask, position_ids = batch
+            attention_mask = attention_mask[0:1]
+            output_tensor = model(tokens, position_ids, attention_mask, labels)
 
             def loss_func(output_tensor):
                 loss = self.loss_func(loss_mask, output_tensor)
                 reduced_loss = average_losses_across_data_parallel_group([loss])
                 return loss, {'avg': reduced_loss}
 
             return output_tensor, loss_func
 
         return fwd_output_and_loss_func
 
     def get_forward_output_only_func(self):
         def fwd_output_only_func(batch, model):
-            # batch = [x.cuda() for x in batch]
             extra_arg = {}
-            if self.use_soft_prompts:
-                if len(batch) == 4:
-                    batch = [x.cuda() for x in batch]
-                    tokens, attention_mask, position_ids, prompt_ids = batch
-                    extra_arg['prompt_ids'] = prompt_ids
-                else:
-                    (
-                        tokens,
-                        attention_mask,
-                        position_ids,
-                        prompt_ids,
-                        set_inference_key_value_memory,
-                        inference_max_sequence_len,
-                    ) = batch
-                    tokens = tokens.cuda()
-                    attention_mask = attention_mask.cuda()
-                    position_ids = position_ids.cuda()
-                    extra_arg['prompt_ids'] = prompt_ids.cuda()
-                    extra_arg['set_inference_key_value_memory'] = set_inference_key_value_memory[0].item()
-                    extra_arg['inference_max_sequence_len'] = inference_max_sequence_len[0].item()
-                output_tensor = model(tokens, position_ids, attention_mask, **extra_arg)
+            if len(batch) == 3:
+                batch = [x.cuda() for x in batch]
+                tokens, attention_mask, position_ids = batch
+                attention_mask = attention_mask[0:1]
             else:
-                if len(batch) == 3:
-                    batch = [x.cuda() for x in batch]
-                    tokens, attention_mask, position_ids = batch
-                    attention_mask = attention_mask[0:1]
-                else:
-                    (
-                        tokens,
-                        attention_mask,
-                        position_ids,
-                        set_inference_key_value_memory,
-                        inference_max_sequence_len,
-                    ) = batch
-                    tokens = tokens.cuda()
-                    attention_mask = attention_mask.cuda()
-                    position_ids = position_ids.cuda()
-                    attention_mask = attention_mask[0:1]
-                    extra_arg['set_inference_key_value_memory'] = set_inference_key_value_memory[0].item()
-                    extra_arg['inference_max_sequence_len'] = inference_max_sequence_len[0].item()
-                output_tensor = model(tokens, position_ids, attention_mask, **extra_arg)
+                (
+                    tokens,
+                    attention_mask,
+                    position_ids,
+                    set_inference_key_value_memory,
+                    inference_max_sequence_len,
+                ) = batch
+                tokens = tokens.cuda()
+                attention_mask = attention_mask.cuda()
+                position_ids = position_ids.cuda()
+                attention_mask = attention_mask[0:1]
+                extra_arg['set_inference_key_value_memory'] = set_inference_key_value_memory[0].item()
+                extra_arg['inference_max_sequence_len'] = inference_max_sequence_len[0].item()
+            output_tensor = model(tokens, position_ids, attention_mask, **extra_arg)
 
             def id_func(output_tensor):
                 return output_tensor, {'logits': output_tensor}
 
             return output_tensor, id_func
 
         return fwd_output_only_func
@@ -491,21 +426,16 @@
         """
             Our dataloaders produce a micro-batch and then we fetch
             a number of microbatches depending on the global batch size and model parallel size
             from the dataloader to produce a list of microbatches.
             The list of microbatches is then piped through the pipeline using Apex fwd/bwd functions.
         """
 
-        if self.use_soft_prompts:
-            # The micro batches are already prepared for apex by the prompt tuning dataclass
-            batch_for_pipeline = batch
-            tensor_shape = [len(batch_for_pipeline[0][0]), self.cfg.micro_batch_size, self.cfg.hidden_size]
-        else:
-            batch_for_pipeline = self.process_global_batch(batch)
-            tensor_shape = [self.cfg.encoder_seq_length, self.cfg.micro_batch_size, self.cfg.hidden_size]
+        batch_for_pipeline = self.process_global_batch(batch)
+        tensor_shape = [self.cfg.encoder_seq_length, self.cfg.micro_batch_size, self.cfg.hidden_size]
 
         if self.cfg.get('pipeline_model_parallel_size', 1) > 1:
             losses_reduced_per_micro_batch = forward_backward_pipelining_without_interleaving(
                 forward_step_func=self.get_forward_output_and_loss_func(),
                 batch=batch_for_pipeline,
                 model=self.model,
                 forward_only=True,
@@ -575,17 +505,14 @@
             global_batch["labels"],
             global_batch["loss_mask"],
             global_batch["attention_mask"],
             global_batch["position_ids"],
         ]
 
     def build_train_valid_test_datasets(self):
-        if self.use_soft_prompts:
-            return
-
         logging.info('Building GPT datasets.')
         global_batch_size = self.cfg.global_batch_size
         max_train_steps = self.trainer.max_steps
         eval_iters = (max_train_steps // self.trainer.val_check_interval + 1) * self.trainer.limit_val_batches
         test_iters = self.trainer.limit_test_batches
 
         train_valid_test_num_samples = [
@@ -649,40 +576,14 @@
         else:
             raise ValueError('cfg.data.dataloader_type not found. Must be "single" or "cyclic"')
 
         return torch.utils.data.DataLoader(
             dataset, batch_sampler=batch_sampler, num_workers=self.cfg.data.num_workers, pin_memory=True,
         )
 
-    def build_prompt_tuning_dataset(self, dataset_path):
-        dataset = GPTPromptTuningDataset(
-            dataset_path=dataset_path,
-            tokenizer=self.tokenizer,
-            prompt_table=self.prompt_table,
-            num_prompt_tokens=self.cfg.num_prompt_tokens,
-            micro_batch_size=self.cfg.micro_batch_size,
-            max_seq_length=self.cfg.data.get('max_seq_length', self.cfg.max_position_embeddings),
-            min_seq_length=self.cfg.data.get('min_seq_length', 1),
-            add_bos=self.cfg.data.get('add_bos', False),
-            add_eos=self.cfg.data.get('add_eos', True),
-            calc_loss_on_answer_only=self.cfg.get('calc_loss_on_answer_only', False),
-        )
-
-        dataloader = torch.utils.data.DataLoader(
-            dataset,
-            batch_size=self.cfg.global_batch_size,
-            collate_fn=dataset.collate_fn,
-            num_workers=self.cfg.data.num_workers,
-            drop_last=True,
-            shuffle=True,
-            pin_memory=True,
-        )
-
-        return dataset, dataloader
-
     def setup(self, stage=None):
         """ PTL hook that is executed after DDP spawns.
             We setup datasets here as megatron datasets require DDP to instantiate.
             See https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#setup for more information.
         Args:
             stage (str, optional): Can be 'fit', 'validate', 'test' or 'predict'. Defaults to None.
         """
@@ -698,68 +599,43 @@
         else:
             init_consumed_samples = 0
         self.init_consumed_samples = init_consumed_samples
 
         if stage == 'predict':
             return
         else:
-            # Initalize soft prompts before loading datasets and training
-            if self.use_soft_prompts:
-                self.init_new_prompts()
-
             # TODO: consider adding a ModelPT guard to check if model is being restored.
             # allowing restored models to optionally setup datasets
             self.build_train_valid_test_datasets()
             self.setup_training_data(self.cfg.data)
             self.setup_validation_data(self.cfg.data)
             self.setup_test_data(self.cfg.data)
 
         # when using pipeline model parallel the final stage need to initialize word embeddings
         if parallel_state.get_pipeline_model_parallel_world_size() > 1:
             self.model.sync_initial_word_embeddings()
 
     def setup_training_data(self, cfg):
-        if self.use_soft_prompts:
-            if cfg.get('train_ds', None):
-                self._train_ds, self._train_dl = self.build_prompt_tuning_dataset(self.cfg.data.train_ds)
-            else:
-                raise AttributeError('No prompt tuning train dataset was specified in the cfg file')
-
-            # Freeze all weights except prompt embeddings and setup optimizer with prompt embedding params
-            self.prompt_tuning_param_freeze_and_optimizer_setup()
-
-        elif hasattr(self, '_train_ds'):
+        if hasattr(self, '_train_ds'):
             consumed_samples = self.compute_consumed_samples(0)
             logging.info(
                 f'Setting up train dataloader with len(len(self._train_ds)): {len(self._train_ds)} and consumed samples: {consumed_samples}'
             )
             self._train_dl = self.build_pretraining_data_loader(self._train_ds, consumed_samples)
 
     def setup_validation_data(self, cfg):
-        if self.use_soft_prompts:
-            if cfg.get('valid_ds', None):
-                self._validation_ds, self._validation_dl = self.build_prompt_tuning_dataset(self.cfg.data.valid_ds)
-            else:
-                raise AttributeError('No prompt tuning validation dataset was specified in the cfg file')
-
-        elif hasattr(self, '_validation_ds'):
+        if hasattr(self, '_validation_ds'):
             consumed_samples = 0
             logging.info(
                 f'Setting up validation dataloader with len(len(self._validation_ds)): {len(self._validation_ds)} and consumed samples: {consumed_samples}'
             )
             self._validation_dl = self.build_pretraining_data_loader(self._validation_ds, consumed_samples)
 
     def setup_test_data(self, cfg):
-        if self.use_soft_prompts:
-            if cfg.get('test_ds', None):
-                self._test_ds, self._test_dl = self.build_prompt_tuning_dataset(self.cfg.data.test_ds)
-            else:
-                logging.info('No prompt tuning test dataset file provided in config, skipping')
-
-        elif hasattr(self, '_test_ds'):
+        if hasattr(self, '_test_ds'):
             consumed_samples = 0
             logging.info(
                 f'Setting up test dataloader with len(len(self._test_ds)): {len(self._test_ds)} and consumed samples: {consumed_samples}'
             )
             self._test_dl = self.build_pretraining_data_loader(self._test_ds, consumed_samples)
 
     def configure_optimizers(self):
@@ -819,45 +695,22 @@
 
         clip_val = float(clip_val)
         if clip_val <= 0:
             return
 
         if self.megatron_amp_o2:
             # grep fp32 master parameters for gradient clipping
-            if self.use_soft_prompts:
-                raise NotImplementedError("Prompt tuning is not implemented for amp_o2")
             parameters = self._optimizer.get_parameters()
         else:
             parameters = self.get_parameters()
 
         grad_norm = clip_grad_norm_fp32(parameters=parameters, max_norm=clip_val)
 
         self.log('grad_norm', grad_norm, rank_zero_only=True)
 
-    def prompt_tuning_param_freeze_and_optimizer_setup(self):
-        """Freeze weights of word embeddings and decoder, leaving only prompt embeddings unfrozen
-        """
-        weight_decay_params = {'params': []}
-        no_weight_decay_params = {'params': [], 'weight_decay': 0.0}
-
-        for param in self.model.parameters():
-            param.requires_grad = False
-
-        # Only want new prompt tags to be tunable, leave existing prompt tags alone
-        for prompt_tag in self.model.language_model.prompt_table.prompt_table.keys():
-            if prompt_tag in self.prompts_to_tune:
-                for params in self.model.language_model.prompt_table.prompt_table[prompt_tag].parameters():
-                    params.requires_grad = True
-                    weight_decay_params['params'].append(params)
-            else:
-                for param in self.model.language_model.prompt_table.prompt_table[prompt_tag].parameters():
-                    param.requires_grad = False
-
-        self._optimizer_param_groups = weight_decay_params, no_weight_decay_params
-
     def get_parameters(self):
         params = []
         for param_group in self._optimizer_param_groups:
             for param in param_group['params']:
                 params.append(param)
         return params
 
@@ -867,98 +720,32 @@
         length_params: LengthParam,
         sampling_params: SamplingParam = None,
     ) -> OutputType:
 
         # check whether the DDP is initialized
         if parallel_state.is_unitialized():
 
-            class RequestDataSet(Dataset):
-                def __init__(self, sentences):
-                    super().__init__()
-                    self.sentences = sentences
-
-                def __len__(self):
-                    return len(self.sentences)
-
-                def __getitem__(self, idx):
-                    return self.sentences[idx]
-
-            # TODO, this is a little hacky. need to handle this nicely in the future
-            # run empty predict to initialize the DDP
-            ds = RequestDataSet([""])
-            request_dl = DataLoader(dataset=ds, batch_size=1)
-            self.trainer.predict(self, request_dl)
+            def dummy():
+                return
+
+            if self.trainer.strategy.launcher is not None:
+                self.trainer.strategy.launcher.launch(dummy, trainer=self.trainer)
+            self.trainer.strategy.setup_environment()
 
         # set the default sampling params if it is None.
         # default do greedy sampling
         if sampling_params is None:
-            sampling_params: SamplingParam = {
-                "use_greedy": True,
-                "temperature": 1.0,
-                "top_k": 0,
-                "top_p": 1.0,
-                "repetition_penalty": 1.0,
-                "add_BOS": True,
-                "all_probs": False,
-                "compute_logprob": False,
-            }
+            sampling_params = get_default_sampling_params()
 
         # set the default length params if it is None.
         # default do greedy sampling
         if length_params is None:
-            length_params: LengthParam = {"min_length": 0, "max_length": 30}
+            length_params = get_default_length_params()
 
-        # reproduce the old compute_prob method
-        # a very special case
-        if sampling_params['compute_logprob']:
-            # need to overwrite some configuration, make it immutable
-            sampling_params = sampling_params.copy()
-            length_params = length_params.copy()
-            length_params['max_length'] = 1
-            sampling_params['all_probs'] = True
-            sampling_params["add_BOS"] = False
-            sampling_params['use_greedy'] = True
-            response = generate(
-                self.cuda(),
-                inputs=inputs,
-                tokens_to_generate=length_params['max_length'],
-                all_probs=sampling_params['all_probs'],
-                temperature=sampling_params['temperature'],
-                add_BOS=sampling_params['add_BOS'],
-                top_k=sampling_params['top_k'],
-                top_p=sampling_params['top_p'],
-                greedy=sampling_params['use_greedy'],
-                repetition_penalty=sampling_params['repetition_penalty'],
-                min_tokens_to_generate=length_params['min_length'],
-            )
-            compute_prob_response = get_computeprob_response(self.tokenizer, response, inputs)
-            return compute_prob_response
-
-        if isinstance(inputs, (list, tuple)):
-            if isinstance(inputs[0], (str, torch.Tensor)):
-                output = generate(
-                    self.cuda(),
-                    inputs=inputs,
-                    tokens_to_generate=length_params['max_length'],
-                    all_probs=sampling_params['all_probs'],
-                    temperature=sampling_params['temperature'],
-                    add_BOS=sampling_params['add_BOS'],
-                    top_k=sampling_params['top_k'],
-                    top_p=sampling_params['top_p'],
-                    greedy=sampling_params['use_greedy'],
-                    repetition_penalty=sampling_params['repetition_penalty'],
-                    min_tokens_to_generate=length_params['min_length'],
-                )
-                return output
-            elif isinstance(inputs[0], dict):
-                raise NotImplementedError("json object not implemented")
-            else:
-                raise NotImplementedError("unknown type is not implemented")
-        else:
-            raise NotImplementedError("unknown type is not implemented")
+        return megatron_gpt_generate(self.cuda(), inputs, self.tokenizer, length_params, sampling_params)
 
     def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: Optional[int] = None) -> Any:
         inference_config = self.get_inference_config()
         if inference_config is None:
             return None
         else:
             # need to overwrite some configuration, make it immutable
@@ -975,64 +762,17 @@
                 compute_prob_response = get_computeprob_response(self.tokenizer, response, batch)
                 return compute_prob_response
             else:
                 del inference_config['compute_logprob']
                 inference_config['inputs'] = batch
                 return generate(self, **inference_config)
 
-    def init_new_prompts(self):
-        for idx, tag in enumerate(self.cfg.new_prompt_tags):
-            init_method = self.cfg.new_prompt_init_methods[idx]
-
-            if init_method == "text":
-                init_text = self.cfg.new_prompt_init_text[idx]
-                self.init_prompt_from_text(tag, init_text)
-
-            elif init_method == 'random':
-                self.init_prompt_from_random(tag)
-
-            else:
-                raise AttributeError(
-                    f'\n Soft prompt init method {init_method} is not recognized\
-                                        please use text or random'
-                )
-
-    def init_prompt_from_random(self, prompt_tag):
-        prompt_id = self._get_next_prompt_id()
-        self.model._init_prompt_from_random(prompt_tag, prompt_id)
-        self._add_prompt_tag(prompt_tag, prompt_id)
-
-    def init_prompt_from_text(self, prompt_tag, init_text):
-        prompt_id = self._get_next_prompt_id()
-        init_token_ids = self.tokenizer.text_to_ids(init_text)
-        self.model._init_prompt_from_text(prompt_tag, prompt_id, init_token_ids)
-        self._add_prompt_tag(prompt_tag, prompt_id)
-
-    def get_prompt_table(self):
-        if hasattr(self, 'prompt_table'):
-            return self.prompt_table
-
     def list_available_models(self):
         return None
 
-    def _get_next_prompt_id(self):
-        self.next_prompt_id += 1
-        return self.next_prompt_id
-
-    def _add_prompt_tag(self, prompt_tag, prompt_id):
-        if not hasattr(self, 'prompt_table'):
-            raise AttributeError('Please set "use_soft_prompts" in cfg to True')
-
-        self.prompt_table.add((prompt_tag, prompt_id))
-        self.prompts_to_tune.add(prompt_tag)
-
-        # Add new prompt tag to cfg for loading prompt table at inference
-        with open_dict(self.cfg):
-            self.cfg.existing_prompt_tags = list(self.prompt_table)
-
     def _vocab_size_with_padding(self, orig_vocab_size, make_vocab_size_divisible_by, tensor_model_parallel_size):
         """Pad vocab size so it is divisible by model parallel size and
         still having GPU friendly size."""
 
         after = orig_vocab_size
         multiple = make_vocab_size_divisible_by * tensor_model_parallel_size
         while (after % multiple) != 0:
@@ -1082,138 +822,14 @@
             Here we try to catch them and raise an error.
         """
         if self.trainer.accumulate_grad_batches > 1:
             raise ValueError(
                 f'Gradient accumulation is done within training_step. trainer.accumulate_grad_batches must equal 1'
             )
 
-    def compute_logprobs(self, request: Dict, positions: List):
-        """
-            Only logprobs computation without generation tokens
-        Args:
-            request:
-                * tokens: List of "buckets" with unpadded tokens of the same length
-                * prompt_tags: List of "buckets" where each bucket contains the prompt_tag strings
-                                    specifying the prompt tag to use (optional)
-            positions: List with initial prompts positions
-        Returns:
-            response: A python list of tuples
-            (text, tokens, log_probs, offsets)
-            * text: string, inputted prompt + generated text by model
-            * tokens: list of tokens correspond to text
-            * log_probs: list of log_softmax's from output_tensor in respect to text tokens
-            * offsets: list of tokens start positions in text
-        """
-        app_state = AppState()
-
-        results = []
-        request_tokens = request["tokens"]
-        for idx, tokens in enumerate(request_tokens):
-            tokens_cut = tokens[:, :-1]
-            micro_batch_size = tokens_cut.shape[0]
-            _reconfigure_microbatch_calculator(
-                rank=app_state.global_rank,
-                rampup_batch_size=None,
-                global_batch_size=micro_batch_size,
-                micro_batch_size=micro_batch_size,
-                data_parallel_size=1,
-            )
-            # For prompt tuned GPT models
-            if self.use_soft_prompts:
-                if self.cfg.get('pipeline_model_parallel_size', 1) > 1:
-                    raise ValueError('compute_logprobs method is not yet supported for pipeline with soft prompts')
-                prompt_tags = request["prompt_tags"][idx]
-                prompt_tags_to_ids = dict(self.prompt_table)
-                prompt_ids = torch.tensor([prompt_tags_to_ids[tag] for tag in prompt_tags])
-            else:
-                prompt_ids = None
-
-            if self.use_soft_prompts:
-                batch_size = len(tokens_cut)
-                full_length = len(tokens_cut[0]) + self.num_prompt_tokens
-                # Get postion ids for text after soft prompt
-                position_ids = torch.arange(
-                    start=self.num_prompt_tokens, end=full_length, dtype=torch.long, device=self.device
-                )
-                position_ids = position_ids.unsqueeze(0).expand_as(tokens_cut).clone()
-                # Make attention mask starting with first token in soft prompt
-                attention_mask = torch.tril(
-                    torch.ones((batch_size, full_length, full_length), device=self.device)
-                ).view(batch_size, 1, full_length, full_length)
-                attention_mask = attention_mask < 0.5
-
-            else:
-                attention_mask, _, position_ids = get_ltor_masks_and_position_ids(
-                    data=tokens_cut,
-                    eod_token=self.tokenizer.eos_id,
-                    reset_position_ids=self.cfg.get('reset_position_ids', False),
-                    reset_attention_mask=self.cfg.get('reset_attention_mask', False),
-                    eod_mask_loss=self.cfg.get('eod_mask_loss', False),
-                )
-
-            # we repeat attention mask to work with apex fwd/bwd function
-            attention_mask_repeat = torch.concat([attention_mask for _ in range(micro_batch_size)])
-            if self.use_soft_prompts:
-                batch = [tokens_cut, attention_mask_repeat, position_ids, prompt_ids]
-            else:
-                batch = [tokens_cut, attention_mask_repeat, position_ids]
-            tensor_shape = [tokens_cut.shape[1], micro_batch_size, self.cfg.hidden_size]
-            if self.cfg.get('pipeline_model_parallel_size', 1) > 1:
-                output_tensor = forward_backward_pipelining_without_interleaving(
-                    forward_step_func=self.get_forward_output_only_func(),
-                    batch=batch,
-                    model=self.model,
-                    forward_only=True,
-                    tensor_shape=tensor_shape,
-                    dtype=self.autocast_dtype,
-                )
-            else:
-                output_tensor = forward_backward_no_pipelining(
-                    forward_step_func=self.get_forward_output_only_func(),
-                    batch=batch,
-                    model=self.model,
-                    forward_only=True,
-                    tensor_shape=tensor_shape,
-                    dtype=self.autocast_dtype,
-                )
-
-            # get output tensor
-            if parallel_state.is_pipeline_last_stage():
-                output_tensor = output_tensor[0]['logits']
-                output_tensor = tensor_parallel.gather_from_tensor_model_parallel_region(output_tensor)
-
-            else:
-                output_tensor = torch.zeros(
-                    (tokens_cut.shape[0], tokens_cut.shape[1], self.padded_vocab_size), dtype=torch.float
-                ).cuda()
-
-            torch.distributed.broadcast(output_tensor, get_last_rank())
-
-            log_probs = []
-            for output in output_tensor:
-                probs = F.log_softmax(output, dim=1)
-                probs = probs[-len(tokens_cut[0]) :]
-                log_probs.append(probs)
-
-            for token, prob in zip(tokens, log_probs):
-                results.append((self.tokenizer.ids_to_text(token), self.tokenizer.ids_to_tokens(token), prob, [0]))
-
-        # offsets calculation
-        for item in results:
-            for index, token in enumerate(item[1]):
-                if index != len(item[1]) - 1:
-                    item[3].append(len(token) + item[3][-1])
-
-        # return prompts in order they were inputted
-        response = [0 for i in range(len(positions))]
-        for item, index in zip(results, positions):
-            response[index] = item
-
-        return response
-
     @classmethod
     def list_available_models(cls) -> Optional[PretrainedModelInfo]:
         """
         This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
         Returns:
             List of available pre-trained models.
         """
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_lm_encoder_decoder_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_lm_encoder_decoder_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -167,17 +167,22 @@
             precision=self.cfg.get('precision', 16),
             fp32_residual_connection=self.cfg.get('fp32_residual_connection', False),
             activations_checkpoint_method=self.cfg.get('activations_checkpoint_method', None),
             activations_checkpoint_num_layers=self.cfg.get('activations_checkpoint_num_layers', 1),
             layernorm_epsilon=self.cfg.get('layernorm_epsilon', 1e-5),
             persist_layer_norm=self.cfg.get('persist_layer_norm', False),
             bias_gelu_fusion=self.cfg.get('bias_gelu_fusion', True),
+            bias_dropout_add_fusion=self.cfg.get('bias_dropout_add_fusion', True),
             masked_softmax_fusion=self.cfg.get('masked_softmax_fusion', True),
             onnx_safe=self.cfg.get('onnx_safe', False),
             activation=self.cfg.get('activation', 'gelu'),
+            bias=self.cfg.get('bias', True),
+            normalization=self.cfg.get('normalization', 'layernorm'),
+            transformer_block_type=self.cfg.get('transformer_block_type', 'pre_ln'),
+            headscale=self.cfg.get('headscale', False),
             add_encoder=add_encoder,
             add_decoder=add_decoder,
         )
         return model
 
     def forward(
         self,
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_ptune_gpt_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_ptune_t5_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,95 +11,110 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import Dict, List
 
 import torch
-import torch.nn as nn
+from omegaconf import OmegaConf, open_dict
 from omegaconf.dictconfig import DictConfig
 from pytorch_lightning.trainer.trainer import Trainer
 from torch import Tensor
 
-from nemo.collections.nlp.data.glue_benchmark.gpt_ptune_dataset import GPTPTuneDataset, GPTPTuneInferenceDataset
+from nemo.collections.nlp.data.glue_benchmark.t5_ptune_dataset import T5PTuneDataset, T5PTuneInferenceDataset
 from nemo.collections.nlp.models.language_modeling.megatron_base_model import MegatronBaseModel
-from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel
+from nemo.collections.nlp.models.language_modeling.megatron_t5_model import MegatronT5Model
 from nemo.collections.nlp.modules.common.megatron.utils import (
     average_losses_across_data_parallel_group,
     build_position_ids,
-    make_inference_attention_mask_3d,
-    make_inference_history_mask_3d,
 )
-from nemo.collections.nlp.modules.common.prompt_encoder import PromptEncoder
+from nemo.collections.nlp.modules.common.t5_prompt_encoder import PromptEncoder
 from nemo.utils import logging
 
 try:
     from apex.transformer import tensor_parallel
 
     HAVE_APEX = True
-
 except (ImportError, ModuleNotFoundError):
-
     HAVE_APEX = False
 
 
-__all__ = ['MegatronGPTPTuneModel']
+__all__ = ['MegatronT5PTuneModel']
 
 
-class MegatronGPTPTuneModel(MegatronBaseModel):
+class MegatronT5PTuneModel(MegatronBaseModel):
     """
-    Megatron GPT P-Tune
+    Megatron T5 P-Tune
     """
 
     def __init__(self, cfg: DictConfig, trainer: Trainer):
         super().__init__(cfg, trainer)
 
-        self.model = MegatronGPTModel.restore_from(
+        raise Exception("Please use the NeMo r1.8.0 branch for T5 PTuning.")
+
+        self.megatron_amp_o2 = cfg.get('megatron_amp_O2', False)
+        # TODO: Fix this once apex patches FusedScaledMaskedSoftmax.
+        # This is a workaround for the fact that `masked_softmax_fusion` has issues with certain input sizes that may be present while finetuning.
+        t5_cfg = MegatronT5Model.restore_from(
+            self.register_artifact('language_model.nemo_file', cfg.language_model.get('nemo_file', None)),
+            trainer=trainer,
+            return_config=True,
+        )
+        OmegaConf.set_struct(t5_cfg, True)
+        with open_dict(t5_cfg):
+            t5_cfg.masked_softmax_fusion = False
+            t5_cfg.megatron_amp_O2 = self.megatron_amp_o2
+            # TODO, need to fix this later
+            # hack to make the _GLOBAL_NUM_MICROBATCHES_CALCULATOR initialize
+            t5_cfg.micro_batch_size = 4
+            t5_cfg.global_batch_size = 4
+
+        self.model = MegatronT5Model.restore_from(
             self.register_artifact('language_model.nemo_file', cfg.language_model.get('nemo_file', None)),
             trainer=trainer,
+            override_config_path=t5_cfg,
         )
 
+        # self.model = MegatronT5Model.restore_from(
+        #     self.register_artifact('language_model.nemo_file', cfg.language_model.get('nemo_file', None)),
+        #     trainer=trainer)
+
         self.tokenizer = self.model.tokenizer
-        self.float_type = self.model.model.language_model.encoder.layers[0].dtype
+
+        self.float_type = self.model.enc_dec_model.enc_dec_model.encoder.model.layers[0].dtype
 
         if not cfg.use_lm_finetune:
             self.model.freeze()
 
         hidden_size = self.model.cfg.hidden_size
 
-        self.embeddings = self.model.model.language_model.embedding.word_embeddings
+        # register the file containing the labels into the artifacts to get stored in the '.nemo' file later
+        self.word_embeddings = self.model.enc_dec_model.encoder_embedding.word_embeddings
+        self.position_embeddings = self.model.enc_dec_model.encoder_embedding.position_embeddings
+
+        # self.vocab = self.tokenizer.tokenizer.get_vocab()
 
         self.template = cfg.prompt_encoder.template
 
         self.prompt_encoder = PromptEncoder(
             template=cfg.prompt_encoder.template,
             hidden_size=hidden_size,
             lstm_dropout=cfg.prompt_encoder.dropout,
             num_layers=cfg.prompt_encoder.num_layers,
         )
 
-        self._reduced_loss_buffer = []
-
         # load prompt encoder
         self.hidden_size = hidden_size
-        self.tokenizer.add_special_tokens({'additional_special_tokens': [cfg.pseudo_token]})
+        self.tokenizer.add_special_tokens([cfg.pseudo_token])
 
-        self.pseudo_token_id = self.tokenizer.token_to_id(cfg.pseudo_token)
+        self.pseudo_token_id = self.tokenizer.special_token_to_id[cfg.pseudo_token]
         self.pad_token_id = self.tokenizer.pad_id if self.tokenizer.pad_id is not None else self.tokenizer.unk_id
         self.spell_length = sum(self.template)
-        self.special_tokens = set(
-            [
-                self.tokenizer.eos_id,
-                self.tokenizer.pad_id,
-                self.tokenizer.sep_id,
-                self.tokenizer.unk_id,
-                self.tokenizer.bos_id,
-                self.tokenizer.cls_id,
-            ]
-        )
+        self._reduced_loss_buffer = []
+        self.decoder_seq_length = cfg.get('decoder_seq_length', 10)
 
     def embed_input(self, enc_input_id: Tensor, enc_taskname_id: Tensor):
         """
         This method will replace the virtual tokens in the enc_input_id with
         embeddings calculated from `prompt_encoder`. If the `enc_taskname_id` is
         not None, the computed virtual token embeddings are depenedent on it.
         The virtual token placeholders has the token_id `self.pseudo_token_id`.
@@ -109,18 +124,18 @@
         returns:
             the token embedding for the LM model.
         """
         bz = enc_input_id.shape[0]
         queries_for_embedding = enc_input_id.clone()
 
         queries_for_embedding[(enc_input_id == self.pseudo_token_id)] = self.pad_token_id
+        raw_embeds = self.word_embeddings(queries_for_embedding).clone()
 
-        raw_embeds = self.embeddings(queries_for_embedding).clone()
         if self.cfg.prompt_encoder.task_dependent:
-            enc_taskname = self.embeddings(enc_taskname_id)
+            enc_taskname = self.word_embeddings(enc_taskname_id)
         else:
             enc_taskname = None
 
         if self.float_type == torch.float32:
             replace_embeds = self.prompt_encoder(enc_taskname=enc_taskname)
         else:
             with torch.autocast(device_type="cuda", dtype=self.float_type):
@@ -139,62 +154,81 @@
             # taskname none, encoder returens batch 1
             # need to expand
             _, replace_seq, _ = replace_embeds.shape
             replace_embeds = replace_embeds.expand(bz, replace_seq, emb)
 
         # scatter the psedo-token embeddings to the raw embeddings
         raw_embeds.scatter_(1, index, replace_embeds)
-        # slow version of above scatter logics
-        # for bidx in range(bz):
-        #     position = blocked_indices[bidx].nonzero()[:, 0]
-        #     for i in range(len(position)):
-        #         raw_embeds[bidx, position[i], :] = replace_embeds[bidx, i, :]
-
         return raw_embeds
 
-    def get_loss(self, batch):
-        enc_input = batch['enc_input']
-        enc_taskname = batch['enc_taskname']
-        labels = batch['labels']
-        loss_mask = batch['loss_mask']
-        enc_query = batch['enc_query']
-        input_attn_mask = batch['input_attn_mask']
+    def process_batch(self, batch):
+        """Build the batch."""
 
-        input_attn_mask = input_attn_mask.unsqueeze(1) < 0.5
+        keys = ['text_enc', 'text_dec', 'labels', 'loss_mask', 'enc_mask', 'dec_mask', 'enc_taskname']
+        datatype = torch.int64
+        data = batch
+        data_b = tensor_parallel.broadcast_data(keys, data, datatype)
+
+        # Unpack.
+        tokens_enc = data_b['text_enc'].long()
+        tokens_dec = data_b['text_dec'].long()
+        labels = data_b['labels'].long()
+        loss_mask = data_b['loss_mask'].float()
+
+        enc_mask = data_b['enc_mask']
+        dec_mask = data_b['dec_mask']
+        enc_taskname = data_b['enc_taskname']
 
-        input_embeds = self.embed_input(enc_input, enc_taskname)
+        return tokens_enc, tokens_dec, loss_mask, labels, enc_mask, dec_mask, enc_taskname
 
-        encoder_position_ids = build_position_ids(enc_input)
+    def get_loss(self, batch):
+        tokens_enc, tokens_dec, loss_mask, labels, enc_mask, dec_mask, enc_taskname = self.process_batch(batch)
+        input_embeds = self.embed_input(tokens_enc, enc_taskname)
 
-        position_embeddings = self.model.model.language_model.embedding.position_embeddings(encoder_position_ids)
+        encoder_position_ids = build_position_ids(tokens_enc)
+
+        position_embeddings = self.position_embeddings(encoder_position_ids)
 
         encoder_input = input_embeds + position_embeddings
 
         if self.float_type == torch.float32:
-            output = self.model.model(
-                None, None, encoder_input=encoder_input, attention_mask=input_attn_mask, labels=labels,
+            output = self.model.enc_dec_model(
+                enc_input_ids=None,
+                enc_attn_mask=enc_mask,
+                dec_input_ids=tokens_dec,
+                dec_attn_mask=dec_mask,
+                token_type_ids=None,
+                labels=labels,
+                enc_hidden_states=None,
+                output_enc_hidden_only=False,
+                enc_input=encoder_input,
             )
         else:
             with torch.autocast(device_type="cuda", dtype=self.float_type):
-                output = self.model.model(
-                    None, None, encoder_input=encoder_input, attention_mask=input_attn_mask, labels=labels,
+                output = self.model.enc_dec_model(
+                    enc_input_ids=None,
+                    enc_attn_mask=enc_mask,
+                    dec_input_ids=tokens_dec,
+                    dec_attn_mask=dec_mask,
+                    token_type_ids=None,
+                    labels=labels,
+                    enc_hidden_states=None,
+                    output_enc_hidden_only=False,
+                    enc_input=encoder_input,
                 )
-        output_tensor, encoder_hidden_states = output
-        loss = self.loss_func(loss_mask, output_tensor)
-        return loss
 
-    def loss_func(self, loss_mask, output_tensor):
-        losses = output_tensor.float()
-        loss_mask = loss_mask.view(-1).float()
-        # TODO: add nemo version here
-        loss = torch.sum(losses.view(-1) * loss_mask) / loss_mask.sum()  # sequence level nll
-        return loss
+        tokens_loss = output
+
+        loss = self.model.loss_func(loss_mask, tokens_loss)
+        self.log('train_loss', loss)
+
+        return loss, tokens_enc, labels, enc_mask, encoder_input
 
     def training_step(self, batch, batch_idx):
-        loss = self.get_loss(batch)
+        loss, _, _, _, _ = self.get_loss(batch)
         self.log('train_loss', loss)
         # Reduced loss for logging.
         reduced_loss = average_losses_across_data_parallel_group([loss])
         # cache reduced loss while accumulating gradients
         self._reduced_loss_buffer.append(reduced_loss[0])
 
         if (batch_idx + 1) % self.trainer.accumulate_grad_batches == 0:
@@ -205,99 +239,39 @@
             self.log('lr', lr)
             self.log('global_step', self.trainer.global_step, prog_bar=True)
             self._reduced_loss_buffer = []
 
         return loss
 
     def inference_step(self, batch, batch_ix):
-        loss = self.get_loss(batch)
-        enc_query = batch['enc_query']
-        enc_taskname = batch['enc_taskname']
-        labels = batch['labels']
-        label_position = batch['label_position']
-        # loss, tokens_enc, labels, enc_mask, encoder_input = self.get_loss(batch)
-        predicted_token_ids, log_probs = self.decode(
-            enc_query=enc_query,
-            enc_taskname=enc_taskname,
-            label_position=label_position,
-            num_tokens_to_generate=self.num_tokens_to_gen,
-        )
-
-        return {
-            'loss': loss,
-            'predicted_token_ids': predicted_token_ids,
-            'labels': labels,
-            'label_position': label_position,
-        }
-
-    def decode(self, enc_query, enc_taskname, label_position, num_tokens_to_generate):
-        with torch.no_grad():
-            predicted_tokens_dec = enc_query
-
-            label_start = label_position[:, 0].clone()
-
-            for _ in range(num_tokens_to_generate):
-                attn_mask = make_inference_attention_mask_3d(
-                    predicted_tokens_dec, predicted_tokens_dec, self.pad_token_id
-                )
-                attn_mask = attn_mask * make_inference_history_mask_3d(predicted_tokens_dec)
-
-                attn_mask = attn_mask < 0.5
-
-                attn_mask = attn_mask.unsqueeze(1)
+        loss, tokens_enc, labels, enc_mask, encoder_input = self.get_loss(batch)
 
-                input_embeds = self.embed_input(predicted_tokens_dec, enc_taskname)
-
-                encoder_position_ids = build_position_ids(predicted_tokens_dec)
-                position_embeddings = self.model.model.language_model.embedding.position_embeddings(
-                    encoder_position_ids
-                )
-
-                encoder_input = input_embeds + position_embeddings
-
-                if self.float_type == torch.float32:
-                    output = self.model.model(None, None, encoder_input=encoder_input, attention_mask=attn_mask,)
-                else:
-                    with torch.autocast(device_type="cuda", dtype=self.float_type):
-                        output = self.model.model(None, None, encoder_input=encoder_input, attention_mask=attn_mask,)
-                output_tensor = output
-
-                output_tensor = tensor_parallel.gather_from_tensor_model_parallel_region(output_tensor)
-
-                # TODO, add logic to use the allowed labels if it is defined
-                log_probs, token_ids = torch.max(nn.functional.log_softmax(output_tensor, dim=-1), dim=-1)
-
-                new_pred = torch.full_like(token_ids[:, 0:1], self.pad_token_id)
-                predicted_tokens_dec = torch.cat([predicted_tokens_dec, new_pred], 1)
-
-                predicted = torch.gather(token_ids, 1, label_start.view(-1, 1))
-
-                # need to scatter the token id at the right position
-                label_start += 1
-                predicted_tokens_dec.scatter_(1, label_start.view(-1, 1), predicted)
+        predicted_token_ids, log_probs = self.model.decode(
+            tokens_enc=tokens_enc,
+            enc_mask=enc_mask,
+            num_tokens_to_generate=self.decoder_seq_length,
+            encoder_input=encoder_input,
+        )
 
-        return predicted_tokens_dec, log_probs
+        return {'loss': loss, 'predicted_token_ids': predicted_token_ids, 'labels': labels}
 
     def inference_epoch_end(self, outputs):
         losses = [x['loss'] for x in outputs]
         averaged_loss = average_losses_across_data_parallel_group(losses)
         all_preds = []
         all_labels = []
         for item in outputs:
             preds = item['predicted_token_ids'].cpu().numpy().tolist()
             labels = item['labels'].cpu().numpy().tolist()
-            label_positions = item['label_position'].cpu().numpy().tolist()
-            for i, (pred, label, label_position) in enumerate(zip(preds, labels, label_positions)):
-                start_position = label_position[0] + 1
-                pred = pred[start_position:]
+            for i, (pred, label) in enumerate(zip(preds, labels)):
                 if self.tokenizer.eos_id in pred:
                     idx = pred.index(self.tokenizer.eos_id)
                     pred = pred[:idx]
-                pred = [id for id in pred if id not in self.special_tokens]
-                label = [id for id in label[label_position[0] : label_position[1]] if id not in self.special_tokens]
+                pred = [id for id in pred if id not in self.tokenizer.special_token_to_id.values()]
+                label = [id for id in label if id not in self.tokenizer.special_token_to_id.values()]
                 pred = self.tokenizer.ids_to_text(pred)
                 label = self.tokenizer.ids_to_text(label)
                 all_preds.append(pred)
                 all_labels.append(label)
 
         correct = 0
         for pred, label in zip(all_preds, all_labels):
@@ -323,54 +297,47 @@
         test_loss, test_acc = self.inference_epoch_end(outputs)
         self.log('test_loss', test_loss, prog_bar=True)
         self.log('test_acc', test_acc, prog_bar=True)
         logging.info(f'Test loss: {test_loss}')
         logging.info(f'Test accuracy: {test_acc}')
 
     def build_train_valid_test_datasets(self, test_only=False):
-        logging.info('Building P-Tune datasets.')
-        self._test_ds = GPTPTuneDataset(
+        logging.info('Building GLUE datasets.')
+        self._test_ds = T5PTuneDataset(
             self.cfg.data.test_ds.file_path,
             data_type="test",
             tokenizer=self.tokenizer,
             templates=self.template,
             pseudo_token_id=self.pseudo_token_id,
             pad_id=self.pad_token_id,
-            max_seq_length=self.model.cfg.encoder_seq_length,
-            max_seq_length_decoder=self.cfg.get('max_decode_length', None),
+            max_seq_length=self.cfg.data.test_ds.max_seq_length,
+            max_seq_length_decoder=None,
         )
-        # update the num_tokens_to_gen from dataset
-        length_for_test = self._test_ds.max_seq_length_decoder
         if test_only:
-            self.num_tokens_to_gen = length_for_test
             return None, None, self._test_ds
-        self._train_ds = GPTPTuneDataset(
+        self._train_ds = T5PTuneDataset(
             self.cfg.data.train_ds.file_path,
             data_type="train",
             tokenizer=self.tokenizer,
             templates=self.template,
             pseudo_token_id=self.pseudo_token_id,
             pad_id=self.pad_token_id,
-            max_seq_length=self.model.cfg.encoder_seq_length,
-            max_seq_length_decoder=length_for_test,
+            max_seq_length=self.cfg.data.train_ds.max_seq_length,
+            max_seq_length_decoder=None,
         )
-        # update the num_tokens_to_gen from dataset
-        length_for_train = self._train_ds.max_seq_length_decoder
-        self._validation_ds = GPTPTuneDataset(
+        self._validation_ds = T5PTuneDataset(
             self.cfg.data.validation_ds.file_path,
             data_type="validation",
             tokenizer=self.tokenizer,
             templates=self.template,
             pseudo_token_id=self.pseudo_token_id,
             pad_id=self.pad_token_id,
-            max_seq_length=self.model.cfg.encoder_seq_length,
-            max_seq_length_decoder=length_for_train,
+            max_seq_length=self.cfg.data.validation_ds.max_seq_length,
+            max_seq_length_decoder=None,
         )
-        length_for_validation = self._validation_ds.max_seq_length_decoder
-        self.num_tokens_to_gen = min(length_for_validation, length_for_train)
         logging.info(f'Length of train dataset: {len(self._train_ds)}')
         logging.info(f'Length of val dataset: {len(self._validation_ds)}')
         logging.info(f'Length of test dataset: {len(self._test_ds)}')
         logging.info(f'Finished building T5 datasets.')
         return self._train_ds, self._validation_ds, self._test_ds
 
     def build_pretraining_data_loader(self, dataset, batch_size, shuffle, num_workers, pin_memory):
@@ -428,54 +395,72 @@
         )
 
     @classmethod
     def list_available_models(cls):
         pass
 
     @torch.no_grad()
-    def ptune_inference(self, queries: List[Dict], batch_size: int = 1, decode_token_len: int = 5) -> List[str]:
+    def ptune_inference(self, queries: List[Dict], batch_size: int = 1, decode_token_len: int = None) -> List[str]:
         """
         Get prediction for the queries
         Args:
             queries: List of data samples without labels
             batch_size: batch size to use during inference
             decode_token_len: max number of tokens to generate during inference
         Returns:
             all_preds: model predictions
         """
+        if decode_token_len is None:
+            decode_token_len = self.decoder_seq_length
         # store predictions for all queries in a single list
         all_preds = []
         mode = self.training
         try:
             # Switch model to evaluation mode
             self.eval()
             logging_level = logging.get_verbosity()
             logging.set_verbosity(logging.WARNING)
             dataloader_cfg = {"batch_size": batch_size, "num_workers": 3, "pin_memory": False}
             infer_datalayer = self._setup_infer_dataloader(dataloader_cfg, queries, decode_token_len)
             for i, batch in enumerate(infer_datalayer):
-                enc_query = batch['enc_query'].to(self.device)
-                label_position = batch['label_position'].to(self.device)
+                tokens_enc = batch['text_enc'].to(self.device)
                 enc_taskname = batch['enc_taskname'].to(self.device)
+                enc_mask = batch['enc_mask'].to(self.device)
+
+                input_embeds = self.embed_input(tokens_enc, enc_taskname)
+
+                encoder_position_ids = build_position_ids(tokens_enc)
+
+                position_embeddings = self.position_embeddings(encoder_position_ids)
+
+                encoder_input = input_embeds + position_embeddings
+
                 # loss, tokens_enc, labels, enc_mask, encoder_input = self.get_loss(batch)
-                predicted_token_ids, _ = self.decode(
-                    enc_query=enc_query,
-                    enc_taskname=enc_taskname,
-                    label_position=label_position,
-                    num_tokens_to_generate=self.num_tokens_to_gen,
-                )
+                if self.float_type == torch.float32:
+                    predicted_token_ids, _ = self.model.decode(
+                        tokens_enc=tokens_enc,
+                        enc_mask=enc_mask,
+                        num_tokens_to_generate=decode_token_len,
+                        enc_input=encoder_input,
+                    )
+                else:
+                    with torch.autocast(device_type="cuda", dtype=self.float_type):
+                        predicted_token_ids, _ = self.model.decode(
+                            tokens_enc=tokens_enc,
+                            enc_mask=enc_mask,
+                            num_tokens_to_generate=decode_token_len,
+                            enc_input=encoder_input,
+                        )
+
                 preds = predicted_token_ids.cpu().numpy().tolist()
-                label_positions = label_position.cpu().numpy().tolist()
-                for i, (pred, label_position) in enumerate(zip(preds, label_positions)):
-                    start_position = label_position[0] + 1
-                    pred = pred[start_position:]
+                for i, pred in enumerate(preds):
                     if self.tokenizer.eos_id in pred:
                         idx = pred.index(self.tokenizer.eos_id)
                         pred = pred[:idx]
-                    pred = [id for id in pred if id not in self.special_tokens]
+                    pred = [id for id in pred if id not in self.tokenizer.special_token_to_id.values()]
                     pred = self.tokenizer.ids_to_text(pred)
                     all_preds.append(pred)
         finally:
             # set mode back to its original value
             self.train(mode=mode)
             logging.set_verbosity(logging_level)
         return all_preds
@@ -489,22 +474,22 @@
         Args:
             cfg: config dictionary containing data loader params like batch_size, num_workers and pin_memory
             queries: queries object
         Returns:
             A pytorch DataLoader.
         """
         # dataset = PTuneTextClassificationDataset(None, queries, prompt)
-        dataset = GPTPTuneInferenceDataset(
+        dataset = T5PTuneInferenceDataset(
             queries=queries,
             data_type="test",
             tokenizer=self.tokenizer,
             templates=self.template,
             pseudo_token_id=self.pseudo_token_id,
             pad_id=self.pad_token_id,
-            max_seq_length=self.model.cfg.encoder_seq_length,
+            max_seq_length=self.cfg.data.test_ds.max_seq_length,
             max_seq_length_decoder=decode_token_len,
         )
 
         # Torch dataloader.
         return torch.utils.data.DataLoader(
             dataset,
             collate_fn=dataset.collate_fn,
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_ptune_t5_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_gpt_generation_model.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,499 +1,411 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright 2019 The Google Research Authors.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from typing import Dict, List
+import os
+from typing import Dict, Optional, Union
 
+import numpy as np
 import torch
-from omegaconf import OmegaConf, open_dict
-from omegaconf.dictconfig import DictConfig
-from pytorch_lightning.trainer.trainer import Trainer
-from torch import Tensor
-
-from nemo.collections.nlp.data.glue_benchmark.t5_ptune_dataset import T5PTuneDataset, T5PTuneInferenceDataset
-from nemo.collections.nlp.models.language_modeling.megatron_base_model import MegatronBaseModel
-from nemo.collections.nlp.models.language_modeling.megatron_t5_model import MegatronT5Model
-from nemo.collections.nlp.modules.common.megatron.utils import (
-    average_losses_across_data_parallel_group,
-    build_position_ids,
-)
-from nemo.collections.nlp.modules.common.prompt_encoder import PromptEncoder
+from omegaconf import DictConfig
+from pytorch_lightning import Trainer
+from torch.utils.data import DataLoader
+from transformers import AutoModelWithLMHead
+
+from nemo.collections.nlp.data.dialogue.data_processor.mellon_qa_data_processor import DialogueMellonQADataProcessor
+from nemo.collections.nlp.data.dialogue.data_processor.ms_marco_data_processor import DialogueMSMarcoDataProcessor
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_gpt_generation_dataset import DialogueGPTGenerationDataset
+from nemo.collections.nlp.metrics.dialogue_metrics import DialogueGenerationMetrics
+from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel
+from nemo.collections.nlp.models.nlp_model import NLPModel
+from nemo.core.classes.common import PretrainedModelInfo
 from nemo.utils import logging
 
-try:
-    from apex.transformer import tensor_parallel
+__all__ = ['DialogueGPTGenerationModel']
 
-    HAVE_APEX = True
-except (ImportError, ModuleNotFoundError):
-    HAVE_APEX = False
+NUM_TASKS = 1  # focussing on intent currently 6  # number of multi-head tasks
 
 
-__all__ = ['MegatronT5PTuneModel']
-
+class DialogueGPTGenerationModel(NLPModel):
+    def __init__(
+        self, cfg: DictConfig, trainer: Trainer = None,
+    ):
+
+        self.cfg = cfg
+        self.data_prepared = False
+
+        self.setup_tokenizer(cfg.tokenizer)
+        self.tokenizer.tokenizer.pad_token = self.tokenizer.tokenizer.eos_token
+        self.epoch_number = 0
+        super().__init__(cfg=cfg, trainer=trainer, no_lm_init=True)
+
+        if self.cfg.library == "huggingface":
+            self.language_model = AutoModelWithLMHead.from_pretrained(cfg.language_model.pretrained_model_name)
+            self.language_model.resize_token_embeddings(len(self.tokenizer.tokenizer))
+            if self.cfg.language_model.lm_checkpoint:
+                self.language_model.load_state_dict(torch.load(self.cfg.language_model.lm_checkpoint))
+        elif self.cfg.library == "megatron":
+            self.language_model = MegatronGPTModel.restore_from(cfg.language_model.lm_checkpoint, trainer=trainer)
+            # 1 corresponds to intent slot; 0 corresponds to squad
+            self.prompt_tags = [1, 0] if 'prompt_table' in dir(self.language_model) else []
+            if hasattr(self.language_model, 'prompt_table'):
+                self.language_model.prompt_tuning_param_freeze_and_optimizer_setup()
+
+            # Init all new prompts
+            for idx, tag in enumerate(cfg.new_prompt_tags):
+                self.prompt_tags.append(tag)
+                init_method = cfg.new_prompt_init_methods[idx]
+                if init_method == "text":
+                    init_text = cfg.new_prompt_init_text[idx]
+                    self.language_model.init_prompt_from_text(tag, init_text)
+                elif init_method == 'random':
+                    self.language_model.init_prompt_from_random(tag)
+                else:
+                    raise ValueError(
+                        f'\n Soft prompt init method {init_method} is not recognized, please use text or random'
+                    )
 
-class MegatronT5PTuneModel(MegatronBaseModel):
-    """
-    Megatron T5 P-Tune
-    """
+    def training_step(self, batch, batch_idx):
+        input_ids, attn_masks, labels, _, _ = batch
 
-    def __init__(self, cfg: DictConfig, trainer: Trainer):
-        super().__init__(cfg, trainer)
+        loss = self(input_ids, attn_masks, labels)
+        self.log("train_loss", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)
+        return {'loss': loss}
 
-        self.megatron_amp_o2 = cfg.get('megatron_amp_O2', False)
-        # TODO: Fix this once apex patches FusedScaledMaskedSoftmax.
-        # This is a workaround for the fact that `masked_softmax_fusion` has issues with certain input sizes that may be present while finetuning.
-        t5_cfg = MegatronT5Model.restore_from(
-            self.register_artifact('language_model.nemo_file', cfg.language_model.get('nemo_file', None)),
-            trainer=trainer,
-            return_config=True,
-        )
-        OmegaConf.set_struct(t5_cfg, True)
-        with open_dict(t5_cfg):
-            t5_cfg.masked_softmax_fusion = False
-            t5_cfg.megatron_amp_O2 = self.megatron_amp_o2
-            # TODO, need to fix this later
-            # hack to make the _GLOBAL_NUM_MICROBATCHES_CALCULATOR initialize
-            t5_cfg.micro_batch_size = 4
-            t5_cfg.global_batch_size = 4
-
-        self.model = MegatronT5Model.restore_from(
-            self.register_artifact('language_model.nemo_file', cfg.language_model.get('nemo_file', None)),
-            trainer=trainer,
-            override_config_path=t5_cfg,
-        )
-
-        # self.model = MegatronT5Model.restore_from(
-        #     self.register_artifact('language_model.nemo_file', cfg.language_model.get('nemo_file', None)),
-        #     trainer=trainer)
+    def validation_step(self, batch, batch_idx):
+        return self.eval_step_helper(batch=batch)
 
-        self.tokenizer = self.model.tokenizer
+    def validation_epoch_end(self, outputs):
+        self.eval_epoch_end(outputs, mode='val')
 
-        self.float_type = self.model.enc_dec_model.enc_dec_model.encoder.model.layers[0].dtype
+    def test_epoch_end(self, outputs):
+        self.eval_epoch_end(outputs, mode='test')
 
-        if not cfg.use_lm_finetune:
-            self.model.freeze()
+    def eval_epoch_end(self, outputs, mode='val'):
 
-        hidden_size = self.model.cfg.hidden_size
+        generated_field = []
+        ground_truth_field = []
+        inputs = []
+        loss = []
+
+        for output in outputs:
+            generated_field += output["generated_field"]
+            ground_truth_field += output["ground_truth_field"]
+            inputs += output["input"]
+            loss.append(output["loss"].item())
+
+        os.makedirs(self.cfg.dataset.dialogues_example_dir, exist_ok=True)
+        filename = os.path.join(
+            self.cfg.dataset.dialogues_example_dir, f"{mode}_predictions_epoch{self.epoch_number}.jsonl"
+        )
+
+        DialogueGenerationMetrics.save_predictions(
+            filename, generated_field, ground_truth_field, inputs,
+        )
+
+        label_acc = np.mean([int(generated_field[i] == ground_truth_field[i]) for i in range(len(generated_field))])
+        precision, recall, f1 = DialogueGenerationMetrics.get_f1(generated_field, ground_truth_field)
+        bleu = DialogueGenerationMetrics.get_bleu(generated_field, ground_truth_field)
+        avg_loss = np.mean(loss)
+        ppl = np.exp(avg_loss)
+
+        self.log('{}_accuracy'.format(mode), label_acc * 100)
+        self.log('precision', precision)
+        self.log('recall', recall)
+        self.log('f1', f1)
+        self.log('bleu', bleu)
+        self.log('{}_loss'.format(mode), avg_loss)
+        self.log('{}_ppl'.format(mode), ppl)
+
+        if mode == 'val':
+            self.epoch_number += 1
+            if self.cfg.save_model:
+                filename = '{}/val_loss-{}-epoch-{}-answer-extender.bin'.format(
+                    self.cfg.dataset.dialogues_example_dir, avg_loss, self.epoch_number
+                )
+                torch.save(self.language_model.state_dict(), filename)
 
-        # register the file containing the labels into the artifacts to get stored in the '.nemo' file later
-        self.word_embeddings = self.model.enc_dec_model.encoder_embedding.word_embeddings
-        self.position_embeddings = self.model.enc_dec_model.encoder_embedding.position_embeddings
+    def test_step(self, batch, batch_idx):
+        return self.eval_step_helper(batch=batch, mode='test')
 
-        # self.vocab = self.tokenizer.tokenizer.get_vocab()
+    # for inference only
+    def predict_step(self, batch, batch_idx, dataloader_idx=None):
+        # return self(batch)
+        raise NotImplementedError()
+
+    def forward(self, input_ids, attention_mask, labels):
+
+        if self.cfg.library == "huggingface":
+            output = self.language_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
+            loss = output['loss']
+
+        elif self.cfg.library == "megatron":
+            num_prompt_tokens = (
+                self.language_model.num_prompt_tokens if hasattr(self.language_model, 'num_prompt_tokens') else 0
+            )
+            position_ids = torch.arange(
+                start=num_prompt_tokens,
+                end=num_prompt_tokens + input_ids.size(1),
+                dtype=torch.long,
+                device=input_ids.device,
+            )
 
-        self.template = cfg.prompt_encoder.template
+            position_ids = position_ids.unsqueeze(0).repeat(input_ids.size(0), 1)
 
-        self.prompt_encoder = PromptEncoder(
-            template=cfg.prompt_encoder.template,
-            hidden_size=hidden_size,
-            lstm_dropout=cfg.prompt_encoder.dropout,
-            num_layers=cfg.prompt_encoder.num_layers,
-        )
+            # 'assit_intent_and_slot' has prompt_id of 1
+            # 'assit_intent_and_slot_with_options' has prompt_id of 2
+            prompt_ids = torch.tensor([1] * input_ids.size(0)) if self.prompt_tags else None
+
+            # this makes a 1d tensor of values 2 rather than 1, which is the prompt_id of 'assit_intent_and_slot_with_options'
+            if self.cfg.dataset.prompt_template == "prompt_tuning_with_options" and prompt_ids is not None:
+                prompt_ids = prompt_ids * 2
+            attn_mask_add_on = torch.ones((attention_mask.size(0), num_prompt_tokens), device=attention_mask.device)
+            full_attention_mask = torch.cat([attn_mask_add_on, attention_mask], axis=-1)
+            full_attention_mask_expand = torch.tril(
+                full_attention_mask.unsqueeze(2).tile(full_attention_mask.size(1))
+            ).unsqueeze(1)
+
+            attn_mask = full_attention_mask_expand > 0
+
+            prompt_token_labels = torch.full(
+                size=(input_ids.size(0), num_prompt_tokens),
+                fill_value=self.tokenizer.tokenizer.pad_token_id,
+                dtype=torch.long,
+                device=input_ids.device,
+            )
 
-        # load prompt encoder
-        self.hidden_size = hidden_size
-        self.tokenizer.add_special_tokens([cfg.pseudo_token])
-
-        self.pseudo_token_id = self.tokenizer.special_token_to_id[cfg.pseudo_token]
-        self.pad_token_id = self.tokenizer.pad_id if self.tokenizer.pad_id is not None else self.tokenizer.unk_id
-        self.spell_length = sum(self.template)
-        self._reduced_loss_buffer = []
-        self.decoder_seq_length = cfg.get('decoder_seq_length', 10)
+            input_ids_new = torch.cat([prompt_token_labels, input_ids], axis=1)
+            make_up_last_column_input_ids = (
+                torch.ones_like(input_ids_new[:, -1:]) * self.tokenizer.tokenizer.pad_token_id
+            )
+            left_shifted_input_ids = torch.cat([input_ids_new[:, 1:], make_up_last_column_input_ids], axis=-1)
 
-    def embed_input(self, enc_input_id: Tensor, enc_taskname_id: Tensor):
-        """
-        This method will replace the virtual tokens in the enc_input_id with
-        embeddings calculated from `prompt_encoder`. If the `enc_taskname_id` is
-        not None, the computed virtual token embeddings are depenedent on it.
-        The virtual token placeholders has the token_id `self.pseudo_token_id`.
-        params:
-            enc_input_id: the input token ids
-            enc_taskname_id: the NLP task tag token ids
-        returns:
-            the token embedding for the LM model.
-        """
-        bz = enc_input_id.shape[0]
-        queries_for_embedding = enc_input_id.clone()
+            unmasked_unreduced_loss = self.language_model(
+                input_ids, position_ids, attn_mask, left_shifted_input_ids, prompt_ids=prompt_ids
+            )
 
-        queries_for_embedding[(enc_input_id == self.pseudo_token_id)] = self.pad_token_id
-        raw_embeds = self.word_embeddings(queries_for_embedding).clone()
+            labels = torch.cat([torch.zeros_like(prompt_token_labels), labels], axis=1)
+            make_up_last_column_labels = torch.ones_like(labels[:, -1:]) * self.tokenizer.tokenizer.pad_token_id
+            new_labels = torch.cat([labels[:, 1:], make_up_last_column_labels], axis=-1)
+            filler = torch.zeros_like(new_labels)
+            labels_mask_0 = torch.where(new_labels != -100, new_labels, filler)
+            labels_mask = labels_mask_0 > 0
 
-        if self.cfg.prompt_encoder.task_dependent:
-            enc_taskname = self.word_embeddings(enc_taskname_id)
-        else:
-            enc_taskname = None
+            loss = self.language_model.loss_func(labels_mask, unmasked_unreduced_loss)
 
-        if self.float_type == torch.float32:
-            replace_embeds = self.prompt_encoder(enc_taskname=enc_taskname)
-        else:
-            with torch.autocast(device_type="cuda", dtype=self.float_type):
-                replace_embeds = self.prompt_encoder(enc_taskname=enc_taskname)
+        return loss
 
-        blocked_indices = enc_input_id == self.pseudo_token_id
-        raw_embeds = raw_embeds.clone().type(self.float_type)
-        # find the index to the psedo-tokens
-        index = blocked_indices.nonzero().reshape((bz, -1, 2))[:, :, 1][:, :, None]
-
-        _, seq, _ = index.shape
-        _, _, emb = raw_embeds.shape
-        index = index.expand(bz, seq, emb)
-
-        if enc_taskname is None:
-            # taskname none, encoder returens batch 1
-            # need to expand
-            _, replace_seq, _ = replace_embeds.shape
-            replace_embeds = replace_embeds.expand(bz, replace_seq, emb)
-
-        # scatter the psedo-token embeddings to the raw embeddings
-        raw_embeds.scatter_(1, index, replace_embeds)
-        return raw_embeds
-
-    def process_batch(self, batch):
-        """Build the batch."""
-
-        keys = ['text_enc', 'text_dec', 'labels', 'loss_mask', 'enc_mask', 'dec_mask', 'enc_taskname']
-        datatype = torch.int64
-        data = batch
-        data_b = tensor_parallel.broadcast_data(keys, data, datatype)
-
-        # Unpack.
-        tokens_enc = data_b['text_enc'].long()
-        tokens_dec = data_b['text_dec'].long()
-        labels = data_b['labels'].long()
-        loss_mask = data_b['loss_mask'].float()
-
-        enc_mask = data_b['enc_mask']
-        dec_mask = data_b['dec_mask']
-        enc_taskname = data_b['enc_taskname']
-
-        return tokens_enc, tokens_dec, loss_mask, labels, enc_mask, dec_mask, enc_taskname
-
-    def get_loss(self, batch):
-        tokens_enc, tokens_dec, loss_mask, labels, enc_mask, dec_mask, enc_taskname = self.process_batch(batch)
-        input_embeds = self.embed_input(tokens_enc, enc_taskname)
-
-        encoder_position_ids = build_position_ids(tokens_enc)
-
-        position_embeddings = self.position_embeddings(encoder_position_ids)
-
-        encoder_input = input_embeds + position_embeddings
-
-        if self.float_type == torch.float32:
-            output = self.model.enc_dec_model(
-                enc_input_ids=None,
-                enc_attn_mask=enc_mask,
-                dec_input_ids=tokens_dec,
-                dec_attn_mask=dec_mask,
-                token_type_ids=None,
-                labels=labels,
-                enc_hidden_states=None,
-                output_enc_hidden_only=False,
-                enc_input=encoder_input,
-            )
-        else:
-            with torch.autocast(device_type="cuda", dtype=self.float_type):
-                output = self.model.enc_dec_model(
-                    enc_input_ids=None,
-                    enc_attn_mask=enc_mask,
-                    dec_input_ids=tokens_dec,
-                    dec_attn_mask=dec_mask,
-                    token_type_ids=None,
-                    labels=labels,
-                    enc_hidden_states=None,
-                    output_enc_hidden_only=False,
-                    enc_input=encoder_input,
+    def prepare_megatron_generation(self, labels, input_ids, template_length):
+        """
+        # adapted from MegatronGPTModel._bucketize_gpt_inference 
+        """
+        batch_size = labels.size(0)
+        prompt_tags = [self.prompt_tags[0]] * batch_size if self.prompt_tags else None
+        batch_tokens = input_ids.tolist()
+
+        # unpad tokens
+        lens = template_length
+        indxs = [index for index in range(batch_size)]
+        for lenn, index in zip(lens, indxs):
+            batch_tokens[index] = batch_tokens[index][:lenn]
+
+        # chunk tokens by same length
+        pre_buckets, lens = [], list(set(lens.tolist()))
+        for lenn in lens:
+            pre_buckets.append([(tokens, index) for index, tokens in enumerate(batch_tokens) if len(tokens) == lenn])
+
+        buckets, positions, bucket_prompt_tags = [], [], []
+
+        # get buckets and prompts initial positions
+        for bucket in pre_buckets:
+            buckets.append(torch.tensor([item[0] for item in bucket]).to(device=labels.device))
+            positions.append([item[1] for item in bucket])
+
+            # bucket prompt tags identically to their corresponding examples
+            if prompt_tags:
+                bucket_prompt_tags.append([prompt_tags[item[1]] for item in bucket])
+
+        # Flatten position list
+        positions = [item for sublist in positions for item in sublist]
+
+        # Flatten buckets and bucket_prompt_tags # temp fix for megatron complete issue. However, this is also slower than bucketized inference
+        buckets = [item.unsqueeze(0) for sublist in buckets for item in sublist]
+        bucket_prompt_tags = [[item] for sublist in bucket_prompt_tags for item in sublist]
+
+        request = {"tokens": buckets, "prompt_tags": bucket_prompt_tags}
+
+        return positions, request
+
+    def post_process_megatron_generation(self, outputs):
+        text_outputs = [output[0] for output in outputs]
+        generated_tokens = self.tokenizer.tokenizer(text_outputs, padding=True, return_tensors="pt").data["input_ids"]
+        return generated_tokens
+
+    def generate_candidates(self, labels, template_length, input_ids, attn_masks):
+
+        tokens_to_generate = self.cfg.tokens_to_generate
+        if self.cfg.library == "huggingface":
+            generated_tokens = []
+            max_length = 0
+            for i in range(input_ids.size(0)):
+                param_dict = {
+                    "input_ids": input_ids[i : i + 1, : template_length[i]],
+                    "attention_masks": attn_masks[i : i + 1, : template_length[i]],
+                    "max_length": template_length[i] + tokens_to_generate,
+                    "pad_token_id": self.tokenizer.tokenizer.pad_token_id,
+                }
+                generated_tokens.append(self.language_model.generate(**param_dict))
+                max_length = max(max_length, generated_tokens[-1].size(1))
+
+            # pad each generated to ensure they are of same length in dim 1, therefore stack-able
+            generated_tokens = [
+                torch.cat(
+                    [i, torch.ones((1, max_length - i.size(1))).to(i.device) * self.tokenizer.tokenizer.pad_token_id],
+                    axis=-1,
                 )
+                for i in generated_tokens
+            ]
+            generated_tokens = torch.cat(generated_tokens, axis=0)
 
-        tokens_loss = output
+        elif self.cfg.library == "megatron":
+            positions, request = self.prepare_megatron_generation(labels, input_ids, template_length)
+            outputs = self.language_model.complete(request, positions, tokens_to_generate)
+            generated_tokens = self.post_process_megatron_generation(outputs)
 
-        loss = self.model.loss_func(loss_mask, tokens_loss)
-        self.log('train_loss', loss)
+        generated_field = self.process_into_structured_fields(generated_tokens, template_length=template_length)
 
-        return loss, tokens_enc, labels, enc_mask, encoder_input
+        ground_truth_field = self.process_into_structured_fields(labels, template_length=template_length)
 
-    def training_step(self, batch, batch_idx):
-        loss, _, _, _, _ = self.get_loss(batch)
-        self.log('train_loss', loss)
-        # Reduced loss for logging.
-        reduced_loss = average_losses_across_data_parallel_group([loss])
-        # cache reduced loss while accumulating gradients
-        self._reduced_loss_buffer.append(reduced_loss[0])
-
-        if (batch_idx + 1) % self.trainer.accumulate_grad_batches == 0:
-            # Reduced loss for logging.
-            average_reduced_loss = sum(self._reduced_loss_buffer) / len(self._reduced_loss_buffer)
-            self.log('reduced_train_loss', average_reduced_loss, prog_bar=True)
-            lr = self._optimizer.param_groups[0]['lr']
-            self.log('lr', lr)
-            self.log('global_step', self.trainer.global_step, prog_bar=True)
-            self._reduced_loss_buffer = []
+        return generated_field, ground_truth_field
 
-        return loss
+    def process_into_structured_fields(self, full_seq_ids, template_length=None):
 
-    def inference_step(self, batch, batch_ix):
-        loss, tokens_enc, labels, enc_mask, encoder_input = self.get_loss(batch)
+        structured_field = []
+        for i in range(full_seq_ids.size(0)):
+            start_point = 0 if template_length is None else template_length[i].item()
+            stop_point = full_seq_ids.size(1)
 
-        predicted_token_ids, log_probs = self.model.decode(
-            tokens_enc=tokens_enc,
-            enc_mask=enc_mask,
-            num_tokens_to_generate=self.decoder_seq_length,
-            encoder_input=encoder_input,
-        )
+            for j in range(start_point, stop_point):
+                if full_seq_ids.data[i, j] == self.tokenizer.tokenizer.pad_token_id:
+                    stop_point = j
+                    break
+            one_generated_field = self.tokenizer.tokenizer.decode(full_seq_ids[i, start_point:stop_point]).strip()
+            structured_field.append(one_generated_field)
+        return structured_field
 
-        return {'loss': loss, 'predicted_token_ids': predicted_token_ids, 'labels': labels}
+    def eval_step_helper(self, batch, mode='val'):
 
-    def inference_epoch_end(self, outputs):
-        losses = [x['loss'] for x in outputs]
-        averaged_loss = average_losses_across_data_parallel_group(losses)
-        all_preds = []
-        all_labels = []
-        for item in outputs:
-            preds = item['predicted_token_ids'].cpu().numpy().tolist()
-            labels = item['labels'].cpu().numpy().tolist()
-            for i, (pred, label) in enumerate(zip(preds, labels)):
-                if self.tokenizer.eos_id in pred:
-                    idx = pred.index(self.tokenizer.eos_id)
-                    pred = pred[:idx]
-                pred = [id for id in pred if id not in self.tokenizer.special_token_to_id.values()]
-                label = [id for id in label if id not in self.tokenizer.special_token_to_id.values()]
-                pred = self.tokenizer.ids_to_text(pred)
-                label = self.tokenizer.ids_to_text(label)
-                all_preds.append(pred)
-                all_labels.append(label)
-
-        correct = 0
-        for pred, label in zip(all_preds, all_labels):
-            if pred == label:
-                correct += 1
-        acc = correct / len(all_preds)
-        return averaged_loss[0], acc
+        input_ids, attn_masks, labels, template_length, utterance_length = batch
 
-    def validation_step(self, batch, batch_idx):
-        return self.inference_step(batch, batch_idx)
+        loss = self(input_ids, attn_masks, labels)
+        self.log("{}_loss".format(mode), loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)
 
-    def validation_epoch_end(self, outputs):
-        val_loss, val_acc = self.inference_epoch_end(outputs)
-        self.log('val_loss', val_loss, prog_bar=True)
-        self.log('val_acc', val_acc, prog_bar=True)
-        logging.info(f'Validation loss: {val_loss}')
-        logging.info(f'Validation accuracy: {val_acc}')
+        # autoregressively generate candidates (possibly with constraint)
+        generated_field, ground_truth_field = self.generate_candidates(labels, template_length, input_ids, attn_masks)
 
-    def test_step(self, batch, batch_idx):
-        return self.inference_step(batch, batch_idx)
+        return {
+            'loss': loss,
+            'input': self.tokenizer.tokenizer.batch_decode(input_ids, skip_special_tokens=True),
+            'generated_field': generated_field,
+            'ground_truth_field': ground_truth_field,
+        }
 
-    def test_epoch_end(self, outputs):
-        test_loss, test_acc = self.inference_epoch_end(outputs)
-        self.log('test_loss', test_loss, prog_bar=True)
-        self.log('test_acc', test_acc, prog_bar=True)
-        logging.info(f'Test loss: {test_loss}')
-        logging.info(f'Test accuracy: {test_acc}')
-
-    def build_train_valid_test_datasets(self, test_only=False):
-        logging.info('Building GLUE datasets.')
-        self._test_ds = T5PTuneDataset(
-            self.cfg.data.test_ds.file_path,
-            data_type="test",
-            tokenizer=self.tokenizer,
-            templates=self.template,
-            pseudo_token_id=self.pseudo_token_id,
-            pad_id=self.pad_token_id,
-            max_seq_length=self.cfg.data.test_ds.max_seq_length,
-            max_seq_length_decoder=None,
-        )
-        if test_only:
-            return None, None, self._test_ds
-        self._train_ds = T5PTuneDataset(
-            self.cfg.data.train_ds.file_path,
-            data_type="train",
-            tokenizer=self.tokenizer,
-            templates=self.template,
-            pseudo_token_id=self.pseudo_token_id,
-            pad_id=self.pad_token_id,
-            max_seq_length=self.cfg.data.train_ds.max_seq_length,
-            max_seq_length_decoder=None,
-        )
-        self._validation_ds = T5PTuneDataset(
-            self.cfg.data.validation_ds.file_path,
-            data_type="validation",
-            tokenizer=self.tokenizer,
-            templates=self.template,
-            pseudo_token_id=self.pseudo_token_id,
-            pad_id=self.pad_token_id,
-            max_seq_length=self.cfg.data.validation_ds.max_seq_length,
-            max_seq_length_decoder=None,
-        )
-        logging.info(f'Length of train dataset: {len(self._train_ds)}')
-        logging.info(f'Length of val dataset: {len(self._validation_ds)}')
-        logging.info(f'Length of test dataset: {len(self._test_ds)}')
-        logging.info(f'Finished building T5 datasets.')
-        return self._train_ds, self._validation_ds, self._test_ds
-
-    def build_pretraining_data_loader(self, dataset, batch_size, shuffle, num_workers, pin_memory):
-        """Buld dataloader given an input dataset."""
-
-        if dataset is None:
-            return None
-
-        # Torch dataloader.
-        return torch.utils.data.DataLoader(
-            dataset,
-            collate_fn=dataset.collate_fn,
-            batch_size=batch_size,
-            shuffle=shuffle,
-            num_workers=num_workers,
-            pin_memory=pin_memory,
-            drop_last=False,
-        )
-
-    def setup(self, stage=None):
-        if stage == 'predict':
-            return
-        self.build_train_valid_test_datasets(test_only=stage == 'test')
-        self.setup_test_data()
-        if stage == 'test':
+    def prepare_data(self):
+        """
+        Preprocessed schema and dialogues and caches this
+        """
+        if self.data_prepared:
             return
-        self.setup_training_data()
-        self.setup_validation_data()
-
-    def setup_training_data(self, training_data_config=None):
-        self._train_dl = self.build_pretraining_data_loader(
-            self._train_ds,
-            self.cfg.data.train_ds.batch_size,
-            shuffle=True,
-            num_workers=self.cfg.data.train_ds.num_workers,
-            pin_memory=True,
-        )
 
-    def setup_validation_data(self, validation_data_config=None):
-        self._validation_dl = self.build_pretraining_data_loader(
-            self._validation_ds,
-            self.cfg.data.validation_ds.batch_size,
-            shuffle=False,
-            num_workers=self.cfg.data.validation_ds.num_workers,
-            pin_memory=True,
-        )
-
-    def setup_test_data(self, test_data_config=None):
-        self._test_dl = self.build_pretraining_data_loader(
-            self._test_ds,
-            self.cfg.data.test_ds.batch_size,
-            shuffle=False,
-            num_workers=self.cfg.data.test_ds.num_workers,
-            pin_memory=True,
-        )
+        if self._cfg.dataset.task == "ms_marco":
+            self.dialogues_processor = DialogueMSMarcoDataProcessor(
+                data_dir=self._cfg.dataset.data_dir, tokenizer=self.tokenizer, cfg=self._cfg.dataset
+            )
+        elif self._cfg.dataset.task == "mellon_qa":
+            self.dialogues_processor = DialogueMellonQADataProcessor(
+                data_dir=self._cfg.dataset.data_dir, tokenizer=self.tokenizer, cfg=self._cfg.dataset
+            )
+        else:
+            raise ValueError("Only ms_marco and mellon_qa supported for Dialogue GPT Generation Model")
 
-    @classmethod
-    def list_available_models(cls):
-        pass
+        self.data_prepared = True
 
-    @torch.no_grad()
-    def ptune_inference(self, queries: List[Dict], batch_size: int = 1, decode_token_len: int = None) -> List[str]:
+    def update_data_dirs(self, data_dir: str, dialogues_example_dir: str):
         """
-        Get prediction for the queries
+        Update data directories
+
         Args:
-            queries: List of data samples without labels
-            batch_size: batch size to use during inference
-            decode_token_len: max number of tokens to generate during inference
-        Returns:
-            all_preds: model predictions
+            data_dir: path to data directory
+            dialogues_example_dir: path to preprocessed dialogues example directory, if not exists will be created.
         """
-        if decode_token_len is None:
-            decode_token_len = self.decoder_seq_length
-        # store predictions for all queries in a single list
-        all_preds = []
-        mode = self.training
-        try:
-            # Switch model to evaluation mode
-            self.eval()
-            logging_level = logging.get_verbosity()
-            logging.set_verbosity(logging.WARNING)
-            dataloader_cfg = {"batch_size": batch_size, "num_workers": 3, "pin_memory": False}
-            infer_datalayer = self._setup_infer_dataloader(dataloader_cfg, queries, decode_token_len)
-            for i, batch in enumerate(infer_datalayer):
-                tokens_enc = batch['text_enc'].to(self.device)
-                enc_taskname = batch['enc_taskname'].to(self.device)
-                enc_mask = batch['enc_mask'].to(self.device)
-
-                input_embeds = self.embed_input(tokens_enc, enc_taskname)
-
-                encoder_position_ids = build_position_ids(tokens_enc)
-
-                position_embeddings = self.position_embeddings(encoder_position_ids)
-
-                encoder_input = input_embeds + position_embeddings
-
-                # loss, tokens_enc, labels, enc_mask, encoder_input = self.get_loss(batch)
-                if self.float_type == torch.float32:
-                    predicted_token_ids, _ = self.model.decode(
-                        tokens_enc=tokens_enc,
-                        enc_mask=enc_mask,
-                        num_tokens_to_generate=decode_token_len,
-                        enc_input=encoder_input,
-                    )
-                else:
-                    with torch.autocast(device_type="cuda", dtype=self.float_type):
-                        predicted_token_ids, _ = self.model.decode(
-                            tokens_enc=tokens_enc,
-                            enc_mask=enc_mask,
-                            num_tokens_to_generate=decode_token_len,
-                            enc_input=encoder_input,
-                        )
-
-                preds = predicted_token_ids.cpu().numpy().tolist()
-                for i, pred in enumerate(preds):
-                    if self.tokenizer.eos_id in pred:
-                        idx = pred.index(self.tokenizer.eos_id)
-                        pred = pred[:idx]
-                    pred = [id for id in pred if id not in self.tokenizer.special_token_to_id.values()]
-                    pred = self.tokenizer.ids_to_text(pred)
-                    all_preds.append(pred)
-        finally:
-            # set mode back to its original value
-            self.train(mode=mode)
-            logging.set_verbosity(logging_level)
-        return all_preds
-
-    def _setup_infer_dataloader(
-        self, cfg: Dict, queries: List[str], decode_token_len: int
-    ) -> 'torch.utils.data.DataLoader':
+        if not os.path.exists(data_dir):
+            raise ValueError(f"{data_dir} is not found")
+        self._cfg.dataset.data_dir = data_dir
+        self._cfg.dataset.dialogues_example_dir = dialogues_example_dir
+        logging.info(f'Setting model.dataset.data_dir to {data_dir}.')
+        logging.info(f'Setting model.dataset.dialogues_example_dir to {dialogues_example_dir}.')
+
+    def setup_training_data(self, train_data_config: Optional[DictConfig] = None):
+        self.prepare_data()
+        self._train_dl = self._setup_dataloader_from_config(cfg=train_data_config, split=train_data_config.ds_item)
+
+    def setup_multiple_validation_data(self, val_data_config: Optional[DictConfig] = None):
+        return self.setup_validation_data(val_data_config)
+
+    def setup_validation_data(self, val_data_config: Optional[DictConfig] = None):
+        self.prepare_data()
+        self._validation_dl = self._setup_dataloader_from_config(cfg=val_data_config, split=val_data_config.ds_item)
+
+    def setup_multiple_test_data(self, test_data_config: Union[DictConfig, Dict]):
+        self.setup_test_data(test_data_config)
+
+    def setup_test_data(self, test_data_config: Optional[DictConfig] = None):
+        self.prepare_data()
+        self._test_dl = self._setup_dataloader_from_config(cfg=test_data_config, split=test_data_config.ds_item)
+
+    def _setup_dataloader_from_config(self, cfg: DictConfig, split: str) -> DataLoader:
+        dataset_cfg = self._cfg.dataset
+        data_dir = dataset_cfg.data_dir
+
+        if not os.path.exists(data_dir):
+            raise FileNotFoundError(f"Data directory is not found at: {data_dir}.")
+
+        dataset = DialogueGPTGenerationDataset(
+            dataset_split=split,
+            dialogues_processor=self.dialogues_processor,
+            tokenizer=self.dialogues_processor._tokenizer,
+            cfg=dataset_cfg,
+        )
+
+        dl = torch.utils.data.DataLoader(
+            dataset=dataset,
+            batch_size=cfg.batch_size,
+            collate_fn=dataset.collate_fn,
+            drop_last=cfg.drop_last,
+            shuffle=cfg.shuffle,
+            num_workers=cfg.num_workers,
+            pin_memory=cfg.pin_memory,
+        )
+        return dl
+
+    @classmethod
+    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
         """
-        Setup function for a infer data loader.
+        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
 
-        Args:
-            cfg: config dictionary containing data loader params like batch_size, num_workers and pin_memory
-            queries: queries object
         Returns:
-            A pytorch DataLoader.
+            List of available pre-trained models.
         """
-        # dataset = PTuneTextClassificationDataset(None, queries, prompt)
-        dataset = T5PTuneInferenceDataset(
-            queries=queries,
-            data_type="test",
-            tokenizer=self.tokenizer,
-            templates=self.template,
-            pseudo_token_id=self.pseudo_token_id,
-            pad_id=self.pad_token_id,
-            max_seq_length=self.cfg.data.test_ds.max_seq_length,
-            max_seq_length_decoder=decode_token_len,
-        )
-
-        # Torch dataloader.
-        return torch.utils.data.DataLoader(
-            dataset,
-            collate_fn=dataset.collate_fn,
-            batch_size=cfg["batch_size"],
-            shuffle=False,
-            num_workers=cfg.get("num_workers", 0),
-            pin_memory=cfg.get("pin_memory", False),
-            drop_last=False,
-        )
+        result = []
+        return result
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/megatron_t5_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/megatron_t5_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/language_modeling/transformer_lm_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/language_modeling/transformer_lm_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/losses/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -8,9 +8,9 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.machine_translation.mt_enc_dec_bottleneck_model import MTBottleneckModel
-from nemo.collections.nlp.models.machine_translation.mt_enc_dec_model import MTEncDecModel
+import nemo.collections.tts.losses.tacotron2loss
+import nemo.collections.tts.losses.waveglowloss
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/megatron_nmt_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/megatron_nmt_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/mt_enc_dec_bottleneck_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/mt_enc_dec_bottleneck_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -108,17 +108,17 @@
     def _validate_encoder_decoder_hidden_size(self):
         """
         Validate encoder and decoder hidden sizes, and enforce same size.
         We support here encoder/decoder with different hidden_size, so do nothing.
         """
         pass
 
-    def eval_epoch_end(self, outputs, mode):
+    def eval_epoch_end(self, outputs, mode, global_rank):
         # call parent for logging
-        super().eval_epoch_end(outputs, mode)
+        super().eval_epoch_end(outputs, mode, global_rank)
 
         # if user specifies one validation dataloader, then PTL reverts to giving a list of dictionary instead of a list of list of dictionary
         if isinstance(outputs[0], dict):
             outputs = [outputs]
 
         for dataloader_idx, output in enumerate(outputs):
             # add logs if available in outputs
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/mt_enc_dec_config.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/mt_enc_dec_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/machine_translation/mt_enc_dec_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/machine_translation/mt_enc_dec_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -399,14 +399,17 @@
         Lightning calls this inside the validation loop with the data from the validation dataloader
         passed in as `batch`.
         """
         return self.eval_step(batch, batch_idx, 'val', dataloader_idx)
 
     def eval_epoch_end(self, outputs, mode, global_rank):
         # if user specifies one validation dataloader, then PTL reverts to giving a list of dictionary instead of a list of list of dictionary
+        if not outputs:
+            return
+
         if isinstance(outputs[0], dict):
             outputs = [outputs]
 
         loss_list = []
         sb_score_list = []
         for dataloader_idx, output in enumerate(outputs):
             if dataloader_idx == 0:
@@ -868,32 +871,32 @@
         Creates source and target processor objects for input and output pre/post-processing.
         """
         source_processor, target_processor = None, None
 
         if encoder_tokenizer_library == 'byte-level':
             source_processor = ByteLevelProcessor()
         elif (source_lang == 'en' and target_lang == 'ja') or (source_lang == 'ja' and target_lang == 'en'):
-            self.source_processor = EnJaProcessor(source_lang)
+            source_processor = EnJaProcessor(source_lang)
         elif source_lang == 'ja-mecab':
-            self.source_processor = JaMecabProcessor()
+            source_processor = JaMecabProcessor()
         elif source_lang == 'zh':
             source_processor = ChineseProcessor()
         elif source_lang == 'hi':
             source_processor = IndicProcessor(source_lang)
         elif source_lang == 'ignore':
             source_processor = None
         elif source_lang is not None and source_lang not in ['ja', 'zh', 'hi']:
             source_processor = MosesProcessor(source_lang)
 
         if decoder_tokenizer_library == 'byte-level':
             target_processor = ByteLevelProcessor()
         elif (source_lang == 'en' and target_lang == 'ja') or (source_lang == 'ja' and target_lang == 'en'):
-            self.target_processor = EnJaProcessor(target_lang)
+            target_processor = EnJaProcessor(target_lang)
         elif target_lang == 'ja-mecab':
-            self.target_processor = JaMecabProcessor()
+            target_processor = JaMecabProcessor()
         elif target_lang == 'zh':
             target_processor = ChineseProcessor()
         elif target_lang == 'hi':
             target_processor = IndicProcessor(target_lang)
         elif target_lang == 'ignore':
             target_processor = None
         elif target_lang is not None and target_lang not in ['ja', 'zh', 'hi']:
@@ -976,31 +979,32 @@
             src_ids_[i][: len(txt)] = txt
 
         src_mask = torch.FloatTensor((src_ids_ != tokenizer.pad_id)).to(self.device)
         src = torch.LongTensor(src_ids_).to(self.device)
 
         return src, src_mask
 
-    # TODO: We should drop source/target_lang arguments in favor of using self.src/tgt_language
     @torch.no_grad()
     def translate(
         self,
         text: List[str],
         source_lang: str = None,
         target_lang: str = None,
         return_beam_scores: bool = False,
         log_timing: bool = False,
     ) -> List[str]:
         """
         Translates list of sentences from source language to target language.
         Should be regular text, this method performs its own tokenization/de-tokenization
         Args:
             text: list of strings to translate
-            source_lang: if not None, corresponding MosesTokenizer and MosesPunctNormalizer will be run
-            target_lang: if not None, corresponding MosesDecokenizer will be run
+            source_lang: if not "ignore", corresponding MosesTokenizer and MosesPunctNormalizer will be run
+            target_lang: if not "ignore", corresponding MosesDecokenizer will be run
+            return_beam_scores: if True, returns a list of translations and their corresponding beam scores.
+            log_timing: if True, prints timing information.
         Returns:
             list of translated strings
         """
         # __TODO__: This will reset both source and target processors even if you want to reset just one.
         if source_lang is not None or target_lang is not None:
             self.source_processor, self.target_processor = MTEncDecModel.setup_pre_and_post_processing_utils(
                 source_lang, target_lang, self.encoder_tokenizer_library, self.decoder_tokenizer_library
@@ -1050,14 +1054,46 @@
             if type(return_val) is tuple:
                 return_val = return_val + (timing,)
             else:
                 return_val = (return_val, timing)
 
         return return_val
 
+    def itn_translate_tn(
+        self,
+        text: List[str],
+        source_lang: str = None,
+        target_lang: str = None,
+        return_beam_scores: bool = False,
+        log_timing: bool = False,
+        inverse_normalizer=None,
+        normalizer=None,
+    ) -> List[str]:
+        """
+        Calls the translate() method with the option of running ITN (inverse text-normalization) on the input adn TN (text-normalization) on the output.
+        Pipeline : ITN -> translate -> TN
+        NOTE: ITN and TN objects must be initialized with the right languages.
+        Args:
+            text: list of strings to translate
+            source_lang: if not "ignore", corresponding MosesTokenizer and MosesPunctNormalizer will be run
+            target_lang: if not "ignore", corresponding MosesDecokenizer will be run
+            return_beam_scores: if True, returns a list of translations and their corresponding beam scores.
+            log_timing: if True, prints timing information.
+            inverse_normalizer: instance of nemo_text_processing.inverse_text_normalization.inverse_normalize.InverseNormalizer
+            normalizer: instance of nemo_text_processing.text_normalization.normalize.Normalizer
+        Returns:
+            list of translated strings
+        """
+        if inverse_normalizer is not None:
+            text = [inverse_normalizer.normalize(example) for example in text]
+        translations = self.translate(text, source_lang, target_lang, return_beam_scores, log_timing)
+        if normalizer is not None:
+            translations = [normalizer.normalize(example) for example in translations]
+        return translations
+
     def export(self, output: str, input_example=None, **kwargs):
         encoder_exp, encoder_descr = self.encoder.export(
             augment_filename(output, 'Encoder'), input_example=input_example, **kwargs,
         )
         decoder_exp, decoder_descr = self.decoder.export(
             augment_filename(output, 'Decoder'),
             # TODO: propagate from export()
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/nlp_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/nlp_model.py`

 * *Files 0% similar despite different names*

```diff
@@ -115,28 +115,27 @@
                 bert_model, 'tokenizer'
             ):
                 self.tokenizer = bert_model.tokenizer
 
             # Required to pull up the config for MegatronBert models
             self.pretrained_model_name = cfg.language_model.pretrained_model_name
 
-            # register encoder config
-            self.register_bert_model()
-
             if (
                 cfg.tokenizer is not None
                 and cfg.tokenizer.get("tokenizer_name", "") is not None
                 and "megatron" in cfg.tokenizer.get("tokenizer_name", "")
             ) or pretrain_model_name in all_pretrained_megatron_bert_models:
                 self.hidden_size = bert_model.cfg.hidden_size
             else:
                 self.hidden_size = bert_model.config.hidden_size
 
         if cfg.get('language_model') and not no_lm_init:
             self.bert_model = bert_model
+            # register encoder config
+            self.register_bert_model()
 
     def register_artifact(
         self, config_path: str, src: str, verify_src_exists: bool = False,
     ):
         """ Overrides ModelPT register_artifact default behavior.
         NLP models usually need artifacts that are optional."""
         return super().register_artifact(config_path, src, verify_src_exists=verify_src_exists)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/question_answering/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/question_answering/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/question_answering/qa_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/question_answering/qa_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/text2sparql/__init__.py` & `nemo_toolkit-1.9.0/nemo/core/utils/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.text2sparql.text2sparql_model import Text2SparqlModel
+from nemo.core.utils import k2_utils, numba_utils
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/text2sparql/text2sparql_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/text2sparql/text2sparql_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/text_classification/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -8,17 +8,14 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.text_classification.text_classification_model import TextClassificationModel
-
-try:
-    from nemo.collections.nlp.models.text_classification.ptune_text_classification_model import (
-        PTuneTextClassificationModel,
-    )
-
-    HAVE_APEX = True
-except (ImportError, ModuleNotFoundError, NameError):
-    HAVE_APEX = False
+from nemo.collections.nlp.models.token_classification.punctuation_capitalization_config import (
+    PunctuationCapitalizationModelConfig,
+)
+from nemo.collections.nlp.models.token_classification.punctuation_capitalization_model import (
+    PunctuationCapitalizationModel,
+)
+from nemo.collections.nlp.models.token_classification.token_classification_model import TokenClassificationModel
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/text_classification/ptune_text_classification_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_zero_shot_intent_model.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,503 +1,445 @@
-# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.
+# Copyright 2018 The HuggingFace Inc. team.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
 import os
-from typing import Dict, List, Optional
+from collections import defaultdict
+from typing import Dict, List, Optional, Union
 
+import numpy as np
 import torch
 from omegaconf import DictConfig
 from pytorch_lightning import Trainer
-from torch.nn.utils.rnn import pad_sequence
+from transformers import AutoModelForSequenceClassification, AutoTokenizer
 
-from nemo.collections.nlp.data.text_classification.ptune_text_classification_dataset import (
-    PTuneTextClassificationDataset,
-    token_wrapper,
+from nemo.collections.nlp.data.dialogue import DialogueSGDDataProcessor
+from nemo.collections.nlp.data.dialogue.data_processor.assistant_data_processor import DialogueAssistantDataProcessor
+from nemo.collections.nlp.data.dialogue.data_processor.design_data_processor import DialogueDesignDataProcessor
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_zero_shot_intent_dataset import DialogueZeroShotIntentDataset
+from nemo.collections.nlp.data.zero_shot_intent_recognition.zero_shot_intent_dataset import (
+    ZeroShotIntentInferenceDataset,
+    calc_class_weights_from_dataloader,
 )
 from nemo.collections.nlp.metrics.classification_report import ClassificationReport
-from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel
-from nemo.collections.nlp.models.nlp_model import NLPModel
-from nemo.collections.nlp.modules.common.megatron.megatron_init import initialize_model_parallel_for_nemo
-from nemo.collections.nlp.modules.common.prompt_encoder import PromptEncoder
-from nemo.collections.nlp.modules.common.tokenizer_utils import get_nmt_tokenizer
-from nemo.core.classes.common import typecheck
-from nemo.core.classes.exportable import Exportable
-from nemo.core.neural_types import LossType, NeuralType, PredictionsType, StringLabel, StringType
+from nemo.collections.nlp.metrics.dialogue_metrics import DialogueGenerationMetrics
+from nemo.collections.nlp.models import TextClassificationModel
+from nemo.core.classes.common import PretrainedModelInfo
 from nemo.utils import logging
-from nemo.utils.app_state import AppState
-
-__all__ = ['PTuneTextClassificationModel']
-
 
-SMALL_LOGITS = -100
+__all__ = ['DialogueZeroShotIntentModel']
 
 
-class PTuneTextClassificationModel(NLPModel, Exportable):
-    @property
-    def input_types(self) -> Optional[Dict[str, NeuralType]]:
-        return {"sentences": [NeuralType(('T'), StringType())], "labels": [NeuralType(('T'), StringLabel())]}
-
-    @property
-    def output_types(self) -> Optional[Dict[str, NeuralType]]:
-        return {
-            "floss": NeuralType((), LossType()),
-            "returned_pred": NeuralType(('B'), PredictionsType()),
-            "returned_label": NeuralType(('B'), PredictionsType()),
-        }
+class DialogueZeroShotIntentModel(TextClassificationModel):
+    """TextClassificationModel to be trained on two- or three-class textual entailment data, to be used for zero shot intent recognition."""
 
     def __init__(self, cfg: DictConfig, trainer: Trainer = None):
-        """Initializes the PTune TextClassifier model."""
-        super().__init__(cfg=cfg, trainer=trainer, no_lm_init=True)
-
-        initialize_model_parallel_for_nemo(
-            world_size=trainer.world_size,
-            global_rank=trainer.global_rank,
-            local_rank=trainer.local_rank,
-            tensor_model_parallel_size=cfg.get('tensor_model_parallel_size', 1),
-            seed=cfg.get('seed', 1234),
-        )
-
-        # shared params for dataset and data loaders
-        self.dataset_cfg = cfg.dataset
-        # tokenizer needs to get initialized before the super.__init__()
-        # as dataloaders and datasets need it to process the data
-        self.tokenizer = get_nmt_tokenizer(
-            library=cfg.tokenizer.library,
-            model_name=cfg.tokenizer.type,
-            tokenizer_model=self.register_artifact("tokenizer.model", cfg.tokenizer.model),
-            vocab_file=self.register_artifact("tokenizer.vocab_file", cfg.tokenizer.vocab_file),
-            merges_file=self.register_artifact("tokenizer.merge_file", cfg.tokenizer.merge_file),
-        )
-
-        self.class_weights = None
-
-        self.model = MegatronGPTModel.restore_from(
-            self.register_artifact('language_model.nemo_file', cfg.language_model.get('nemo_file', None)),
-            trainer=trainer,
-        )
-
-        if not cfg.use_lm_finetune:
-            self.model.freeze()
+        self.cfg = cfg
+        super().__init__(cfg=cfg, trainer=trainer)
 
-        hidden_size = self.model.cfg.hidden_size
-
-        # register the file containing the labels into the artifacts to get stored in the '.nemo' file later
-        self.classes = cfg.dataset.classes
-
-        self.embeddings = self.model.model.language_model.embedding.word_embeddings
-
-        # set allowed vocab set
-        self.vocab = self.tokenizer.tokenizer.get_vocab()
-
-        # make sure classes are part of the vocab
-        for k in cfg.dataset.classes:
-            if token_wrapper(k) not in self.vocab:
-                logging.error(f'class {k} is not part of the vocabulary. Please add it to your vocab')
-        self.allowed_vocab_ids = set(self.vocab[token_wrapper(k)] for k in cfg.dataset.classes)
-
-        # map from id to label
-        self.allowed_vocab = {}
-        self.label_ids = {}
-        self.id_to_label = {}
-        for i, k in enumerate(cfg.dataset.classes):
-            self.allowed_vocab[self.vocab[token_wrapper(k)]] = i
-            self.label_ids[k] = i
-            self.id_to_label[i] = k
-
-        self.template = cfg.prompt_encoder.template
-
-        self.prompt_encoder = PromptEncoder(
-            template=cfg.prompt_encoder.template,
-            hidden_size=hidden_size,
-            lstm_dropout=cfg.prompt_encoder.dropout,
-            num_layers=cfg.prompt_encoder.num_layers,
-        )
+        if self.cfg.library == 'megatron':
+            # zero shot intent classification loading
+            # cannot directly load as .nemo uses the pre-refactor model
+            # therefore transfer its attributes over
+            if self.cfg.original_nemo_checkpoint is not None:
+                original_model = DialogueZeroShotIntentModel.restore_from(self.cfg.original_nemo_checkpoint)
+                self.classifier = original_model.classifier
+                self.bert_model = original_model.bert_model
+                self.loss = original_model.loss
+                self.classification_report = original_model.classification_report
+        elif self.cfg.library == "huggingface":
+            self.nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')
+            self.bert_model = self.nli_model.model
+            self.classifier = self.nli_model.classification_head
+            original_model = DialogueZeroShotIntentModel.restore_from(self.cfg.original_nemo_checkpoint)
+            self.loss = original_model.loss
+            self.classification_report = original_model.classification_report
+            self.tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')
+            self.tokenizer.max_seq_length = self.cfg.dataset.max_seq_length
+
+    def _setup_dataloader_from_config(self, cfg: DictConfig, dataset_split) -> 'torch.utils.data.DataLoader':
+        if self._cfg.dataset.task == "zero_shot":
+            self.data_processor = DialogueAssistantDataProcessor(
+                self.cfg.data_dir, self.tokenizer, cfg=self.cfg.dataset
+            )
+        elif self._cfg.dataset.task == "design":
+            self.data_processor = DialogueDesignDataProcessor(
+                data_dir=self._cfg.dataset.data_dir, tokenizer=self.tokenizer, cfg=self._cfg.dataset
+            )
+        elif self._cfg.dataset.task == 'sgd':
+            self.data_processor = DialogueSGDDataProcessor(
+                data_dir=self._cfg.dataset.data_dir,
+                dialogues_example_dir=self._cfg.dataset.dialogues_example_dir,
+                tokenizer=self.tokenizer,
+                cfg=self._cfg.dataset,
+            )
+        else:
+            raise ValueError("Only zero_shot, design and sgd supported for Zero Shot Intent Model")
 
-        # load prompt encoder
-        self.hidden_size = hidden_size
-        self.tokenizer.add_special_tokens({'additional_special_tokens': [cfg.pseudo_token]})
-
-        self.pseudo_token_id = self.tokenizer.tokenizer.get_vocab()[cfg.pseudo_token]
-        self.pad_token_id = (
-            self.tokenizer.tokenizer.pad_token_id
-            if self.tokenizer.tokenizer.pad_token_id is not None
-            else self.tokenizer.tokenizer.unk_token_id
+        dataset = DialogueZeroShotIntentDataset(
+            dataset_split,
+            self.data_processor,
+            self.tokenizer,
+            self.cfg.dataset,  # this is the model.dataset cfg, which is diff from train_ds cfg etc
         )
-        self.spell_length = sum(self.template)
 
-    def setup(self, stage):
-        # setup to track metrics, need to put here
-        # as data_parallel_group is initialized when calling `fit, or test function`
-        app = AppState()
-        self.classification_report = ClassificationReport(
-            num_classes=len(self.classes),
-            label_ids=self.label_ids,
-            mode='micro',
-            dist_sync_on_step=True,
-            process_group=app.data_parallel_group,
+        return torch.utils.data.DataLoader(
+            dataset=dataset,
+            collate_fn=dataset.collate_fn,
+            batch_size=cfg.batch_size,
+            shuffle=cfg.shuffle,
+            num_workers=cfg.get("num_workers", 0),
+            pin_memory=cfg.get("pin_memory", False),
+            drop_last=cfg.get("drop_last", False),
         )
 
-    def embed_input(self, queries):
-        bz = queries.shape[0]
-        queries_for_embedding = queries.clone()
-
-        queries_for_embedding[(queries == self.pseudo_token_id)] = self.pad_token_id
-        raw_embeds = self.embeddings(queries_for_embedding)
-        dtype = self.model.model.language_model.encoder.layers[0].dtype
-        if dtype == torch.float32:
-            replace_embeds = self.prompt_encoder(enc_taskname=None)
-        else:
-            with torch.autocast(device_type="cuda", dtype=dtype):
-                replace_embeds = self.prompt_encoder(enc_taskname=None)
+    def forward(self, input_ids, attention_mask, token_type_ids):
+        if self.cfg.library == 'megatron':
+            hidden_states = self.bert_model(
+                input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask
+            )
+            if isinstance(hidden_states, tuple):
+                hidden_states = hidden_states[0]
+            logits = self.classifier(hidden_states=hidden_states)
+        elif self.cfg.library == 'huggingface':
+            output = self.nli_model(input_ids=input_ids, attention_mask=attention_mask)
+            logits = output['logits']
+        return logits
 
-        blocked_indices = queries == self.pseudo_token_id
-        raw_embeds = raw_embeds.clone().type(dtype)
-        # find the index to the psedo-tokens
-        index = blocked_indices.nonzero().reshape((bz, -1, 2))[:, :, 1][:, :, None]
-
-        _, seq, _ = index.shape
-        _, _, emb = raw_embeds.shape
-        index = index.expand(bz, seq, emb)
-
-        _, replace_seq, replace_emb = replace_embeds.shape
-        replace_embeds = replace_embeds.expand(bz, replace_seq, replace_emb)
-        # scatter the psedo-token embeddings to the raw embeddings
-        raw_embeds.scatter_(1, index, replace_embeds)
-        # slow version of above scatter logics
-        # for bidx in range(bz):
-        #     position = blocked_indices[bidx].nonzero()[:, 0]
-        #     for i in range(len(position)):
-        #         raw_embeds[bidx, position[i], :] = replace_embeds[bidx, i, :]
-
-        return raw_embeds
-
-    def get_query(self, x_h, prompt_tokens, x_t=None):
-        max_seq_len = self.model._cfg.encoder_seq_length
-        input_token_ids = self.tokenizer.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenizer.tokenize(' ' + x_h))
-        cut = 0
-        if len(input_token_ids) + sum(self.template) > max_seq_len:
-            logging.warning("Input sequence is longer than the LM model max seq, will cut it off to fit")
-            cut = len(input_token_ids) + sum(self.template) - max_seq_len
-        return [
-            prompt_tokens * self.template[0]
-            + input_token_ids[cut:]  # head entity
-            + prompt_tokens * self.template[1]
-            + (
-                self.tokenizer.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(' ' + x_t))
-                if x_t is not None
-                else []
+    def setup_training_data(self, train_data_config: Optional[DictConfig]):
+        if not train_data_config:
+            logging.info(
+                f"Dataloader config or file_name for the training set is missing, so no data loader for test is created!"
             )
-        ]
+            self._test_dl = None
+            return
+        self._train_dl = self._setup_dataloader_from_config(train_data_config, "train")
 
-    def get_ground_truth_labels(self, batch_size, label_ids):
-        returned_label = []
-        for i in range(batch_size):
-            returned_label.append(self.allowed_vocab[label_ids[i, 0].item()])
-        return torch.tensor(returned_label).to(self.device)
-
-    def get_prediction(self, batch_size, label_position, logits):
-        top10 = []
-        returned_pred = []
-        for i in range(batch_size):
-            array = []
-            for allowed_id in self.allowed_vocab_ids:
-                pred_p = logits[i, label_position[i, 0], allowed_id]
-                array.append((pred_p, allowed_id))
-            sorted_array = sorted(array, key=lambda x: x[0], reverse=True)
-            pred = sorted_array[0][1]
-            returned_pred.append(self.allowed_vocab[pred])
-        return top10, torch.tensor(returned_pred).to(self.device)
-
-    def get_encoder_input(self, sentences):
-        batch_size = len(sentences)
-        # construct query ids
-        prompt_tokens = [self.pseudo_token_id]
-
-        queries = [torch.LongTensor(self.get_query(sentences[i], prompt_tokens)).squeeze(0) for i in range(batch_size)]
-        queries = pad_sequence(queries, True, padding_value=self.pad_token_id).long().to(self.device)
-
-        # attention_mask indicates the boundary of attention
-        attention_mask = queries != self.pad_token_id
-        # get embedded input
-        inputs_embeds = self.embed_input(queries)
-
-        bz, seq_len, _ = inputs_embeds.shape
-
-        # get the GPT causal mask
-        causal_mask = torch.tril(torch.ones((bz, seq_len, seq_len), device=self.device)).view(bz, 1, seq_len, seq_len)
-        # combine the attention_mask and causal_mask
-        r = causal_mask.permute((1, 2, 0, 3)) * attention_mask.int()
-        new_atten = r.permute((2, 0, 1, 3))
-        # convert it to the boolean
-        new_atten = new_atten < 0.5
-
-        # calculate the position embedding based on the seq_len
-        position_ids = torch.arange(seq_len, dtype=torch.long, device=self.device)
-        position_ids = position_ids.unsqueeze(0).expand_as(inputs_embeds[:, :, 0])
-        position_embeddings = self.model.model.language_model.embedding.position_embeddings(position_ids)
-
-        # get the final input for encoder
-        encoder_input = inputs_embeds + position_embeddings
-
-        # calculate the position of the output token
-        label_position = (attention_mask.long().sum(dim=1) - 1).unsqueeze(1)
-        return encoder_input, new_atten, label_position
-
-    def get_label_input(self, labels, label_position, seq_len):
-        batch_size, _ = label_position.shape
-        x_ts = [token_wrapper(x_t) for x_t in labels]
-
-        # construct label ids
-        label_ids = (
-            torch.LongTensor(self.tokenizer.tokenizer.convert_tokens_to_ids(x_ts))
-            .reshape((batch_size, -1))
-            .to(self.device)
-        )
-        labels = torch.zeros(batch_size, seq_len).to(self.device).fill_(SMALL_LOGITS).long()  # bz * seq_len
-        labels = labels.scatter_(1, label_position, label_ids)
-        return labels, label_ids
-
-    def forward_eval(self, sentences):
-        encoder_input, new_atten, label_position = self.get_encoder_input(sentences)
-        batch_size, _, seq_len, _ = new_atten.shape
-
-        # workaround to do auto-cast
-        # get the LM dtype
-        dtype = self.model.model.language_model.encoder.layers[0].dtype
-
-        if dtype == torch.float32:
-            output = self.model.model(
-                None, None, encoder_input=encoder_input.to(self.device), attention_mask=new_atten.to(self.device)
+        # calculate the class weights to be used in the loss function
+        if self.cfg.dataset.class_balancing == 'weighted_loss':
+            self.class_weights = calc_class_weights_from_dataloader(
+                self._train_dl, self.cfg.dataset.num_classes, self.cfg.dataset.data_dir
             )
         else:
-            with torch.autocast(device_type="cuda", dtype=dtype):
-                output = self.model.model(
-                    None, None, encoder_input=encoder_input.to(self.device), attention_mask=new_atten.to(self.device)
-                )
-        logits = output
+            self.class_weights = None
+        # we need to create/update the loss module by using the weights calculated from the training data
+        self.create_loss_module()
 
-        _, returned_pred = self.get_prediction(batch_size, label_position.to(self.device), logits)
-        return returned_pred
-
-    @typecheck()
-    def forward(self, sentences, labels):
-        encoder_input, new_atten, label_position = self.get_encoder_input(sentences)
-        batch_size, _, seq_len, _ = new_atten.shape
-        labels_input, label_ids = self.get_label_input(labels, label_position, seq_len)
-        # workaround to do auto-cast
-        # get the LM dtype
-        dtype = self.model.model.language_model.encoder.layers[0].dtype
-
-        if dtype == torch.float32:
-            output = self.model.model(
-                None, None, encoder_input=encoder_input, attention_mask=new_atten, labels=labels_input
+    def setup_validation_data(self, val_data_config: Optional[DictConfig]):
+        if not val_data_config:
+            logging.info(
+                f"Dataloader config or file_path for the validation data set is missing, so no data loader for test is created!"
             )
-        else:
-            with torch.autocast(device_type="cuda", dtype=dtype):
-                output = self.model.model(
-                    None, None, encoder_input=encoder_input, attention_mask=new_atten, labels=labels_input
-                )
-        loss, logits = output
-        floss = (loss[(labels_input != SMALL_LOGITS)]).mean()
+            self._test_dl = None
+            return
+        self._validation_dl = self._setup_dataloader_from_config(val_data_config, "dev")
 
-        _, returned_pred = self.get_prediction(batch_size, label_position, logits)
-        returned_label = self.get_ground_truth_labels(batch_size, label_ids)
-        return floss, returned_pred, returned_label
+    def setup_test_data(self, test_data_config: Optional[DictConfig]):
+        if not test_data_config:
+            logging.info(
+                f"Dataloader config or file_path for the test data set is missing, so no data loader for test is created!"
+            )
+            self._test_dl = None
+            return
+        self._test_dl = self._setup_dataloader_from_config(test_data_config, "test")
 
-    def training_step(self, batch, batch_idx):
+    def _setup_infer_dataloader(
+        self,
+        queries: List[str],
+        candidate_labels: List[str],
+        hypothesis_template=str,
+        batch_size=1,
+        max_seq_length: int = -1,
+    ) -> 'torch.utils.data.DataLoader':
         """
-        Lightning calls this inside the training loop with the data from the training dataloader
-        passed in as `batch`.
+        Setup method for inference data loader. Here the premise-hypothesis pairs are made from queries and candidate labels.
+
+        Args:
+            queries: the queries to classify
+            candidate_labels: strings to be used as labels
+            hypothesis_template: the template used to turn each label into an NLI-style hypothesis. Must include a {}
+                or similar syntax for the candidate label to be inserted.
+            batch_size: batch size to use during inference
+            max_seq_length: maximum length of queries, default is -1 for no limit
+        Returns:
+            A pytorch DataLoader.
         """
-        # forward pass
-        sentences, labels = batch
-        train_loss, _, _ = self.forward(sentences=sentences, labels=labels)
-
-        lr = self._optimizer.param_groups[0]['lr']
-        self.log('train_loss', train_loss)
-        self.log('lr', lr, prog_bar=True)
+        dataset = ZeroShotIntentInferenceDataset(
+            queries=queries,
+            candidate_labels=candidate_labels,
+            tokenizer=self.tokenizer,
+            max_seq_length=max_seq_length,
+            hypothesis_template=hypothesis_template,
+        )
 
-        return {
-            'loss': train_loss,
-            'lr': lr,
-        }
+        return torch.utils.data.DataLoader(
+            dataset=dataset,
+            batch_size=batch_size,
+            shuffle=False,
+            num_workers=2,
+            pin_memory=False,
+            drop_last=False,
+            collate_fn=dataset.collate_fn,
+        )
 
     def validation_step(self, batch, batch_idx):
         """
         Lightning calls this inside the validation loop with the data from the validation dataloader
         passed in as `batch`.
         """
-        sentences, labels = batch
-        val_loss, preds, gt_labels = self.forward(sentences=sentences, labels=labels)
+        input_ids, input_type_ids, input_mask, labels = batch
+        logits = self.forward(input_ids=input_ids, token_type_ids=input_type_ids, attention_mask=input_mask)
 
-        hit = 0
-        for pred, gt_label in zip(preds, gt_labels):
-            if pred == gt_label:
-                hit += 1
+        val_loss = self.loss(logits=logits, labels=labels)
 
-        tp, fn, fp, _ = self.classification_report(preds, gt_labels)
+        preds = torch.argmax(logits, axis=-1)
 
-        return {'val_loss': val_loss, 'tp': tp, 'fn': fn, 'fp': fp, 'hit': hit}
+        tp, fn, fp, _ = self.classification_report(preds, labels)
+
+        return {
+            'val_loss': val_loss,
+            'tp': tp,
+            'fn': fn,
+            'fp': fp,
+            'logits': logits,
+            'input_ids': input_ids,
+            'labels': labels,
+        }
 
     def validation_epoch_end(self, outputs):
         """
-        Called at the end of validation to aggregate outputs.
-        :param outputs: list of individual outputs of each validation step.
+        Get metrics based on the candidate label with the highest predicted likelihood and the ground truth label for intent
         """
-        if not outputs:
-            return {}
-        if self.trainer.testing:
-            prefix = 'test'
-        else:
-            prefix = 'val'
-
-        avg_loss = torch.stack([x[f'val_loss'] for x in outputs]).mean()
-
-        total_hit = sum([x[f'hit'] for x in outputs])
-        # calculate metrics and classification report
-        precision, recall, f1, report = self.classification_report.compute()
+        output_logits = torch.cat([output['logits'] for output in outputs], dim=0)
+        output_input_ids = torch.cat([output['input_ids'] for output in outputs], dim=0)
+        output_labels = torch.cat([output['labels'] for output in outputs], dim=0)
+
+        if self.cfg.library == 'huggingface':
+            entail_logits = output_logits[..., 2]
+            decoded_input_ids = [self.tokenizer.decode(output_input_ids[i]) for i in range(len(output_input_ids))]
+            utterance_candidate_pairs = [i.split(self.tokenizer.sep_token) for i in decoded_input_ids]
+            utterances = [
+                i[0].replace(self.tokenizer.bos_token, '').replace(self.tokenizer.eos_token, '')
+                for i in utterance_candidate_pairs
+            ]
+
+        elif self.cfg.library == 'megatron':
+            entail_logits = output_logits[..., 1]
+            decoded_input_ids = [
+                self.tokenizer.tokenizer.decode(output_input_ids[i]) for i in range(len(output_input_ids))
+            ]
+            utterance_candidate_pairs = [i.split(self.tokenizer.tokenizer.sep_token) for i in decoded_input_ids]
+            utterances = [
+                i[0].replace(self.tokenizer.tokenizer.bos_token, '').replace(self.tokenizer.tokenizer.eos_token, '')
+                for i in utterance_candidate_pairs
+            ]
+
+        # account for uncased tokenization
+        candidates = [
+            i[1]
+            .replace(self.cfg.dataset.prompt_template.lower(), '')
+            .replace(self.cfg.dataset.prompt_template, '')
+            .strip()
+            for i in utterance_candidate_pairs
+        ]
+        utterance_to_idx = defaultdict(list)
+        for idx, utterance in enumerate(utterances):
+            utterance_to_idx[utterance].append(idx)
+
+        predicted_labels = []
+        ground_truth_labels = []
+        utterances = []
+        for utterance, idxs in utterance_to_idx.items():
+            utterance_candidates = [candidates[idx] for idx in idxs]
+            logits = [entail_logits[idx].item() for idx in idxs]
+            labels = [output_labels[idx].item() for idx in idxs]
+            correct_candidate = utterance_candidates[np.argmax(labels)]
+            predicted_candidate = utterance_candidates[np.argmax(logits)]
+            predicted_labels.append(predicted_candidate)
+            ground_truth_labels.append(correct_candidate)
+            utterances.append(utterance)
 
-        total_data = torch.sum(self.classification_report.num_examples_per_class)
-        accuracy = total_hit / total_data.item()
-        logging.info(f'{prefix}_report: {report}')
-        logging.info(f'{total_hit} correct out of {total_data}, accuracy: {accuracy*100:.2f}')
-        self.log(f'{prefix}_loss', avg_loss, prog_bar=True)
-        self.log(f'{prefix}_accuracy', accuracy)
-        self.log(f'{prefix}_precision', precision)
-        self.log(f'{prefix}_f1', f1)
-        self.log(f'{prefix}_recall', recall)
+        os.makedirs(self.cfg.dataset.dialogues_example_dir, exist_ok=True)
+        filename = os.path.join(self.cfg.dataset.dialogues_example_dir, "test_predictions.jsonl")
 
-        self.classification_report.reset()
+        DialogueGenerationMetrics.save_predictions(
+            filename, predicted_labels, ground_truth_labels, utterances,
+        )
 
-    def test_step(self, batch, batch_idx):
-        """
-        Lightning calls this inside the test loop with the data from the test dataloader
-        passed in as `batch`.
-        """
-        return self.validation_step(batch, batch_idx)
+        label_to_ids = {label: idx for idx, label in enumerate(list(set(predicted_labels + ground_truth_labels)))}
+        self.classification_report = ClassificationReport(
+            num_classes=len(label_to_ids), mode='micro', label_ids=label_to_ids, dist_sync_on_step=True
+        ).to(output_logits[0].device)
+        predicted_label_ids = torch.tensor([label_to_ids[label] for label in predicted_labels]).to(
+            output_logits[0].device
+        )
+        ground_truth_label_ids = torch.tensor([label_to_ids[label] for label in ground_truth_labels]).to(
+            output_logits[0].device
+        )
 
-    def test_epoch_end(self, outputs):
-        """
-        Called at the end of test to aggregate outputs.
-        :param outputs: list of individual outputs of each test step.
-        """
-        return self.validation_epoch_end(outputs)
+        tp, fn, fp, _ = self.classification_report(predicted_label_ids, ground_truth_label_ids)
+        precision, recall, f1, report = self.classification_report.compute()
+        label_acc = np.mean([int(predicted_labels[i] == ground_truth_labels[i]) for i in range(len(predicted_labels))])
 
-    def setup_training_data(self, train_data_config: Optional[DictConfig]):
-        if not train_data_config or not train_data_config.file_path:
-            logging.info(
-                f"Dataloader config or file_path for the train is missing, so no data loader for test is created!"
-            )
-            self._test_dl = None
-            return
-        self._train_dl = self._setup_dataloader_from_config(cfg=train_data_config)
+        avg_loss = torch.stack([x[f'val_loss'] for x in outputs]).mean()
 
-    def setup_validation_data(self, val_data_config: Optional[DictConfig]):
-        if not val_data_config or not val_data_config.file_path:
-            logging.info(
-                f"Dataloader config or file_path for the validation is missing, so no data loader for test is created!"
-            )
-            self._test_dl = None
-            return
-        self._validation_dl = self._setup_dataloader_from_config(cfg=val_data_config)
+        logging.info(report)
 
-    def setup_test_data(self, test_data_config: Optional[DictConfig]):
-        if not test_data_config or not test_data_config.file_path:
-            logging.info(
-                f"Dataloader config or file_path for the test is missing, so no data loader for test is created!"
-            )
-            self._test_dl = None
-            return
-        self._test_dl = self._setup_dataloader_from_config(cfg=test_data_config)
+        self.log('unified_precision', precision)
+        self.log('unified_f1', f1)
+        self.log('unified_recall', recall)
+        self.log('unfied_accuracy', label_acc * 100)
+        self.log('val_loss', avg_loss, prog_bar=True)
 
-    def _setup_dataloader_from_config(self, cfg: Dict) -> 'torch.utils.data.DataLoader':
-        input_file = cfg.file_path
-        if not os.path.exists(input_file):
-            raise FileNotFoundError(
-                f'{input_file} not found! The data should be be stored in TAB-separated files \n\
-                "validation_ds.file_path" and "train_ds.file_path" for train and evaluation respectively. \n\
-                Each line of the files contains text sequences, where words are separated with spaces. \n\
-                The label of the example is separated with TAB at the end of each line. \n\
-                Each line of the files should follow the format: \n\
-                [WORD][SPACE][WORD][SPACE][WORD][...][TAB][LABEL]'
-            )
+        self.classification_report.reset()
 
-        dataset = PTuneTextClassificationDataset(input_file)
+    def predict(
+        self,
+        queries: Union[str, List[str]],
+        candidate_labels: Union[str, List[str]],
+        hypothesis_template='This example is {}.',
+        batch_size=1,
+        multi_label=True,
+        entailment_idx=1,
+        contradiction_idx=0,
+    ) -> List[Dict]:
+
+        """
+        Given a list of queries and a list of candidate labels, return a ranked list of labels and scores for each query.
+
+        Example usage:
+            queries = ["I'd like a veggie burger, fries, and a coke", "Turn off the lights in the living room",]
+            candidate_labels = ["Food order", "Change lighting"]
+            model.predict(queries, candidate_labels)
+
+        Example output:
+            [{'sentence': "I'd like a veggie burger, fries, and a coke",
+              'labels': ['Food order', 'Change lighting'],
+              'scores': [0.8557153344154358, 0.12036784738302231]},
+             {'sentence': 'Turn off the lights in the living room',
+              'labels': ['Change lighting', 'Food order'],
+              'scores': [0.8506497144699097, 0.06594637036323547]}]
 
-        return torch.utils.data.DataLoader(
-            dataset=dataset,
-            batch_size=cfg.batch_size,
-            shuffle=cfg.shuffle,
-            num_workers=cfg.get("num_workers", 0),
-            pin_memory=cfg.get("pin_memory", False),
-            drop_last=cfg.get("drop_last", False),
-            collate_fn=dataset.collate_fn,
-        )
 
-    @torch.no_grad()
-    def classifytext(self, queries: List[str], batch_size: int = 1, prompt: str = 'Sentiment') -> List[int]:
-        """
-        Get prediction for the queries
         Args:
-            queries: text sequences
-            batch_size: batch size to use during inference
-            prompt: the prompt string appended at the end of your input sentence
+            queries: the query or list of queries to classify
+            candidate_labels: string or list of strings to be used as labels
+            hypothesis_template: the template used to turn each label into an NLI-style hypothesis. Must include a {}
+            or similar syntax for the candidate label to be inserted.
+            batch_size: the batch size to use for inference.
+            multi_label: whether or not multiple candidate labels can be true. If False, the scores are normalized
+            such that all class probabilities sum to 1. If True, the labels are
+            considered independent and probabilities are normalized for each candidate by doing a softmax of
+            the entailment score vs. the contradiction score.
+            entailment_idx: the index of the "entailment" class in the trained model; models trained on MNLI
+             using NeMo's glue_benchmark.py or zero_shot_intent_model.py use an index of 1 by default.
+            contradiction_idx: the index of the "contradiction" class in the trained model; models trained on MNLI
+             using NeMo's glue_benchmark.py or zero_shot_intent_model.py use an index of 0 by default.
+
         Returns:
-            all_preds: model predictions
+            list of dictionaries; one dict per input query. Each dict has keys "sentence", "labels", "scores".
+            labels and scores are parallel lists (with each score corresponding to the label at the same index),
+                 sorted from highest to lowest score.
+
         """
-        # store predictions for all queries in a single list
-        all_preds = []
+        if not queries:
+            raise ValueError("No queries were passed for classification!")
+        if not candidate_labels:
+            raise ValueError("No candidate labels were provided!")
+
+        queries = [queries] if isinstance(queries, str) else queries
+        candidate_labels = [candidate_labels] if isinstance(candidate_labels, str) else candidate_labels
+
+        if len(candidate_labels) == 1:
+            multi_label = True
+
         mode = self.training
         try:
+            device = 'cuda' if torch.cuda.is_available() else 'cpu'
+
             # Switch model to evaluation mode
             self.eval()
-            logging_level = logging.get_verbosity()
-            logging.set_verbosity(logging.WARNING)
-            dataloader_cfg = {"batch_size": batch_size, "num_workers": 3, "pin_memory": False}
-            infer_datalayer = self._setup_infer_dataloader(dataloader_cfg, queries, prompt)
-            for i, batch in enumerate(infer_datalayer):
-                sentences, _ = batch
-                preds = self.forward_eval(sentences)
-                all_preds.extend([self.id_to_label[i.item()] for i in preds])
+            self.to(device)
+
+            infer_datalayer = self._setup_infer_dataloader(
+                queries,
+                candidate_labels,
+                hypothesis_template=hypothesis_template,
+                batch_size=batch_size,
+                max_seq_length=self._cfg.dataset.max_seq_length,
+            )
+
+            all_batch_logits = []
+            for batch in infer_datalayer:
+                input_ids, input_type_ids, input_mask, _ = batch
+
+                logits = self.forward(
+                    input_ids=input_ids.to(device),
+                    token_type_ids=input_type_ids.to(device),
+                    attention_mask=input_mask.to(device),
+                )
+                all_batch_logits.append(logits.detach().cpu().numpy())
+
+            all_logits = np.concatenate(all_batch_logits)
+            outputs = all_logits.reshape((len(queries), len(candidate_labels), -1))
+
+            if not multi_label:
+                # softmax the "entailment" logits over all candidate labels
+                entail_logits = outputs[..., entailment_idx]
+                scores = np.exp(entail_logits) / np.exp(entail_logits).sum(-1, keepdims=True)
+            else:
+                # softmax over the entailment vs. contradiction dim for each label independently
+                entail_contr_logits = outputs[..., [contradiction_idx, entailment_idx]]
+                scores = np.exp(entail_contr_logits) / np.exp(entail_contr_logits).sum(-1, keepdims=True)
+                scores = scores[..., 1]
+
+            result = []
+            for i in range(len(queries)):
+                sorted_idxs = list(reversed(scores[i].argsort()))
+                result.append(
+                    {
+                        "sentence": queries[i],
+                        "labels": [candidate_labels[j] for j in sorted_idxs],
+                        "scores": scores[i][sorted_idxs].tolist(),
+                    }
+                )
+
         finally:
             # set mode back to its original value
             self.train(mode=mode)
-            logging.set_verbosity(logging_level)
-        return all_preds
+        return result
 
-    def _setup_infer_dataloader(self, cfg: Dict, queries: List[str], prompt: str) -> 'torch.utils.data.DataLoader':
+    @classmethod
+    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
         """
-        Setup function for a infer data loader.
+        This method returns a list of pre-trained models which can be instantiated directly from NVIDIA's NGC cloud.
 
-        Args:
-            cfg: config dictionary containing data loader params like batch_size, num_workers and pin_memory
-            queries: text
-            prompt: the prompt string appended at the end of your input sentence
         Returns:
-            A pytorch DataLoader.
+            List of available pre-trained models.
         """
-        dataset = PTuneTextClassificationDataset(None, queries, prompt)
-        return torch.utils.data.DataLoader(
-            dataset=dataset,
-            batch_size=cfg["batch_size"],
-            shuffle=False,
-            num_workers=cfg.get("num_workers", 0),
-            pin_memory=cfg.get("pin_memory", False),
-            drop_last=False,
-            collate_fn=dataset.collate_fn,
+        result = []
+        result.append(
+            PretrainedModelInfo(
+                pretrained_model_name="zeroshotintent_en_bert_base_uncased",
+                location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/zeroshotintent_en_bert_base_uncased/versions/1.4.1/files/zeroshotintent_en_bert_base_uncased.nemo",
+                description="DialogueZeroShotIntentModel trained by fine tuning BERT-base-uncased on the MNLI (Multi-Genre Natural Language Inference) dataset, which achieves an accuracy of 84.9% and 84.8% on the matched and mismatched dev sets, respectively.",
+            )
         )
-
-    @classmethod
-    def list_available_models(cls) -> Optional[Dict[str, str]]:
-        pass
+        result.append(
+            PretrainedModelInfo(
+                pretrained_model_name="zeroshotintent_en_megatron_uncased",
+                location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/zeroshotintent_en_megatron_uncased/versions/1.4.1/files/zeroshotintent_en_megatron_uncased.nemo",
+                description="DialogueZeroShotIntentModel trained by fine tuning Megatron-BERT-345m=M-uncased on the MNLI (Multi-Genre Natural Language Inference) dataset, which achieves an accuracy of 90.0% and 89.9% on the matched and mismatched dev sets, respectively",
+            )
+        )
+        return result
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/text_classification/text_classification_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/text_classification/text_classification_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/__init__.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,21 +1,22 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.nlp.models.token_classification.punctuation_capitalization_config import (
-    PunctuationCapitalizationModelConfig,
+from nemo.collections.nlp.data.dialogue.data_processor.sgd_data_processor import DialogueSGDDataProcessor
+from nemo.collections.nlp.data.dialogue.dataset import (
+    DialogueBERTDataset,
+    DialogueGPTClassificationDataset,
+    DialogueSGDBERTDataset,
+    DialogueZeroShotIntentDataset,
 )
-from nemo.collections.nlp.models.token_classification.punctuation_capitalization_model import (
-    PunctuationCapitalizationModel,
-)
-from nemo.collections.nlp.models.token_classification.token_classification_model import TokenClassificationModel
+from nemo.collections.nlp.data.dialogue.sgd.schema import Schema
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/punctuation_capitalization_config.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/punctuation_capitalization_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/punctuation_capitalization_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/punctuation_capitalization_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,14 +9,15 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import copy
+import warnings
 from math import ceil
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import numpy as np
 import torch
 from omegaconf import DictConfig, OmegaConf
@@ -634,24 +635,24 @@
             if label_ids is not None and label_ids[pad_label] != 0:
                 raise ValueError(
                     f"Pad label '{pad_label}' has non zero id {label_ids[pad_label]} in "
                     f"`model.common_dataset_parameters.{parameter_name}`."
                 )
 
     def _extract_label_vocab_files_from_config(self) -> Tuple[Optional[Path], Optional[Path]]:
-        if self._cfg.common_dataset_parameters.label_vocab_dir is None:
-            if self._is_model_being_restored():
-                punct_label_vocab_file = self._cfg.class_labels.punct_labels_file
-                capit_label_vocab_file = self._cfg.class_labels.capit_labels_file
-            else:
-                punct_label_vocab_file, capit_label_vocab_file = None, None
+        if self._is_model_being_restored():
+            punct_label_vocab_file = self._cfg.class_labels.punct_labels_file
+            capit_label_vocab_file = self._cfg.class_labels.capit_labels_file
         else:
-            label_vocab_dir = Path(self._cfg.common_dataset_parameters.label_vocab_dir).expanduser()
-            punct_label_vocab_file = label_vocab_dir / self._cfg.class_labels.punct_labels_file
-            capit_label_vocab_file = label_vocab_dir / self._cfg.class_labels.capit_labels_file
+            if self._cfg.common_dataset_parameters.label_vocab_dir is None:
+                punct_label_vocab_file, capit_label_vocab_file = None, None
+            else:
+                label_vocab_dir = Path(self._cfg.common_dataset_parameters.label_vocab_dir).expanduser()
+                punct_label_vocab_file = label_vocab_dir / self._cfg.class_labels.punct_labels_file
+                capit_label_vocab_file = label_vocab_dir / self._cfg.class_labels.capit_labels_file
         return punct_label_vocab_file, capit_label_vocab_file
 
     def _set_label_ids(self) -> None:
         """
         Set model attributes ``punct_label_ids`` and ``capit_label_ids`` based on label ids passed in config
         item ``common_dataset_parameters``.
 
@@ -766,27 +767,62 @@
                 punct_label_vocab_file, capit_label_vocab_file = self._extract_label_vocab_files_from_config()
                 label_kwargs = {
                     'punct_label_ids': self._cfg.common_dataset_parameters.punct_label_ids,
                     'capit_label_ids': self._cfg.common_dataset_parameters.capit_label_ids,
                     'punct_label_vocab_file': punct_label_vocab_file,
                     'capit_label_vocab_file': capit_label_vocab_file,
                 }
+            if train:
+                number_of_batches_is_multiple_of = 1
+                if self._trainer is None:
+                    warnings.warn(
+                        'A model attribute `trainer` is not set before training dataset setting. If training is '
+                        'resumed from checkpoint, then current epoch data loading can be distorted: some batches '
+                        'may be processed several times and some can be not processed at all. `trainer.current_epoch`'
+                        ' is used as random seed for shuffling batches. Now 0 will be used. If the '
+                        'checkpoint was created not during initial epoch a shuffling of the dataset will '
+                        'be different. You may try use `exp_manager()` function and '
+                        '`PunctuationCapitalizationModel.set_trainer()` method before '
+                        '`PunctuationCapitalizationModel.setup_training_data()` method.'
+                    )
+                    batch_shuffling_random_seed = 0
+                else:
+                    batch_shuffling_random_seed = self._trainer.current_epoch
+            else:
+                batch_shuffling_random_seed = 0
+                if self._trainer is None:
+                    warnings.warn(
+                        'A model attribute `trainer` is not set before test or validation dataset setting. If more '
+                        'than 1 GPU is used for testing, then some examples may be tested several times because '
+                        'number of batches may be not evenly divisible by number of processes. This leads to '
+                        'distortion of metrics. See more in description of `number_of_batches_is_multiple_of` '
+                        'parameter of class `BertPunctuationCapitalizationDataset` initializer and '
+                        'https://pytorch.org/docs/stable/data.html#multi-process-data-loading. You may try to use '
+                        '`PunctuationCapitalizationModel.set_trainer()` method before '
+                        '`PunctuationCapitalizationModel.setup_validation_data()` and '
+                        '`PunctuationCapitalizationModel.setup_test_data()` methods.'
+                    )
+                    number_of_batches_is_multiple_of = 1
+                else:
+                    number_of_batches_is_multiple_of = self._trainer.num_nodes * self._trainer.num_devices
             dataset = BertPunctuationCapitalizationDataset(
                 tokenizer=self.tokenizer,
                 text_file=text_file,
                 labels_file=labels_file,
                 pad_label=self._cfg.common_dataset_parameters.pad_label,
                 **label_kwargs,
                 max_seq_length=cfg.max_seq_length,
                 ignore_extra_tokens=self._cfg.common_dataset_parameters.ignore_extra_tokens,
                 ignore_start_end=self._cfg.common_dataset_parameters.ignore_start_end,
                 use_cache=cfg.use_cache,
                 num_samples=cfg.num_samples,
                 tokens_in_batch=cfg.tokens_in_batch,
                 n_jobs=cfg.n_jobs,
+                number_of_batches_is_multiple_of=number_of_batches_is_multiple_of,
+                batch_shuffling_random_seed=batch_shuffling_random_seed,
                 verbose=cfg.verbose,
                 get_label_frequencies=cfg.get_label_frequences,
                 cache_dir=cfg.cache_dir,
                 label_info_save_dir=cfg.label_info_save_dir,
             )
         if cfg.shuffle and cfg.use_tarred_dataset:
             logging.warning(f"Shuffling in dataloader is not supported for tarred dataset.")
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/token_classification/token_classification_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/token_classification/token_classification_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/zero_shot_intent_recognition/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/zero_shot_intent_recognition/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/models/zero_shot_intent_recognition/zero_shot_intent_model.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/zero_shot_intent_recognition/zero_shot_intent_model.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -15,14 +15,16 @@
 
 from nemo.collections.nlp.modules.common import (
     AlbertEncoder,
     BertEncoder,
     BertModule,
     CamembertEncoder,
     DistilBertEncoder,
+    PromptEncoder,
+    PromptTable,
     RobertaEncoder,
     SequenceClassifier,
     SequenceRegression,
     SequenceTokenClassifier,
     get_lm_model,
     get_pretrained_lm_models_list,
     get_tokenizer,
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -19,12 +19,14 @@
     AlbertEncoder,
     BertEncoder,
     CamembertEncoder,
     DistilBertEncoder,
     RobertaEncoder,
 )
 from nemo.collections.nlp.modules.common.lm_utils import get_lm_model, get_pretrained_lm_models_list
+from nemo.collections.nlp.modules.common.prompt_encoder import PromptEncoder
+from nemo.collections.nlp.modules.common.prompt_table import PromptTable, VirtualPromptSource, VirtualPromptStyle
 from nemo.collections.nlp.modules.common.sequence_classifier import SequenceClassifier
 from nemo.collections.nlp.modules.common.sequence_regression import SequenceRegression
 from nemo.collections.nlp.modules.common.sequence_token_classifier import SequenceTokenClassifier
 from nemo.collections.nlp.modules.common.token_classifier import BertPretrainingTokenClassifier, TokenClassifier
 from nemo.collections.nlp.modules.common.tokenizer_utils import get_tokenizer, get_tokenizer_list
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/bert_module.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/bert_module.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/classifier.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/classifier.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/decoder_module.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/decoder_module.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/encoder_module.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/encoder_module.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/gpt_module.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/gpt_module.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/albert.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/albert.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/bert.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/bert.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/camembert.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/camembert.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/distilbert.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/distilbert.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/gpt2.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/gpt2.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/huggingface_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/huggingface_decoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/huggingface_encoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/huggingface_encoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/huggingface_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/huggingface_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -84,15 +84,17 @@
 
 VOCAB_FILE_NAME = {
     'AlbertTokenizer': "spiece.model",
     'RobertaTokenizer': "vocab.json",
     'BertTokenizer': "vocab.txt",
     'DistilBertTokenizer': "vocab.txt",
     'CamembertTokenizer': "sentencepiece.bpe.model",
-    "GPT2Tokenizer": "vocab.json",
+    'GPT2Tokenizer': "vocab.json",
+    'T5Tokenizer': "spiece.model",
+    "BartTokenizer": "vocab.json",
 }
 
 
 def get_huggingface_lm_model(
     pretrained_model_name: str, config_dict: Optional[dict] = None, config_file: Optional[str] = None,
 ):
     """
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/huggingface/roberta.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/huggingface/roberta.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/lm_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/lm_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/clip_grads.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/clip_grads.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/fused_bias_dropout_add.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/fused_bias_dropout_add.py`

 * *Files 14% similar despite different names*

```diff
@@ -20,14 +20,23 @@
     from apex._autocast_utils import _cast_if_autocast_enabled
 
     HAVE_APEX = True
 except (ImportError, ModuleNotFoundError):
     HAVE_APEX = False
 
 
+def dropout_add(x, bias, residual, prob, training):
+    # type: (Tensor, None, Tensor, float, bool) -> Tensor
+    if bias is not None:
+        raise ValueError(f"bias is expected to be None when using the bias_dropout function.")
+    out = torch.nn.functional.dropout(x, p=prob, training=training)
+    out = residual + out
+    return out
+
+
 def bias_dropout_add(x, bias, residual, prob, training):
     # type: (Tensor, Tensor, Tensor, float, bool) -> Tensor
     out = torch.nn.functional.dropout(x + bias, p=prob, training=training)
     out = residual + out
     return out
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/fused_bias_gelu.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/fused_bias_gelu.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/fused_layer_norm.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/fused_layer_norm.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_decoders.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_encoders.py`

 * *Files 27% similar despite different names*

```diff
@@ -9,26 +9,20 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Transformer based language model."""
-import math
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import torch.nn.init as init
-
-from nemo.collections.nlp.modules.common.megatron.megatron_transformer_decoder import MegatronTransformerDecoderModule
-from nemo.collections.nlp.modules.common.megatron.module import MegatronModule
+from nemo.collections.nlp.modules.common.megatron.megatron_transformer_encoder import MegatronTransformerEncoderModule
+from nemo.collections.nlp.modules.common.megatron.retrieval_transformer import (
+    MegatronRetrievalTransformerEncoderModule,
+)
 from nemo.collections.nlp.modules.common.megatron.utils import (
     ApexGuardDefaults,
-    get_linear_layer,
     init_method_normal,
     scaled_init_method_normal,
 )
 
 try:
     from apex.transformer.enums import AttnMaskType, ModelType
 
@@ -37,49 +31,55 @@
     HAVE_APEX = False
     # fake missing classes with None attributes
     AttnMaskType = ApexGuardDefaults()
     ModelType = ApexGuardDefaults()
 
 __all__ = []
 
-AVAILABLE_DECODERS = ["transformer"]
+AVAILABLE_ENCODERS = ["transformer"]
 
 
-def get_decoder_model(
+def get_encoder_model(
     arch,
     hidden_size,
     ffn_hidden_size,
     num_layers,
     num_attention_heads,
     apply_query_key_layer_scaling=True,
     kv_channels=None,
     init_method=None,
     scaled_init_method=None,
-    add_decoder=False,
-    decoder_attn_mask_type=AttnMaskType.causal,
+    encoder_attn_mask_type=AttnMaskType.padding,
     pre_process=True,
     post_process=True,
     init_method_std=0.02,
     use_cpu_initialization=False,
     hidden_dropout=0.1,
     attention_dropout=0.1,
     precision=16,
     fp32_residual_connection=False,
     activations_checkpoint_method=None,
     activations_checkpoint_num_layers=1,
     layernorm_epsilon=1e-5,
     bias_gelu_fusion=True,
+    bias_dropout_add_fusion=True,
     masked_softmax_fusion=True,
     persist_layer_norm=False,
     openai_gelu=False,
     activation="gelu",
     onnx_safe=False,
+    bias=True,
+    normalization="layernorm",
+    headscale=False,
+    transformer_block_type="pre_ln",
     hidden_steps=-1,
     hidden_blocks=1,
     parent_model_type=ModelType.encoder_or_decoder,
+    layer_type=None,
+    chunk_size=64,
 ):
     """Build language model and return along with the key to save."""
 
     if kv_channels is None:
         assert (
             hidden_size % num_attention_heads == 0
         ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
@@ -88,40 +88,77 @@
     if init_method is None:
         init_method = init_method_normal(init_method_std)
 
     if scaled_init_method is None:
         scaled_init_method = scaled_init_method_normal(init_method_std, num_layers)
 
     if arch == "transformer":
-        # Language model.
-        decoder = MegatronTransformerDecoderModule(
+        # Language encoder.
+        encoder = MegatronTransformerEncoderModule(
+            init_method=init_method,
+            output_layer_init_method=scaled_init_method,
+            hidden_size=hidden_size,
+            num_layers=num_layers,
+            num_attention_heads=num_attention_heads,
+            apply_query_key_layer_scaling=apply_query_key_layer_scaling,
+            kv_channels=kv_channels,
+            ffn_hidden_size=ffn_hidden_size,
+            encoder_attn_mask_type=encoder_attn_mask_type,
+            pre_process=pre_process,
+            post_process=post_process,
+            use_cpu_initialization=use_cpu_initialization,
+            hidden_dropout=hidden_dropout,
+            attention_dropout=attention_dropout,
+            precision=precision,
+            fp32_residual_connection=fp32_residual_connection,
+            activations_checkpoint_method=activations_checkpoint_method,
+            activations_checkpoint_num_layers=activations_checkpoint_num_layers,
+            layernorm_epsilon=layernorm_epsilon,
+            bias_gelu_fusion=bias_gelu_fusion,
+            bias_dropout_add_fusion=bias_dropout_add_fusion,
+            masked_softmax_fusion=masked_softmax_fusion,
+            persist_layer_norm=persist_layer_norm,
+            openai_gelu=openai_gelu,
+            onnx_safe=onnx_safe,
+            activation=activation,
+            bias=bias,
+            normalization=normalization,
+            transformer_block_type=transformer_block_type,
+            headscale=headscale,
+            parent_model_type=parent_model_type,
+        )
+    elif arch == "retro":
+        encoder = MegatronRetrievalTransformerEncoderModule(
             init_method=init_method,
             output_layer_init_method=scaled_init_method,
             hidden_size=hidden_size,
             num_layers=num_layers,
             num_attention_heads=num_attention_heads,
             apply_query_key_layer_scaling=apply_query_key_layer_scaling,
             kv_channels=kv_channels,
+            layer_type=layer_type,
             ffn_hidden_size=ffn_hidden_size,
-            decoder_attn_mask_type=decoder_attn_mask_type,
             pre_process=pre_process,
             post_process=post_process,
             use_cpu_initialization=use_cpu_initialization,
             hidden_dropout=hidden_dropout,
             attention_dropout=attention_dropout,
             precision=precision,
             fp32_residual_connection=fp32_residual_connection,
             activations_checkpoint_method=activations_checkpoint_method,
             activations_checkpoint_num_layers=activations_checkpoint_num_layers,
             layernorm_epsilon=layernorm_epsilon,
             bias_gelu_fusion=bias_gelu_fusion,
+            bias_dropout_add_fusion=bias_dropout_add_fusion,
             masked_softmax_fusion=masked_softmax_fusion,
             persist_layer_norm=persist_layer_norm,
             openai_gelu=openai_gelu,
             onnx_safe=onnx_safe,
             activation=activation,
+            bias=bias,
             parent_model_type=parent_model_type,
+            chunk_size=chunk_size,
         )
     else:
-        raise ValueError(f"Unknown decoder arch = {arch}. Available decoder arch = {AVAILABLE_DECODERS}")
+        raise ValueError(f"Unknown encoder arch = {arch}. Available encoder arch = {AVAILABLE_ENCODERS}")
 
-    return decoder
+    return encoder
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_encoder_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_encoder_decoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_encoders.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_decoders.py`

 * *Files 24% similar despite different names*

```diff
@@ -9,26 +9,20 @@
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Transformer based language model."""
-import math
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import torch.nn.init as init
-
-from nemo.collections.nlp.modules.common.megatron.megatron_transformer_encoder import MegatronTransformerEncoderModule
-from nemo.collections.nlp.modules.common.megatron.module import MegatronModule
+from nemo.collections.nlp.modules.common.megatron.megatron_transformer_decoder import MegatronTransformerDecoderModule
+from nemo.collections.nlp.modules.common.megatron.retrieval_transformer import (
+    MegatronRetrievalTransformerDecoderModule,
+)
 from nemo.collections.nlp.modules.common.megatron.utils import (
     ApexGuardDefaults,
-    get_linear_layer,
     init_method_normal,
     scaled_init_method_normal,
 )
 
 try:
     from apex.transformer.enums import AttnMaskType, ModelType
 
@@ -37,48 +31,56 @@
     HAVE_APEX = False
     # fake missing classes with None attributes
     AttnMaskType = ApexGuardDefaults()
     ModelType = ApexGuardDefaults()
 
 __all__ = []
 
-AVAILABLE_ENCODERS = ["transformer"]
+AVAILABLE_DECODERS = ["transformer"]
 
 
-def get_encoder_model(
+def get_decoder_model(
     arch,
     hidden_size,
     ffn_hidden_size,
     num_layers,
     num_attention_heads,
     apply_query_key_layer_scaling=True,
     kv_channels=None,
     init_method=None,
     scaled_init_method=None,
-    encoder_attn_mask_type=AttnMaskType.padding,
+    add_decoder=False,
+    decoder_attn_mask_type=AttnMaskType.causal,
     pre_process=True,
     post_process=True,
     init_method_std=0.02,
     use_cpu_initialization=False,
     hidden_dropout=0.1,
     attention_dropout=0.1,
     precision=16,
     fp32_residual_connection=False,
     activations_checkpoint_method=None,
     activations_checkpoint_num_layers=1,
     layernorm_epsilon=1e-5,
     bias_gelu_fusion=True,
+    bias_dropout_add_fusion=True,
     masked_softmax_fusion=True,
     persist_layer_norm=False,
     openai_gelu=False,
     activation="gelu",
     onnx_safe=False,
+    bias=True,
+    normalization="layernorm",
+    headscale=False,
+    transformer_block_type="pre_ln",
     hidden_steps=-1,
     hidden_blocks=1,
     parent_model_type=ModelType.encoder_or_decoder,
+    layer_type=None,
+    chunk_size=64,
 ):
     """Build language model and return along with the key to save."""
 
     if kv_channels is None:
         assert (
             hidden_size % num_attention_heads == 0
         ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
@@ -87,40 +89,77 @@
     if init_method is None:
         init_method = init_method_normal(init_method_std)
 
     if scaled_init_method is None:
         scaled_init_method = scaled_init_method_normal(init_method_std, num_layers)
 
     if arch == "transformer":
-        # Language encoder.
-        encoder = MegatronTransformerEncoderModule(
+        # Language model.
+        decoder = MegatronTransformerDecoderModule(
+            init_method=init_method,
+            output_layer_init_method=scaled_init_method,
+            hidden_size=hidden_size,
+            num_layers=num_layers,
+            num_attention_heads=num_attention_heads,
+            apply_query_key_layer_scaling=apply_query_key_layer_scaling,
+            kv_channels=kv_channels,
+            ffn_hidden_size=ffn_hidden_size,
+            decoder_attn_mask_type=decoder_attn_mask_type,
+            pre_process=pre_process,
+            post_process=post_process,
+            use_cpu_initialization=use_cpu_initialization,
+            hidden_dropout=hidden_dropout,
+            attention_dropout=attention_dropout,
+            precision=precision,
+            fp32_residual_connection=fp32_residual_connection,
+            activations_checkpoint_method=activations_checkpoint_method,
+            activations_checkpoint_num_layers=activations_checkpoint_num_layers,
+            layernorm_epsilon=layernorm_epsilon,
+            bias_gelu_fusion=bias_gelu_fusion,
+            bias_dropout_add_fusion=bias_dropout_add_fusion,
+            masked_softmax_fusion=masked_softmax_fusion,
+            persist_layer_norm=persist_layer_norm,
+            openai_gelu=openai_gelu,
+            onnx_safe=onnx_safe,
+            activation=activation,
+            bias=bias,
+            normalization=normalization,
+            transformer_block_type=transformer_block_type,
+            headscale=headscale,
+            parent_model_type=parent_model_type,
+        )
+    elif arch == "retro":
+        decoder = MegatronRetrievalTransformerDecoderModule(
             init_method=init_method,
             output_layer_init_method=scaled_init_method,
             hidden_size=hidden_size,
             num_layers=num_layers,
             num_attention_heads=num_attention_heads,
             apply_query_key_layer_scaling=apply_query_key_layer_scaling,
             kv_channels=kv_channels,
+            layer_type=layer_type,
             ffn_hidden_size=ffn_hidden_size,
-            encoder_attn_mask_type=encoder_attn_mask_type,
             pre_process=pre_process,
             post_process=post_process,
             use_cpu_initialization=use_cpu_initialization,
             hidden_dropout=hidden_dropout,
             attention_dropout=attention_dropout,
             precision=precision,
             fp32_residual_connection=fp32_residual_connection,
             activations_checkpoint_method=activations_checkpoint_method,
             activations_checkpoint_num_layers=activations_checkpoint_num_layers,
             layernorm_epsilon=layernorm_epsilon,
             bias_gelu_fusion=bias_gelu_fusion,
+            bias_dropout_add_fusion=bias_dropout_add_fusion,
             masked_softmax_fusion=masked_softmax_fusion,
             persist_layer_norm=persist_layer_norm,
             openai_gelu=openai_gelu,
             onnx_safe=onnx_safe,
             activation=activation,
+            bias=bias,
             parent_model_type=parent_model_type,
+            chunk_size=chunk_size,
         )
     else:
-        raise ValueError(f"Unknown encoder arch = {arch}. Available encoder arch = {AVAILABLE_ENCODERS}")
+        raise ValueError(f"Unknown decoder arch = {arch}. Available decoder arch = {AVAILABLE_DECODERS}")
 
-    return encoder
+    return decoder
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_init.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_init.py`

 * *Files 9% similar despite different names*

```diff
@@ -26,14 +26,15 @@
         get_pipeline_model_parallel_rank,
         set_pipeline_model_parallel_rank,
         set_pipeline_model_parallel_split_rank,
         set_pipeline_model_parallel_world_size,
         set_tensor_model_parallel_rank,
         set_tensor_model_parallel_world_size,
     )
+    from apex.transformer.microbatches import ConstantNumMicroBatches
     from apex.transformer.pipeline_parallel.utils import setup_microbatch_calculator
     from apex.transformer.utils import ensure_divisibility
 
     HAVE_APEX = True
 except (ImportError, ModuleNotFoundError):
     HAVE_APEX = False
 
@@ -80,21 +81,33 @@
     set_pipeline_model_parallel_world_size(app_state.pipeline_model_parallel_size)
     set_pipeline_model_parallel_split_rank(app_state.pipeline_model_parallel_split_rank)
 
     _set_random_seed(seed)
 
     if global_batch_size and micro_batch_size is not None:
         # TODO: add rampup_batch_size here when we have it implemented
-        setup_microbatch_calculator(
-            rank=global_rank,
-            global_batch_size=global_batch_size,
-            micro_batch_size=micro_batch_size,
-            data_parallel_size=app_state.data_parallel_size,
-            rampup_batch_size=None,
-        )
+        from apex.transformer.pipeline_parallel.utils import _GLOBAL_NUM_MICROBATCHES_CALCULATOR
+
+        if _GLOBAL_NUM_MICROBATCHES_CALCULATOR is None:
+            setup_microbatch_calculator(
+                rank=global_rank,
+                global_batch_size=global_batch_size,
+                micro_batch_size=micro_batch_size,
+                data_parallel_size=app_state.data_parallel_size,
+                rampup_batch_size=None,
+            )
+        else:
+            if isinstance(_GLOBAL_NUM_MICROBATCHES_CALCULATOR, ConstantNumMicroBatches):
+                assert _GLOBAL_NUM_MICROBATCHES_CALCULATOR.current_global_batch_size == global_batch_size
+                assert _GLOBAL_NUM_MICROBATCHES_CALCULATOR.micro_batch_size == micro_batch_size
+                assert _GLOBAL_NUM_MICROBATCHES_CALCULATOR.num_micro_batches == global_batch_size // (
+                    micro_batch_size * app_state.data_parallel_size
+                )
+            else:
+                raise Exception("Microbatch calculator already initialized.")
 
     app_state._is_megatron_initialized = True
 
     set_logging_level(apex_transformer_log_level)
 
 
 def _set_random_seed(seed_):
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_transformer_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_transformer_decoder.py`

 * *Files 5% similar despite different names*

```diff
@@ -10,24 +10,25 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Transformer based language model."""
 
+from nemo.collections.nlp.modules.common.megatron.layer_type import LayerType
 from nemo.collections.nlp.modules.common.megatron.module import MegatronModule
 from nemo.collections.nlp.modules.common.megatron.transformer import ParallelTransformer
 from nemo.collections.nlp.modules.common.megatron.utils import (
     ApexGuardDefaults,
     attn_mask_postprocess,
     build_attention_mask_3d,
 )
 
 try:
-    from apex.transformer.enums import AttnMaskType, LayerType, ModelType
+    from apex.transformer.enums import AttnMaskType, ModelType
 
     HAVE_APEX = True
 except (ImportError, ModuleNotFoundError):
     HAVE_APEX = False
     # fake missing classes with None attributes
     AttnMaskType = ApexGuardDefaults()
     LayerType = ApexGuardDefaults()
@@ -59,32 +60,38 @@
         attention_dropout=0.1,
         precision=16,
         fp32_residual_connection=False,
         activations_checkpoint_method=None,
         activations_checkpoint_num_layers=1,
         layernorm_epsilon=1e-5,
         bias_gelu_fusion=True,
+        bias_dropout_add_fusion=True,
         masked_softmax_fusion=True,
         persist_layer_norm=False,
         openai_gelu=False,
         onnx_safe=False,
         activation='gelu',
+        bias=True,
+        normalization='layernorm',
+        transformer_block_type='pre_ln',
+        headscale=False,
         parent_model_type=ModelType.encoder_or_decoder,
     ):
         super(MegatronTransformerDecoderModule, self).__init__()
 
         self.pre_process = pre_process
         self.post_process = post_process
         self.hidden_size = hidden_size
         self.num_layers = num_layers
         self.init_method = init_method
         self.model_attn_mask_type = decoder_attn_mask_type
         self.hidden_dropout = hidden_dropout
         self.output_layer_init_method = output_layer_init_method
         self.parent_model_type = parent_model_type
+        self.normalization = normalization
 
         if kv_channels is None:
 
             assert (
                 hidden_size % num_attention_heads == 0
             ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
             kv_channels = hidden_size // num_attention_heads
@@ -108,20 +115,25 @@
             activations_checkpoint_method=activations_checkpoint_method,
             activations_checkpoint_num_layers=activations_checkpoint_num_layers,
             layernorm_epsilon=layernorm_epsilon,
             hidden_dropout=hidden_dropout,
             attention_dropout=attention_dropout,
             use_cpu_initialization=use_cpu_initialization,
             bias_gelu_fusion=bias_gelu_fusion,
+            bias_dropout_fusion=bias_dropout_add_fusion,
             masked_softmax_fusion=masked_softmax_fusion,
             persist_layer_norm=persist_layer_norm,
             openai_gelu=openai_gelu,
             onnx_safe=onnx_safe,
             activation=activation,
+            bias=bias,
+            normalization=normalization,
             model_type=parent_model_type,
+            transformer_block_type=transformer_block_type,
+            headscale=headscale,
         )
         self._model_key = 'model'
 
     def set_input_tensor(self, input_tensor):
         """ See megatron.model.transformer.set_input_tensor()"""
         self.model.set_input_tensor(input_tensor)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_transformer_encoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_transformer_encoder.py`

 * *Files 8% similar despite different names*

```diff
@@ -57,32 +57,39 @@
         attention_dropout=0.1,
         precision=16,
         fp32_residual_connection=False,
         activations_checkpoint_method=None,
         activations_checkpoint_num_layers=1,
         layernorm_epsilon=1e-5,
         bias_gelu_fusion=True,
+        bias_dropout_add_fusion=True,
         masked_softmax_fusion=True,
         persist_layer_norm=False,
         openai_gelu=False,
         onnx_safe=False,
         activation='gelu',
+        bias=True,
+        normalization='layernorm',
+        transformer_block_type='pre_ln',
+        headscale=False,
         parent_model_type=ModelType.encoder_or_decoder,
     ):
         super(MegatronTransformerEncoderModule, self).__init__()
 
         self.pre_process = pre_process
         self.post_process = post_process
         self.hidden_size = hidden_size
         self.num_layers = num_layers
         self.init_method = init_method
         self.model_attn_mask_type = encoder_attn_mask_type
         self.hidden_dropout = hidden_dropout
         self.output_layer_init_method = output_layer_init_method
         self.parent_model_type = parent_model_type
+        self.normalization = normalization
+        self.transformer_block_type = transformer_block_type
 
         if kv_channels is None:
 
             assert (
                 hidden_size % num_attention_heads == 0
             ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
             kv_channels = hidden_size // num_attention_heads
@@ -105,19 +112,24 @@
             activations_checkpoint_method=activations_checkpoint_method,
             activations_checkpoint_num_layers=activations_checkpoint_num_layers,
             layernorm_epsilon=layernorm_epsilon,
             hidden_dropout=hidden_dropout,
             attention_dropout=attention_dropout,
             use_cpu_initialization=use_cpu_initialization,
             bias_gelu_fusion=bias_gelu_fusion,
+            bias_dropout_fusion=bias_dropout_add_fusion,
             masked_softmax_fusion=masked_softmax_fusion,
             persist_layer_norm=persist_layer_norm,
             openai_gelu=openai_gelu,
             onnx_safe=onnx_safe,
             activation=activation,
+            bias=bias,
+            normalization=normalization,
+            transformer_block_type=transformer_block_type,
+            headscale=headscale,
             model_type=parent_model_type,
         )
         self._model_key = 'model'
 
     def set_input_tensor(self, input_tensor):
         """ See megatron.model.transformer.set_input_tensor()"""
         self.model.set_input_tensor(input_tensor)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/megatron_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/megatron_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/module.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/module.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/token_level_encoder_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/token_level_encoder_decoder.py`

 * *Files 3% similar despite different names*

```diff
@@ -95,32 +95,38 @@
         precision=16,
         fp32_residual_connection=False,
         activations_checkpoint_method=None,
         activations_checkpoint_num_layers=1,
         layernorm_epsilon=1e-5,
         persist_layer_norm=False,
         bias_gelu_fusion=True,
+        bias_dropout_add_fusion=True,
         masked_softmax_fusion=True,
         openai_gelu=False,
         activation='gelu',
         onnx_safe=False,
+        bias=True,
+        normalization='layernorm',
+        transformer_block_type='pre_ln',
         hidden_steps=-1,
         hidden_blocks=1,
+        headscale=False,
         add_encoder=True,
         add_decoder=True,
     ):
         super(MegatronTokenLevelEncoderDecoderModule, self).__init__()
 
         self.parallel_output = parallel_output
         self.pre_process = pre_process
         self.post_process = post_process
         self.fp16_cross_entropy = fp16_cross_entropy
         self.precision = precision
         self.add_encoder = add_encoder
         self.add_decoder = add_decoder
+        self.normalization = normalization
 
         if kv_channels is None:
             assert (
                 hidden_size % num_attention_heads == 0
             ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
             kv_channels = hidden_size // num_attention_heads
 
@@ -157,21 +163,26 @@
                 attention_dropout=attention_dropout,
                 precision=precision,
                 fp32_residual_connection=fp32_residual_connection,
                 activations_checkpoint_method=activations_checkpoint_method,
                 activations_checkpoint_num_layers=activations_checkpoint_num_layers,
                 layernorm_epsilon=layernorm_epsilon,
                 bias_gelu_fusion=bias_gelu_fusion,
+                bias_dropout_add_fusion=bias_dropout_add_fusion,
                 masked_softmax_fusion=masked_softmax_fusion,
                 persist_layer_norm=persist_layer_norm,
                 openai_gelu=openai_gelu,
                 onnx_safe=onnx_safe,
                 hidden_steps=hidden_steps,
                 hidden_blocks=hidden_blocks,
                 activation=activation,
+                bias=bias,
+                normalization=normalization,
+                transformer_block_type=transformer_block_type,
+                headscale=headscale,
                 parent_model_type=ModelType.encoder_and_decoder,
             )
 
         if add_decoder:
             # If this is the decoder first stage
             if pre_process:
                 # If the encoder also lies on this rank (PP = 1), then just assign embeddings directly.
@@ -213,21 +224,26 @@
                 attention_dropout=attention_dropout,
                 precision=precision,
                 fp32_residual_connection=fp32_residual_connection,
                 activations_checkpoint_method=activations_checkpoint_method,
                 activations_checkpoint_num_layers=activations_checkpoint_num_layers,
                 layernorm_epsilon=layernorm_epsilon,
                 bias_gelu_fusion=bias_gelu_fusion,
+                bias_dropout_add_fusion=bias_dropout_add_fusion,
                 masked_softmax_fusion=masked_softmax_fusion,
                 persist_layer_norm=persist_layer_norm,
                 openai_gelu=openai_gelu,
                 onnx_safe=onnx_safe,
                 hidden_steps=hidden_steps,
                 hidden_blocks=hidden_blocks,
                 activation=activation,
+                bias=bias,
+                normalization=normalization,
+                transformer_block_type=transformer_block_type,
+                headscale=headscale,
                 parent_model_type=ModelType.encoder_and_decoder,
             )
 
         self.enc_dec_model = MegatronTransformerEncoderDecoderModule(encoder=encoder, decoder=decoder)
         self._enc_dec_model_key = "enc_dec_model"
 
         self.initialize_word_embeddings(
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/transformer.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/transformer.py`

 * *Files 19% similar despite different names*

```diff
@@ -14,36 +14,42 @@
 # limitations under the License.
 
 """Transformer."""
 import math
 
 import torch
 import torch.nn.functional as F
+from einops import rearrange, repeat
 
 from nemo.collections.nlp.modules.common.megatron.fused_bias_dropout_add import (
     bias_dropout_add,
     bias_dropout_add_fused_inference,
     bias_dropout_add_fused_train,
+    dropout_add,
 )
 from nemo.collections.nlp.modules.common.megatron.fused_bias_gelu import fused_bias_gelu
 from nemo.collections.nlp.modules.common.megatron.fused_layer_norm import get_layer_norm
+from nemo.collections.nlp.modules.common.megatron.layer_type import LayerType
 from nemo.collections.nlp.modules.common.megatron.module import MegatronModule
+from nemo.collections.nlp.modules.common.megatron.rotary_pos_embedding import apply_rotary_pos_emb
 from nemo.collections.nlp.modules.common.megatron.utils import ApexGuardDefaults, attention_mask_func, erf_gelu
 from nemo.utils import logging
 
 try:
     from apex.transformer import parallel_state, tensor_parallel
-    from apex.transformer.enums import AttnMaskType, AttnType, LayerType, ModelType
+    from apex.transformer.enums import AttnMaskType, AttnType, ModelType
     from apex.transformer.functional.fused_softmax import FusedScaleMaskSoftmax
     from apex.transformer.utils import divide as safe_divide
     from apex.transformer.parallel_state import get_tensor_model_parallel_world_size
+    from apex.normalization import MixedFusedRMSNorm
 
     HAVE_APEX = True
 
 except (ImportError, ModuleNotFoundError):
+
     HAVE_APEX = False
 
     # fake missing classes with None attributes
     ModelType = AttnMaskType = AttnType = LayerType = ApexGuardDefaults()
 
 
 """ We use the following notation throughout this file:
@@ -68,15 +74,15 @@
         def forward(self, input_):
             world_size = get_tensor_model_parallel_world_size()
             if input_.requires_grad or world_size > 1:
                 return tensor_parallel.ColumnParallelLinear.forward(self, input_)
 
             # Matrix multiply.
             output = torch.matmul(input_, self.weight.t())
-            if not self.skip_bias_add:
+            if not self.skip_bias_add and self.bias is not None:
                 output = output + self.bias
 
             output_bias = self.bias if self.skip_bias_add else None
 
             return output, output_bias
 
 
@@ -106,41 +112,54 @@
         hidden_size,
         ffn_hidden_size,
         use_cpu_initialization=False,
         bias_gelu_fusion=True,
         openai_gelu=False,
         onnx_safe=False,
         activation='gelu',
+        bias=True,
+        transformer_block_type='pre_ln',
+        normalization='layernorm',
+        layernorm_epsilon=1e-5,
+        persist_layer_norm=False,
     ):
         super(ParallelMLP, self).__init__()
         self.activation = activation
+        self.bias = bias
+        self.transformer_block_type = transformer_block_type
+        self.normalization = normalization
+        self.layernorm_epsilon = layernorm_epsilon
+        self.persist_layer_norm = persist_layer_norm
+        self.activation = activation
 
         if activation not in ['gelu', 'geglu', 'reglu', 'swiglu']:
             raise ValueError(f"Activation {activation} not supported. Only gelu, geglu, reglu, swiglu are supported.")
 
         # Project to 4h.
         self.dense_h_to_4h = ColumnLinear(
             hidden_size,
             ffn_hidden_size,  # NOTE: When using geglu, divide ffn dim by 2/3 to keep overall params the same.
             gather_output=False,
             init_method=init_method,
             skip_bias_add=True,
             use_cpu_initialization=use_cpu_initialization,
+            bias=bias,
         )
 
         if activation in ['geglu', 'reglu', 'swiglu']:
             # Separate linear layer for *GLU activations.
             # Source: https://github.com/huggingface/transformers/blob/bee361c6f1f7704f8c688895f2f86f6e5ff84727/src/transformers/models/t5/modeling_t5.py#L292
             self.dense_h_to_4h_2 = ColumnLinear(
                 hidden_size,
                 ffn_hidden_size,  # NOTE: When using *glu, divide ffn dim by 2/3 to keep overall params the same.
                 gather_output=False,
                 init_method=init_method,
                 skip_bias_add=True,
                 use_cpu_initialization=use_cpu_initialization,
+                bias=bias,
             )
             glu_activation_family = True
         else:
             glu_activation_family = False
 
         if glu_activation_family and bias_gelu_fusion:
             raise ValueError(
@@ -153,61 +172,82 @@
             )
 
         if glu_activation_family and onnx_safe:
             raise ValueError(
                 f"Cannot use onnx_safe with specificed activation function : {activation} Please turn onnx safe off."
             )
 
+        if bias_gelu_fusion and not bias:
+            raise ValueError(
+                f"Cannot use bias_gelu_fusion without bias terms. Please set bias=True or bias_gelu_fusion=False."
+            )
+        else:
+            glu_activation_family = False
+
         self.bias_gelu_fusion = bias_gelu_fusion
 
-        if activation == "gelu":
+        if activation in ["gelu", "geglu"]:
             self.activation_func = F.gelu
         elif openai_gelu:
             self.activation_func = openai_gelu
         elif onnx_safe:
             self.activation_func = erf_gelu
-        else:
-            # Remaining acitvations are implemeted in the forward function.
-            self.activation_func = None
+        elif activation == "reglu":
+            self.activation_func = F.relu
+        elif activation == "swiglu":
+            # SiLU or sigmoid linear unit is the same as swish with beta = 1 (which is what https://arxiv.org/pdf/2002.05202.pdf uses.)
+            self.activation_func = F.silu
 
         # Project back to h.
         self.dense_4h_to_h = tensor_parallel.RowParallelLinear(
             ffn_hidden_size,
             hidden_size,
             input_is_parallel=True,
             init_method=output_layer_init_method,
             skip_bias_add=True,
             use_cpu_initialization=use_cpu_initialization,
+            bias=bias,
         )
 
+        # Normformer normalization
+        if transformer_block_type == 'normformer':
+            if normalization == 'layernorm':
+                self.normalization = get_layer_norm(
+                    ffn_hidden_size // get_tensor_model_parallel_world_size(), layernorm_epsilon, persist_layer_norm
+                )
+            else:
+                self.normalization = MixedFusedRMSNorm(
+                    ffn_hidden_size // get_tensor_model_parallel_world_size(), layernorm_epsilon
+                )
+
     def forward(self, hidden_states):
 
         # [s, b, 4hp]
         intermediate_parallel, bias_parallel = self.dense_h_to_4h(hidden_states)
 
         if self.activation in ['geglu', 'reglu', 'swiglu']:
             intermediate_parallel_2, bias_parallel_2 = self.dense_h_to_4h_2(hidden_states)
+            if bias_parallel is not None:
+                intermediate_parallel = self.activation_func(intermediate_parallel + bias_parallel) * (
+                    intermediate_parallel_2 + bias_parallel_2
+                )
+            else:
+                intermediate_parallel = self.activation_func(intermediate_parallel) * intermediate_parallel_2
 
-        if self.activation == 'geglu':
-            intermediate_parallel = F.gelu(intermediate_parallel + bias_parallel) * (
-                intermediate_parallel_2 + bias_parallel_2
-            )
-        elif self.activation == 'swiglu':
-            # SiLU or sigmoid linear unit is the same as swish with beta = 1 (which is what https://arxiv.org/pdf/2002.05202.pdf uses.)
-            intermediate_parallel = F.silu(intermediate_parallel + bias_parallel) * (
-                intermediate_parallel_2 + bias_parallel_2
-            )
-        elif self.activation == 'reglu':
-            intermediate_parallel = F.relu(intermediate_parallel + bias_parallel) * (
-                intermediate_parallel_2 + bias_parallel_2
-            )
         elif self.bias_gelu_fusion and self.activation == 'gelu':
             intermediate_parallel = fused_bias_gelu(intermediate_parallel, bias_parallel)
         else:
-            intermediate_parallel = self.activation_func(intermediate_parallel + bias_parallel)
+            if bias_parallel is not None:
+                intermediate_parallel = self.activation_func(intermediate_parallel + bias_parallel)
+            else:
+                intermediate_parallel = self.activation_func(intermediate_parallel)
+
+        # Normformer normalization
+        if self.transformer_block_type == 'normformer':
+            intermediate_parallel = self.normalization(intermediate_parallel)
 
         # [s, b, h]
         output, output_bias = self.dense_4h_to_h(intermediate_parallel)
         return output, output_bias
 
 
 class ParallelAttention(MegatronModule):
@@ -229,54 +269,66 @@
         precision=16,
         apply_query_key_layer_scaling=True,
         kv_channels=None,
         use_cpu_initialization=False,
         masked_softmax_fusion=True,
         attention_dropout=0.1,
         megatron_legacy=False,
+        bias=True,
+        headscale=True,
     ):
         super(ParallelAttention, self).__init__()
 
         self.apply_query_key_layer_scaling = apply_query_key_layer_scaling
         self.attention_softmax_in_fp32 = False
         if self.apply_query_key_layer_scaling:
             self.attention_softmax_in_fp32 = True
         self.layer_number = max(1, layer_number)
         self.attention_type = attention_type
         self.attn_mask_type = attn_mask_type
         self.megatron_legacy = megatron_legacy
+        self.headscale = headscale
 
         if kv_channels is None:
             assert (
                 hidden_size % num_attention_heads == 0
             ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
             kv_channels = hidden_size // num_attention_heads
         projection_size = kv_channels * num_attention_heads
 
         # Per attention head and per partition values.
         world_size = parallel_state.get_tensor_model_parallel_world_size()
         self.hidden_size_per_partition = safe_divide(projection_size, world_size)
         self.hidden_size_per_attention_head = safe_divide(projection_size, num_attention_heads)
         self.num_attention_heads_per_partition = safe_divide(num_attention_heads, world_size)
 
+        # Headscale
+        if headscale:
+            self.head_scale_tensor = torch.nn.Parameter(
+                torch.ones(1, self.num_attention_heads_per_partition, 1, 1), requires_grad=True
+            )
+
         # Strided linear layer.
         if attention_type == AttnType.self_attn:
             self.query_key_value = ColumnLinear(
                 hidden_size,
                 3 * projection_size,
                 gather_output=False,
                 init_method=init_method,
                 use_cpu_initialization=use_cpu_initialization,
+                bias=bias,
             )
         else:
             assert attention_type == AttnType.cross_attn
-            self.query = ColumnLinear(hidden_size, projection_size, gather_output=False, init_method=init_method)
+            self.query = ColumnLinear(
+                hidden_size, projection_size, gather_output=False, init_method=init_method, bias=bias
+            )
 
             self.key_value = ColumnLinear(
-                hidden_size, 2 * projection_size, gather_output=False, init_method=init_method
+                hidden_size, 2 * projection_size, gather_output=False, init_method=init_method, bias=bias
             )
 
         coeff = None
         self.norm_factor = math.sqrt(self.hidden_size_per_attention_head)
         if self.apply_query_key_layer_scaling:
             coeff = self.layer_number
             self.norm_factor *= coeff
@@ -302,14 +354,15 @@
         self.dense = tensor_parallel.RowParallelLinear(
             projection_size,
             hidden_size,
             input_is_parallel=True,
             init_method=output_layer_init_method,
             skip_bias_add=True,
             use_cpu_initialization=use_cpu_initialization,
+            bias=bias,
         )
 
         # Inference key-value memory
         self.inference_key_memory = None
         self.inference_value_memory = None
         self.inference_current_sequence_len = 0
 
@@ -362,14 +415,15 @@
         hidden_states,
         attention_mask,
         layer_past=None,
         get_key_value=False,
         encoder_output=None,
         set_inference_key_value_memory=False,
         inference_max_sequence_len=None,
+        rotary_pos_emb=None,  # rotary positional embedding
     ):
         # hidden_states: [sq, b, h]
 
         # =================================================
         # Pre-allocate memory for key-values for inference.
         # =================================================
         if set_inference_key_value_memory:
@@ -433,26 +487,35 @@
             )
             query_layer = query_layer.view(*new_tensor_shape)
 
         # ===================================================
         # Adjust key, value, and attention mask for inference
         # ===================================================
 
+        # duplicate the pos_emb for self attention
+        if rotary_pos_emb is not None:
+            rotary_pos_emb = rotary_pos_emb if isinstance(rotary_pos_emb, tuple) else ((rotary_pos_emb,) * 2)
+
         if inference_max_sequence_len:
             # Adjust the range variables.
             start = self.inference_current_sequence_len
             self.inference_current_sequence_len += key_layer.size(0)
             end = self.inference_current_sequence_len
             # Copy key and values.
             self.inference_key_memory[start:end, ...] = key_layer
             self.inference_value_memory[start:end, ...] = value_layer
             key_layer = self.inference_key_memory[:end, ...]
             value_layer = self.inference_value_memory[:end, ...]
             # Adjust attention mask
             attention_mask = attention_mask[..., start:end, :end]
+            # adjust the key rotary positional embedding
+            if rotary_pos_emb is not None:
+                q_pos_emb, k_pos_emb = rotary_pos_emb
+                k_pos_emb = k_pos_emb[:, :, :end, :]
+                rotary_pos_emb = (q_pos_emb, k_pos_emb)
 
         if layer_past is not None:
             past_key, past_value = layer_past
             key_layer = torch.cat((past_key.type_as(key_layer), key_layer), dim=0)
             value_layer = torch.cat((past_value.type_as(value_layer), value_layer), dim=0)
         if get_key_value:
             present = (key_layer, value_layer)
@@ -460,14 +523,25 @@
         # ===================================
         # Raw attention scores. [b, np, s, s]
         # ===================================
 
         # [b, np, sq, sk]
         output_size = (query_layer.size(1), query_layer.size(2), query_layer.size(0), key_layer.size(0))
 
+        # apply relative positional encoding (rotary embedding)
+        if rotary_pos_emb is not None:
+            q_pos_emb, k_pos_emb = rotary_pos_emb
+
+            query_layer = apply_rotary_pos_emb(query_layer, q_pos_emb)
+            key_layer = apply_rotary_pos_emb(key_layer, k_pos_emb)
+            # TODO, can apply positional embedding to value_layer so it has
+            # absolute positional embedding.
+            # otherwise, only relative positional embedding takes effect
+            # value_layer = apply_rotary_pos_emb(value_layer, k_pos_emb)
+
         # [sq, b, np, hn] -> [sq, b * np, hn]
         query_layer = query_layer.view(output_size[2], output_size[0] * output_size[1], -1)
         # [sk, b, np, hn] -> [sk, b * np, hn]
         key_layer = key_layer.view(output_size[3], output_size[0] * output_size[1], -1)
 
         # preallocting result tensor: [b * np, sq, sk]
         matmul_result = torch.empty(
@@ -533,14 +607,17 @@
 
         # matmul: [b * np, sq, hn]
         context_layer = torch.bmm(attention_probs, value_layer.transpose(0, 1))
 
         # change view [b, np, sq, hn]
         context_layer = context_layer.view(*output_size)
 
+        if self.headscale:
+            context_layer = context_layer * self.head_scale_tensor
+
         # [b, np, sq, hn] --> [sq, b, np, hn]
         context_layer = context_layer.permute(2, 0, 1, 3).contiguous()
 
         # [sq, b, np, hn] --> [sq, b, hp]
         new_context_layer_shape = context_layer.size()[:-2] + (self.hidden_size_per_partition,)
         context_layer = context_layer.view(*new_context_layer_shape)
 
@@ -552,21 +629,136 @@
 
         if get_key_value:
             output = [output, present]
 
         return output, bias
 
 
+class ParallelChunkedCrossAttention(MegatronModule):
+    """Parallel chunked cross-attention layer abstract class.
+
+    Self-attention layer takes input with size [b, s, h]
+    and returns output of the same size.
+    """
+
+    def __init__(
+        self,
+        init_method,
+        output_layer_init_method,
+        layer_number,
+        num_attention_heads,
+        hidden_size,
+        precision=16,
+        apply_query_key_layer_scaling=True,
+        kv_channels=None,
+        use_cpu_initialization=False,
+        masked_softmax_fusion=True,
+        attention_dropout=0.1,
+        megatron_legacy=False,
+        chunk_size=64,  # each chunk, how many tokens
+        bias=True,
+    ):
+        super(ParallelChunkedCrossAttention, self).__init__()
+        self.cross_attention = ParallelAttention(
+            init_method=init_method,
+            output_layer_init_method=output_layer_init_method,
+            layer_number=layer_number,
+            num_attention_heads=num_attention_heads,
+            hidden_size=hidden_size,
+            attention_type=AttnType.cross_attn,
+            attn_mask_type=AttnMaskType.padding,
+            precision=precision,
+            apply_query_key_layer_scaling=apply_query_key_layer_scaling,
+            kv_channels=kv_channels,
+            use_cpu_initialization=use_cpu_initialization,
+            masked_softmax_fusion=masked_softmax_fusion,
+            attention_dropout=attention_dropout,
+            megatron_legacy=megatron_legacy,
+            bias=bias,
+        )
+        self.chunk_size = chunk_size
+
+    def forward(
+        self, hidden_states, attention_mask, encoder_output=None, rotary_pos_emb=None,
+    ):
+        # hidden_states is assumed to have dimension [token length, batch, dimension]
+        # derive variables
+        # encoder_output here is the retrieved context
+        context = encoder_output
+        # context is assumed to have dimension [num_chunks, num_neighbors, context_token_len, batch, dimension]
+        chunk_size = self.chunk_size
+
+        b, n, num_chunks, num_retrieved = (
+            hidden_states.shape[1],
+            hidden_states.shape[0],
+            context.shape[-5],
+            context.shape[-4],
+        )
+
+        # if sequence length less than chunk size, do an early return
+
+        if n < self.chunk_size:
+            return torch.zeros_like(hidden_states)
+
+        # causal padding
+        causal_padding = chunk_size - 1
+
+        x = F.pad(hidden_states, (0, 0, 0, 0, -causal_padding, causal_padding), value=0.0)
+
+        # remove sequence which is ahead of the neighbors retrieved (during inference)
+
+        seq_index = (n // chunk_size) * chunk_size
+        x, x_remainder = x[:seq_index], x[seq_index:]
+
+        seq_remain_len = x_remainder.shape[0]
+
+        # take care of rotary positional embedding
+        # make sure queries positions are properly shifted to the future
+
+        q_pos_emb, k_pos_emb = rotary_pos_emb
+        # currently implementation is broken
+        # q need to extend to causal_padding, and just do
+        # q_pos_emb = F.pad(q_pos_emb, (0, 0, -causal_padding, 0), value = 0.)
+        q_pos_emb = F.pad(q_pos_emb, (0, 0, 0, 0, 0, 0, -causal_padding, 0), value=0.0)
+
+        k_pos_emb = repeat(k_pos_emb, 'n b h d -> (r n) b h d', r=num_retrieved)
+        rotary_pos_emb = (q_pos_emb, k_pos_emb)
+
+        # reshape so we have chunk to chunk attention, without breaking causality
+
+        x = rearrange(x, '(k n) b d -> n (b k) d', k=num_chunks)
+        context = rearrange(context, 'k r n b d -> (r n) (b k) d')
+        # cross attention
+        out, bias = self.cross_attention(x, attention_mask, encoder_output=context, rotary_pos_emb=rotary_pos_emb)
+
+        # reshape back to original sequence
+
+        out = rearrange(out, 'n (b k) d -> (k n) b d', b=b)
+
+        # pad back to original, with 0s at the beginning (which will be added to the residual and be fine)
+
+        out = F.pad(out, (0, 0, 0, 0, causal_padding, -causal_padding + seq_remain_len), value=0.0)
+        return out, bias
+
+
 def get_bias_dropout_add(training):
     def _bias_dropout_add(x, bias, residual, prob):
         return bias_dropout_add(x, bias, residual, prob, training)
 
     return _bias_dropout_add
 
 
+def get_dropout_add(training):
+    def _dropout_add(x, bias, residual, prob):
+        assert bias is None
+        return dropout_add(x, bias, residual, prob, training)
+
+    return _dropout_add
+
+
 class ParallelTransformerLayer_(MegatronModule):
     """A single transformer layer.
 
     Transformer layer takes input with size [b, s, h] and returns an
     output of the same size.
     """
 
@@ -577,15 +769,14 @@
         layer_number,
         hidden_size,
         ffn_hidden_size,
         num_attention_heads,
         layer_type=LayerType.encoder,
         self_attn_mask_type=AttnMaskType.padding,
         fp32_residual_connection=False,
-        apply_residual_connection_post_layernorm=False,
         precision=16,
         apply_query_key_layer_scaling=True,
         kv_channels=None,
         layernorm_epsilon=1e-5,
         hidden_dropout=0.1,
         bias_dropout_fusion=True,
         persist_layer_norm=False,
@@ -593,33 +784,53 @@
         bias_gelu_fusion=True,
         openai_gelu=False,
         onnx_safe=False,
         masked_softmax_fusion=True,
         attention_dropout=0.1,
         activation='gelu',
         megatron_legacy=False,
+        bias=True,
+        chunk_size=64,
+        normalization='layernorm',
+        transformer_block_type='pre_ln',
+        headscale=False,
     ):
         super(ParallelTransformerLayer_, self).__init__()
 
         if kv_channels is None:
             assert (
                 hidden_size % num_attention_heads == 0
             ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
             kv_channels = hidden_size // num_attention_heads
 
         self.layer_number = layer_number
         self.layer_type = layer_type
+        self.bias = bias
+        self.transformer_block_type = transformer_block_type
+
+        if not bias and bias_dropout_fusion:
+            raise ValueError(
+                'bias_dropout_fusion=True requires bias=True, found bias=False. Either set both to True or both to False.'
+            )
 
-        # if true apply residual connection post layer norm (like original bert)
-        self.apply_residual_connection_post_layernorm = apply_residual_connection_post_layernorm
+        if normalization not in ['layernorm', 'rmsnorm']:
+            raise ValueError(f'normalization must be either "layernorm" or "rmsnorm", found {normalization}')
+
+        if transformer_block_type not in ['pre_ln', 'post_ln', 'normformer']:
+            raise ValueError(
+                f'transformer_block_type must be either "pre_ln" or "post_ln" or "normformer", found {transformer_block_type}'
+            )
 
         self.fp32_residual_connection = fp32_residual_connection  # if true move residual connections to fp32
 
         # Layernorm on the input data.
-        self.input_layernorm = get_layer_norm(hidden_size, layernorm_epsilon, persist_layer_norm)
+        if normalization == 'layernorm':
+            self.input_layernorm = get_layer_norm(hidden_size, layernorm_epsilon, persist_layer_norm)
+        else:
+            self.input_layernorm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
 
         # Self attention.
         self.self_attention = ParallelAttention(
             init_method=init_method,
             output_layer_init_method=output_layer_init_method,
             layer_number=layer_number,
             num_attention_heads=num_attention_heads,
@@ -629,23 +840,37 @@
             precision=precision,
             apply_query_key_layer_scaling=apply_query_key_layer_scaling,
             kv_channels=kv_channels,
             use_cpu_initialization=use_cpu_initialization,
             masked_softmax_fusion=masked_softmax_fusion,
             attention_dropout=attention_dropout,
             megatron_legacy=megatron_legacy,
+            bias=bias,
+            headscale=headscale,
         )
         self.hidden_dropout = hidden_dropout
         self.attention_dropout = attention_dropout
         self.bias_dropout_fusion = bias_dropout_fusion  # if true, enable bias dropout fusion
 
+        # Normformer normalization
+        if transformer_block_type == 'normformer':
+            if normalization == 'layernorm':
+                self.post_attention_normformer_norm = get_layer_norm(
+                    hidden_size, layernorm_epsilon, persist_layer_norm
+                )
+            else:
+                self.post_attention_normformer_norm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
+
         # Layernorm on the attention output
-        self.post_attention_layernorm = get_layer_norm(hidden_size, layernorm_epsilon, persist_layer_norm)
+        if normalization == 'layernorm':
+            self.post_attention_layernorm = get_layer_norm(hidden_size, layernorm_epsilon, persist_layer_norm)
+        else:
+            self.post_attention_layernorm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
 
-        if self.layer_type == LayerType.decoder:
+        if self.layer_type == LayerType.decoder or self.layer_type == LayerType.retrieval_encoder:
             self.inter_attention = ParallelAttention(
                 init_method=init_method,
                 output_layer_init_method=output_layer_init_method,
                 layer_number=layer_number,
                 num_attention_heads=num_attention_heads,
                 hidden_size=hidden_size,
                 attention_type=AttnType.cross_attn,
@@ -653,111 +878,228 @@
                 precision=precision,
                 apply_query_key_layer_scaling=apply_query_key_layer_scaling,
                 kv_channels=kv_channels,
                 use_cpu_initialization=use_cpu_initialization,
                 masked_softmax_fusion=masked_softmax_fusion,
                 attention_dropout=attention_dropout,
                 megatron_legacy=megatron_legacy,
+                bias=bias,
+                headscale=headscale,
             )
+            # Normformer normalization
+            if transformer_block_type == 'normformer':
+                if normalization == 'layernorm':
+                    self.post_inter_attention_normformer_norm = get_layer_norm(
+                        hidden_size, layernorm_epsilon, persist_layer_norm
+                    )
+                else:
+                    self.post_inter_attention_normformer_norm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
+
+            # Layernorm on the attention output.
+            if normalization == 'layernorm':
+                self.post_inter_attention_layernorm = get_layer_norm(
+                    hidden_size, layernorm_epsilon, persist_layer_norm
+                )
+            else:
+                self.post_inter_attention_layernorm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
+        elif self.layer_type == LayerType.retrieval_decoder:
+            self.inter_attention = ParallelChunkedCrossAttention(
+                init_method=init_method,
+                output_layer_init_method=output_layer_init_method,
+                layer_number=layer_number,
+                num_attention_heads=num_attention_heads,
+                hidden_size=hidden_size,
+                precision=precision,
+                apply_query_key_layer_scaling=apply_query_key_layer_scaling,
+                kv_channels=kv_channels,
+                use_cpu_initialization=use_cpu_initialization,
+                masked_softmax_fusion=masked_softmax_fusion,
+                attention_dropout=attention_dropout,
+                megatron_legacy=megatron_legacy,
+                chunk_size=chunk_size,
+                bias=bias,
+            )
+            # Normformer normalization
+            if transformer_block_type == 'normformer':
+                if normalization == 'layernorm':
+                    self.post_inter_attention_normformer_norm = get_layer_norm(
+                        hidden_size, layernorm_epsilon, persist_layer_norm
+                    )
+                else:
+                    self.post_inter_attention_normformer_norm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
             # Layernorm on the attention output.
-            self.post_inter_attention_layernorm = get_layer_norm(hidden_size, layernorm_epsilon, persist_layer_norm)
+            if normalization == 'layernorm':
+                self.post_inter_attention_layernorm = get_layer_norm(
+                    hidden_size, layernorm_epsilon, persist_layer_norm
+                )
+            else:
+                self.post_inter_attention_layernorm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
 
         # MLP
         self.mlp = ParallelMLP(
             init_method=init_method,
             output_layer_init_method=output_layer_init_method,
             hidden_size=hidden_size,
             ffn_hidden_size=ffn_hidden_size,
             use_cpu_initialization=use_cpu_initialization,
             bias_gelu_fusion=bias_gelu_fusion,
             openai_gelu=openai_gelu,
             onnx_safe=onnx_safe,
             activation=activation,
+            bias=bias,
+            transformer_block_type=transformer_block_type,
+            normalization=normalization,
+            layernorm_epsilon=layernorm_epsilon,
+            persist_layer_norm=persist_layer_norm,
         )
 
+    def _get_bias_droput_add_func(self, transformer_block_type='pre_ln', position_after='attention'):
+        """
+        Returns a function that potentially fuses the dropout and bias addition.
+
+        This function is particularly helpful for the normformer architecture that does not the fused kernel after attention layers, but can after the MLP.
+        """
+        # Normformer activations at this point have no bias vector since they've gone through another normalization layer.
+        if transformer_block_type == 'normformer' and position_after == 'attention':
+            bias_dropout_add_func = get_dropout_add(self.training)
+        # Bias dropout add fused kernel
+        elif self.bias and self.bias_dropout_fusion:
+            if self.training:
+                bias_dropout_add_func = bias_dropout_add_fused_train
+            else:
+                bias_dropout_add_func = bias_dropout_add_fused_inference
+        # Bias dropout add non-fused kernel
+        elif self.bias and not self.bias_dropout_fusion:
+            bias_dropout_add_func = get_bias_dropout_add(self.training)
+        # Dropout add non-fused kernel for a model without bias terms.
+        else:
+            bias_dropout_add_func = get_dropout_add(self.training)
+
+        return bias_dropout_add_func
+
     def forward(
         self,
         hidden_states,
         attention_mask,
         encoder_output=None,
         enc_dec_attn_mask=None,
         layer_past=None,
         get_key_value=False,
         set_inference_key_value_memory=False,
         inference_max_sequence_len=None,
+        rotary_pos_emb=None,  # list of positional embedding tensors, first one self attention, second one and third one are for cross attention (q, k)
     ):
         # hidden_states: [b, s, h]
 
+        # Pre-LN: x -> LN -> MHA -> Residual -> LN -> MLP -> Residual
+        # Post-LN: x -> MHA -> Residual -> LN -> MLP -> Residual -> LN
+        # Normformer: x -> LN -> MHA -> LN -> Residual -> MLP (w/LN) -> Residual
+
+        residual = hidden_states
         # Layer norm at the beginning of the transformer layer.
-        layernorm_output = self.input_layernorm(hidden_states)
+        if self.transformer_block_type in ['pre_ln', 'normformer']:
+            hidden_states = self.input_layernorm(hidden_states)
+
         # Self attention.
+        if rotary_pos_emb is not None:
+            # self attention pos_emb is (q, q)
+            self_attention_pos_emb = (rotary_pos_emb[0], rotary_pos_emb[0])
+            cross_attention_pos_emb = (rotary_pos_emb[1], rotary_pos_emb[2])
+        else:
+            self_attention_pos_emb = None
+            cross_attention_pos_emb = None
         attention_output, attention_bias = self.self_attention(
-            layernorm_output,
+            hidden_states,
             attention_mask,
             layer_past=layer_past,
             get_key_value=get_key_value,
             set_inference_key_value_memory=set_inference_key_value_memory,
             inference_max_sequence_len=inference_max_sequence_len,
+            rotary_pos_emb=self_attention_pos_emb,
         )
 
         if get_key_value:
             attention_output, presents = attention_output
 
-        # Residual connection.
-        if self.apply_residual_connection_post_layernorm:
-            residual = layernorm_output
-        else:
-            residual = hidden_states
+        # If normformer, apply norm on the output of the self attention.
+        if self.transformer_block_type == 'normformer':
+            # Normformer normalization
+            attention_output = attention_output + attention_bias if attention_bias is not None else attention_output
+            attention_output = self.post_attention_normformer_norm(attention_output)
+            attention_bias = None
 
         # jit scripting for a nn.module (with dropout) is not
         # trigerring the fusion kernel. For now, we use two
         # different nn.functional routines to account for varying
         # dropout semantics during training and inference phases.
-        if self.bias_dropout_fusion:
-            if self.training:
-                bias_dropout_add_func = bias_dropout_add_fused_train
-            else:
-                bias_dropout_add_func = bias_dropout_add_fused_inference
-        else:
-            bias_dropout_add_func = get_bias_dropout_add(self.training)
 
-        layernorm_input = bias_dropout_add_func(
-            attention_output, attention_bias.expand_as(residual), residual, self.hidden_dropout
+        bias_dropout_add_func = self._get_bias_droput_add_func(
+            transformer_block_type=self.transformer_block_type, position_after='attention'
         )
 
-        # Layer norm post the self attention.
-        layernorm_output = self.post_attention_layernorm(layernorm_input)
+        if attention_bias is not None:
+            attention_bias = attention_bias.expand_as(residual)
+
+        layernorm_input = bias_dropout_add_func(attention_output, attention_bias, residual, self.hidden_dropout)
 
-        if self.layer_type == LayerType.decoder:
+        # Post-LN normalization after residual
+        if self.transformer_block_type == 'post_ln':
+            normalization_output = self.input_layernorm(layernorm_input)
+        elif self.transformer_block_type in ['pre_ln', 'normformer']:
+            # Layer norm post the self attention.
+            normalization_output = self.post_attention_layernorm(layernorm_input)
+
+        if (
+            self.layer_type == LayerType.decoder
+            or self.layer_type == LayerType.retrieval_decoder
+            or self.layer_type == LayerType.retrieval_encoder
+        ):
             attention_output, attention_bias = self.inter_attention(
-                layernorm_output, enc_dec_attn_mask, encoder_output=encoder_output
+                normalization_output,
+                enc_dec_attn_mask,
+                encoder_output=encoder_output,
+                rotary_pos_emb=cross_attention_pos_emb,
             )
-            # residual connection
-            if self.apply_residual_connection_post_layernorm:
-                residual = layernorm_output
-            else:
-                residual = layernorm_input
+            # If normformer, apply norm on the output of the self attention.
+            if self.transformer_block_type == 'normformer':
+                # Normformer normalization
+                attention_output = (
+                    attention_output + attention_bias if attention_bias is not None else attention_output
+                )
+                attention_output = self.post_inter_attention_normformer_norm(attention_output)
+                attention_bias = None
 
-            layernorm_input = bias_dropout_add_func(
-                attention_output, attention_bias.expand_as(residual), residual, self.hidden_dropout
+            residual = layernorm_input
+
+            if attention_bias is not None:
+                attention_bias = attention_bias.expand_as(residual)
+
+            bias_dropout_add_func = self._get_bias_droput_add_func(
+                transformer_block_type=self.transformer_block_type, position_after='attention'
             )
 
-            # Layer norm post the decoder attention
-            layernorm_output = self.post_inter_attention_layernorm(layernorm_input)
+            layernorm_input = bias_dropout_add_func(attention_output, attention_bias, residual, self.hidden_dropout)
+            normalization_output = self.post_inter_attention_layernorm(layernorm_input)
 
         # MLP.
-        mlp_output, mlp_bias = self.mlp(layernorm_output)
+        mlp_output, mlp_bias = self.mlp(normalization_output)
 
-        # Second residual connection.
-        if self.apply_residual_connection_post_layernorm:
-            residual = layernorm_output
-        else:
-            residual = layernorm_input
+        residual = layernorm_input
 
-        output = bias_dropout_add_func(mlp_output, mlp_bias.expand_as(residual), residual, self.hidden_dropout)
+        if mlp_bias is not None:
+            mlp_bias = mlp_bias.expand_as(residual)
+
+        bias_dropout_add_func = self._get_bias_droput_add_func(
+            transformer_block_type=self.transformer_block_type, position_after='mlp'
+        )
+
+        output = bias_dropout_add_func(mlp_output, mlp_bias, residual, self.hidden_dropout)
+
+        if self.transformer_block_type == 'post_ln':
+            output = self.post_attention_layernorm(output)
 
         if get_key_value:
             output = [output, presents]
 
         return output
 
 
@@ -776,14 +1118,15 @@
 
     def forward(
         self,
         hidden_states,
         attention_mask,
         encoder_output=None,
         enc_dec_attn_mask=None,
+        rotary_pos_emb=None,
         layer_past=None,
         get_key_value=False,
         set_inference_key_value_memory=False,
         inference_max_sequence_len=None,
     ):
         if self.dtype == torch.float32:
             return super().forward(
@@ -791,25 +1134,27 @@
                 attention_mask,
                 encoder_output,
                 enc_dec_attn_mask,
                 layer_past,
                 get_key_value,
                 set_inference_key_value_memory,
                 inference_max_sequence_len,
+                rotary_pos_emb,
             )
         with torch.autocast(device_type="cuda", dtype=self.dtype):
             return super().forward(
                 hidden_states,
                 attention_mask,
                 encoder_output,
                 enc_dec_attn_mask,
                 layer_past,
                 get_key_value,
                 set_inference_key_value_memory,
                 inference_max_sequence_len,
+                rotary_pos_emb,
             )
 
 
 class ParallelTransformer(MegatronModule):
     """Transformer class."""
 
     def __init__(
@@ -818,34 +1163,40 @@
         output_layer_init_method,
         num_layers,
         hidden_size,
         ffn_hidden_size,
         num_attention_heads,
         apply_query_key_layer_scaling=True,
         kv_channels=None,
-        layer_type=LayerType.encoder,
+        layer_type=LayerType.encoder,  # it can be a list of types or single type
         self_attn_mask_type=AttnMaskType.padding,
         pre_process=True,
         post_process=True,
         precision=16,
         fp32_residual_connection=False,
         activations_checkpoint_method=None,
         activations_checkpoint_num_layers=1,
         layernorm_epsilon=1e-5,
         hidden_dropout=0.1,
         attention_dropout=0.1,
         use_cpu_initialization=False,
         bias_gelu_fusion=True,
+        bias_dropout_fusion=True,
         masked_softmax_fusion=True,
         persist_layer_norm=False,
         openai_gelu=False,
         onnx_safe=False,
         activation='gelu',
         model_type=ModelType.encoder_or_decoder,
         megatron_legacy=False,
+        bias=True,
+        chunk_size=64,
+        normalization='layernorm',
+        transformer_block_type='pre_ln',
+        headscale=False,
     ):
         super(ParallelTransformer, self).__init__()
 
         if kv_channels is None:
             assert (
                 hidden_size % num_attention_heads == 0
             ), 'hidden_size must be divisible by num_attention_heads if kv_channels is None'
@@ -853,14 +1204,16 @@
 
         self.fp32_residual_connection = fp32_residual_connection
         self.pre_process = pre_process
         self.post_process = post_process
         self.input_tensor = None
         self.self_attn_mask_type = self_attn_mask_type
         self.model_type = model_type
+        self.normalization = normalization
+        self.transformer_block_type = transformer_block_type
 
         # Store activation checkpointing flag.
         self.activations_checkpoint_method = activations_checkpoint_method
         self.activations_checkpoint_num_layers = activations_checkpoint_num_layers
 
         if self.model_type == ModelType.encoder_or_decoder:
             assert (
@@ -868,38 +1221,48 @@
             ), 'num_layers must be divisible by pipeline_model_parallel_size'
 
         # TODO: Add similar assert for encoder-decoder.
 
         self.num_layers = self.get_num_layers(num_layers)
         # Transformer layers.
         def build_layer(layer_number):
+            if isinstance(layer_type, list):
+                lt = layer_type[layer_number - 1]
+            else:
+                lt = layer_type
             return ParallelTransformerLayer(
                 init_method=init_method,
                 output_layer_init_method=output_layer_init_method,
                 layer_number=layer_number,
                 hidden_size=hidden_size,
                 ffn_hidden_size=ffn_hidden_size,
                 num_attention_heads=num_attention_heads,
                 apply_query_key_layer_scaling=apply_query_key_layer_scaling,
                 kv_channels=kv_channels,
-                layer_type=layer_type,
+                layer_type=lt,
                 self_attn_mask_type=self_attn_mask_type,
                 precision=precision,
                 fp32_residual_connection=fp32_residual_connection,
                 layernorm_epsilon=layernorm_epsilon,
                 hidden_dropout=hidden_dropout,
                 attention_dropout=attention_dropout,
                 use_cpu_initialization=use_cpu_initialization,
                 bias_gelu_fusion=bias_gelu_fusion,
+                bias_dropout_fusion=bias_dropout_fusion,
                 masked_softmax_fusion=masked_softmax_fusion,
                 persist_layer_norm=persist_layer_norm,
                 openai_gelu=openai_gelu,
                 onnx_safe=onnx_safe,
                 activation=activation,
                 megatron_legacy=megatron_legacy,
+                bias=bias,
+                chunk_size=chunk_size,
+                normalization=normalization,
+                transformer_block_type=transformer_block_type,
+                headscale=headscale,
             )
 
         if parallel_state.get_virtual_pipeline_model_parallel_world_size() is not None:
             assert num_layers % parallel_state.get_virtual_pipeline_model_parallel_world_size() == 0, (
                 'num_layers_per_stage must be divisible by ' 'virtual_pipeline_model_parallel_size'
             )
             assert self.model_type != ModelType.encoder_or_decoder
@@ -932,15 +1295,18 @@
             else:
                 offset = parallel_state.get_pipeline_model_parallel_rank() * self.num_layers
 
         self.layers = torch.nn.ModuleList([build_layer(i + 1 + offset) for i in range(self.num_layers)])
 
         if self.post_process:
             # Final layer norm before output.
-            self.final_layernorm = get_layer_norm(hidden_size, layernorm_epsilon, persist_layer_norm)
+            if normalization == 'layernorm':
+                self.final_layernorm = get_layer_norm(hidden_size, layernorm_epsilon, persist_layer_norm)
+            else:
+                self.final_layernorm = MixedFusedRMSNorm(hidden_size, layernorm_epsilon)
 
     def _get_layer(self, layer_number):
         return self.layers[layer_number]
 
     def get_num_layers(self, num_layers):
         """Compute the number of transformer layers resident on the current rank."""
         if parallel_state.get_pipeline_model_parallel_world_size() > 1:
@@ -962,26 +1328,27 @@
                 assert (
                     num_layers % parallel_state.get_pipeline_model_parallel_world_size() == 0
                 ), 'num_layers must be divisible by pipeline_model_parallel_size'
                 num_layers = num_layers // parallel_state.get_pipeline_model_parallel_world_size()
 
         return num_layers
 
-    def _checkpointed_forward(self, hidden_states, attention_mask, encoder_output, enc_dec_attn_mask):
+    def _checkpointed_forward(self, hidden_states, attention_mask, encoder_output, enc_dec_attn_mask, rotary_pos_emb):
         """Forward method with activation checkpointing."""
 
         def custom(start, end):
             def custom_forward(*inputs):
                 x_ = inputs[0]
                 attention_mask = inputs[1]
                 encoder_output = inputs[2]
                 enc_dec_attn_mask = inputs[3]
+                rotary_pos_emb = inputs[4]
                 for index in range(start, end):
                     layer = self._get_layer(index)
-                    x_ = layer(x_, attention_mask, encoder_output, enc_dec_attn_mask)
+                    x_ = layer(x_, attention_mask, encoder_output, enc_dec_attn_mask, rotary_pos_emb)
                 return x_
 
             return custom_forward
 
         # Make sure memory is freed.
         tensor_parallel.reset_checkpointed_activations_memory_buffer()
 
@@ -993,27 +1360,35 @@
             while l < self.num_layers:
                 hidden_states = tensor_parallel.checkpoint(
                     custom(l, l + self.activations_checkpoint_num_layers),
                     hidden_states,
                     attention_mask,
                     encoder_output,
                     enc_dec_attn_mask,
+                    rotary_pos_emb,
                 )
                 l += self.activations_checkpoint_num_layers
         elif self.activations_checkpoint_method == 'block':
             # Checkpoint the input activation of only a set number of individual
             # Transformer layers and skip the rest.
             # A method fully use the device memory removing redundant re-computation.
             for l in range(self.num_layers):
                 if l < self.activations_checkpoint_num_layers:
                     hidden_states = tensor_parallel.checkpoint(
-                        custom(l, l + 1), hidden_states, attention_mask, encoder_output, enc_dec_attn_mask
+                        custom(l, l + 1),
+                        hidden_states,
+                        attention_mask,
+                        encoder_output,
+                        enc_dec_attn_mask,
+                        rotary_pos_emb,
                     )
                 else:
-                    hidden_states = custom(l, l + 1)(hidden_states, attention_mask, encoder_output, enc_dec_attn_mask)
+                    hidden_states = custom(l, l + 1)(
+                        hidden_states, attention_mask, encoder_output, enc_dec_attn_mask, rotary_pos_emb
+                    )
         else:
             raise ValueError("Invalid activation checkpoint method.")
 
         return hidden_states
 
     def set_input_tensor(self, input_tensor):
         """Set input tensor to be used instead of forward()'s input.
@@ -1031,14 +1406,16 @@
         attention_mask,
         layer_past=None,
         get_key_value=False,
         encoder_output=None,
         enc_dec_attn_mask=None,
         set_inference_key_value_memory=False,
         inference_max_sequence_len=None,
+        rotary_pos_emb=None,  # list of positional embedding tensors, first one self attention, second one and third one are for cross attention (q, k)
+        retrieved_emb=None,  # tensor of retrieved embedding of shape [b, k, r, n, d]
     ):
         # Checks.
         if inference_max_sequence_len:
             assert self.activations_checkpoint_method is None, 'inference does not work with activation checkpointing'
 
         if layer_past is not None:
             assert get_key_value, 'for not None values in layer_past, ' 'expected get_key_value to be set'
@@ -1057,18 +1434,22 @@
                 hidden_states = hidden_states.transpose(0, 1).contiguous()
         else:
             # See set_input_tensor()
             hidden_states = self.input_tensor
 
         if encoder_output is not None:
             encoder_output = encoder_output.transpose(0, 1).contiguous()
+        elif retrieved_emb is not None:
+            assert len(retrieved_emb.shape) == 5
+            # this is retrival decoder, need special transpose
+            encoder_output = rearrange(retrieved_emb, 'b k r n d -> k r n b d').contiguous()
 
         if self.activations_checkpoint_method is not None:
             hidden_states = self._checkpointed_forward(
-                hidden_states, attention_mask, encoder_output, enc_dec_attn_mask
+                hidden_states, attention_mask, encoder_output, enc_dec_attn_mask, rotary_pos_emb
             )
         else:
             if get_key_value:
                 presents = []
             for index in range(self.num_layers):
                 layer = self._get_layer(index)
                 past = None
@@ -1079,14 +1460,15 @@
                     attention_mask,
                     encoder_output=encoder_output,
                     enc_dec_attn_mask=enc_dec_attn_mask,
                     layer_past=past,
                     get_key_value=get_key_value,
                     set_inference_key_value_memory=set_inference_key_value_memory,
                     inference_max_sequence_len=inference_max_sequence_len,
+                    rotary_pos_emb=rotary_pos_emb,
                 )
                 if get_key_value:
                     hidden_states, present = hidden_states
                     presents.append(present)
 
         # Final layer norm.
         if self.post_process:
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/megatron/utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/megatron/utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -189,15 +189,15 @@
     return [attn_mask_postprocess(attn_mask) for attn_mask in attention_mask_list]
 
 
 def build_position_ids(token_ids):
     # Create position ids
     seq_length = token_ids.size(1)
     position_ids = torch.arange(seq_length, dtype=torch.long, device=token_ids.device)
-    position_ids = position_ids.unsqueeze(0).expand_as(token_ids)
+    position_ids = position_ids.unsqueeze(0).expand_as(token_ids).clone()
 
     return position_ids
 
 
 def make_attention_mask_3d(source_mask, target_mask):
     """
     Returns a 3-dimensional (3-D) attention mask
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/prompt_encoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/t5_prompt_encoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/sequence_classifier.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/sequence_classifier.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/sequence_regression.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/sequence_regression.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/sequence_token_classifier.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/sequence_token_classifier.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/text_generation_server.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/text_generation_server.py`

 * *Files 14% similar despite different names*

```diff
@@ -26,14 +26,15 @@
 GENERATE_NUM = 0
 lock = threading.Lock()
 
 API_ALLOWED_KEYS = set(
     [
         'all_probs',
         'sentences',
+        "task_ids",
         "tokens_to_generate",
         "temperature",
         "add_BOS",
         "greedy",
         "top_k",
         "top_p",
         "repetition_penalty",
@@ -56,17 +57,29 @@
         logging.info(json.dumps(request.get_json()))
         # check keys
         for key in request.get_json().keys():
             if key not in API_ALLOWED_KEYS:
                 logging.error(f"The request key {key} is not allowed")
 
         sentences = request.get_json()["sentences"]
-        if len(sentences) > 128:
+        if isinstance(sentences, tuple):  # Input can be text or tensor
+            if len(sentences[0]) != len(sentences[1]) or sentences[0] > 128:
+                return "Maximum number of sentences is 128", 400
+        elif len(sentences) > 128:
             return "Maximum number of sentences is 128", 400
 
+        task_ids = None  # Used for ptuned/prompt tuned models only
+        if "task_ids" in request.get_json():
+            task_ids = request.get_json()["task_ids"]
+            if not isinstance(sentences, tuple):
+                return "Input at 'sentences' must by a tuple of two tensors like:\
+                    (context_tokens_tensor, context_length_tensor) if task ids are given"
+            if len(task_ids) != len(sentences[0]):
+                return "Each sentence must have a corresponding task id for p-tuned/prompt-tuned models"
+
         tokens_to_generate = 64  # Choosing hopefully sane default.  Full sequence is slow
         if "tokens_to_generate" in request.get_json():
             tokens_to_generate = request.get_json()["tokens_to_generate"]
             if not isinstance(tokens_to_generate, int):
                 return "tokens_to_generate must be an integer greater than 0"
             if tokens_to_generate < 1:
                 return "tokens_to_generate must be an integer greater than 0"
@@ -130,24 +143,28 @@
                 return "min_tokens_to_generate must be an integer no less than 0"
 
         with lock:  # Need to get lock to keep multiple threads from hitting code
             MegatronGenerate.send_do_generate()  # Tell other ranks we're doing generate
             output = generate(
                 self.model,
                 sentences,
+                task_ids,
                 tokens_to_generate,
                 all_probs,
                 temperature,
                 add_BOS,
                 top_k,
                 top_p,
                 greedy,
                 repetition_penalty,
                 min_tokens_to_generate,
             )
+            for k in output:
+                if isinstance(output[k], torch.Tensor):
+                    output[k] = output[k].tolist()
         if not all_probs:
             del output['full_logprob']
         return jsonify(output)
 
 
 class MegatronServer(object):
     def __init__(self, model):
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/text_generation_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/text_generation_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -15,30 +15,112 @@
 """Utilities for generating text."""
 
 import torch
 import torch.nn.functional as F
 
 from nemo.collections.common.tokenizers.tabular_tokenizer import TabularTokenizer
 from nemo.collections.nlp.modules.common.megatron.utils import get_ltor_masks_and_position_ids
-from nemo.collections.nlp.modules.common.transformer.text_generation import OutputType
+from nemo.collections.nlp.modules.common.transformer.text_generation import LengthParam, OutputType, SamplingParam
 from nemo.utils import AppState
 
 try:
     from apex.transformer import parallel_state, tensor_parallel
     from apex.transformer.pipeline_parallel.schedules.fwd_bwd_pipelining_without_interleaving import (
         forward_backward_pipelining_without_interleaving,
     )
     from apex.transformer.pipeline_parallel.schedules.fwd_bwd_no_pipelining import forward_backward_no_pipelining
     from apex.transformer.pipeline_parallel.utils import _reconfigure_microbatch_calculator
 
     HAVE_APEX = True
 except (ImportError, ModuleNotFoundError):
     HAVE_APEX = False
 
-__all__ = ["get_computeprob_response", "generate"]
+__all__ = [
+    "get_default_sampling_params",
+    "get_default_length_params",
+    "megatron_gpt_generate",
+    "get_computeprob_response",
+    "generate",
+]
+
+
+def get_default_sampling_params():
+    # default do greedy sampling
+    sampling_params: SamplingParam = {
+        "use_greedy": True,
+        "temperature": 1.0,
+        "top_k": 0,
+        "top_p": 1.0,
+        "repetition_penalty": 1.0,
+        "add_BOS": True,
+        "all_probs": False,
+        "compute_logprob": False,
+    }
+
+    return sampling_params
+
+
+def get_default_length_params():
+    # default do greedy sampling
+    length_params: LengthParam = {"min_length": 0, "max_length": 30}
+
+    return length_params
+
+
+def megatron_gpt_generate(model, inputs, tokenizer, length_params, sampling_params, task_ids=None):
+    # reproduce the old compute_prob method
+    # a very special case
+    if sampling_params['compute_logprob']:
+        # need to overwrite some configuration, make it immutable
+        sampling_params = sampling_params.copy()
+        length_params = length_params.copy()
+        length_params['max_length'] = 1
+        sampling_params['all_probs'] = True
+        sampling_params["add_BOS"] = False
+        sampling_params['greedy'] = True
+        response = generate(
+            model,
+            inputs=inputs,
+            task_ids=task_ids,
+            tokens_to_generate=length_params['max_length'],
+            all_probs=sampling_params['all_probs'],
+            temperature=sampling_params['temperature'],
+            add_BOS=sampling_params['add_BOS'],
+            top_k=sampling_params['top_k'],
+            top_p=sampling_params['top_p'],
+            greedy=sampling_params['use_greedy'],
+            repetition_penalty=sampling_params['repetition_penalty'],
+            min_tokens_to_generate=length_params['min_length'],
+        )
+        compute_prob_response = get_computeprob_response(tokenizer, response, inputs)
+        return compute_prob_response
+
+    if isinstance(inputs, (list, tuple)):
+        if isinstance(inputs[0], (str, torch.Tensor)):
+            output = generate(
+                model,
+                inputs=inputs,
+                task_ids=task_ids,
+                tokens_to_generate=length_params['max_length'],
+                all_probs=sampling_params['all_probs'],
+                temperature=sampling_params['temperature'],
+                add_BOS=sampling_params['add_BOS'],
+                top_k=sampling_params['top_k'],
+                top_p=sampling_params['top_p'],
+                greedy=sampling_params['use_greedy'],
+                repetition_penalty=sampling_params['repetition_penalty'],
+                min_tokens_to_generate=length_params['min_length'],
+            )
+            return output
+        elif isinstance(inputs[0], dict):
+            raise NotImplementedError("json object not implemented")
+        else:
+            raise NotImplementedError("unknown type is not implemented")
+    else:
+        raise NotImplementedError("unknown type is not implemented")
 
 
 def get_computeprob_response(tokenizer, response, inputs):
     compute_prob_response = {}
     new_token_ids = []
     new_tokens = []
     new_texts = []
@@ -153,14 +235,15 @@
     context_length_tensor = torch.cuda.LongTensor(context_lengths)
     return context_tokens_tensor, context_length_tensor
 
 
 def send_generate_info(
     context_tokens_tensor,
     context_length_tensor,
+    task_ids,
     tokens_to_generate,
     all_probs,
     temperature,
     top_k,
     top_p,
     greedy,
     repetition_penalty,
@@ -184,14 +267,15 @@
     ]
     input_info_tensor = torch.cuda.FloatTensor(input_info)
     torch.distributed.broadcast(input_info_tensor, 0)
 
     # Send variables to all ranks
     torch.distributed.broadcast(context_length_tensor, 0)
     torch.distributed.broadcast(context_tokens_tensor, 0)
+    torch.distributed.broadcast(task_ids, 0)
 
 
 def receive_generate_info():
     """
     Needs to be synced up with send_generate_info
     """
     input_info_tensor = torch.empty(10, dtype=torch.float32, device=torch.cuda.current_device())
@@ -205,22 +289,25 @@
     top_p = float(input_info_tensor[6].item())
     greedy = bool(input_info_tensor[7].item())
     repetition_penalty = float(input_info_tensor[8].item())
     min_tokens_to_generate = int(input_info_tensor[9].item())
 
     context_length_tensor = torch.empty(batch_size, dtype=torch.int64, device=torch.cuda.current_device())
     context_tokens_tensor = torch.empty(batch_size, seq_len, dtype=torch.int64, device=torch.cuda.current_device())
+    task_ids = torch.empty(batch_size, dtype=torch.int64, device=torch.cuda.current_device())
 
     # Send variables to all ranks
     torch.distributed.broadcast(context_length_tensor, 0)
     torch.distributed.broadcast(context_tokens_tensor, 0)
+    torch.distributed.broadcast(task_ids, 0)
 
     return (
         context_length_tensor,
         context_tokens_tensor,
+        task_ids,
         tokens_to_generate,
         all_probs,
         temperature,
         top_k,
         top_p,
         greedy,
         repetition_penalty,
@@ -228,14 +315,15 @@
     )
 
 
 def synced_generate(
     model,
     context_tokens_tensor,
     context_length_tensor,
+    task_ids,
     tokens_to_generate,
     all_probs,
     temperature,
     top_k=0,
     top_p=0.0,
     greedy=False,
     repetition_penalty=1.2,
@@ -256,14 +344,15 @@
             temperature=temperature,
         )
     else:
         batch_token_iterator = sample_sequence_batch(
             model,
             context_tokens_tensor,
             context_length_tensor,
+            task_ids,
             attention_mask,
             position_ids,
             tokens_to_generate,
             all_probs,
             temperature=temperature,
             extra={
                 "top_p": top_p,
@@ -309,28 +398,30 @@
     if tokens is not None:
         return tokens[:, :context_length], output_logits, full_logits
 
 
 def generate(
     model,
     inputs=None,
+    task_ids=None,
     tokens_to_generate=0,
     all_probs=False,
     temperature=1.0,
     add_BOS=False,
     top_k=0,
     top_p=0.0,
     greedy=False,
     repetition_penalty=1.0,
     min_tokens_to_generate=0,
 ) -> OutputType:
     """
     Args:
         model (NLPModel): text generative model
         inputs (Union[tuple, List[str]]): if it is a tuple, it is assumed to be (context_tokens_tensor, context_length_tensor). Otherwise it it a list of prompt text strings
+        task_ids (Tensor): used to specify that task when generating with p-tuned/prompt-tuned models (optional, default=None)
         tokens_to_generate (int): The maximum length of the tokens to be generated.
         all_probs (bool): Return the log prob for all the tokens
         temperature (float): sampling temperature
         add_BOS (bool): add the bos token at the begining of the prompt
         top_k (int): The number of highest probability vocabulary tokens to keep for top-k-filtering.
         top_p (float): If set to float < 1, only the most probable tokens with probabilities that add up to top_p or higher are kept for generation.
         greedy (bool):  Whether or not to use sampling ; use greedy decoding otherwise
@@ -350,44 +441,52 @@
     if torch.distributed.get_rank() == 0:
         if isinstance(inputs, tuple):
             context_tokens_tensor, context_length_tensor = inputs
         else:
             context_tokens_tensor, context_length_tensor = tokenize_batch(
                 tokenizer, inputs, tokens_to_generate, add_BOS
             )
+        if task_ids is None:
+            # Make a dummy tensor of -1s that won't be used during generation
+            task_ids = torch.neg(torch.ones(context_tokens_tensor.size(0), dtype=torch.int64))
+            task_ids = task_ids.to(device=context_tokens_tensor.get_device())
+
         send_generate_info(
             context_tokens_tensor,
             context_length_tensor,
+            task_ids,
             tokens_to_generate,
             all_probs,
             temperature,
             top_k,
             top_p,
             greedy,
             repetition_penalty,
             min_tokens_to_generate,
         )
     else:
         (
             context_length_tensor,
             context_tokens_tensor,
+            task_ids,
             tokens_to_generate,
             all_probs,
             temperature,
             top_k,
             top_p,
             greedy,
             repetition_penalty,
             min_tokens_to_generate,
         ) = receive_generate_info()
 
     output = synced_generate(
         model,
         context_tokens_tensor,
         context_length_tensor,
+        task_ids,
         tokens_to_generate,
         all_probs,
         temperature,
         top_k=top_k,
         top_p=top_p,
         greedy=greedy,
         repetition_penalty=repetition_penalty,
@@ -401,14 +500,17 @@
         decode_tokens = decode_tokens.cpu().numpy().tolist()
         for decode_token in decode_tokens:
             sentence = tokenizer.ids_to_text(decode_token)
             resp_sentences.append(sentence)
             if not isinstance(tokenizer, TabularTokenizer):
                 words = []
                 for token in decode_token:
+                    # Skip any soft prompt pseudo tokens
+                    if token not in tokenizer.tokenizer.decoder:
+                        continue
                     word = tokenizer.tokenizer.decoder[token]
                     word = bytearray([tokenizer.tokenizer.byte_decoder[c] for c in word]).decode(
                         'utf-8', errors='replace'
                     )
                     words.append(word)
                 resp_sentences_seg.append(words)
             else:
@@ -435,48 +537,62 @@
 
 def switch(val1, val2, boolean):
     boolean = boolean.type_as(val1)
     return (1 - boolean) * val1 + boolean * val2
 
 
 def forward_step(model, batch, tensor_shape):
+    # Importing here to avoid circular import errors
+    from nemo.collections.nlp.models.language_modeling import MegatronGPTPromptLearningModel
+
+    # Should call MegatronGPTPPromptLearningModel's forward method
+    if isinstance(model, MegatronGPTPromptLearningModel):
+        forward_model = model
+
+    # Should call GPTModel's forward method
+    else:
+        forward_model = model.model
 
     if model.cfg.get('pipeline_model_parallel_size', 1) > 1:
         output_tensor = forward_backward_pipelining_without_interleaving(
             forward_step_func=model.get_forward_output_only_func(),
             batch=batch,
-            model=model.model,
+            model=forward_model,
             forward_only=True,
             tensor_shape=tensor_shape,
             dtype=model.autocast_dtype,
         )
     else:
         output_tensor = forward_backward_no_pipelining(
             forward_step_func=model.get_forward_output_only_func(),
             batch=batch,
-            model=model.model,
+            model=forward_model,
             forward_only=True,
             tensor_shape=tensor_shape,
             dtype=model.autocast_dtype,
         )
     return output_tensor
 
 
 def sample_sequence_batch(
     model,
     context_tokens,
     context_lengths,
+    task_ids,
     attention_mask,
     position_ids,
     tokens_to_generate,
     all_probs=False,
     type_ids=None,
     temperature=None,
     extra={},
 ):
+    # Importing here to avoid circular import errors
+    from nemo.collections.nlp.models.language_modeling import MegatronGPTPromptLearningModel
+
     app_state = AppState()
     micro_batch_size = context_tokens.shape[0]
     _reconfigure_microbatch_calculator(
         rank=app_state.global_rank,
         rampup_batch_size=None,
         global_batch_size=micro_batch_size,
         micro_batch_size=micro_batch_size,
@@ -525,16 +641,22 @@
                 #     types2use = type_ids[:, context_length - 1].view(batch_size, -1)
 
             attention_mask_repeat = torch.concat([attention_mask for _ in range(micro_batch_size)])
             setkey_value_array = torch.tensor(
                 [set_inference_key_value_memory] * micro_batch_size, device=torch.cuda.current_device()
             )
             len_array = torch.tensor([maxlen] * micro_batch_size, device=torch.cuda.current_device())
-            batch = [tokens2use, attention_mask_repeat, positions2use, setkey_value_array, len_array]
-            tensor_shape = [tokens2use.shape[1], micro_batch_size, model.cfg.hidden_size]
+
+            # Only prompt learning models will have a prompt table, and require task ids
+            if isinstance(model, MegatronGPTPromptLearningModel):
+                batch = [tokens2use, attention_mask_repeat, positions2use, task_ids, setkey_value_array, len_array]
+                tensor_shape = [tokens2use.shape[1], micro_batch_size, model.model.cfg.hidden_size]
+            else:
+                batch = [tokens2use, attention_mask_repeat, positions2use, setkey_value_array, len_array]
+                tensor_shape = [tokens2use.shape[1], micro_batch_size, model.cfg.hidden_size]
 
             output = forward_step(model, batch, tensor_shape)
 
             if parallel_state.is_pipeline_last_stage():
                 output = output[0]['logits'].float()
                 output = tensor_parallel.gather_from_tensor_model_parallel_region(output)
                 assert output is not None
@@ -546,30 +668,42 @@
                 if min_length > 0:
                     within_min_length = (context_length - context_lengths) < min_length
                     logits[within_min_length, eod_id] = -float('Inf')
 
                 # make sure it won't sample outside the vocab_size range
                 logits[:, tokenizer.vocab_size :] = -float('Inf')
 
-                if extra.get('greedy', False):  # args.greedy:
+                if extra.get('greedy', False):
                     prev = torch.argmax(logits, dim=-1).view(-1)
                 else:
                     logits = logits.float()
                     logits /= temperature
                     # handle repetition penality
                     logits = repetition_penalty(logits, extra.get('repetition_penalty', 1.2), all_generated_indices)
                     logits = top_k_logits(logits, top_k=extra.get('top_k', 0), top_p=extra.get('top_p', 0.9))
                     log_probs = F.softmax(logits, dim=-1)
                     prev = torch.multinomial(log_probs, num_samples=1).view(-1)
                 started = context_lengths <= context_length
 
-                # Clamp the out of vocabulary tokens.
+                # Clamp the predicted out of vocabulary tokens
                 prev = torch.clamp(prev, max=tokenizer.vocab_size - 1)
-
                 new_tokens = switch(tokens[:, context_length].view(-1), prev, started)
+
+                # Replace sampled tokens w/ done token if EOD has already been sampled
+                new_tokens = switch(new_tokens, eod_id, is_done)
+
+                # Replace special soft prompt token ids with unk token ids
+                if isinstance(model, MegatronGPTPromptLearningModel):
+                    pseudo_token_ids_start = model.pseudo_token_ids_start
+                    new_tokens[(new_tokens >= pseudo_token_ids_start)] = tokenizer.unk_id
+                    tokens[:, :context_length][
+                        (tokens[:, :context_length] >= pseudo_token_ids_start)
+                    ] = tokenizer.unk_id
+
+                # Insert either new predicted or next prompt token
                 tokens[:, context_length] = new_tokens
 
                 if output_logits is None:
                     output_context = F.log_softmax(output[:, :context_length, :], 2)
                     indices = torch.unsqueeze(tokens[:, 1 : context_length + 1], 2)
                     output_logits = torch.gather(output_context, 2, indices).squeeze(2)
                     all_generated_indices = indices[:, :, 0]
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/token_classifier.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/token_classifier.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/tokenizer_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/tokenizer_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/bridge_encoders.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/bridge_encoders.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/perceiver_encoders.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/perceiver_encoders.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/reduction_encoders.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/reduction_encoders.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/text_generation.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/text_generation.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_bottleneck.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_bottleneck.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_decoders.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_decoders.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_encoders.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_encoders.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_generators.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_generators.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_modules.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_modules.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/common/transformer/transformer_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/common/transformer/transformer_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/dialogue_state_tracking/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/dialogue_state_tracking/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_decoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_decoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_encoder.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/modules/dialogue_state_tracking/sgd_encoder.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/parts/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/parts/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/parts/nlp_overrides.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/parts/nlp_overrides.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/nlp/parts/utils_funcs.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/parts/utils_funcs.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,28 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import nemo.collections.tts.data
-import nemo.collections.tts.helpers
-import nemo.collections.tts.models
+from nemo.utils import logging
+
+try:
+    import pynini
+
+    PYNINI_AVAILABLE = True
+except (ModuleNotFoundError, ImportError):
+    logging.warning(
+        "`pynini` is not installed ! \n"
+        "Please run the `nemo_text_processing/setup.sh` script"
+        "prior to usage of this toolkit."
+    )
+
+    PYNINI_AVAILABLE = False
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/data/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/helpers/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,8 +8,8 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import nemo.collections.tts.data.datalayers
+import nemo.collections.tts.helpers.helpers
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/data/datalayers.py` & `nemo_toolkit-1.9.0/nemo/collections/asr/data/audio_to_text.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,776 +1,1074 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-# MIT License
-
-# Copyright (c) 2019 Jeongmin Liu
-
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-
-import collections as py_collections
-import json
-import logging
+import io
 import math
 import os
-import pickle
-import random
-import shutil
-import sys
-from os.path import expanduser
-from pathlib import Path
-from typing import Any, Dict, Optional, Union
+from typing import Callable, Dict, Iterable, List, Optional, Union
 
-import librosa
+import braceexpand
 import numpy as np
-import soundfile as sf
 import torch
-from torch.nn.utils.rnn import pad_sequence
-from tqdm import tqdm
+import webdataset as wd
+from torch.utils.data import ChainDataset
 
 from nemo.collections.asr.parts.preprocessing.features import WaveformFeaturizer
-from nemo.collections.asr.parts.preprocessing.segment import AudioSegment
+from nemo.collections.common import tokenizers
 from nemo.collections.common.parts.preprocessing import collections, parsers
-from nemo.core.classes import Dataset
-from nemo.core.neural_types.elements import *
-from nemo.core.neural_types.neural_type import NeuralType
+from nemo.core.classes import Dataset, IterableDataset
+from nemo.core.neural_types import *
 from nemo.utils import logging
-from nemo.utils.decorators import deprecated
 
-DataDict = Dict[str, Any]
+__all__ = [
+    'AudioToCharDataset',
+    'AudioToBPEDataset',
+    'TarredAudioToCharDataset',
+    'TarredAudioToBPEDataset',
+]
+
+
+def _speech_collate_fn(batch, pad_id):
+    """collate batch of audio sig, audio len, tokens, tokens len
+    Args:
+        batch (Optional[FloatTensor], Optional[LongTensor], LongTensor,
+               LongTensor):  A tuple of tuples of signal, signal lengths,
+               encoded tokens, and encoded tokens length.  This collate func
+               assumes the signals are 1d torch tensors (i.e. mono audio).
+    """
+    packed_batch = list(zip(*batch))
+    if len(packed_batch) == 5:
+        _, audio_lengths, _, tokens_lengths, sample_ids = packed_batch
+    elif len(packed_batch) == 4:
+        sample_ids = None
+        _, audio_lengths, _, tokens_lengths = packed_batch
+    else:
+        raise ValueError("Expects 4 or 5 tensors in the batch!")
+    max_audio_len = 0
+    has_audio = audio_lengths[0] is not None
+    if has_audio:
+        max_audio_len = max(audio_lengths).item()
+    max_tokens_len = max(tokens_lengths).item()
 
+    audio_signal, tokens = [], []
+    for b in batch:
+        if len(b) == 5:
+            sig, sig_len, tokens_i, tokens_i_len, _ = b
+        else:
+            sig, sig_len, tokens_i, tokens_i_len = b
+        if has_audio:
+            sig_len = sig_len.item()
+            if sig_len < max_audio_len:
+                pad = (0, max_audio_len - sig_len)
+                sig = torch.nn.functional.pad(sig, pad)
+            audio_signal.append(sig)
+        tokens_i_len = tokens_i_len.item()
+        if tokens_i_len < max_tokens_len:
+            pad = (0, max_tokens_len - tokens_i_len)
+            tokens_i = torch.nn.functional.pad(tokens_i, pad, value=pad_id)
+        tokens.append(tokens_i)
 
-@deprecated(version="1.8", explanation="Please, use ``nemo.tts.collections.torch.data.VocoderDataset`` instead.")
-class AudioDataset(Dataset):
-    @property
-    def output_types(self) -> Optional[Dict[str, NeuralType]]:
-        """Returns definitions of module output ports.
-               """
-        return {
-            "audio_signal": NeuralType(("B", "T"), AudioSignal()),
-            "a_sig_length": NeuralType(tuple("B"), LengthsType()),
-        }
+    if has_audio:
+        audio_signal = torch.stack(audio_signal)
+        audio_lengths = torch.stack(audio_lengths)
+    else:
+        audio_signal, audio_lengths = None, None
+    tokens = torch.stack(tokens)
+    tokens_lengths = torch.stack(tokens_lengths)
+    if sample_ids is None:
+        return audio_signal, audio_lengths, tokens, tokens_lengths
+    else:
+        sample_ids = torch.tensor(sample_ids, dtype=torch.int32)
+        return audio_signal, audio_lengths, tokens, tokens_lengths, sample_ids
+
+
+class ASRManifestProcessor:
+    """
+    Class that processes a manifest json file containing paths to audio files, transcripts, and durations (in seconds).
+    Each new line is a different sample. Example below:
+    {"audio_filepath": "/path/to/audio.wav", "text_filepath": "/path/to/audio.txt", "duration": 23.147}
+    ...
+    {"audio_filepath": "/path/to/audio.wav", "text": "the transcription", "offset": 301.75, "duration": 0.82, "utt":
+    "utterance_id", "ctm_utt": "en_4156", "side": "A"}
+    Args:
+        manifest_filepath: Path to manifest json as described above. Can be comma-separated paths.
+        parser: Str for a language specific preprocessor or a callable.
+        max_duration: If audio exceeds this length, do not include in dataset.
+        min_duration: If audio is less than this length, do not include in dataset.
+        max_utts: Limit number of utterances.
+        bos_id: Id of beginning of sequence symbol to append if not None.
+        eos_id: Id of end of sequence symbol to append if not None.
+        pad_id: Id of pad symbol. Defaults to 0.
+    """
 
     def __init__(
         self,
-        manifest_filepath: Union[str, "pathlib.Path"],
-        n_segments: int,
+        manifest_filepath: str,
+        parser: Union[str, Callable],
         max_duration: Optional[float] = None,
         min_duration: Optional[float] = None,
-        trim: Optional[bool] = False,
-        truncate_to: Optional[int] = 1,
+        max_utts: int = 0,
+        bos_id: Optional[int] = None,
+        eos_id: Optional[int] = None,
+        pad_id: int = 0,
+        index_by_file_id: bool = False,
     ):
-        """
-        Mostly compliant with nemo.collections.asr.data.datalayers.AudioToTextDataset except it only returns Audio
-        without text. Dataset that loads tensors via a json file containing paths to audio files, transcripts, and
-        durations (in seconds). Each new line is a different sample. Note that text is required, but is ignored for
-        AudioDataset. Example below:
-        {"audio_filepath": "/path/to/audio.wav", "text_filepath":
-        "/path/to/audio.txt", "duration": 23.147}
-        ...
-        {"audio_filepath": "/path/to/audio.wav", "text": "the
-        transcription", "offset": 301.75, "duration": 0.82, "utt":
-        "utterance_id", "ctm_utt": "en_4156", "side": "A"}
-        Args:
-            manifest_filepath (str, Path): Path to manifest json as described above. Can be comma-separated paths
-                such as "train_1.json,train_2.json" which is treated as two separate json files.
-            n_segments (int): The length of audio in samples to load. For example, given a sample rate of 16kHz, and
-                n_segments=16000, a random 1 second section of audio from the clip will be loaded. The section will
-                be randomly sampled everytime the audio is batched. Can be set to -1 to load the entire audio.
-            max_duration (float): If audio exceeds this length in seconds, it is filtered from the dataset.
-                Defaults to None, which does not filter any audio.
-            min_duration(float): If audio is less than this length in seconds, it is filtered from the dataset.
-                Defaults to None, which does not filter any audio.
-            trim (bool): Whether to use librosa.effects.trim on the audio clip
-            truncate_to (int): Ensures that the audio segment returned is a multiple of truncate_to.
-                Defaults to 1, which does no truncating.
-        """
+        self.parser = parser
 
         self.collection = collections.ASRAudioText(
-            manifests_files=manifest_filepath.split(","),
-            parser=parsers.make_parser(),
+            manifests_files=manifest_filepath,
+            parser=parser,
             min_duration=min_duration,
             max_duration=max_duration,
+            max_number=max_utts,
+            index_by_file_id=index_by_file_id,
         )
-        self.trim = trim
-        self.n_segments = n_segments
-        self.truncate_to = truncate_to
-
-    def _collate_fn(self, batch):
-        """
-        Takes a batch: a lists of length batch_size, defined in the dataloader. Returns 2 padded and batched
-        tensors corresponding to the audio and audio_length.
-        """
 
-        def find_max_len(seq, index):
-            max_len = -1
-            for item in seq:
-                if item[index].size(0) > max_len:
-                    max_len = item[index].size(0)
-            return max_len
+        self.eos_id = eos_id
+        self.bos_id = bos_id
+        self.pad_id = pad_id
+
+    def process_text_by_id(self, index: int) -> (List[int], int):
+        sample = self.collection[index]
+        return self.process_text_by_sample(sample)
+
+    def process_text_by_file_id(self, file_id: str) -> (List[int], int):
+        manifest_idx = self.collection.mapping[file_id]
+        sample = self.collection[manifest_idx]
+        return self.process_text_by_sample(sample)
+
+    def process_text_by_sample(self, sample: collections.ASRAudioText.OUTPUT_TYPE) -> (List[int], int):
+        t, tl = sample.text_tokens, len(sample.text_tokens)
+
+        if self.bos_id is not None:
+            t = [self.bos_id] + t
+            tl += 1
+        if self.eos_id is not None:
+            t = t + [self.eos_id]
+            tl += 1
+
+        return t, tl
+
+
+def expand_audio_filepaths(audio_tar_filepaths, shard_strategy: str, world_size: int, global_rank: int):
+    valid_shard_strategies = ['scatter', 'replicate']
+    if shard_strategy not in valid_shard_strategies:
+        raise ValueError(f"`shard_strategy` must be one of {valid_shard_strategies}")
+
+    if isinstance(audio_tar_filepaths, str):
+        # Replace '(' and '[' with '{'
+        brace_keys_open = ['(', '[', '<', '_OP_']
+        for bkey in brace_keys_open:
+            if bkey in audio_tar_filepaths:
+                audio_tar_filepaths = audio_tar_filepaths.replace(bkey, "{")
+
+        # Replace ')' and ']' with '}'
+        brace_keys_close = [')', ']', '>', '_CL_']
+        for bkey in brace_keys_close:
+            if bkey in audio_tar_filepaths:
+                audio_tar_filepaths = audio_tar_filepaths.replace(bkey, "}")
+
+    if isinstance(audio_tar_filepaths, str):
+        # Brace expand
+        audio_tar_filepaths = list(braceexpand.braceexpand(audio_tar_filepaths))
+
+    # Check for distributed and partition shards accordingly
+    if world_size > 1:
+        if shard_strategy == 'scatter':
+            logging.info("All tarred dataset shards will be scattered evenly across all nodes.")
 
-        batch_size = len(batch)
-
-        audio_signal, audio_lengths = None, None
-        if batch[0][0] is not None:
-            if self.n_segments > 0:
-                max_audio_len = self.n_segments
-            else:
-                max_audio_len = find_max_len(batch, 0)
-
-            audio_signal = torch.zeros(batch_size, max_audio_len, dtype=torch.float)
-            audio_lengths = []
-            for i, sample in enumerate(batch):
-                audio_signal[i].narrow(0, 0, sample[0].size(0)).copy_(sample[0])
-                audio_lengths.append(sample[1])
-            audio_lengths = torch.tensor(audio_lengths, dtype=torch.long)
+            if len(audio_tar_filepaths) % world_size != 0:
+                logging.warning(
+                    f"Number of shards in tarred dataset ({len(audio_tar_filepaths)}) is not divisible "
+                    f"by number of distributed workers ({world_size})."
+                )
 
-        return audio_signal, audio_lengths
+            begin_idx = (len(audio_tar_filepaths) // world_size) * global_rank
+            end_idx = begin_idx + len(audio_tar_filepaths) // world_size
+            audio_tar_filepaths = audio_tar_filepaths[begin_idx:end_idx]
+            logging.info(
+                "Partitioning tarred dataset: process (%d) taking shards [%d, %d)", global_rank, begin_idx, end_idx
+            )
 
-    def __getitem__(self, index):
-        """
-        Given a index, returns audio and audio_length of the corresponding element. Audio clips of n_segments are
-        randomly chosen if the audio is longer than n_segments.
-        """
-        example = self.collection[index]
-        features = AudioSegment.segment_from_file(example.audio_file, n_segments=self.n_segments, trim=self.trim,)
-        features = torch.tensor(features.samples)
-        audio, audio_length = features, torch.tensor(features.shape[0]).long()
-
-        truncate = audio_length % self.truncate_to
-        if truncate != 0:
-            audio_length -= truncate.long()
-            audio = audio[:audio_length]
+        elif shard_strategy == 'replicate':
+            logging.info("All tarred dataset shards will be replicated across all nodes.")
+        else:
+            raise ValueError(f"Invalid shard strategy ! Allowed values are : {valid_shard_strategies}")
 
-        return audio, audio_length
+    return audio_tar_filepaths
 
-    def __len__(self):
-        return len(self.collection)
 
+class _AudioTextDataset(Dataset):
+    """
+    Dataset that loads tensors via a json file containing paths to audio files, transcripts, and durations (in seconds).
+    Each new line is a different sample. Example below:
+    {"audio_filepath": "/path/to/audio.wav", "text_filepath": "/path/to/audio.txt", "duration": 23.147}
+    ...
+    {"audio_filepath": "/path/to/audio.wav", "text": "the transcription", "offset": 301.75, "duration": 0.82, "utt":
+    "utterance_id", "ctm_utt": "en_4156", "side": "A"}
+    Args:
+        manifest_filepath: Path to manifest json as described above. Can be comma-separated paths.
+        parser: Str for a language specific preprocessor or a callable.
+        sample_rate (int): Sample rate to resample loaded audio to
+        int_values (bool): If true, load samples as 32-bit integers. Defauts to False.
+        augmentor (nemo.collections.asr.parts.perturb.AudioAugmentor): An AudioAugmentor object used to augment loaded
+            audio
+        max_duration: If audio exceeds this length, do not include in dataset
+        min_duration: If audio is less than this length, do not include in dataset
+        max_utts: Limit number of utterances
+        trim: whether or not to trim silence. Defaults to False
+        bos_id: Id of beginning of sequence symbol to append if not None
+        eos_id: Id of end of sequence symbol to append if not None
+        pad_id: Id of pad symbol. Defaults to 0
+        return_sample_id (bool): whether to return the sample_id as a part of each sample
+    """
 
-@deprecated(version="1.8", explanation="Please, use ``nemo.tts.collections.torch.data.VocoderDataset`` instead.")
-class MelAudioDataset(Dataset):
     @property
     def output_types(self) -> Optional[Dict[str, NeuralType]]:
         """Returns definitions of module output ports.
                """
         return {
-            "audio_signal": NeuralType(("B", "T"), AudioSignal()),
-            "audio_length": NeuralType(tuple("B"), LengthsType()),
-            "melspec": NeuralType(("B", "D", "T"), MelSpectrogramType()),
+            'audio_signal': NeuralType(('B', 'T'), AudioSignal()),
+            'a_sig_length': NeuralType(tuple('B'), LengthsType()),
+            'transcripts': NeuralType(('B', 'T'), LabelsType()),
+            'transcript_length': NeuralType(tuple('B'), LengthsType()),
+            'sample_id': NeuralType(tuple('B'), LengthsType(), optional=True),
         }
 
     def __init__(
         self,
-        manifest_filepath: Union[str, "pathlib.Path"],
-        n_segments: int,
-        max_duration: Optional[float] = float("inf"),
-        min_duration: Optional[float] = 0,
-        mel_hop_size=256,
-        mel_load_func=np.load,
+        manifest_filepath: str,
+        parser: Union[str, Callable],
+        sample_rate: int,
+        int_values: bool = False,
+        augmentor: 'nemo.collections.asr.parts.perturb.AudioAugmentor' = None,
+        max_duration: Optional[int] = None,
+        min_duration: Optional[int] = None,
+        max_utts: int = 0,
+        trim: bool = False,
+        bos_id: Optional[int] = None,
+        eos_id: Optional[int] = None,
+        pad_id: int = 0,
+        return_sample_id: bool = False,
     ):
-        """
-        `manifest_filepath` should point to a file with the following structure:
-        {"audio_filepath": "/path/to/audio.wav", "mel_filepath": "/path/to/mel.npy", "duration": 23.147}
-        where `mel.npy` is a pre-computed tensor of a melspectrogram.
-        this dataset class is used for fine-tuning vocoders with pre-computed mel-spectrograms.
-        """
-        self.collection = [json.loads(line) for line in open(manifest_filepath, "r")]
-        self.collection = list(filter(lambda item: min_duration <= item["duration"] <= max_duration, self.collection))
-        self.n_segments = n_segments
-        self.mel_hop_size = mel_hop_size
-        self.mel_load_func = mel_load_func
+        if type(manifest_filepath) == str:
+            manifest_filepath = manifest_filepath.split(",")
+
+        self.manifest_processor = ASRManifestProcessor(
+            manifest_filepath=manifest_filepath,
+            parser=parser,
+            max_duration=max_duration,
+            min_duration=min_duration,
+            max_utts=max_utts,
+            bos_id=bos_id,
+            eos_id=eos_id,
+            pad_id=pad_id,
+        )
+        self.featurizer = WaveformFeaturizer(sample_rate=sample_rate, int_values=int_values, augmentor=augmentor)
+        self.trim = trim
+        self.return_sample_id = return_sample_id
+
+    def get_manifest_sample(self, sample_id):
+        return self.manifest_processor.collection[sample_id]
 
     def __getitem__(self, index):
-        """
-        Given a index, returns audio and audio_length of the corresponding element. Audio clips of n_segments are
-        randomly chosen if the audio is longer than n_segments.
-        """
-        example = self.collection[index]
-        audio_file = example["audio_filepath"]
-        mel_file = example["mel_filepath"]
-
-        audio, sr = sf.read(audio_file)
-        audio = torch.FloatTensor(audio).unsqueeze(0)
-        mel = self.mel_load_func(mel_file)
-
-        frames = math.ceil(self.n_segments / self.mel_hop_size)
-        if audio.shape[1] > self.n_segments:
-            start = random.randint(0, mel.shape[1] - frames - 2)
-            mel = mel[:, start : start + frames]
-            audio = audio[:, start * self.mel_hop_size : (start + frames) * self.mel_hop_size]
+        sample = self.manifest_processor.collection[index]
+        offset = sample.offset
+
+        if offset is None:
+            offset = 0
+
+        features = self.featurizer.process(
+            sample.audio_file, offset=offset, duration=sample.duration, trim=self.trim, orig_sr=sample.orig_sr
+        )
+        f, fl = features, torch.tensor(features.shape[0]).long()
+
+        t, tl = self.manifest_processor.process_text_by_sample(sample=sample)
+
+        if self.return_sample_id:
+            output = f, fl, torch.tensor(t).long(), torch.tensor(tl).long(), index
         else:
-            mel = np.pad(mel, ((0, 0), (0, frames - mel.shape[1])))
-            audio = torch.nn.functional.pad(audio, (0, self.n_segments - audio.shape[1]))
+            output = f, fl, torch.tensor(t).long(), torch.tensor(tl).long()
 
-        return audio.squeeze(0), audio.shape[1], mel
+        return output
 
     def __len__(self):
-        return len(self.collection)
+        return len(self.manifest_processor.collection)
+
+    def _collate_fn(self, batch):
+        return _speech_collate_fn(batch, pad_id=self.manifest_processor.pad_id)
+
 
+class AudioToCharDataset(_AudioTextDataset):
+    """
+    Dataset that loads tensors via a json file containing paths to audio
+    files, transcripts, and durations (in seconds). Each new line is a
+    different sample. Example below:
+    {"audio_filepath": "/path/to/audio.wav", "text_filepath":
+    "/path/to/audio.txt", "duration": 23.147}
+    ...
+    {"audio_filepath": "/path/to/audio.wav", "text": "the
+    transcription", "offset": 301.75, "duration": 0.82, "utt":
+    "utterance_id", "ctm_utt": "en_4156", "side": "A"}
+    Args:
+        manifest_filepath: Path to manifest json as described above. Can
+            be comma-separated paths.
+        labels: String containing all the possible characters to map to
+        sample_rate (int): Sample rate to resample loaded audio to
+        int_values (bool): If true, load samples as 32-bit integers. Defauts to False.
+        augmentor (nemo.collections.asr.parts.perturb.AudioAugmentor): An AudioAugmentor
+            object used to augment loaded audio
+        max_duration: If audio exceeds this length, do not include in dataset
+        min_duration: If audio is less than this length, do not include
+            in dataset
+        max_utts: Limit number of utterances
+        blank_index: blank character index, default = -1
+        unk_index: unk_character index, default = -1
+        normalize: whether to normalize transcript text (default): True
+        bos_id: Id of beginning of sequence symbol to append if not None
+        eos_id: Id of end of sequence symbol to append if not None
+        return_sample_id (bool): whether to return the sample_id as a part of each sample
+    """
 
-@deprecated(version="1.8", explanation="Please, use ``nemo.tts.collections.torch.data.VocoderDataset`` instead.")
-class SplicedAudioDataset(Dataset):
     @property
     def output_types(self) -> Optional[Dict[str, NeuralType]]:
         """Returns definitions of module output ports.
                """
         return {
             'audio_signal': NeuralType(('B', 'T'), AudioSignal()),
             'a_sig_length': NeuralType(tuple('B'), LengthsType()),
+            'transcripts': NeuralType(('B', 'T'), LabelsType()),
+            'transcript_length': NeuralType(tuple('B'), LengthsType()),
+            'sample_id': NeuralType(tuple('B'), LengthsType(), optional=True),
         }
 
     def __init__(
         self,
-        manifest_filepath: Union[str, 'pathlib.Path'],
-        n_segments: int,
+        manifest_filepath: str,
+        labels: Union[str, List[str]],
+        sample_rate: int,
+        int_values: bool = False,
+        augmentor: 'nemo.collections.asr.parts.perturb.AudioAugmentor' = None,
         max_duration: Optional[float] = None,
         min_duration: Optional[float] = None,
-        trim: Optional[bool] = False,
-        truncate_to: Optional[int] = 1,
+        max_utts: int = 0,
+        blank_index: int = -1,
+        unk_index: int = -1,
+        normalize: bool = True,
+        trim: bool = False,
+        bos_id: Optional[int] = None,
+        eos_id: Optional[int] = None,
+        pad_id: int = 0,
+        parser: Union[str, Callable] = 'en',
+        return_sample_id: bool = False,
     ):
-        """
-        See above AudioDataset for details on dataset and manifest formats.
+        self.labels = labels
 
-        Unlike the regular AudioDataset, which samples random segments from each audio array as an example,
-        SplicedAudioDataset concatenates all audio arrays together and indexes segments as examples. This way,
-        the model sees more data (about 9x for LJSpeech) per epoch.
-
-        Note: this class is not recommended to be used in validation.
-
-        Args:
-            manifest_filepath (str, Path): Path to manifest json as described above. Can be comma-separated paths
-                such as "train_1.json,train_2.json" which is treated as two separate json files.
-            n_segments (int): The length of audio in samples to load. For example, given a sample rate of 16kHz, and
-                n_segments=16000, a random 1 second section of audio from the clip will be loaded. The section will
-                be randomly sampled everytime the audio is batched. Can be set to -1 to load the entire audio.
-            max_duration (float): If audio exceeds this length in seconds, it is filtered from the dataset.
-                Defaults to None, which does not filter any audio.
-            min_duration(float): If audio is less than this length in seconds, it is filtered from the dataset.
-                Defaults to None, which does not filter any audio.
-            trim (bool): Whether to use librosa.effects.trim on the audio clip
-            truncate_to (int): Ensures that the audio segment returned is a multiple of truncate_to.
-                Defaults to 1, which does no truncating.
-        """
-        assert n_segments > 0
+        parser = parsers.make_parser(
+            labels=labels, name=parser, unk_id=unk_index, blank_id=blank_index, do_normalize=normalize
+        )
 
-        collection = collections.ASRAudioText(
-            manifests_files=manifest_filepath.split(','),
-            parser=parsers.make_parser(),
-            min_duration=min_duration,
+        super().__init__(
+            manifest_filepath=manifest_filepath,
+            parser=parser,
+            sample_rate=sample_rate,
+            int_values=int_values,
+            augmentor=augmentor,
             max_duration=max_duration,
+            min_duration=min_duration,
+            max_utts=max_utts,
+            trim=trim,
+            bos_id=bos_id,
+            eos_id=eos_id,
+            pad_id=pad_id,
+            return_sample_id=return_sample_id,
         )
-        self.trim = trim
-        self.n_segments = n_segments
-        self.truncate_to = truncate_to
 
-        self.samples = []
-        for index in range(len(collection)):
-            example = collection[index]
-            with sf.SoundFile(example.audio_file, 'r') as f:
-                samples = f.read(dtype='float32').transpose()
-                self.samples.append(samples)
-        self.samples = np.concatenate(self.samples, axis=0)
-        self.samples = self.samples[: self.samples.shape[0] - (self.samples.shape[0] % self.n_segments), ...]
-
-    def __getitem__(self, index):
-        """
-        Given a index, returns audio and audio_length of the corresponding element. Audio clips of n_segments are
-        randomly chosen if the audio is longer than n_segments.
-        """
-        audio_index = index * self.n_segments
-        audio = self.samples[audio_index : audio_index + self.n_segments]
-
-        return audio, self.n_segments
-
-    def __len__(self):
-        return self.samples.shape[0] // self.n_segments
 
+class AudioToBPEDataset(_AudioTextDataset):
+    """
+    Dataset that loads tensors via a json file containing paths to audio
+    files, transcripts, and durations (in seconds). Each new line is a
+    different sample. Example below:
+    {"audio_filepath": "/path/to/audio.wav", "text_filepath":
+    "/path/to/audio.txt", "duration": 23.147}
+    ...
+    {"audio_filepath": "/path/to/audio.wav", "text": "the
+    transcription", "offset": 301.75, "duration": 0.82, "utt":
+    "utterance_id", "ctm_utt": "en_4156", "side": "A"}
+
+    In practice, the dataset and manifest used for character encoding and byte pair encoding
+    are exactly the same. The only difference lies in how the dataset tokenizes the text in
+    the manifest.
+
+    Args:
+        manifest_filepath: Path to manifest json as described above. Can
+            be comma-separated paths.
+        tokenizer: A subclass of the Tokenizer wrapper found in the common collection,
+            nemo.collections.common.tokenizers.TokenizerSpec. ASR Models support a subset of
+            all available tokenizers.
+        sample_rate (int): Sample rate to resample loaded audio to
+        int_values (bool): If true, load samples as 32-bit integers. Defauts to False.
+        augmentor (nemo.collections.asr.parts.perturb.AudioAugmentor): An AudioAugmentor
+            object used to augment loaded audio
+        max_duration: If audio exceeds this length, do not include in dataset
+        min_duration: If audio is less than this length, do not include
+            in dataset
+        max_utts: Limit number of utterances
+        trim: Whether to trim silence segments
+        use_start_end_token: Boolean which dictates whether to add [BOS] and [EOS]
+            tokens to beginning and ending of speech respectively.
+        return_sample_id (bool): whether to return the sample_id as a part of each sample
+    """
 
-@deprecated(version="1.8", explanation="Please, use ``nemo.tts.collections.torch.data.VocoderDataset`` instead.")
-class NoisySpecsDataset(Dataset):
     @property
     def output_types(self) -> Optional[Dict[str, NeuralType]]:
         """Returns definitions of module output ports.
                """
         return {
-            'x': NeuralType(('B', 'C', 'D', 'T'), SpectrogramType()),
-            'mag': NeuralType(('B', 'any', 'D', 'T'), SpectrogramType()),
-            'max_length': NeuralType(None, LengthsType()),
-            'y': NeuralType(('B', 'C', 'D', 'T'), SpectrogramType()),
-            'T_ys': NeuralType(tuple('B'), LengthsType()),
-            'length': NeuralType(tuple('B'), LengthsType()),
-            'path_speech': NeuralType(tuple('B'), StringType()),
+            'audio_signal': NeuralType(('B', 'T'), AudioSignal()),
+            'a_sig_length': NeuralType(tuple('B'), LengthsType()),
+            'transcripts': NeuralType(('B', 'T'), LabelsType()),
+            'transcript_length': NeuralType(tuple('B'), LengthsType()),
+            'sample_id': NeuralType(tuple('B'), LengthsType(), optional=True),
         }
 
     def __init__(
-        self, destination: Union[str, 'pathlib.Path'], subdir: str, n_fft: int, hop_length: int, num_snr: int,
+        self,
+        manifest_filepath: str,
+        tokenizer: 'nemo.collections.common.tokenizers.TokenizerSpec',
+        sample_rate: int,
+        int_values: bool = False,
+        augmentor: 'nemo.collections.asr.parts.perturb.AudioAugmentor' = None,
+        max_duration: Optional[int] = None,
+        min_duration: Optional[int] = None,
+        max_utts: int = 0,
+        trim: bool = False,
+        use_start_end_token: bool = True,
+        return_sample_id: bool = False,
     ):
-        self.tar_dir = Path("%s/degli_data_%d_%dx%d/%s/" % (destination, n_fft, hop_length, num_snr, subdir))
-        """
-        A modified dataset for training deep-griffin-lim iteration. Contains MSTFT (mag), STFT (y) , and noisy STFT which is
-        used for initial phase. By using different levels of noise, the Degli model can learn to improve any phase, and thus
-        it can be used iteratively.
-
-        Args:
-            destination (str, Path): Path to a directory containing the main data set folder, Similar to the directory
-            provided to the preprocessor script, which generates this dataset.
-            subdir (str): Either 'train', or 'valid', when using the standard script for generation.
-            n_fft (int): STFT parameter. Also detrmines the STFT filter length.
-            hop_length (int): STFT parameter.
-            num_snr (int): number of noisy samples per clean audio in the original dataset.
-        """
-
-        self._all_files = [f for f in os.listdir(self.tar_dir) if 'npz' in f]
+        if use_start_end_token and hasattr(tokenizer, 'bos_token'):
+            bos_id = tokenizer.bos_id
+        else:
+            bos_id = None
 
-    def __getitem__(self, index):
+        if use_start_end_token and hasattr(tokenizer, 'eos_token'):
+            eos_id = tokenizer.eos_id
+        else:
+            eos_id = None
 
-        file = Path(self.tar_dir / self._all_files[index])
-        sample = dict()
+        if hasattr(tokenizer, 'pad_token'):
+            pad_id = tokenizer.pad_id
+        else:
+            pad_id = 0
 
-        with np.load(file, mmap_mode='r') as npz_data:
-            for k, v in npz_data.items():
-                if k in ['x', 'y', 'y_mag']:
-                    sample[k] = torch.from_numpy(v)
-                elif k == "path_speech":
-                    sample[k] = str(v)
-                elif k in ['T_x', 'T_y', 'length']:
-                    sample[k] = int(v)
+        class TokenizerWrapper:
+            def __init__(self, tokenizer):
+                if isinstance(tokenizer, tokenizers.aggregate_tokenizer.AggregateTokenizer):
+                    self.is_aggregate = True
                 else:
-                    sample[k] = v
-        return sample
+                    self.is_aggregate = False
+                self._tokenizer = tokenizer
 
-    def __len__(self):
-        return len(self._all_files)
+            def __call__(self, *args):
+                t = self._tokenizer.text_to_ids(*args)
+                return t
+
+        super().__init__(
+            manifest_filepath=manifest_filepath,
+            parser=TokenizerWrapper(tokenizer),
+            sample_rate=sample_rate,
+            int_values=int_values,
+            augmentor=augmentor,
+            max_duration=max_duration,
+            min_duration=min_duration,
+            max_utts=max_utts,
+            bos_id=bos_id,
+            eos_id=eos_id,
+            pad_id=pad_id,
+            trim=trim,
+            return_sample_id=return_sample_id,
+        )
 
-    @torch.no_grad()
-    def _collate_fn(self, batch):
-        """ return data with zero-padding
 
-        Important data like x, y are all converted to Tensor(cpu).
-        :param batch:
-        :return: DataDict
-            Values can be an Tensor(cpu), list of str, ndarray of int.
+class _TarredAudioToTextDataset(IterableDataset):
+    """
+    A similar Dataset to the AudioToCharDataset/AudioToBPEDataset, but which loads tarred audio files.
+
+    Accepts a single comma-separated JSON manifest file (in the same style as for the AudioToCharDataset/AudioToBPEDataset),
+    as well as the path(s) to the tarball(s) containing the wav files. Each line of the manifest should
+    contain the information for one audio file, including at least the transcript and name of the audio
+    file within the tarball.
+
+    Valid formats for the audio_tar_filepaths argument include:
+    (1) a single string that can be brace-expanded, e.g. 'path/to/audio.tar' or 'path/to/audio_{1..100}.tar.gz', or
+    (2) a list of file paths that will not be brace-expanded, e.g. ['audio_1.tar', 'audio_2.tar', ...].
+
+    Note: For brace expansion in (1), there may be cases where `{x..y}` syntax cannot be used due to shell interference.
+    This occurs most commonly inside SLURM scripts. Therefore we provide a few equivalent replacements.
+    Supported opening braces - { <=> (, [, < and the special tag _OP_.
+    Supported closing braces - } <=> ), ], > and the special tag _CL_.
+    For SLURM based tasks, we suggest the use of the special tags for ease of use.
+
+    See the WebDataset documentation for more information about accepted data and input formats.
+
+    If using multiple workers the number of shards should be divisible by world_size to ensure an
+    even split among workers. If it is not divisible, logging will give a warning but training will proceed.
+    In addition, if using mutiprocessing, each shard MUST HAVE THE SAME NUMBER OF ENTRIES after filtering
+    is applied. We currently do not check for this, but your program may hang if the shards are uneven!
+
+    Notice that a few arguments are different from the AudioToCharDataset; for example, shuffle (bool) has been
+    replaced by shuffle_n (int).
+
+    Additionally, please note that the len() of this DataLayer is assumed to be the length of the manifest
+    after filtering. An incorrect manifest length may lead to some DataLoader issues down the line.
+
+    Args:
+        audio_tar_filepaths: Either a list of audio tarball filepaths, or a
+            string (can be brace-expandable).
+        manifest_filepath (str): Path to the manifest.
+        parser (callable): A callable which is used to pre-process the text output.
+        sample_rate (int): Sample rate to resample loaded audio to
+        int_values (bool): If true, load samples as 32-bit integers. Defauts to False.
+        augmentor (nemo.collections.asr.parts.perturb.AudioAugmentor): An AudioAugmentor
+            object used to augment loaded audio
+        shuffle_n (int): How many samples to look ahead and load to be shuffled.
+            See WebDataset documentation for more details.
+            Defaults to 0.
+        min_duration (float): Dataset parameter.
+            All training files which have a duration less than min_duration
+            are dropped. Note: Duration is read from the manifest JSON.
+            Defaults to 0.1.
+        max_duration (float): Dataset parameter.
+            All training files which have a duration more than max_duration
+            are dropped. Note: Duration is read from the manifest JSON.
+            Defaults to None.
+        max_utts (int): Limit number of utterances. 0 means no maximum.
+        blank_index (int): Blank character index, defaults to -1.
+        unk_index (int): Unknown character index, defaults to -1.
+        normalize (bool): Dataset parameter.
+            Whether to use automatic text cleaning.
+            It is highly recommended to manually clean text for best results.
+            Defaults to True.
+        trim (bool): Whether to use trim silence from beginning and end
+            of audio signal using librosa.effects.trim().
+            Defaults to False.
+        bos_id (id): Dataset parameter.
+            Beginning of string symbol id used for seq2seq models.
+            Defaults to None.
+        eos_id (id): Dataset parameter.
+            End of string symbol id used for seq2seq models.
+            Defaults to None.
+        pad_id (id): Token used to pad when collating samples in batches.
+            If this is None, pads using 0s.
+            Defaults to None.
+        shard_strategy (str): Tarred dataset shard distribution strategy chosen as a str value during ddp.
+            -   `scatter`: The default shard strategy applied by WebDataset, where each node gets
+                a unique set of shards, which are permanently pre-allocated and never changed at runtime.
+            -   `replicate`: Optional shard strategy, where each node gets all of the set of shards
+                available in the tarred dataset, which are permanently pre-allocated and never changed at runtime.
+                The benefit of replication is that it allows each node to sample data points from the entire
+                dataset independently of other nodes, and reduces dependence on value of `shuffle_n`.
+
+                Note: Replicated strategy allows every node to sample the entire set of available tarfiles,
+                and therefore more than one node may sample the same tarfile, and even sample the same
+                data points! As such, there is no assured guarantee that all samples in the dataset will be
+                sampled at least once during 1 epoch.
+        global_rank (int): Worker rank, used for partitioning shards. Defaults to 0.
+        world_size (int): Total number of processes, used for partitioning shards. Defaults to 0.
+        return_sample_id (bool): whether to return the sample_id as a part of each sample
+    """
+
+    def __init__(
+        self,
+        audio_tar_filepaths: Union[str, List[str]],
+        manifest_filepath: str,
+        parser: Callable,
+        sample_rate: int,
+        int_values: bool = False,
+        augmentor: Optional['nemo.collections.asr.parts.perturb.AudioAugmentor'] = None,
+        shuffle_n: int = 0,
+        min_duration: Optional[float] = None,
+        max_duration: Optional[float] = None,
+        max_utts: int = 0,
+        trim: bool = False,
+        bos_id: Optional[int] = None,
+        eos_id: Optional[int] = None,
+        pad_id: int = 0,
+        shard_strategy: str = "scatter",
+        global_rank: int = 0,
+        world_size: int = 0,
+        return_sample_id: bool = False,
+    ):
+        self.manifest_processor = ASRManifestProcessor(
+            manifest_filepath=manifest_filepath,
+            parser=parser,
+            max_duration=max_duration,
+            min_duration=min_duration,
+            max_utts=max_utts,
+            bos_id=bos_id,
+            eos_id=eos_id,
+            pad_id=pad_id,
+            index_by_file_id=True,  # Must set this so the manifest lines can be indexed by file ID
+        )
+
+        self.featurizer = WaveformFeaturizer(sample_rate=sample_rate, int_values=int_values, augmentor=augmentor)
+        self.trim = trim
+        self.eos_id = eos_id
+        self.bos_id = bos_id
+        self.pad_id = pad_id
+        self.return_sample_id = return_sample_id
+
+        audio_tar_filepaths = expand_audio_filepaths(
+            audio_tar_filepaths=audio_tar_filepaths,
+            shard_strategy=shard_strategy,
+            world_size=world_size,
+            global_rank=global_rank,
+        )
+
+        # Put together WebDataset
+        self._dataset = wd.WebDataset(urls=audio_tar_filepaths, nodesplitter=None)
+
+        if shuffle_n > 0:
+            self._dataset = self._dataset.shuffle(shuffle_n)
+        else:
+            logging.info("WebDataset will not shuffle files within the tar files.")
+
+        self._dataset = (
+            self._dataset.rename(audio='wav;ogg', key='__key__')
+            .to_tuple('audio', 'key')
+            .pipe(self._filter)
+            .map(f=self._build_sample)
+        )
+
+    def _filter(self, iterator):
+        """This function is used to remove samples that have been filtered out by ASRAudioText already.
+        Otherwise, we would get a KeyError as _build_sample attempts to find the manifest entry for a sample
+        that was filtered out (e.g. for duration).
+        Note that if using multi-GPU training, filtering may lead to an imbalance in samples in each shard,
+        which may make your code hang as one process will finish before the other.
         """
 
-        result = dict()
-        T_xs = np.array([item.pop('T_x') for item in batch])
-        idxs_sorted = np.argsort(T_xs)
-        T_xs = T_xs[idxs_sorted].tolist()
-        T_ys = [batch[idx].pop('T_y') for idx in idxs_sorted]
-        length = [batch[idx].pop('length') for idx in idxs_sorted]
-
-        result['T_xs'], result['T_ys'], result['length'] = T_xs, T_ys, length
-
-        for key, value in batch[0].items():
-            if type(value) == str:
-                list_data = [batch[idx][key] for idx in idxs_sorted]
-                set_data = set(list_data)
-                if len(set_data) == 1:
-                    result[key] = set_data.pop()
-                else:
-                    result[key] = list_data
-            else:
-                if len(batch) > 1:
-                    # B, T, F, C
-                    data = [batch[idx][key].permute(1, 0, 2) for idx in idxs_sorted]
-                    data = pad_sequence(data, batch_first=True)
-                    # B, C, F, T
-                    data = data.permute(0, 3, 2, 1)
-                else:  # B, C, F, T
-                    data = batch[0][key].unsqueeze(0).permute(0, 3, 1, 2)
-
-                result[key] = data.contiguous()
-
-        x = result['x']
-        mag = result['y_mag']
-        max_length = max(result['length'])
-        y = result['y']
-        T_ys = result['T_ys']
-        length = result['length']
-        path_speech = result['path_speech']
-        return x, mag, max_length, y, T_ys, length, path_speech
-
-    @staticmethod
-    @torch.no_grad()
-    def decollate_padded(batch: DataDict, idx: int) -> DataDict:
-        """ select the `idx`-th data, get rid of padded zeros and return it.
-
-        Important data like x, y are all converted to ndarray.
-        :param batch:
-        :param idx:
-        :return: DataDict
-            Values can be an str or ndarray.
+        class TarredAudioFilter:
+            def __init__(self, collection):
+                self.iterator = iterator
+                self.collection = collection
+
+            def __iter__(self):
+                return self
+
+            def __next__(self):
+                while True:
+                    audio_bytes, audio_filename = next(self.iterator)
+                    file_id, _ = os.path.splitext(os.path.basename(audio_filename))
+                    if file_id in self.collection.mapping:
+                        return audio_bytes, audio_filename
+
+        return TarredAudioFilter(self.manifest_processor.collection)
+
+    def _collate_fn(self, batch):
+        return _speech_collate_fn(batch, self.pad_id)
+
+    def _build_sample(self, tup):
+        """Builds the training sample by combining the data from the WebDataset with the manifest info.
         """
-        result = dict()
-        for key, value in batch.items():
-            if type(value) == str:
-                result[key] = value
-            elif type(value) == list:
-                result[key] = value[idx]
-            elif not key.startswith('T_'):
-                T_xy = 'T_xs' if 'x' in key else 'T_ys'
-                value = value[idx, :, :, : batch[T_xy][idx]]  # C, F, T
-                value = value.permute(1, 2, 0).contiguous()  # F, T, C
-                value = value.numpy()
-                if value.shape[-1] == 2:
-                    value = value.view(dtype=np.complex64)  # F, T, 1
-                result[key] = value
-
-        return result
-
-
-# TODO(Oktai15): remove this function when DegliModel and EDMel2SpecModel will be removed
-def setup_noise_augmented_dataset(files_list, num_snr, kwargs_stft, dest, desc):
-
-    os.makedirs(dest)
-    with open(files_list, 'r') as list_file:
-        all_lines = [line for line in list_file]
-        list_file_pbar = tqdm(all_lines, desc=desc, dynamic_ncols=True)
-
-        i_speech = 0
-        for line in list_file_pbar:
-            audio_file = line.split('|')[0]
-            speech = sf.read(audio_file)[0].astype(np.float32)
-            spec_clean = np.ascontiguousarray(librosa.stft(y=speech, **kwargs_stft))
-            mag_clean = np.ascontiguousarray(np.abs(spec_clean)[..., np.newaxis])
-            signal_power = np.mean(np.abs(speech) ** 2)
-
-            y = spec_clean.view(dtype=np.float32).reshape((*spec_clean.shape, 2))
-            ##y = torch.from_numpy(y)
-            T_y = spec_clean.shape[1]
-            ##mag_clean = torch.from_numpy(mag_clean)
-            for k in range(num_snr):
-                snr_db = -6 * np.random.rand()
-                snr = librosa.db_to_power(snr_db)
-                noise_power = signal_power / snr
-                noisy = speech + np.sqrt(noise_power) * np.random.randn(len(speech))
-                spec_noisy = librosa.stft(y=noisy, **kwargs_stft)
-                spec_noisy = np.ascontiguousarray(spec_noisy)
-                T_x = spec_noisy.shape[1]
-                x = spec_noisy.view(dtype=np.float32).reshape((*spec_noisy.shape, 2))
-                ##x = torch.from_numpy(x)
-                mdict = dict(x=x, y=y, y_mag=mag_clean, path_speech=audio_file, length=len(speech), T_x=T_x, T_y=T_y)
-                np.savez(
-                    f"{dest}/audio_{i_speech}_{k}.npz", **mdict,
-                )
-                i_speech = i_speech + 1
+        audio_bytes, audio_filename = tup
+
+        # Grab manifest entry from self.manifest_preprocessor.collection
+        file_id, _ = os.path.splitext(os.path.basename(audio_filename))
+        manifest_idx = self.manifest_processor.collection.mapping[file_id]
+        manifest_entry = self.manifest_processor.collection[manifest_idx]
+
+        offset = manifest_entry.offset
+        if offset is None:
+            offset = 0
+
+        # Convert audio bytes to IO stream for processing (for SoundFile to read)
+        audio_filestream = io.BytesIO(audio_bytes)
+        features = self.featurizer.process(
+            audio_filestream,
+            offset=offset,
+            duration=manifest_entry.duration,
+            trim=self.trim,
+            orig_sr=manifest_entry.orig_sr,
+        )
+        audio_filestream.close()
 
-    return i_speech
+        # Audio features
+        f, fl = features, torch.tensor(features.shape[0]).long()
 
+        # Text features
+        t, tl = manifest_entry.text_tokens, len(manifest_entry.text_tokens)
 
-# TODO(Oktai15): remove this function when DegliModel and EDMel2SpecModel will be removed
-def preprocess_linear_specs_dataset(valid_filelist, train_filelist, n_fft, hop_length, num_snr, destination):
-    kwargs_stft = dict(hop_length=hop_length, window='hann', center=True, n_fft=n_fft, dtype=np.complex64)
+        self.manifest_processor.process_text_by_sample(sample=manifest_entry)
 
-    tar_dir = "%s/degli_data_%d_%dx%d/" % (destination, n_fft, hop_length, num_snr)
-    if not os.path.isdir(tar_dir):
+        if self.bos_id is not None:
+            t = [self.bos_id] + t
+            tl += 1
+        if self.eos_id is not None:
+            t = t + [self.eos_id]
+            tl += 1
 
-        if valid_filelist == "none" or train_filelist == "none":
-            logging.error(f"Director {tar_dir} does not exist. Filelists for validation and train must be provided.")
-            raise NameError("Missing Argument")
+        if self.return_sample_id:
+            return f, fl, torch.tensor(t).long(), torch.tensor(tl).long(), manifest_idx
         else:
-            logging.info(
-                f"Director {tar_dir} does not exist. Preprocessing audio files listed in {valid_filelist}, {train_filelist} to create new dataset."
-            )
-        os.makedirs(tar_dir)
-        n_train = 0
-        n_valid = 0
-        try:
-            n_train = setup_noise_augmented_dataset(
-                train_filelist, num_snr, kwargs_stft, tar_dir + "train/", desc="Initializing Train Dataset"
-            )
-            n_valid = setup_noise_augmented_dataset(
-                valid_filelist, num_snr, kwargs_stft, tar_dir + "valid/", desc="Initializing Validation Dataset"
-            )
-        except FileNotFoundError as err:
-            shutil.rmtree(tar_dir)
-            raise err
-        except:
-            e = sys.exc_info()[0]
-            shutil.rmtree(tar_dir)
-            raise e
-
-        if n_train == 0:
-            shutil.rmtree(tar_dir)
-            raise EOFError("Dataset initialization failed. No files to preprocess train dataset")
-
-        if n_valid == 0:
-            shutil.rmtree(tar_dir)
-            raise EOFError("Dataset initialization failed. No files to preprocess validation dataset")
+            return f, fl, torch.tensor(t).long(), torch.tensor(tl).long()
 
-    return tar_dir
+    def get_manifest_sample(self, sample_id):
+        return self.manifest_processor.collection[sample_id]
 
+    def __iter__(self):
+        return self._dataset.__iter__()
+
+    def __len__(self):
+        return len(self.manifest_processor.collection)
 
-@deprecated(version="1.8", explanation="Please, use ``nemo.tts.collections.torch.data.TTSDataset`` instead.")
-class FastSpeech2Dataset(Dataset):
-    @property
-    def output_types(self) -> Optional[Dict[str, NeuralType]]:
-        """Returns definitions of module output ports."""
-        return {
-            'audio_signal': NeuralType(('B', 'T'), AudioSignal()),
-            'a_sig_length': NeuralType(('B'), LengthsType()),
-            'transcripts': NeuralType(('B', 'T'), TokenIndex()),
-            'transcript_length': NeuralType(('B'), LengthsType()),
-            'durations': NeuralType(('B', 'T'), TokenDurationType()),
-            'pitches': NeuralType(('B', 'T'), RegressionValuesType()),
-            'energies': NeuralType(('B', 'T'), RegressionValuesType()),
-        }
+
+class TarredAudioToCharDataset(_TarredAudioToTextDataset):
+    """
+    A similar Dataset to the AudioToCharDataset, but which loads tarred audio files.
+
+    Accepts a single comma-separated JSON manifest file (in the same style as for the AudioToCharDataset),
+    as well as the path(s) to the tarball(s) containing the wav files. Each line of the manifest should
+    contain the information for one audio file, including at least the transcript and name of the audio
+    file within the tarball.
+
+    Valid formats for the audio_tar_filepaths argument include:
+    (1) a single string that can be brace-expanded, e.g. 'path/to/audio.tar' or 'path/to/audio_{1..100}.tar.gz', or
+    (2) a list of file paths that will not be brace-expanded, e.g. ['audio_1.tar', 'audio_2.tar', ...].
+
+    See the WebDataset documentation for more information about accepted data and input formats.
+
+    If using multiple workers the number of shards should be divisible by world_size to ensure an
+    even split among workers. If it is not divisible, logging will give a warning but training will proceed.
+    In addition, if using mutiprocessing, each shard MUST HAVE THE SAME NUMBER OF ENTRIES after filtering
+    is applied. We currently do not check for this, but your program may hang if the shards are uneven!
+
+    Notice that a few arguments are different from the AudioToCharDataset; for example, shuffle (bool) has been
+    replaced by shuffle_n (int).
+
+    Additionally, please note that the len() of this DataLayer is assumed to be the length of the manifest
+    after filtering. An incorrect manifest length may lead to some DataLoader issues down the line.
+
+    Args:
+        audio_tar_filepaths: Either a list of audio tarball filepaths, or a
+            string (can be brace-expandable).
+        manifest_filepath (str): Path to the manifest.
+        labels (list): List of characters that can be output by the ASR model.
+            For Jasper, this is the 28 character set {a-z '}. The CTC blank
+            symbol is automatically added later for models using ctc.
+        sample_rate (int): Sample rate to resample loaded audio to
+        int_values (bool): If true, load samples as 32-bit integers. Defauts to False.
+        augmentor (nemo.collections.asr.parts.perturb.AudioAugmentor): An AudioAugmentor
+            object used to augment loaded audio
+        shuffle_n (int): How many samples to look ahead and load to be shuffled.
+            See WebDataset documentation for more details.
+            Defaults to 0.
+        min_duration (float): Dataset parameter.
+            All training files which have a duration less than min_duration
+            are dropped. Note: Duration is read from the manifest JSON.
+            Defaults to 0.1.
+        max_duration (float): Dataset parameter.
+            All training files which have a duration more than max_duration
+            are dropped. Note: Duration is read from the manifest JSON.
+            Defaults to None.
+        max_utts (int): Limit number of utterances. 0 means no maximum.
+        blank_index (int): Blank character index, defaults to -1.
+        unk_index (int): Unknown character index, defaults to -1.
+        normalize (bool): Dataset parameter.
+            Whether to use automatic text cleaning.
+            It is highly recommended to manually clean text for best results.
+            Defaults to True.
+        trim (bool): Whether to use trim silence from beginning and end
+            of audio signal using librosa.effects.trim().
+            Defaults to False.
+        bos_id (id): Dataset parameter.
+            Beginning of string symbol id used for seq2seq models.
+            Defaults to None.
+        eos_id (id): Dataset parameter.
+            End of string symbol id used for seq2seq models.
+            Defaults to None.
+        pad_id (id): Token used to pad when collating samples in batches.
+            If this is None, pads using 0s.
+            Defaults to None.
+        shard_strategy (str): Tarred dataset shard distribution strategy chosen as a str value during ddp.
+            -   `scatter`: The default shard strategy applied by WebDataset, where each node gets
+                a unique set of shards, which are permanently pre-allocated and never changed at runtime.
+            -   `replicate`: Optional shard strategy, where each node gets all of the set of shards
+                available in the tarred dataset, which are permanently pre-allocated and never changed at runtime.
+                The benefit of replication is that it allows each node to sample data points from the entire
+                dataset independently of other nodes, and reduces dependence on value of `shuffle_n`.
+
+                Note: Replicated strategy allows every node to sample the entire set of available tarfiles,
+                and therefore more than one node may sample the same tarfile, and even sample the same
+                data points! As such, there is no assured guarantee that all samples in the dataset will be
+                sampled at least once during 1 epoch.
+        global_rank (int): Worker rank, used for partitioning shards. Defaults to 0.
+        world_size (int): Total number of processes, used for partitioning shards. Defaults to 0.
+        return_sample_id (bool): whether to return the sample_id as a part of each sample
+    """
 
     def __init__(
         self,
+        audio_tar_filepaths: Union[str, List[str]],
         manifest_filepath: str,
-        mappings_filepath: str,
+        labels: List[str],
         sample_rate: int,
+        int_values: bool = False,
+        augmentor: Optional['nemo.collections.asr.parts.perturb.AudioAugmentor'] = None,
+        shuffle_n: int = 0,
+        min_duration: Optional[float] = None,
         max_duration: Optional[float] = None,
+        max_utts: int = 0,
+        blank_index: int = -1,
+        unk_index: int = -1,
+        normalize: bool = True,
+        trim: bool = False,
+        bos_id: Optional[int] = None,
+        eos_id: Optional[int] = None,
+        parser: Optional[str] = 'en',
+        pad_id: int = 0,
+        shard_strategy: str = "scatter",
+        global_rank: int = 0,
+        world_size: int = 0,
+        return_sample_id: bool = False,
+    ):
+        self.labels = labels
+
+        parser = parsers.make_parser(
+            labels=labels, name=parser, unk_id=unk_index, blank_id=blank_index, do_normalize=normalize
+        )
+
+        super().__init__(
+            audio_tar_filepaths=audio_tar_filepaths,
+            manifest_filepath=manifest_filepath,
+            parser=parser,
+            sample_rate=sample_rate,
+            int_values=int_values,
+            augmentor=augmentor,
+            shuffle_n=shuffle_n,
+            min_duration=min_duration,
+            max_duration=max_duration,
+            max_utts=max_utts,
+            trim=trim,
+            bos_id=bos_id,
+            eos_id=eos_id,
+            pad_id=pad_id,
+            shard_strategy=shard_strategy,
+            global_rank=global_rank,
+            world_size=world_size,
+            return_sample_id=return_sample_id,
+        )
+
+
+class TarredAudioToBPEDataset(_TarredAudioToTextDataset):
+    """
+    A similar Dataset to the AudioToBPEDataset, but which loads tarred audio files.
+
+    Accepts a single comma-separated JSON manifest file (in the same style as for the AudioToBPEDataset),
+    as well as the path(s) to the tarball(s) containing the wav files. Each line of the manifest should
+    contain the information for one audio file, including at least the transcript and name of the audio
+    file within the tarball.
+
+    Valid formats for the audio_tar_filepaths argument include:
+    (1) a single string that can be brace-expanded, e.g. 'path/to/audio.tar' or 'path/to/audio_{1..100}.tar.gz', or
+    (2) a list of file paths that will not be brace-expanded, e.g. ['audio_1.tar', 'audio_2.tar', ...].
+
+    See the WebDataset documentation for more information about accepted data and input formats.
+
+    If using multiple workers the number of shards should be divisible by world_size to ensure an
+    even split among workers. If it is not divisible, logging will give a warning but training will proceed.
+    In addition, if using mutiprocessing, each shard MUST HAVE THE SAME NUMBER OF ENTRIES after filtering
+    is applied. We currently do not check for this, but your program may hang if the shards are uneven!
+
+    Notice that a few arguments are different from the AudioToBPEDataset; for example, shuffle (bool) has been
+    replaced by shuffle_n (int).
+
+    Additionally, please note that the len() of this DataLayer is assumed to be the length of the manifest
+    after filtering. An incorrect manifest length may lead to some DataLoader issues down the line.
+
+    Args:
+        audio_tar_filepaths: Either a list of audio tarball filepaths, or a
+            string (can be brace-expandable).
+        manifest_filepath (str): Path to the manifest.
+        tokenizer (TokenizerSpec): Either a Word Piece Encoding tokenizer (BERT),
+            or a Sentence Piece Encoding tokenizer (BPE). The CTC blank
+            symbol is automatically added later for models using ctc.
+        sample_rate (int): Sample rate to resample loaded audio to
+        int_values (bool): If true, load samples as 32-bit integers. Defauts to False.
+        augmentor (nemo.collections.asr.parts.perturb.AudioAugmentor): An AudioAugmentor
+            object used to augment loaded audio
+        shuffle_n (int): How many samples to look ahead and load to be shuffled.
+            See WebDataset documentation for more details.
+            Defaults to 0.
+        min_duration (float): Dataset parameter.
+            All training files which have a duration less than min_duration
+            are dropped. Note: Duration is read from the manifest JSON.
+            Defaults to 0.1.
+        max_duration (float): Dataset parameter.
+            All training files which have a duration more than max_duration
+            are dropped. Note: Duration is read from the manifest JSON.
+            Defaults to None.
+        max_utts (int): Limit number of utterances. 0 means no maximum.
+        trim (bool): Whether to use trim silence from beginning and end
+            of audio signal using librosa.effects.trim().
+            Defaults to False.
+        use_start_end_token: Boolean which dictates whether to add [BOS] and [EOS]
+            tokens to beginning and ending of speech respectively.
+        pad_id (id): Token used to pad when collating samples in batches.
+            If this is None, pads using 0s.
+            Defaults to None.
+        shard_strategy (str): Tarred dataset shard distribution strategy chosen as a str value during ddp.
+            -   `scatter`: The default shard strategy applied by WebDataset, where each node gets
+                a unique set of shards, which are permanently pre-allocated and never changed at runtime.
+            -   `replicate`: Optional shard strategy, where each node gets all of the set of shards
+                available in the tarred dataset, which are permanently pre-allocated and never changed at runtime.
+                The benefit of replication is that it allows each node to sample data points from the entire
+                dataset independently of other nodes, and reduces dependence on value of `shuffle_n`.
+
+                Note: Replicated strategy allows every node to sample the entire set of available tarfiles,
+                and therefore more than one node may sample the same tarfile, and even sample the same
+                data points! As such, there is no assured guarantee that all samples in the dataset will be
+                sampled at least once during 1 epoch.
+        global_rank (int): Worker rank, used for partitioning shards. Defaults to 0.
+        world_size (int): Total number of processes, used for partitioning shards. Defaults to 0.
+        return_sample_id (bool): whether to return the sample_id as a part of each sample
+    """
+
+    def __init__(
+        self,
+        audio_tar_filepaths: Union[str, List[str]],
+        manifest_filepath: str,
+        tokenizer: 'nemo.collections.common.tokenizers.TokenizerSpec',
+        sample_rate: int,
+        int_values: bool = False,
+        augmentor: Optional['nemo.collections.asr.parts.perturb.AudioAugmentor'] = None,
+        shuffle_n: int = 0,
         min_duration: Optional[float] = None,
-        ignore_file: Optional[str] = None,
+        max_duration: Optional[float] = None,
+        max_utts: int = 0,
         trim: bool = False,
-        load_supplementary_values=True,  # Set to False for validation
+        use_start_end_token: bool = True,
+        shard_strategy: str = "scatter",
+        global_rank: int = 0,
+        world_size: int = 0,
+        return_sample_id: bool = False,
     ):
-        """
-        Dataset that loads audio, phonemes and their durations, pitches per frame, and energies per frame
-        for FastSpeech 2 from paths described in a JSON manifest (see the AudioDataset documentation for details
-        on the manifest format), as well as a mappings file for word to phones and phones to indices.
-        The text in the manifest is ignored; instead, the phoneme indices for prediction come from the
-        duration files.
-
-        For each sample, paths for duration, energy, and pitch files are inferred from the manifest's audio
-        filepaths by replacing '/wavs' with '/phoneme_durations', '/pitches', and '/energies', and swapping out
-        the file extension to '.pt', '.npy', and '.npy' respectively.
-        For example, given manifest audio path `/data/LJSpeech/wavs/LJ001-0001.wav`, the inferred duration and
-        phonemes file path would be `/data/LJSpeech/phoneme_durations/LJ001-0001.pt`.
-
-        Note that validation datasets only need the audio files and phoneme & duration files, set
-        `load_supplementary_values` to False for validation sets.
-
-        Args:
-            manifest_filepath (str): Path to the JSON manifest file that lists audio files.
-            mappings_filepath (str): Path to a JSON mappings file that contains mappings "word2phones" and
-                "phone2idx". The latter is used to determine the padding index.
-            sample_rate (int): Target sample rate of the audio.
-            max_duration (float): If audio exceeds this length in seconds, it is filtered from the dataset.
-                Defaults to None, which does not filter any audio.
-            min_duration (float): If audio is shorter than this length in seconds, it is filtered from the dataset.
-                Defaults to None, which does not filter any audio.
-            ignore_file (str): Optional pickled file which contains a list of files to ignore (e.g. files that
-                contain OOV words).
-                Defaults to None.
-            trim (bool): Whether to use librosa.effects.trim on the audio clip.
-                Defaults to False.
-            load_supplementary_values (bool): Whether or not to load pitch and energy files. Set this to False for
-                validation datasets.
-                Defaults to True.
-        """
-        super().__init__()
+        if use_start_end_token and hasattr(tokenizer, 'bos_token'):
+            bos_id = tokenizer.bos_id
+        else:
+            bos_id = None
 
-        # Retrieve mappings from file
-        with open(mappings_filepath, 'r') as f:
-            mappings = json.load(f)
-            self.word2phones = mappings['word2phones']
-            self.phone2idx = mappings['phone2idx']
-
-        # Load data from manifests
-        audio_files = []
-        total_duration = 0
-        if isinstance(manifest_filepath, str):
-            manifest_filepath = [manifest_filepath]
-        for manifest_file in manifest_filepath:
-            with open(expanduser(manifest_file), 'r') as f:
-                logging.info(f"Loading dataset from {manifest_file}.")
-                for line in f:
-                    item = json.loads(line)
-                    audio_files.append({"audio_filepath": item["audio_filepath"], "duration": item["duration"]})
-                    total_duration += item["duration"]
-
-        total_dataset_len = len(audio_files)
-        logging.info(f"Loaded dataset with {total_dataset_len} files totalling {total_duration/3600:.2f} hours.")
-        self.data = []
-        if load_supplementary_values:
-            dataitem = py_collections.namedtuple(
-                typename='AudioTextEntity', field_names='audio_file duration text_tokens pitches energies'
-            )
+        if use_start_end_token and hasattr(tokenizer, 'eos_token'):
+            eos_id = tokenizer.eos_id
         else:
-            dataitem = py_collections.namedtuple(
-                typename='AudioTextEntity', field_names='audio_file duration text_tokens'
-            )
+            eos_id = None
 
-        if ignore_file:
-            logging.info(f"using {ignore_file} to prune dataset.")
-            with open(ignore_file, "rb") as f:
-                wavs_to_ignore = set(pickle.load(f))
-
-        pruned_duration = 0
-        pruned_items = 0
-        for item in audio_files:
-            audio_path = item['audio_filepath']
-            LJ_id = os.path.splitext(os.path.basename(audio_path))[0]
-
-            # Prune data according to min/max_duration & the ignore file
-            if (min_duration and item["duration"] < min_duration) or (
-                max_duration and item["duration"] > max_duration
-            ):
-                pruned_duration += item["duration"]
-                pruned_items += 1
-                continue
-            if ignore_file and (LJ_id in wavs_to_ignore):
-                pruned_items += 1
-                pruned_duration += item["duration"]
-                wavs_to_ignore.remove(LJ_id)
-                continue
-
-            # Else not pruned, load additional info
-
-            # Phoneme durations and text token indices from durations file
-            dur_path = audio_path.replace('/wavs/', '/phoneme_durations/').replace('.wav', '.pt')
-            duration_info = torch.load(dur_path)
-            durs = duration_info['token_duration']
-            text_tokens = duration_info['text_encoded']
-
-            if load_supplementary_values:
-                # Load pitch file (F0s)
-                pitch_path = audio_path.replace('/wavs/', '/pitches/').replace('.wav', '.npy')
-                pitches = torch.from_numpy(np.load(pitch_path).astype(dtype='float32'))
-
-                # Load energy file (L2-norm of the amplitude of each STFT frame of an utterance)
-                energies_path = audio_path.replace('/wavs/', '/energies/').replace('.wav', '.npy')
-                energies = torch.from_numpy(np.load(energies_path))
-
-                self.data.append(
-                    dataitem(
-                        audio_file=item['audio_filepath'],
-                        duration=durs,
-                        pitches=torch.clamp(pitches, min=1e-5),
-                        energies=energies,
-                        text_tokens=text_tokens,
-                    )
-                )
-            else:
-                self.data.append(dataitem(audio_file=item['audio_filepath'], duration=durs, text_tokens=text_tokens,))
+        if hasattr(tokenizer, 'pad_token'):
+            pad_id = tokenizer.pad_id
+        else:
+            pad_id = 0
+
+        class TokenizerWrapper:
+            def __init__(self, tokenizer):
+                if isinstance(tokenizer, tokenizers.aggregate_tokenizer.AggregateTokenizer):
+                    self.is_aggregate = True
+                else:
+                    self.is_aggregate = False
+                self._tokenizer = tokenizer
 
-        logging.info(f"Pruned {pruned_items} files and {pruned_duration/3600:.2f} hours.")
-        logging.info(
-            f"Final dataset contains {len(self.data)} files and {(total_duration-pruned_duration)/3600:.2f} hours."
+            def __call__(self, *args):
+                t = self._tokenizer.text_to_ids(*args)
+                return t
+
+        super().__init__(
+            audio_tar_filepaths=audio_tar_filepaths,
+            manifest_filepath=manifest_filepath,
+            parser=TokenizerWrapper(tokenizer),
+            sample_rate=sample_rate,
+            int_values=int_values,
+            augmentor=augmentor,
+            shuffle_n=shuffle_n,
+            min_duration=min_duration,
+            max_duration=max_duration,
+            max_utts=max_utts,
+            trim=trim,
+            bos_id=bos_id,
+            eos_id=eos_id,
+            pad_id=pad_id,
+            shard_strategy=shard_strategy,
+            global_rank=global_rank,
+            world_size=world_size,
+            return_sample_id=return_sample_id,
         )
 
-        self.featurizer = WaveformFeaturizer(sample_rate=sample_rate)
-        self.trim = trim
-        self.load_supplementary_values = load_supplementary_values
 
-    def __getitem__(self, index):
-        sample = self.data[index]
+class BucketingDataset(IterableDataset):
+    """
+    A Dataset which wraps another IterableDataset and adopts it for bucketing
+    Args:
+        dataset (IterableDataset): The IterableDataset to get wrapped
+        bucketing_batch_size (int): Number of samples to build a batch
+    """
 
-        features = self.featurizer.process(sample.audio_file, trim=self.trim)
-        f, fl = features, torch.tensor(features.shape[0]).long()
-        t, tl = sample.text_tokens.long(), torch.tensor(len(sample.text_tokens)).long()
+    def __init__(
+        self, dataset: IterableDataset, bucketing_batch_size: int,
+    ):
+        self.wrapped_dataset = dataset
+        self.bucketing_batch_size = bucketing_batch_size
+        super().__init__()
 
-        if self.load_supplementary_values:
-            return f, fl, t, tl, sample.duration, sample.pitches, sample.energies
-        else:
-            return f, fl, t, tl, sample.duration, None, None
+    def _collate_fn(self, batch):
+        return _speech_collate_fn(batch[0], self.wrapped_dataset.pad_id)
 
-    def __len__(self):
-        return len(self.data)
+    def __iter__(self):
+        return BucketingIterator(
+            wrapped_iter=self.wrapped_dataset._dataset.__iter__(), bucketing_batch_size=self.bucketing_batch_size
+        ).__iter__()
 
-    def _collate_fn(self, batch):
-        pad_id = len(self.phone2idx)
-        if self.load_supplementary_values:
-            _, audio_lengths, _, tokens_lengths, duration, pitches, energies = zip(*batch)
-        else:
-            _, audio_lengths, _, tokens_lengths, duration, _, _ = zip(*batch)
-        max_audio_len = 0
-        max_audio_len = max(audio_lengths).item()
-        max_tokens_len = max(tokens_lengths).item()
-        max_durations_len = max([len(i) for i in duration])
-        max_duration_sum = max([sum(i) for i in duration])
-        if self.load_supplementary_values:
-            max_pitches_len = max([len(i) for i in pitches])
-            max_energies_len = max([len(i) for i in energies])
-            if max_pitches_len != max_energies_len or max_pitches_len != max_duration_sum:
-                logging.warning(
-                    f"max_pitches_len: {max_pitches_len} != max_energies_len: {max_energies_len} != "
-                    f"max_duration_sum:{max_duration_sum}. Your training run will error out!"
-                )
+    def __len__(self):
+        return int(math.ceil(len(self.wrapped_dataset) / float(self.bucketing_batch_size)))
 
-        # Add padding where necessary
-        audio_signal, tokens, duration_batched, pitches_batched, energies_batched = [], [], [], [], []
-        for sample_tuple in batch:
-            if self.load_supplementary_values:
-                sig, sig_len, tokens_i, tokens_i_len, duration, pitch, energy = sample_tuple
-            else:
-                sig, sig_len, tokens_i, tokens_i_len, duration, _, _ = sample_tuple
-            sig_len = sig_len.item()
-            if sig_len < max_audio_len:
-                pad = (0, max_audio_len - sig_len)
-                sig = torch.nn.functional.pad(sig, pad)
-            audio_signal.append(sig)
-            tokens_i_len = tokens_i_len.item()
-            if tokens_i_len < max_tokens_len:
-                pad = (0, max_tokens_len - tokens_i_len)
-                tokens_i = torch.nn.functional.pad(tokens_i, pad, value=pad_id)
-            tokens.append(tokens_i)
-            if len(duration) < max_durations_len:
-                pad = (0, max_durations_len - len(duration))
-                duration = torch.nn.functional.pad(duration, pad)
-            duration_batched.append(duration)
-
-            if self.load_supplementary_values:
-                pitch = pitch.squeeze(0)
-                if len(pitch) < max_pitches_len:
-                    pad = (0, max_pitches_len - len(pitch))
-                    pitch = torch.nn.functional.pad(pitch.squeeze(0), pad)
-                pitches_batched.append(pitch)
-
-                if len(energy) < max_energies_len:
-                    pad = (0, max_energies_len - len(energy))
-                    energy = torch.nn.functional.pad(energy, pad)
-                energies_batched.append(energy)
 
-        audio_signal = torch.stack(audio_signal)
-        audio_lengths = torch.stack(audio_lengths)
-        tokens = torch.stack(tokens)
-        tokens_lengths = torch.stack(tokens_lengths)
-        duration_batched = torch.stack(duration_batched)
-
-        if self.load_supplementary_values:
-            pitches_batched = torch.stack(pitches_batched)
-            energies_batched = torch.stack(energies_batched)
-            assert pitches_batched.shape == energies_batched.shape
-
-            return (
-                audio_signal,
-                audio_lengths,
-                tokens,
-                tokens_lengths,
-                duration_batched,
-                pitches_batched,
-                energies_batched,
-            )
-        return (audio_signal, audio_lengths, tokens, tokens_lengths, duration_batched, None, None)
+class BucketingIterator:
+    def __init__(self, wrapped_iter, bucketing_batch_size):
+        self.wrapped_iter = wrapped_iter
+        self.bucketing_batch_size = bucketing_batch_size
+
+    def __iter__(self):
+        return self
+
+    def __next__(self):
+        batches = []
+        for idx in range(self.bucketing_batch_size):
+            try:
+                sample = next(self.wrapped_iter)
+            except StopIteration:
+                break
+            batches.append(sample)
+        if len(batches) == 0:
+            raise StopIteration
+        return batches
+
+
+class RandomizedChainDataset(ChainDataset):
+    def __init__(self, datasets: Iterable[Dataset], rnd_seed=0) -> None:
+        super(RandomizedChainDataset, self).__init__(list(datasets))
+        self.rnd_gen = np.random.RandomState(rnd_seed)
+
+    def __iter__(self):
+        shuffled_order = self.rnd_gen.permutation(len(self.datasets))
+        for dataset_idx in shuffled_order:
+            d = self.datasets[dataset_idx]
+            assert isinstance(d, IterableDataset), "ChainDataset only supports IterableDataset"
+            for x in d:
+                yield x
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/helpers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/telephone/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,13 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-import nemo.collections.tts.helpers.helpers
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/helpers/helpers.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/helpers/helpers.py`

 * *Files 18% similar despite different names*

```diff
@@ -52,14 +52,20 @@
 from numba import jit, prange
 from numpy import ndarray
 from pesq import pesq
 from pystoi import stoi
 
 from nemo.utils import logging
 
+HAVE_WANDB = True
+try:
+    import wandb
+except ModuleNotFoundError:
+    HAVE_WANDB = False
+
 try:
     from pytorch_lightning.utilities import rank_zero_only
 except ModuleNotFoundError:
     from functools import wraps
 
     def rank_zero_only(fn):
         @wraps(fn)
@@ -87,25 +93,15 @@
         else:
             raise ValueError(f'Could not find batch_size from batch_sampler: {train_dataloader.batch_sampler}')
     else:
         raise ValueError(f'Could not find batch_size from train_dataloader: {train_dataloader}')
 
 
 def get_num_workers(trainer):
-    if trainer.accelerator is None:
-        return trainer.num_devices or 1
-    elif trainer.accelerator == "ddp_cpu":
-        return trainer.num_devices * trainer.num_nodes
-    elif trainer.accelerator == "ddp":
-        return trainer.num_devices * trainer.num_nodes
-    else:
-        logging.warning(
-            f"The lightning trainer received accelerator: {trainer.accelerator}. We " "recommend to use 'ddp' instead."
-        )
-        return trainer.num_devices * trainer.num_nodes
+    return trainer.num_devices * trainer.num_nodes
 
 
 def binarize_attention(attn, in_len, out_len):
     """Convert soft attention matrix to hard attention matrix.
 
     Args:
         attn (torch.Tensor): B x 1 x max_mel_len x max_text_len. Soft attention matrix.
@@ -290,14 +286,15 @@
         )
         swriter.add_image(
             f"{tag}_gate",
             plot_gate_outputs_to_numpy(gate_target[0].data.cpu().numpy(), torch.sigmoid(gate[0]).data.cpu().numpy(),),
             step,
             dataformats="HWC",
         )
+
         if add_audio:
             filterbank = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels, fmax=fmax)
             log_mel = mel_postnet[0].data.cpu().numpy().T
             mel = np.exp(log_mel)
             magnitude = np.dot(mel, filterbank) * griffin_lim_mag_scale
             audio = griffin_lim(magnitude.T ** griffin_lim_power)
             swriter.add_audio(f"audio/{tag}_predicted", audio / max(np.abs(audio)), step, sample_rate=sr)
@@ -305,14 +302,75 @@
             log_mel = spec_target[0].data.cpu().numpy().T
             mel = np.exp(log_mel)
             magnitude = np.dot(mel, filterbank) * griffin_lim_mag_scale
             audio = griffin_lim(magnitude.T ** griffin_lim_power)
             swriter.add_audio(f"audio/{tag}_target", audio / max(np.abs(audio)), step, sample_rate=sr)
 
 
+def tacotron2_log_to_wandb_func(
+    swriter,
+    tensors,
+    step,
+    tag="train",
+    log_images=False,
+    log_images_freq=1,
+    add_audio=True,
+    griffin_lim_mag_scale=1024,
+    griffin_lim_power=1.2,
+    sr=22050,
+    n_fft=1024,
+    n_mels=80,
+    fmax=8000,
+):
+    _, spec_target, mel_postnet, gate, gate_target, alignments = tensors
+    if not HAVE_WANDB:
+        return
+    if log_images and step % log_images_freq == 0:
+        alignments = []
+        specs = []
+        gates = []
+        alignments += [
+            wandb.Image(plot_alignment_to_numpy(alignments[0].data.cpu().numpy().T), caption=f"{tag}_alignment",)
+        ]
+        alignments += [
+            wandb.Image(plot_spectrogram_to_numpy(spec_target[0].data.cpu().numpy()), caption=f"{tag}_mel_target",),
+            wandb.Image(plot_spectrogram_to_numpy(mel_postnet[0].data.cpu().numpy()), caption=f"{tag}_mel_predicted",),
+        ]
+        gates += [
+            wandb.Image(
+                plot_gate_outputs_to_numpy(
+                    gate_target[0].data.cpu().numpy(), torch.sigmoid(gate[0]).data.cpu().numpy(),
+                ),
+                caption=f"{tag}_gate",
+            )
+        ]
+
+        swriter.log({"specs": specs, "alignments": alignments, "gates": gates})
+
+        if add_audio:
+            audios = []
+            filterbank = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels, fmax=fmax)
+            log_mel = mel_postnet[0].data.cpu().numpy().T
+            mel = np.exp(log_mel)
+            magnitude = np.dot(mel, filterbank) * griffin_lim_mag_scale
+            audio_pred = griffin_lim(magnitude.T ** griffin_lim_power)
+
+            log_mel = spec_target[0].data.cpu().numpy().T
+            mel = np.exp(log_mel)
+            magnitude = np.dot(mel, filterbank) * griffin_lim_mag_scale
+            audio_true = griffin_lim(magnitude.T ** griffin_lim_power)
+
+            audios += [
+                wandb.Audio(audio_true / max(np.abs(audio_true)), caption=f"{tag}_wav_target", sample_rate=sr,),
+                wandb.Audio(audio_pred / max(np.abs(audio_pred)), caption=f"{tag}_wav_predicted", sample_rate=sr,),
+            ]
+
+            swriter.log({"audios": audios})
+
+
 def plot_alignment_to_numpy(alignment, info=None):
     fig, ax = plt.subplots(figsize=(6, 4))
     im = ax.imshow(alignment, aspect='auto', origin='lower', interpolation='none')
     fig.colorbar(im, ax=ax)
     xlabel = 'Decoder timestep'
     if info is not None:
         xlabel += '\n\n' + info
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/losses/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,16 +1,28 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import nemo.collections.tts.losses.tacotron2loss
-import nemo.collections.tts.losses.waveglowloss
+from nemo.utils import logging
+
+try:
+    import pynini
+
+    PYNINI_AVAILABLE = True
+except (ModuleNotFoundError, ImportError):
+    logging.warning(
+        "`pynini` is not installed ! \n"
+        "Please run the `nemo_text_processing/setup.sh` script "
+        "prior to usage of this toolkit."
+    )
+
+    PYNINI_AVAILABLE = False
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/losses/aligner_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/losses/aligner_loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/losses/fastpitchloss.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/losses/fastpitchloss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/losses/glow_tts_loss.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/losses/hifigan_losses.py`

 * *Files 26% similar despite different names*

```diff
@@ -8,74 +8,125 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-# MIT License
+
+#  MIT License
 #
-# Copyright (c) 2020 Jaehyeon Kim
+#  Copyright (c) 2020 Jungil Kong
 #
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
+#  Permission is hereby granted, free of charge, to any person obtaining a copy
+#  of this software and associated documentation files (the "Software"), to deal
+#  in the Software without restriction, including without limitation the rights
+#  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+#  copies of the Software, and to permit persons to whom the Software is
+#  furnished to do so, subject to the following conditions:
 #
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
+#  The above copyright notice and this permission notice shall be included in all
+#  copies or substantial portions of the Software.
 #
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
+#  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+#  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+#  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+#  SOFTWARE.
 
-import math
+# The forward functions onf the following classes are based on code from https://github.com/jik876/hifi-gan:
+# FeatureMatchingLoss, DiscriminatorLoss, GeneratorLoss
 
 import torch
 
 from nemo.core.classes import Loss, typecheck
-from nemo.core.neural_types.elements import *
+from nemo.core.neural_types.elements import LossType, VoidType
 from nemo.core.neural_types.neural_type import NeuralType
 
 
-class GlowTTSLoss(Loss):
-    """
-    Loss for the GlowTTS model
-    """
+class FeatureMatchingLoss(Loss):
+    """Feature Matching Loss module"""
+
+    @property
+    def input_types(self):
+        return {
+            "fmap_r": [[NeuralType(elements_type=VoidType())]],
+            "fmap_g": [[NeuralType(elements_type=VoidType())]],
+        }
+
+    @property
+    def output_types(self):
+        return {
+            "loss": NeuralType(elements_type=LossType()),
+        }
+
+    @typecheck()
+    def forward(self, fmap_r, fmap_g):
+        loss = 0
+        for dr, dg in zip(fmap_r, fmap_g):
+            for rl, gl in zip(dr, dg):
+                loss += torch.mean(torch.abs(rl - gl))
+
+        return loss * 2
+
+
+class DiscriminatorLoss(Loss):
+    """Discriminator Loss module"""
 
     @property
     def input_types(self):
         return {
-            "z": NeuralType(('B', 'D', 'T'), NormalDistributionSamplesType()),
-            "y_m": NeuralType(('B', 'D', 'T'), NormalDistributionMeanType()),
-            "y_logs": NeuralType(('B', 'D', 'T'), NormalDistributionLogVarianceType()),
-            "logdet": NeuralType(('B',), LogDeterminantType()),
-            "logw": NeuralType(('B', 'T'), TokenLogDurationType()),
-            "logw_": NeuralType(('B', 'T'), TokenLogDurationType()),
-            "x_lengths": NeuralType(('B',), LengthsType()),
-            "y_lengths": NeuralType(('B',), LengthsType()),
+            "disc_real_outputs": [NeuralType(('B', 'T'), VoidType())],
+            "disc_generated_outputs": [NeuralType(('B', 'T'), VoidType())],
         }
 
     @property
     def output_types(self):
         return {
-            "l_mle": NeuralType(elements_type=LossType()),
-            "l_length": NeuralType(elements_type=LossType()),
-            "logdet": NeuralType(elements_type=VoidType()),
+            "loss": NeuralType(elements_type=LossType()),
+            "real_losses": [NeuralType(elements_type=LossType())],
+            "fake_losses": [NeuralType(elements_type=LossType())],
         }
 
     @typecheck()
-    def forward(self, z, y_m, y_logs, logdet, logw, logw_, x_lengths, y_lengths):
+    def forward(self, disc_real_outputs, disc_generated_outputs):
+        loss = 0
+        r_losses = []
+        g_losses = []
+        for dr, dg in zip(disc_real_outputs, disc_generated_outputs):
+            r_loss = torch.mean((1 - dr) ** 2)
+            g_loss = torch.mean(dg ** 2)
+            loss += r_loss + g_loss
+            r_losses.append(r_loss.item())
+            g_losses.append(g_loss.item())
+
+        return loss, r_losses, g_losses
+
+
+class GeneratorLoss(Loss):
+    """Generator Loss module"""
 
-        logdet = torch.sum(logdet)
-        l_mle = 0.5 * math.log(2 * math.pi) + (
-            torch.sum(y_logs) + 0.5 * torch.sum(torch.exp(-2 * y_logs) * (z - y_m) ** 2) - logdet
-        ) / (torch.sum(y_lengths) * z.shape[1])
+    @property
+    def input_types(self):
+        return {
+            "disc_outputs": [NeuralType(('B', 'T'), VoidType())],
+        }
+
+    @property
+    def output_types(self):
+        return {
+            "loss": NeuralType(elements_type=LossType()),
+            "fake_losses": [NeuralType(elements_type=LossType())],
+        }
+
+    @typecheck()
+    def forward(self, disc_outputs):
+        loss = 0
+        gen_losses = []
+        for dg in disc_outputs:
+            l = torch.mean((1 - dg) ** 2)
+            gen_losses.append(l)
+            loss += l
 
-        l_length = torch.sum((logw - logw_) ** 2) / torch.sum(x_lengths)
-        return l_mle, l_length, logdet
+        return loss, gen_losses
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/losses/stftlosses.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/losses/stftlosses.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/losses/tacotron2loss.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/losses/tacotron2loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/losses/waveglowloss.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/losses/waveglowloss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/aligner.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/aligner.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/base.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,23 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 from abc import ABC, abstractmethod
 from contextlib import ExitStack, contextmanager
 
 import torch
-from torch_stft import STFT
 
 from nemo.collections.tts.helpers.helpers import OperationMode
 from nemo.collections.tts.models import *  # Avoid circular imports
 from nemo.core.classes import ModelPT
 from nemo.core.classes.common import typecheck
 from nemo.core.neural_types.elements import AudioSignal
 from nemo.core.neural_types.neural_type import NeuralType
-from nemo.utils import logging
 
 
 class SpectrogramGenerator(ModelPT, ABC):
     """ Base class for all TTS models that turn text into a spectrogram """
 
     @abstractmethod
     def parse(self, str_input: str, **kwargs) -> 'torch.tensor':
@@ -127,50 +125,43 @@
         with ExitStack() as stack:
             stack.enter_context(self.temp_mode(OperationMode.infer))
             stack.enter_context(torch.no_grad())
             yield
 
     def check_children_attributes(self):
         if self.stft is None:
-            if isinstance(self.audio_to_melspec_precessor.stft, STFT):
-                logging.warning(
-                    "torch_stft is deprecated. Please change your model to use torch.stft and torch.istft instead."
-                )
-                self.stft = self.audio_to_melspec_precessor.stft.transform
-                self.istft = self.audio_to_melspec_precessor.stft.inverse
-            else:
-                try:
-                    n_fft = self.audio_to_melspec_precessor.n_fft
-                    hop_length = self.audio_to_melspec_precessor.hop_length
-                    win_length = self.audio_to_melspec_precessor.win_length
-                    window = self.audio_to_melspec_precessor.window.to(self.device)
-                except AttributeError as e:
-                    raise AttributeError(
-                        f"{self} could not find a valid audio_to_melspec_precessor. GlowVocoder requires child class "
-                        "to have audio_to_melspec_precessor defined to obtain stft parameters. "
-                        "audio_to_melspec_precessor requires n_fft, hop_length, win_length, window, and nfilt to be "
-                        "defined."
-                    ) from e
-
-                def yet_another_patch(audio, n_fft, hop_length, win_length, window):
-                    spec = torch.stft(audio, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window)
-                    if spec.dtype in [torch.cfloat, torch.cdouble]:
-                        spec = torch.view_as_real(spec)
-                    return torch.sqrt(spec.pow(2).sum(-1)), torch.atan2(spec[..., -1], spec[..., 0])
-
-                self.stft = lambda x: yet_another_patch(
-                    x, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window,
-                )
-                self.istft = lambda x, y: torch.istft(
-                    torch.complex(x * torch.cos(y), x * torch.sin(y)),
-                    n_fft=n_fft,
-                    hop_length=hop_length,
-                    win_length=win_length,
-                    window=window,
-                )
+            try:
+                n_fft = self.audio_to_melspec_precessor.n_fft
+                hop_length = self.audio_to_melspec_precessor.hop_length
+                win_length = self.audio_to_melspec_precessor.win_length
+                window = self.audio_to_melspec_precessor.window.to(self.device)
+            except AttributeError as e:
+                raise AttributeError(
+                    f"{self} could not find a valid audio_to_melspec_precessor. GlowVocoder requires child class "
+                    "to have audio_to_melspec_precessor defined to obtain stft parameters. "
+                    "audio_to_melspec_precessor requires n_fft, hop_length, win_length, window, and nfilt to be "
+                    "defined."
+                ) from e
+
+            def yet_another_patch(audio, n_fft, hop_length, win_length, window):
+                spec = torch.stft(audio, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window)
+                if spec.dtype in [torch.cfloat, torch.cdouble]:
+                    spec = torch.view_as_real(spec)
+                return torch.sqrt(spec.pow(2).sum(-1)), torch.atan2(spec[..., -1], spec[..., 0])
+
+            self.stft = lambda x: yet_another_patch(
+                x, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=window,
+            )
+            self.istft = lambda x, y: torch.istft(
+                torch.complex(x * torch.cos(y), x * torch.sin(y)),
+                n_fft=n_fft,
+                hop_length=hop_length,
+                win_length=win_length,
+                window=window,
+            )
 
         if self.n_mel is None:
             try:
                 self.n_mel = self.audio_to_melspec_precessor.nfilt
             except AttributeError as e:
                 raise AttributeError(
                     f"{self} could not find a valid audio_to_melspec_precessor. GlowVocoder requires child class to "
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/degli.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/univnet.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,307 +1,276 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-# MIT License
+import itertools
+from typing import Dict
 
-# Copyright (c) 2019 Jeongmin Liu
-
-# Permission is hereby granted, free of charge, to any person obtaining a copy
-# of this software and associated documentation files (the "Software"), to deal
-# in the Software without restriction, including without limitation the rights
-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-# copies of the Software, and to permit persons to whom the Software is
-# furnished to do so, subject to the following conditions:
-
-# The above copyright notice and this permission notice shall be included in all
-# copies or substantial portions of the Software.
-
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-import warnings
-from dataclasses import dataclass
-from typing import Any, Dict, Optional, Sequence
-
-import librosa
-import numpy as np
-import soundfile as sf
 import torch
+import torch.nn.functional as F
 from hydra.utils import instantiate
-from numpy import ndarray
-from omegaconf import MISSING, DictConfig, OmegaConf, open_dict
-from torch import Tensor, nn
-
-from nemo.collections.tts.helpers.helpers import eval_tts_scores
-from nemo.collections.tts.models.base import LinVocoder
-from nemo.collections.tts.modules.degli import OperationMode
+from omegaconf import DictConfig, open_dict
+from pytorch_lightning.loggers.wandb import WandbLogger
+
+from nemo.collections.tts.helpers.helpers import get_batch_size, get_num_workers, plot_spectrogram_to_numpy
+from nemo.collections.tts.losses.hifigan_losses import DiscriminatorLoss, GeneratorLoss
+from nemo.collections.tts.losses.stftlosses import MultiResolutionSTFTLoss
+from nemo.collections.tts.models.base import Vocoder
+from nemo.collections.tts.modules.univnet_modules import MultiPeriodDiscriminator, MultiResolutionDiscriminator
+from nemo.collections.tts.torch.data import VocoderDataset
+from nemo.core import Exportable
 from nemo.core.classes.common import PretrainedModelInfo, typecheck
-from nemo.core.neural_types.elements import IntType, LengthsType, SpectrogramType
+from nemo.core.neural_types.elements import AudioSignal, MelSpectrogramType
 from nemo.core.neural_types.neural_type import NeuralType
-from nemo.utils import logging
-from nemo.utils.decorators import deprecated
+from nemo.core.optim.lr_scheduler import compute_max_steps
+from nemo.utils import logging, model_utils
 
+HAVE_WANDB = True
+try:
+    import wandb
+except ModuleNotFoundError:
+    HAVE_WANDB = False
 
-@dataclass
-class DegliConfig:
-    degli: Dict[Any, Any] = MISSING
-    train_ds: Optional[Dict[Any, Any]] = None
-    validation_ds: Optional[Dict[Any, Any]] = None
-    train_params: Optional[Dict[Any, Any]] = None
-    sched: Optional[Dict[Any, Any]] = None
-
-
-def reconstruct_wave(*args: ndarray, kwargs_istft, n_sample=-1) -> ndarray:
-    """
-    construct time-domain wave from complex spectrogram
-    Args:
-        *args: the complex spectrogram.
-        kwargs_istft: arguments of Inverse STFT.
-        n_sample: expected audio length.
-    Returns:
-        audio (numpy)
-    """
-
-    if len(args) == 1:
-        spec = args[0].squeeze()
-        mag = None
-        phase = None
-        assert np.iscomplexobj(spec)
-    elif len(args) == 2:
-        spec = None
-        mag = args[0].squeeze()
-        phase = args[1].squeeze()
-        assert np.isrealobj(mag) and np.isrealobj(phase)
-    else:
-        raise ValueError
-
-    kwarg_len = dict(length=n_sample) if n_sample != -1 else dict()
-    if spec is None:
-        spec = mag * np.exp(1j * phase)
-
-    wave = librosa.istft(stft_matrix=spec, **kwargs_istft, **kwarg_len)
-    return wave
-
-
-@deprecated(version="1.9", explanation="DegliModel will be removed.")
-class DegliModel(LinVocoder):
-    """Deep Griffin Lim model used to convert between spectrograms and audio"""
-
-    def __init__(self, cfg: DictConfig, trainer: 'Trainer' = None):
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
-        super().__init__(cfg=cfg, trainer=trainer)
 
-        schema = OmegaConf.structured(DegliConfig)
-        # ModelPT ensures that cfg is a DictConfig, but do this second check in case ModelPT changes
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
-        elif not isinstance(cfg, DictConfig):
-            raise ValueError(f"cfg was type: {type(cfg)}. Expected either a dict or a DictConfig")
-        # Ensure passed cfg is compliant with schema
-        OmegaConf.merge(cfg, schema)
-
-        self.degli = instantiate(self._cfg.degli)
-        self.mode = OperationMode.infer
-        self.criterion = nn.L1Loss(reduction='none')  # maybe should be loss subclass?
-        self.l_hop = self._cfg.degli.hop_length
-        self.n_fft = self._cfg.degli.n_fft
-        self.kwargs_stft = dict(hop_length=self.l_hop, window='hann', center=True, n_fft=self.n_fft, dtype=np.float32)
-        self.kwargs_istft = dict(hop_length=self.l_hop, window='hann', center=True, dtype=np.float32)
-
-        len_weight = self._cfg.train_params.repeat_training
-        self.loss_weight = nn.Parameter(torch.tensor([1.0 / i for i in range(len_weight, 0, -1)]), requires_grad=False)
-        self.loss_weight /= self.loss_weight.sum()
+class UnivNetModel(Vocoder, Exportable):
+    """UnivNet model (https://arxiv.org/abs/2106.07889) that is used to generate audio from mel spectrogram."""
 
-    @property
-    def mode(self):
-        return self._mode
+    def __init__(self, cfg: DictConfig, trainer: 'Trainer' = None):
+        # Convert to Hydra 1.0 compatible DictConfig
+        cfg = model_utils.convert_model_config_to_dict_config(cfg)
+        cfg = model_utils.maybe_update_config_version(cfg)
 
-    @mode.setter
-    def mode(self, new_mode):
-        if new_mode == OperationMode.training:
-            self.train()
-        else:
-            self.eval()
-        self._mode = new_mode
-        self.degli.mode = new_mode
+        super().__init__(cfg=cfg, trainer=trainer)
 
-    @property
-    def input_types(self):
-        return {
-            "x": NeuralType(('B', 'C', 'D', 'T'), SpectrogramType()),
-            "mag": NeuralType(('B', 'any', 'D', 'T'), SpectrogramType()),
-            "max_length": NeuralType(None, LengthsType()),
-            "repeats": NeuralType(None, IntType()),
-        }
+        self.audio_to_melspec_precessor = instantiate(cfg.preprocessor)
+        # We use separate preprocessor for training, because we need to pass grads and remove pitch fmax limitation
+        self.trg_melspec_fn = instantiate(cfg.preprocessor, highfreq=None, use_grads=True)
+        self.generator = instantiate(
+            cfg.generator, n_mel_channels=cfg.preprocessor.nfilt, hop_length=cfg.preprocessor.n_window_stride
+        )
+        self.mpd = MultiPeriodDiscriminator(cfg.discriminator.mpd, debug=cfg.debug if "debug" in cfg else False)
+        self.mrd = MultiResolutionDiscriminator(cfg.discriminator.mrd, debug=cfg.debug if "debug" in cfg else False)
+
+        self.discriminator_loss = DiscriminatorLoss()
+        self.generator_loss = GeneratorLoss()
+
+        # Reshape MRD resolutions hyperparameter and apply them to MRSTFT loss
+        self.stft_resolutions = cfg.discriminator.mrd.resolutions
+        self.fft_sizes = [res[0] for res in self.stft_resolutions]
+        self.hop_sizes = [res[1] for res in self.stft_resolutions]
+        self.win_lengths = [res[2] for res in self.stft_resolutions]
+        self.mrstft_loss = MultiResolutionSTFTLoss(self.fft_sizes, self.hop_sizes, self.win_lengths)
+        self.stft_lamb = cfg.stft_lamb
+
+        self.sample_rate = self._cfg.preprocessor.sample_rate
+        self.stft_bias = None
+
+        self.input_as_mel = False
+        if self._train_dl:
+            self.input_as_mel = self._train_dl.dataset.load_precomputed_mel
+
+        self.automatic_optimization = False
+
+    def _get_max_steps(self):
+        return compute_max_steps(
+            max_epochs=self._cfg.max_epochs,
+            accumulate_grad_batches=self.trainer.accumulate_grad_batches,
+            limit_train_batches=self.trainer.limit_train_batches,
+            num_workers=get_num_workers(self.trainer),
+            num_samples=len(self._train_dl.dataset),
+            batch_size=get_batch_size(self._train_dl),
+            drop_last=self._train_dl.drop_last,
+        )
+
+    def configure_optimizers(self):
+        optim_g = instantiate(self._cfg.optim, params=self.generator.parameters(),)
+        optim_d = instantiate(self._cfg.optim, params=itertools.chain(self.mrd.parameters(), self.mpd.parameters()),)
 
-    @property
-    def output_types(self):
-        if self.mode == OperationMode.training or self.mode == OperationMode.validation:
-            return {
-                "out_repeats": NeuralType(('B', 'any', 'C', 'D', 'T'), SpectrogramType()),
-                "final_out": NeuralType(('B', 'C', 'D', 'T'), SpectrogramType()),
-                "residual": NeuralType(('B', 'C', 'D', 'T'), SpectrogramType()),
-            }
-        else:
-            return {
-                "final_out": NeuralType(('B', 'C', 'D', 'T'), SpectrogramType()),
-            }
+        return [optim_g, optim_d]
 
     @typecheck()
-    def forward(self, *, x, mag, max_length, repeats):
-        if self.mode != self.degli.mode:
-            raise ValueError(f"Degli's mode {self.mode} does not match DegliModule's mode {self.degli.mode}")
-
-        tensors = self.degli(x=x, mag=mag, max_length=max_length, repeat=repeats)
-        return tensors  # audio_pred
-
-    def convert_linear_spectrogram_to_audio(self, spec: torch.Tensor, Ts=None, repeats: int = 32) -> torch.Tensor:
-        self.mode = OperationMode.infer
-
-        batch_size = spec.shape[0]
-        if len(spec.shape) == 3:
-            spec = spec.unsqueeze(1)
-
-        x = torch.normal(0, 1, [batch_size, 2, spec.shape[2], spec.shape[3]]).to(self.device)
-        length = (spec.shape[3] - 1) * self.l_hop
-        with torch.no_grad():
-            y = self.degli(x=x, mag=spec, max_length=length, repeat=repeats)
-
-        if Ts is None:
-            Ts = [y.shape[3]] * batch_size
-
-        max_size = (max(Ts) - 1) * self.l_hop
-
-        audios = torch.zeros(batch_size, max_size)
-
-        for i in range(batch_size):
-            y_i = self.postprocess(y, Ts, i)
-            my_len = (Ts[i] - 1) * self.l_hop
-            audio = reconstruct_wave(y_i, kwargs_istft=self.kwargs_istft, n_sample=my_len)
-            audios[i, 0:my_len] = torch.from_numpy(audio)
-
-        return audios
-
-    def calc_loss(self, out_blocks: Tensor, y: Tensor, T_ys: Sequence[int]) -> Tensor:
+    def forward(self, *, spec):
         """
-        calculate L1 loss (criterion) between the real spectrogram and the outputs.
-
-        Args:
-            out_blocks: output for the Degli model, may include several concatrated outputs.
-            y: desired output.
-            T_ys: lengths (time domain) of non-zero parts of the histrograms, for each sample in the batch.
-        Returns:
-            a loss score.
+        Runs the generator, for inputs and outputs see input_types, and output_types
         """
+        return self.generator(x=spec)
 
-        with warnings.catch_warnings():
-            warnings.simplefilter('ignore')
-            loss_no_red = self.criterion(out_blocks, y.unsqueeze(1))
-        loss_blocks = torch.zeros(out_blocks.shape[1], device=y.device)
-        for T, loss_batch in zip(T_ys, loss_no_red):
-            loss_blocks += torch.mean(loss_batch[..., :T], dim=(1, 2, 3))
-
-        if len(loss_blocks) == 1:
-            loss = loss_blocks.squeeze()
-        else:
-            loss = loss_blocks @ self.loss_weight
-        return loss
+    @typecheck(
+        input_types={"spec": NeuralType(('B', 'C', 'T'), MelSpectrogramType())},
+        output_types={"audio": NeuralType(('B', 'T'), AudioSignal())},
+    )
+    def convert_spectrogram_to_audio(self, spec: 'torch.tensor') -> 'torch.tensor':
+        return self(spec=spec).squeeze(1)
 
     def training_step(self, batch, batch_idx):
-        self.mode = OperationMode.infer
-
-        x, mag, max_length, y, T_ys, _, _ = batch
-        output_loss, _, _ = self(x=x, mag=mag, max_length=max_length, repeats=self._cfg.train_params.repeat_training)
-        loss = self.calc_loss(output_loss, y, T_ys)
-
-        output = {
-            'loss': loss,
-            'progress_bar': {'training_loss': loss},
-            'log': {'loss': loss},
-        }
-        return output
-
-    @torch.no_grad()
-    def postprocess(self, output: Tensor, Ts: ndarray, idx: int):
-        one = output[idx, :, :, : Ts[idx]]
-        one = one.permute(1, 2, 0).contiguous()  # F, T, 2
-        one = one.cpu().numpy().view(dtype=np.complex64)  # F, T, 1
-        return one
+        if self.input_as_mel:
+            # Pre-computed spectrograms will be used as input
+            audio, audio_len, audio_mel = batch
+        else:
+            audio, audio_len = batch
+            audio_mel, _ = self.audio_to_melspec_precessor(audio, audio_len)
 
-    def validation_step(self, batch, batch_idx):
-        """
-        A validation step that also calculates the STOI/PESQ scores,
-        and the scored for high repetition count (repeat_validation argument)
-        """
-        self.mode = OperationMode.infer
-        val_repeats = self._cfg.train_params.repeat_validation
+        audio = audio.unsqueeze(1)
 
-        x, mag, max_length, y, T_ys, length, path_speech = batch
-        output_loss, output, _ = self(x=x, mag=mag, max_length=max_length, repeats=1)
-        _, output_x, _ = self(x=x, mag=mag, max_length=max_length, repeats=val_repeats)
-
-        loss = self.calc_loss(output_loss, y, T_ys)
-        cnt = x.shape[0]
-
-        stoi, pesq, stoi_x, pesq_x = (0.0, 0.0, 0.0, 0.0)
-        for p in range(cnt):
-            y_wav_path = path_speech[p]
-            y_wav = sf.read(y_wav_path)[0].astype(np.float32)
-
-            n_sample = length[p]
-            out = self.postprocess(output, T_ys, p)
-            out_wav = reconstruct_wave(out, kwargs_istft=self.kwargs_istft, n_sample=n_sample)
-            measure = eval_tts_scores(y_wav, out_wav)
-            stoi += torch.tensor(measure['STOI'])
-            pesq += torch.tensor(measure['PESQ'])
-
-            out = self.postprocess(output_x, T_ys, p)
-            out_wav = reconstruct_wave(out, kwargs_istft=self.kwargs_istft, n_sample=n_sample)
-            measure = eval_tts_scores(y_wav, out_wav)
-            stoi_x += torch.tensor(measure['STOI'])
-            pesq_x += torch.tensor(measure['PESQ'])
+        audio_pred = self.generator(x=audio_mel)
+        audio_pred_mel, _ = self.trg_melspec_fn(audio_pred.squeeze(1), audio_len)
 
-        return {
-            "val_loss": loss,
-            "stoi": stoi / cnt,
-            "pesq": pesq / cnt,
-            "stoi_x%d" % val_repeats: stoi_x / cnt,
-            "pesq_x%d" % val_repeats: pesq_x / cnt,
+        optim_g, optim_d = self.optimizers()
+
+        # Train discriminator
+        optim_d.zero_grad()
+        mpd_score_real, mpd_score_gen, _, _ = self.mpd(y=audio, y_hat=audio_pred.detach())
+        loss_disc_mpd, _, _ = self.discriminator_loss(
+            disc_real_outputs=mpd_score_real, disc_generated_outputs=mpd_score_gen
+        )
+        mrd_score_real, mrd_score_gen, _, _ = self.mrd(y=audio, y_hat=audio_pred.detach())
+        loss_disc_mrd, _, _ = self.discriminator_loss(
+            disc_real_outputs=mrd_score_real, disc_generated_outputs=mrd_score_gen
+        )
+        loss_d = loss_disc_mrd + loss_disc_mpd
+        self.manual_backward(loss_d)
+        optim_d.step()
+
+        # Train generator
+        optim_g.zero_grad()
+        loss_sc, loss_mag = self.mrstft_loss(x=audio_pred.squeeze(1), y=audio.squeeze(1), input_lengths=audio_len)
+        loss_sc = torch.stack(loss_sc).mean()
+        loss_mag = torch.stack(loss_mag).mean()
+        loss_mrstft = (loss_sc + loss_mag) * self.stft_lamb
+        _, mpd_score_gen, _, _ = self.mpd(y=audio, y_hat=audio_pred)
+        _, mrd_score_gen, _, _ = self.mrd(y=audio, y_hat=audio_pred)
+        loss_gen_mpd, _ = self.generator_loss(disc_outputs=mpd_score_gen)
+        loss_gen_mrd, _ = self.generator_loss(disc_outputs=mrd_score_gen)
+        loss_g = loss_gen_mrd + loss_gen_mpd + loss_mrstft
+        self.manual_backward(loss_g)
+        optim_g.step()
+
+        metrics = {
+            "g_loss_sc": loss_sc,
+            "g_loss_mag": loss_mag,
+            "g_loss_mrstft": loss_mrstft,
+            "g_loss_gen_mpd": loss_gen_mpd,
+            "g_loss_gen_mrd": loss_gen_mrd,
+            "g_loss": loss_g,
+            "d_loss_mpd": loss_disc_mpd,
+            "d_loss_mrd": loss_disc_mrd,
+            "d_loss": loss_d,
+            "global_step": self.global_step,
+            "lr": optim_g.param_groups[0]['lr'],
         }
+        self.log_dict(metrics, on_step=True, sync_dist=True)
+        self.log("g_mrstft_loss", loss_mrstft, prog_bar=True, logger=False, sync_dist=True)
 
-    def validation_epoch_end(self, outputs):
-        tensorboard_logs = {}
-
-        for k in outputs[0].keys():
-            tensorboard_logs[k] = torch.stack([x[k] for x in outputs]).mean()
+    def validation_step(self, batch, batch_idx):
+        if self.input_as_mel:
+            audio, audio_len, audio_mel = batch
+            audio_mel_len = [audio_mel.shape[1]] * audio_mel.shape[0]
+        else:
+            audio, audio_len = batch
+            audio_mel, audio_mel_len = self.audio_to_melspec_precessor(audio, audio_len)
+        audio_pred = self(spec=audio_mel)
+
+        # Perform bias denoising
+        pred_denoised = self._bias_denoise(audio_pred, audio_mel).squeeze(1)
+        pred_denoised_mel, _ = self.audio_to_melspec_precessor(pred_denoised, audio_len)
+
+        if self.input_as_mel:
+            gt_mel, gt_mel_len = self.audio_to_melspec_precessor(audio, audio_len)
+        audio_pred_mel, _ = self.audio_to_melspec_precessor(audio_pred.squeeze(1), audio_len)
+        loss_mel = F.l1_loss(audio_mel, audio_pred_mel)
+
+        self.log_dict({"val_loss": loss_mel}, on_epoch=True, sync_dist=True)
+
+        # Plot audio once per epoch
+        if batch_idx == 0 and isinstance(self.logger, WandbLogger) and HAVE_WANDB:
+            clips = []
+            specs = []
+            for i in range(min(5, audio.shape[0])):
+                clips += [
+                    wandb.Audio(
+                        audio[i, : audio_len[i]].data.cpu().numpy(),
+                        caption=f"real audio {i}",
+                        sample_rate=self.sample_rate,
+                    ),
+                    wandb.Audio(
+                        audio_pred[i, 0, : audio_len[i]].data.cpu().numpy().astype('float32'),
+                        caption=f"generated audio {i}",
+                        sample_rate=self.sample_rate,
+                    ),
+                    wandb.Audio(
+                        pred_denoised[i, : audio_len[i]].data.cpu().numpy(),
+                        caption=f"denoised audio {i}",
+                        sample_rate=self.sample_rate,
+                    ),
+                ]
+                specs += [
+                    wandb.Image(
+                        plot_spectrogram_to_numpy(audio_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                        caption=f"input mel {i}",
+                    ),
+                    wandb.Image(
+                        plot_spectrogram_to_numpy(audio_pred_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                        caption=f"output mel {i}",
+                    ),
+                    wandb.Image(
+                        plot_spectrogram_to_numpy(pred_denoised_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                        caption=f"denoised mel {i}",
+                    ),
+                ]
+                if self.input_as_mel:
+                    specs += [
+                        wandb.Image(
+                            plot_spectrogram_to_numpy(gt_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                            caption=f"gt mel {i}",
+                        ),
+                    ]
+
+            self.logger.experiment.log({"audio": clips, "specs": specs})
+
+    def _bias_denoise(self, audio, mel):
+        def stft(x):
+            comp = torch.stft(x.squeeze(1), n_fft=1024, hop_length=256, win_length=1024)
+            real, imag = comp[..., 0], comp[..., 1]
+            mags = torch.sqrt(real ** 2 + imag ** 2)
+            phase = torch.atan2(imag, real)
+            return mags, phase
+
+        def istft(mags, phase):
+            comp = torch.stack([mags * torch.cos(phase), mags * torch.sin(phase)], dim=-1)
+            x = torch.istft(comp, n_fft=1024, hop_length=256, win_length=1024)
+            return x
+
+        # Create bias tensor
+        if self.stft_bias is None or self.stft_bias.shape[0] != audio.shape[0]:
+            audio_bias = self(spec=torch.zeros_like(mel, device=mel.device))
+            self.stft_bias, _ = stft(audio_bias)
+            self.stft_bias = self.stft_bias[:, :, 0][:, :, None]
+
+        audio_mags, audio_phase = stft(audio)
+        audio_mags = audio_mags - self.cfg.get("denoise_strength", 0.0025) * self.stft_bias
+        audio_mags = torch.clamp(audio_mags, 0.0)
+        audio_denoised = istft(audio_mags, audio_phase).unsqueeze(1)
 
-        return {'val_loss': tensorboard_logs['val_loss'], 'log': tensorboard_logs}
+        return audio_denoised
 
     def __setup_dataloader_from_config(self, cfg, shuffle_should_be: bool = True, name: str = "train"):
         if "dataset" not in cfg or not isinstance(cfg.dataset, DictConfig):
-            raise ValueError(f"No dataset for {name}")  # TODO
+            raise ValueError(f"No dataset for {name}")
         if "dataloader_params" not in cfg or not isinstance(cfg.dataloader_params, DictConfig):
-            raise ValueError(f"No dataloder_params for {name}")  # TODO
+            raise ValueError(f"No dataloder_params for {name}")
         if shuffle_should_be:
             if 'shuffle' not in cfg.dataloader_params:
                 logging.warning(
                     f"Shuffle should be set to True for {self}'s {name} dataloader but was not found in its "
                     "config. Manually setting to True"
                 )
                 with open_dict(cfg["dataloader_params"]):
@@ -316,17 +285,66 @@
 
     def setup_training_data(self, cfg):
         self._train_dl = self.__setup_dataloader_from_config(cfg)
 
     def setup_validation_data(self, cfg):
         self._validation_dl = self.__setup_dataloader_from_config(cfg, shuffle_should_be=False, name="validation")
 
+    def setup_test_data(self, cfg):
+        pass
+
     @classmethod
-    def list_available_models(cls) -> 'List[PretrainedModelInfo]':
+    def list_available_models(cls) -> 'Optional[Dict[str, str]]':
+        list_of_models = []
+        model = PretrainedModelInfo(
+            pretrained_model_name="tts_en_lj_univnet",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_lj_univnet/versions/1.7.0/files/tts_en_lj_univnet.nemo",
+            description="This model is trained on LJSpeech sampled at 22050Hz, and has been tested on generating female English voices with an American accent.",
+            class_=cls,
+        )
+        list_of_models.append(model)
+
+        model = PretrainedModelInfo(
+            pretrained_model_name="tts_en_libritts_univnet",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_libritts_univnet/versions/1.7.0/files/tts_en_libritts_multispeaker_univnet.nemo",
+            description="This model is trained on all LibriTTS training data (train-clean-100, train-clean-360, and train-other-500) sampled at 22050Hz, and has been tested on generating English voices.",
+            class_=cls,
+        )
+        list_of_models.append(model)
+
+        return list_of_models
+
+    # Methods for model exportability
+    def _prepare_for_export(self, **kwargs):
+        if self.generator is not None:
+            try:
+                self.generator.remove_weight_norm()
+            except ValueError:
+                return
+
+    @property
+    def input_types(self):
+        return {
+            "spec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+        }
+
+    @property
+    def output_types(self):
+        return {
+            "audio": NeuralType(('B', 'S', 'T'), AudioSignal(self.sample_rate)),
+        }
+
+    def input_example(self, max_batch=1, max_dim=256):
         """
-        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
+        Generates input examples for tracing etc.
         Returns:
-            List of available pre-trained models.
+            A tuple of input examples.
         """
-        list_of_models = []
+        par = next(self.parameters())
+        mel = torch.randn((max_batch, self.cfg['preprocessor']['nfilt'], max_dim), device=par.device, dtype=par.dtype)
+        return ({'spec': mel},)
 
-        return list_of_models
+    def forward_for_export(self, spec):
+        """
+        Runs the generator, for inputs and outputs see input_types, and output_types
+        """
+        return self.generator(x=spec)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/ed_mel2spec.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/fastpitch.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,323 +1,305 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+#
+# BSD 3-Clause License
+#
+# Copyright (c) 2021, NVIDIA Corporation
+# All rights reserved.
+#
+# Redistribution and use in source and binary forms, with or without
+# modification, are permitted provided that the following conditions are met:
+#
+# * Redistributions of source code must retain the above copyright notice, this
+#   list of conditions and the following disclaimer.
+#
+# * Redistributions in binary form must reproduce the above copyright notice,
+#   this list of conditions and the following disclaimer in the documentation
+#     and/or other materials provided with the distribution.
+#
+# * Neither the name of the copyright holder nor the names of its
+#   contributors may be used to endorse or promote products derived from
+#     this software without specific prior written permission.
+#
+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
-import warnings
-from dataclasses import dataclass
-from typing import Any, Dict, Optional, Sequence
-
-import numpy as np
-import soundfile as sf
 import torch
-import torch.nn.functional as F
-from hydra.utils import instantiate
-from omegaconf import MISSING, DictConfig, OmegaConf, open_dict
-from torch import Tensor, nn
-
-from nemo.collections.tts.helpers.helpers import eval_tts_scores, griffin_lim
-from nemo.collections.tts.models.base import MelToSpec
-from nemo.core.classes.common import PretrainedModelInfo, typecheck
-from nemo.core.neural_types.elements import MelSpectrogramType, SpectrogramType
-from nemo.core.neural_types.neural_type import NeuralType
-from nemo.utils import logging
-from nemo.utils.decorators import deprecated
 
+from nemo.collections.tts.helpers.helpers import binarize_attention_parallel, regulate_len
+from nemo.core.classes import NeuralModule, typecheck
+from nemo.core.neural_types.elements import (
+    EncodedRepresentation,
+    Index,
+    LengthsType,
+    LogprobsType,
+    MelSpectrogramType,
+    ProbsType,
+    RegressionValuesType,
+    TokenDurationType,
+    TokenIndex,
+    TokenLogDurationType,
+)
+from nemo.core.neural_types.neural_type import NeuralType
 
-@dataclass
-class EDMel2SpecConfig:
-    mel2spec: Dict[Any, Any] = MISSING
-    train_ds: Optional[Dict[Any, Any]] = None
-    validation_ds: Optional[Dict[Any, Any]] = None
-    train_params: Optional[Dict[Any, Any]] = None
-    sched: Optional[Dict[Any, Any]] = None
-
-
-def gen_filter(k):
-    K = torch.ones(1, 1, k, 1)
-    K.requires_grad = False
-    return K
-
-
-@deprecated(version="1.9", explanation="EDMel2SpecModel will be removed.")
-class EDMel2SpecModel(MelToSpec):
-    """
-        A model that convert mel spectrograms to linear spectrograms, using an encoder- decoder like model
-        The module relies on convolutions (encoders) and transposed convolutions (decoders),
-        which does not affect the time-dimension length, and thus applicable to any input length.
-    """
-
-    def __init__(self, cfg: DictConfig, trainer: 'Trainer' = None):
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
-        super().__init__(cfg=cfg, trainer=trainer)
-
-        schema = OmegaConf.structured(EDMel2SpecConfig)
-        # ModelPT ensures that cfg is a DictConfig, but do this second check in case ModelPT changes
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
-        elif not isinstance(cfg, DictConfig):
-            raise ValueError(f"cfg was type: {type(cfg)}. Expected either a dict or a DictConfig")
-        # Ensure passed cfg is compliant with schema
-        OmegaConf.merge(cfg, schema)
-
-        self.ed_mel2spec = instantiate(self._cfg.mel2spec)
-
-        self.criterion = nn.L1Loss(reduction='none')  # maybe should be loss subclass?
-        loss_mode = self._cfg.train_params.loss_mode
-        self.lreg_factor = self._cfg.train_params.lreg_factor
-
-        self.f_specs = {
-            0: [(5, 2), (15, 5)],
-            1: [(5, 2)],
-            2: [(3, 1)],
-            3: [(3, 1), (5, 2)],
-            4: [(3, 1), (5, 2), (7, 3)],
-            5: [(15, 5)],
-            6: [(3, 1), (5, 2), (7, 3), (15, 5), (25, 10)],
-            7: [(1, 1)],
-            8: [(1, 1), (3, 1), (5, 2), (15, 5), (7, 3), (25, 10), (9, 4), (20, 5), (5, 3)],
-            9: [(6, 2), (10, 4)],
-        }[loss_mode]
 
-        self.filters = [gen_filter(k) for k, s in self.f_specs]
+def average_pitch(pitch, durs):
+    durs_cums_ends = torch.cumsum(durs, dim=1).long()
+    durs_cums_starts = torch.nn.functional.pad(durs_cums_ends[:, :-1], (1, 0))
+    pitch_nonzero_cums = torch.nn.functional.pad(torch.cumsum(pitch != 0.0, dim=2), (1, 0))
+    pitch_cums = torch.nn.functional.pad(torch.cumsum(pitch, dim=2), (1, 0))
+
+    bs, l = durs_cums_ends.size()
+    n_formants = pitch.size(1)
+    dcs = durs_cums_starts[:, None, :].expand(bs, n_formants, l)
+    dce = durs_cums_ends[:, None, :].expand(bs, n_formants, l)
+
+    pitch_sums = (torch.gather(pitch_cums, 2, dce) - torch.gather(pitch_cums, 2, dcs)).float()
+    pitch_nelems = (torch.gather(pitch_nonzero_cums, 2, dce) - torch.gather(pitch_nonzero_cums, 2, dcs)).float()
+
+    pitch_avg = torch.where(pitch_nelems == 0.0, pitch_nelems, pitch_sums / pitch_nelems)
+    return pitch_avg
+
+
+class ConvReLUNorm(torch.nn.Module):
+    def __init__(self, in_channels, out_channels, kernel_size=1, dropout=0.0):
+        super(ConvReLUNorm, self).__init__()
+        self.conv = torch.nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=(kernel_size // 2))
+        self.norm = torch.nn.LayerNorm(out_channels)
+        self.dropout = torch.nn.Dropout(dropout)
+
+    def forward(self, signal):
+        out = torch.nn.functional.relu(self.conv(signal))
+        out = self.norm(out.transpose(1, 2)).transpose(1, 2)
+        return self.dropout(out)
+
+
+class TemporalPredictor(NeuralModule):
+    """Predicts a single float per each temporal location"""
+
+    def __init__(self, input_size, filter_size, kernel_size, dropout, n_layers=2):
+        super(TemporalPredictor, self).__init__()
+
+        self.layers = torch.nn.Sequential(
+            *[
+                ConvReLUNorm(
+                    input_size if i == 0 else filter_size, filter_size, kernel_size=kernel_size, dropout=dropout
+                )
+                for i in range(n_layers)
+            ]
+        )
+        self.fc = torch.nn.Linear(filter_size, 1, bias=True)
 
     @property
     def input_types(self):
         return {
-            "mel": NeuralType(('B', 'C', 'D', 'T'), MelSpectrogramType()),
+            "enc": NeuralType(('B', 'T', 'D'), EncodedRepresentation()),
+            "enc_mask": NeuralType(('B', 'T', 1), TokenDurationType()),
         }
 
     @property
     def output_types(self):
         return {
-            "spec": NeuralType(('B', 'C', 'D', 'T'), SpectrogramType()),
+            "out": NeuralType(('B', 'T'), EncodedRepresentation()),
         }
 
-    @typecheck()
-    def forward(self, *, mel):
-        if self.mode != self.ed_mel2spec.mode:
-            raise ValueError(
-                f"Encoder-Decoder Mel-to-Spec's mode {self.mode} does not match EDMel2SpecModule's mode {self.ed_mel2spec.mode}"
-            )
-
-        spec = self.ed_mel2spec(mel=mel)
-        return spec  # audio_pred
-
-    def convert_mel_spectrogram_to_linear(self, mel: torch.Tensor) -> torch.Tensor:
-        self.eval()
-        if len(mel.shape) == 3:
-            mel = mel.unsqueeze(1)
-
-        spec = self(mel=mel)
-        spec = torch.clamp(spec, min=1e-5)
-        return spec.squeeze(1)
-
-    def calc_loss(self, x: Tensor, y: Tensor, T_ys: Sequence[int], crit) -> Tensor:
-        """
-        x: B, C, F, T
-        y: B, C, F, T
-        """
-        with warnings.catch_warnings():
-            warnings.simplefilter('ignore')
-            loss_no_red = crit(x, y)
-
-        loss_blocks = torch.zeros(x.shape[1], device=y.device)
-
-        tot = 0
-        for T, loss_batch in zip(T_ys, loss_no_red):
-            tot += T
-            loss_blocks += torch.sum(loss_batch[..., :T])
-        loss_blocks = loss_blocks / tot
-
-        loss = loss_blocks.squeeze()
-
-        return loss
-
-    def calc_loss_smooth(
-        self, _x: Tensor, _y: Tensor, T_ys: Sequence[int], kern: int, stride: int, pad: int = 0
-    ) -> Tensor:
-        """
-        out_blocks: B, depth, C, F, T
-        y: B, C, F, T
-        """
-
-        crit = self.criterion
-
-        x = F.max_pool2d(_x, (kern, 1), stride=stride)
-        y = F.max_pool2d(_y, (kern, 1), stride=stride)
-
-        with warnings.catch_warnings():
-            warnings.simplefilter('ignore')
-            loss_no_red = crit(x, y)
-
-        loss_blocks = torch.zeros(x.shape[1], device=y.device)
-
-        tot = 0
-        for T, loss_batch in zip(T_ys, loss_no_red):
-            tot += T
-            loss_blocks += torch.sum(loss_batch[..., :T])
-        loss_blocks = loss_blocks / tot
+    def forward(self, enc, enc_mask):
+        out = enc * enc_mask
+        out = self.layers(out.transpose(1, 2)).transpose(1, 2)
+        out = self.fc(out) * enc_mask
+        return out.squeeze(-1)
+
+
+class FastPitchModule(NeuralModule):
+    def __init__(
+        self,
+        encoder_module: NeuralModule,
+        decoder_module: NeuralModule,
+        duration_predictor: NeuralModule,
+        pitch_predictor: NeuralModule,
+        aligner: NeuralModule,
+        n_speakers: int,
+        symbols_embedding_dim: int,
+        pitch_embedding_kernel_size: int,
+        n_mel_channels: int = 80,
+        max_token_duration: int = 75,
+    ):
+        super().__init__()
+
+        self.encoder = encoder_module
+        self.decoder = decoder_module
+        self.duration_predictor = duration_predictor
+        self.pitch_predictor = pitch_predictor
+        self.aligner = aligner
+        self.learn_alignment = aligner is not None
+        self.use_duration_predictor = True
+        self.binarize = False
+
+        if n_speakers > 1:
+            self.speaker_emb = torch.nn.Embedding(n_speakers, symbols_embedding_dim)
+        else:
+            self.speaker_emb = None
+
+        self.max_token_duration = max_token_duration
+        self.min_token_duration = 0
+
+        self.pitch_emb = torch.nn.Conv1d(
+            1,
+            symbols_embedding_dim,
+            kernel_size=pitch_embedding_kernel_size,
+            padding=int((pitch_embedding_kernel_size - 1) / 2),
+        )
+
+        # Store values precomputed from training data for convenience
+        self.register_buffer('pitch_mean', torch.zeros(1))
+        self.register_buffer('pitch_std', torch.zeros(1))
 
-        loss1 = loss_blocks.squeeze()
+        self.proj = torch.nn.Linear(self.decoder.d_model, n_mel_channels, bias=True)
 
-        x = F.max_pool2d(-1 * _x, (kern, 1), stride=stride)
-        y = F.max_pool2d(-1 * _y, (kern, 1), stride=stride)
-
-        with warnings.catch_warnings():
-            warnings.simplefilter('ignore')
-            loss_no_red = crit(x, y)
-
-        loss_blocks = torch.zeros(x.shape[1], device=y.device)
-
-        tot = 0
-        for T, loss_batch in zip(T_ys, loss_no_red):
-            tot += T
-            loss_blocks += torch.sum(loss_batch[..., :T])
-        loss_blocks = loss_blocks / tot
-
-        loss2 = loss_blocks.squeeze()
-
-        loss = loss1 + loss2
-        return loss
-
-    def training_step(self, batch, batch_idx):
-        _, y_spec, _, _, T_ys, _, _ = batch
-
-        x_mel = self.ed_mel2spec.spec_to_mel(y_spec)
-
-        x_spec = self(mel=x_mel)
-        z_mel = self.ed_mel2spec.spec_to_mel(x_spec)
-
-        loss_L1 = self.calc_loss(x_spec, y_spec, T_ys, self.criterion)
-        loss_reg = self.calc_loss(x_mel, z_mel, T_ys, self.criterion)
-
-        loss = loss_L1 + self.lreg_factor * loss_reg
-
-        for (k, s) in self.f_specs:
-            loss = loss + self.calc_loss_smooth(x_spec, y_spec, T_ys, k, s)
-
-        output = {
-            'loss': loss,
-            'progress_bar': {'training_loss': loss},
-            'log': {'loss': loss},
+    @property
+    def input_types(self):
+        return {
+            "text": NeuralType(('B', 'T_text'), TokenIndex()),
+            "durs": NeuralType(('B', 'T_text'), TokenDurationType()),
+            "pitch": NeuralType(('B', 'T_audio'), RegressionValuesType()),
+            "speaker": NeuralType(('B'), Index(), optional=True),
+            "pace": NeuralType(optional=True),
+            "spec": NeuralType(('B', 'D', 'T_spec'), MelSpectrogramType(), optional=True),
+            "attn_prior": NeuralType(('B', 'T_spec', 'T_text'), ProbsType(), optional=True),
+            "mel_lens": NeuralType(('B'), LengthsType(), optional=True),
+            "input_lens": NeuralType(('B'), LengthsType(), optional=True),
         }
-        return output
-
-    def validation_step(self, batch, batch_idx):
-        _, y_spec, _, _, T_ys, _, path_speech = batch
-
-        x_mel = self.ed_mel2spec.spec_to_mel(y_spec)
-
-        x_spec = self(mel=x_mel)
-        z_mel = self.ed_mel2spec.spec_to_mel(x_spec)
-
-        loss_L1 = self.calc_loss(x_spec, y_spec, T_ys, self.criterion)
-        loss_reg = self.calc_loss(x_mel, z_mel, T_ys, self.criterion)
 
-        loss = loss_L1 + self.lreg_factor * loss_reg
-
-        output = {
-            'val_loss': loss,
-            'loss_L1': loss_L1,
-            'loss_reg': loss_reg,
+    @property
+    def output_types(self):
+        return {
+            "spect": NeuralType(('B', 'D', 'T_spec'), MelSpectrogramType()),
+            "num_frames": NeuralType(('B'), TokenDurationType()),
+            "durs_predicted": NeuralType(('B', 'T_text'), TokenDurationType()),
+            "log_durs_predicted": NeuralType(('B', 'T_text'), TokenLogDurationType()),
+            "pitch_predicted": NeuralType(('B', 'T_text'), RegressionValuesType()),
+            "attn_soft": NeuralType(('B', 'S', 'T_spec', 'T_text'), ProbsType()),
+            "attn_logprob": NeuralType(('B', 'S', 'T_spec', 'T_text'), LogprobsType()),
+            "attn_hard": NeuralType(('B', 'S', 'T_spec', 'T_text'), ProbsType()),
+            "attn_hard_dur": NeuralType(('B', 'T_text'), TokenDurationType()),
+            "pitch": NeuralType(('B', 'T_audio'), RegressionValuesType()),
         }
 
-        if self._cfg.train_params.validate_scores:
-            '''
-                For validaiton, estimate the wave using standard griffin lim,
-                comparing the real wave with the griffin lim counterpart.
-            '''
-
-            cnt = x_spec.shape[0]
-            np_x = x_spec.to('cpu').numpy()
-            np_y = y_spec.to('cpu').numpy()
-            stoi_real, pesq_real, stoi_est, pesq_est = (0.0, 0.0, 0.0, 0.0)
-
-            for p in range(cnt):
-                y_wav_path = path_speech[p]
-                wav = sf.read(y_wav_path)[0].astype(np.float32)
-
-                y_est_wav = griffin_lim(np_y[p, 0, :, :])
-                x_est_wav = griffin_lim(np_x[p, 0, :, :])
-
-                min_size = min(wav.shape[0], x_est_wav.shape[0], y_est_wav.shape[0])
-                wav = wav[0:min_size, ...]
-                y_est_wav = y_est_wav[0:min_size, ...]
-                x_est_wav = x_est_wav[0:min_size, ...]
-
-                measure = eval_tts_scores(x_est_wav, wav)
-                stoi_real += torch.tensor(measure['STOI'])
-                pesq_real += torch.tensor(measure['PESQ'])
-
-                measure = eval_tts_scores(x_est_wav, y_est_wav)
-                stoi_est += torch.tensor(measure['STOI'])
-                pesq_est += torch.tensor(measure['PESQ'])
-
-            output['stoi_real'] = stoi_real / cnt
-            output['pesq_real'] = pesq_real / cnt
-            output['stoi_est'] = stoi_est / cnt
-            output['pesq_est'] = pesq_est / cnt
-
-        for (k, s) in self.f_specs:
-            new_loss = self.calc_loss_smooth(x_spec, y_spec, T_ys, k, s)
-            output[f'loss_{k}_{s}'] = new_loss
-            loss = loss + new_loss
-
-        output['val_loss'] = loss
-
-        return output
-
-    def validation_epoch_end(self, outputs):
-        tensorboard_logs = {}
-
-        for k in outputs[0].keys():
-            tensorboard_logs[k] = torch.stack([x[k] for x in outputs]).mean()
-
-        return {'val_loss': tensorboard_logs['val_loss'], 'log': tensorboard_logs}
-
-    def __setup_dataloader_from_config(self, cfg, shuffle_should_be: bool = True, name: str = "train"):
-        if "dataset" not in cfg or not isinstance(cfg.dataset, DictConfig):
-            raise ValueError(f"No dataset for {name}")  # TODO
-        if "dataloader_params" not in cfg or not isinstance(cfg.dataloader_params, DictConfig):
-            raise ValueError(f"No dataloder_params for {name}")  # TODO
-        if shuffle_should_be:
-            if 'shuffle' not in cfg.dataloader_params:
-                logging.warning(
-                    f"Shuffle should be set to True for {self}'s {name} dataloader but was not found in its "
-                    "config. Manually setting to True"
-                )
-                with open_dict(cfg["dataloader_params"]):
-                    cfg.dataloader_params.shuffle = True
-            elif not cfg.dataloader_params.shuffle:
-                logging.error(f"The {name} dataloader for {self} has shuffle set to False!!!")
-        elif not shuffle_should_be and cfg.dataloader_params.shuffle:
-            logging.error(f"The {name} dataloader for {self} has shuffle set to True!!!")
-
-        dataset = instantiate(cfg.dataset)
-        return torch.utils.data.DataLoader(dataset, collate_fn=dataset.collate_fn, **cfg.dataloader_params)
-
-    def setup_training_data(self, cfg):
-        self._train_dl = self.__setup_dataloader_from_config(cfg)
-
-    def setup_validation_data(self, cfg):
-        self._validation_dl = self.__setup_dataloader_from_config(cfg, shuffle_should_be=False, name="validation")
-
-    @classmethod
-    def list_available_models(cls) -> 'List[PretrainedModelInfo]':
-        """
-        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
-        Returns:
-            List of available pre-trained models.
-        """
-        list_of_models = []
-        return list_of_models
+    @typecheck()
+    def forward(
+        self,
+        *,
+        text,
+        durs=None,
+        pitch=None,
+        speaker=None,
+        pace=1.0,
+        spec=None,
+        attn_prior=None,
+        mel_lens=None,
+        input_lens=None,
+    ):
+
+        if not self.learn_alignment and self.training:
+            assert durs is not None
+            assert pitch is not None
+
+        # Calculate speaker embedding
+        if self.speaker_emb is None or speaker is None:
+            spk_emb = 0
+        else:
+            spk_emb = self.speaker_emb(speaker).unsqueeze(1)
+
+        # Input FFT
+        enc_out, enc_mask = self.encoder(input=text, conditioning=spk_emb)
+
+        log_durs_predicted = self.duration_predictor(enc_out, enc_mask)
+        durs_predicted = torch.clamp(torch.exp(log_durs_predicted) - 1, 0, self.max_token_duration)
+
+        attn_soft, attn_hard, attn_hard_dur, attn_logprob = None, None, None, None
+        if self.learn_alignment and spec is not None:
+            text_emb = self.encoder.word_emb(text)
+            attn_soft, attn_logprob = self.aligner(spec, text_emb.permute(0, 2, 1), enc_mask == 0, attn_prior)
+            attn_hard = binarize_attention_parallel(attn_soft, input_lens, mel_lens)
+            attn_hard_dur = attn_hard.sum(2)[:, 0, :]
+
+        # Predict pitch
+        pitch_predicted = self.pitch_predictor(enc_out, enc_mask)
+        if pitch is not None:
+            if self.learn_alignment and pitch.shape[-1] != pitch_predicted.shape[-1]:
+                # Pitch during training is per spectrogram frame, but during inference, it should be per character
+                pitch = average_pitch(pitch.unsqueeze(1), attn_hard_dur).squeeze(1)
+            pitch_emb = self.pitch_emb(pitch.unsqueeze(1))
+        else:
+            pitch_emb = self.pitch_emb(pitch_predicted.unsqueeze(1))
+
+        enc_out = enc_out + pitch_emb.transpose(1, 2)
+
+        if self.learn_alignment and spec is not None:
+            len_regulated, dec_lens = regulate_len(attn_hard_dur, enc_out, pace)
+        elif spec is None and durs is not None:
+            len_regulated, dec_lens = regulate_len(durs, enc_out, pace)
+        # Use predictions during inference
+        elif spec is None:
+            len_regulated, dec_lens = regulate_len(durs_predicted, enc_out, pace)
+
+        # Output FFT
+        dec_out, _ = self.decoder(input=len_regulated, seq_lens=dec_lens)
+        spect = self.proj(dec_out).transpose(1, 2)
+        return (
+            spect,
+            dec_lens,
+            durs_predicted,
+            log_durs_predicted,
+            pitch_predicted,
+            attn_soft,
+            attn_logprob,
+            attn_hard,
+            attn_hard_dur,
+            pitch,
+        )
+
+    def infer(self, *, text, pitch=None, speaker=None, pace=1.0):
+        # Calculate speaker embedding
+        if self.speaker_emb is None or speaker is None:
+            spk_emb = 0
+        else:
+            spk_emb = self.speaker_emb(speaker).unsqueeze(1)
+
+        # Input FFT
+        enc_out, enc_mask = self.encoder(input=text, conditioning=spk_emb)
+
+        # Predict duration and pitch
+        log_durs_predicted = self.duration_predictor(enc_out, enc_mask)
+        durs_predicted = torch.clamp(
+            torch.exp(log_durs_predicted) - 1.0, self.min_token_duration, self.max_token_duration
+        )
+        pitch_predicted = self.pitch_predictor(enc_out, enc_mask) + pitch
+        pitch_emb = self.pitch_emb(pitch_predicted.unsqueeze(1))
+        enc_out = enc_out + pitch_emb.transpose(1, 2)
+
+        # Expand to decoder time dimension
+        len_regulated, dec_lens = regulate_len(durs_predicted, enc_out, pace)
+
+        # Output FFT
+        dec_out, _ = self.decoder(input=len_regulated, seq_lens=dec_lens)
+        spect = self.proj(dec_out).transpose(1, 2)
+        return spect.to(torch.float), dec_lens, durs_predicted, log_durs_predicted, pitch_predicted
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/fastpitch.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/fastpitch.py`

 * *Files 5% similar despite different names*

```diff
@@ -8,23 +8,23 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 import contextlib
+from dataclasses import dataclass
 from typing import Optional
 
 import torch
 from hydra.utils import instantiate
-from omegaconf import DictConfig, open_dict
+from omegaconf import DictConfig, OmegaConf, open_dict
 from pytorch_lightning import Trainer
 from pytorch_lightning.loggers import LoggerCollection, TensorBoardLogger
 
-from nemo.collections.asr.data.audio_to_text import AudioToCharWithDursF0Dataset
 from nemo.collections.common.parts.preprocessing import parsers
 from nemo.collections.tts.helpers.helpers import plot_alignment_to_numpy, plot_spectrogram_to_numpy
 from nemo.collections.tts.losses.aligner_loss import BinLoss, ForwardSumLoss
 from nemo.collections.tts.losses.fastpitchloss import DurationLoss, MelLoss, PitchLoss
 from nemo.collections.tts.models.base import SpectrogramGenerator
 from nemo.collections.tts.modules.fastpitch import FastPitchModule
 from nemo.collections.tts.torch.tts_data_types import SpeakerID
@@ -40,14 +40,39 @@
     TokenIndex,
     TokenLogDurationType,
 )
 from nemo.core.neural_types.neural_type import NeuralType
 from nemo.utils import logging, model_utils
 
 
+@dataclass
+class G2PConfig:
+    _target_: str = "nemo.collections.tts.torch.g2ps.EnglishG2p"
+    phoneme_dict: str = "scripts/tts_dataset_files/cmudict-0.7b_nv22.01"
+    heteronyms: str = "scripts/tts_dataset_files/heteronyms-030921"
+    phoneme_probability: float = 0.5
+
+
+@dataclass
+class TextTokenizer:
+    _target_: str = "nemo.collections.tts.torch.tts_tokenizers.EnglishPhonemesTokenizer"
+    punct: bool = True
+    stresses: bool = True
+    chars: bool = True
+    apostrophe: bool = True
+    pad_with_space: bool = True
+    add_blank_at: bool = True
+    g2p: G2PConfig = G2PConfig()
+
+
+@dataclass
+class TextTokenizerConfig:
+    text_tokenizer: TextTokenizer = TextTokenizer()
+
+
 class FastPitchModel(SpectrogramGenerator, Exportable):
     """FastPitch model (https://arxiv.org/abs/2006.06873) that is used to generate mel spectrogram from text."""
 
     def __init__(self, cfg: DictConfig, trainer: Trainer = None):
         # Convert to Hydra 1.0 compatible DictConfig
         cfg = model_utils.convert_model_config_to_dict_config(cfg)
         cfg = model_utils.maybe_update_config_version(cfg)
@@ -62,23 +87,29 @@
 
         # Setup vocabulary (=tokenizer) and input_fft_kwargs (supported only with self.learn_alignment=True)
         input_fft_kwargs = {}
         if self.learn_alignment:
             self.vocab = None
             self.ds_class_name = cfg.train_ds.dataset._target_.split(".")[-1]
 
-            if self.ds_class_name == "AudioToCharWithPriorAndPitchDataset":
-                self.vocab = AudioToCharWithDursF0Dataset.make_vocab(**cfg.train_ds.dataset.vocab)
-                input_fft_kwargs["n_embed"] = len(self.vocab.labels)
-                input_fft_kwargs["padding_idx"] = self.vocab.pad
-            elif self.ds_class_name == "TTSDataset":
+            if self.ds_class_name == "TTSDataset":
                 self._setup_tokenizer(cfg)
                 assert self.vocab is not None
                 input_fft_kwargs["n_embed"] = len(self.vocab.tokens)
                 input_fft_kwargs["padding_idx"] = self.vocab.pad
+            elif self.ds_class_name == "AudioToCharWithPriorAndPitchDataset":
+                logging.warning(
+                    "AudioToCharWithPriorAndPitchDataset class has been deprecated. No support for"
+                    " training or finetuning. Only inference is supported."
+                )
+                tokenizer_conf = self._get_default_text_tokenizer_conf()
+                self._setup_tokenizer(tokenizer_conf)
+                assert self.vocab is not None
+                input_fft_kwargs["n_embed"] = len(self.vocab.tokens)
+                input_fft_kwargs["padding_idx"] = self.vocab.pad
             else:
                 raise ValueError(f"Unknown dataset class: {self.ds_class_name}")
 
         self._parser = None
         self._tb_logger = None
         super().__init__(cfg=cfg, trainer=trainer)
 
@@ -118,14 +149,18 @@
             cfg.n_speakers,
             cfg.symbols_embedding_dim,
             cfg.pitch_embedding_kernel_size,
             cfg.n_mel_channels,
         )
         self._input_types = self._output_types = None
 
+    def _get_default_text_tokenizer_conf(self):
+        text_tokenizer: TextTokenizerConfig = TextTokenizerConfig()
+        return OmegaConf.create(OmegaConf.to_yaml(text_tokenizer))
+
     def _setup_normalizer(self, cfg):
         if "text_normalizer" in cfg:
             normalizer_kwargs = {}
 
             if "whitelist" in cfg.text_normalizer:
                 normalizer_kwargs["whitelist"] = self.register_artifact(
                     'text_normalizer.whitelist', cfg.text_normalizer.whitelist
@@ -173,22 +208,24 @@
     def parser(self):
         if self._parser is not None:
             return self._parser
 
         if self.learn_alignment:
             ds_class_name = self._cfg.train_ds.dataset._target_.split(".")[-1]
 
-            # TODO(Oktai15): remove it in 1.8.0 version
-            if ds_class_name == "AudioToCharWithPriorAndPitchDataset" or ds_class_name == "TTSDataset":
+            if ds_class_name == "TTSDataset":
+                self._parser = self.vocab.encode
+            elif ds_class_name == "AudioToCharWithPriorAndPitchDataset":
+                if self.vocab is None:
+                    tokenizer_conf = self._get_default_text_tokenizer_conf()
+                    self._setup_tokenizer(tokenizer_conf)
                 self._parser = self.vocab.encode
             else:
                 raise ValueError(f"Unknown dataset class: {ds_class_name}")
         else:
-            # TODO(Oktai15): remove it in 1.8.0 version
-            # ds_class_name == "FastPitchDataset"
             self._parser = parsers.make_parser(
                 labels=self._cfg.labels,
                 name='en',
                 unk_id=-1,
                 blank_id=-1,
                 do_normalize=True,
                 abbreviation_version="fastpitch",
@@ -208,15 +245,14 @@
             if hasattr(self.vocab, "set_phone_prob"):
                 eval_phon_mode = self.vocab.set_phone_prob(prob=1.0)
 
             # Disable mixed g2p representation if necessary
             with eval_phon_mode:
                 tokens = self.parser(str_input)
         else:
-            # TODO(Oktai15): remove it in 1.8.0 version
             tokens = self.parser(str_input)
 
         x = torch.tensor(tokens).unsqueeze_(0).long().to(self.device)
         return x
 
     @typecheck(
         input_types={
@@ -266,26 +302,22 @@
             speaker = torch.tensor([speaker]).to(self.device)
         spect, *_ = self(text=tokens, durs=None, pitch=None, speaker=speaker, pace=pace)
         return spect
 
     def training_step(self, batch, batch_idx):
         attn_prior, durs, speaker = None, None, None
         if self.learn_alignment:
-            # TODO(Oktai15): remove it in 1.8.0 version
-            if self.ds_class_name == "AudioToCharWithPriorAndPitchDataset":
-                audio, audio_lens, text, text_lens, attn_prior, pitch, speaker = batch
-            elif self.ds_class_name == "TTSDataset":
+            if self.ds_class_name == "TTSDataset":
                 if SpeakerID in self._train_dl.dataset.sup_data_types_set:
                     audio, audio_lens, text, text_lens, attn_prior, pitch, _, speaker = batch
                 else:
                     audio, audio_lens, text, text_lens, attn_prior, pitch, _ = batch
             else:
                 raise ValueError(f"Unknown vocab class: {self.vocab.__class__.__name__}")
         else:
-            # TODO(Oktai15): remove it in 1.8.0 version
             audio, audio_lens, text, text_lens, durs, pitch, speaker = batch
 
         mels, spec_len = self.preprocessor(input_signal=audio, length=audio_lens)
 
         mels_pred, _, _, log_durs_pred, pitch_pred, attn_soft, attn_logprob, attn_hard, attn_hard_dur, pitch = self(
             text=text,
             durs=durs,
@@ -345,26 +377,22 @@
                 )
 
         return loss
 
     def validation_step(self, batch, batch_idx):
         attn_prior, durs, speaker = None, None, None
         if self.learn_alignment:
-            # TODO(Oktai15): remove it in 1.8.0 version
-            if self.ds_class_name == "AudioToCharWithPriorAndPitchDataset":
-                audio, audio_lens, text, text_lens, attn_prior, pitch, speaker = batch
-            elif self.ds_class_name == "TTSDataset":
+            if self.ds_class_name == "TTSDataset":
                 if SpeakerID in self._train_dl.dataset.sup_data_types_set:
                     audio, audio_lens, text, text_lens, attn_prior, pitch, _, speaker = batch
                 else:
                     audio, audio_lens, text, text_lens, attn_prior, pitch, _ = batch
             else:
                 raise ValueError(f"Unknown vocab class: {self.vocab.__class__.__name__}")
         else:
-            # TODO(Oktai15): remove it in 1.8.0 version
             audio, audio_lens, text, text_lens, durs, pitch, speaker = batch
 
         mels, mel_lens = self.preprocessor(input_signal=audio, length=audio_lens)
 
         # Calculate val loss on ground truth durations to better align L2 loss in time
         mels_pred, _, _, log_durs_pred, pitch_pred, _, _, _, attn_hard_dur, pitch = self(
             text=text,
@@ -434,31 +462,27 @@
                 with open_dict(cfg.dataloader_params):
                     cfg.dataloader_params.shuffle = True
             elif not cfg.dataloader_params.shuffle:
                 logging.error(f"The {name} dataloader for {self} has shuffle set to False!!!")
         elif not shuffle_should_be and cfg.dataloader_params.shuffle:
             logging.error(f"The {name} dataloader for {self} has shuffle set to True!!!")
 
-        # TODO(Oktai15): remove it in 1.8.0 version
-        if cfg.dataset._target_ == "nemo.collections.asr.data.audio_to_text.FastPitchDataset":
-            dataset = instantiate(cfg.dataset, parser=self.parser)
-        elif cfg.dataset._target_ == "nemo.collections.tts.torch.data.TTSDataset":
+        if cfg.dataset._target_ == "nemo.collections.tts.torch.data.TTSDataset":
             phon_mode = contextlib.nullcontext()
             if hasattr(self.vocab, "set_phone_prob"):
                 phon_mode = self.vocab.set_phone_prob(prob=None if name == "val" else self.vocab.phoneme_probability)
 
             with phon_mode:
                 dataset = instantiate(
                     cfg.dataset,
                     text_normalizer=self.normalizer,
                     text_normalizer_call_kwargs=self.text_normalizer_call_kwargs,
                     text_tokenizer=self.vocab,
                 )
         else:
-            # TODO(Oktai15): remove it in 1.8.0 version
             dataset = instantiate(cfg.dataset)
 
         return torch.utils.data.DataLoader(dataset, collate_fn=dataset.collate_fn, **cfg.dataloader_params)
 
     def setup_training_data(self, cfg):
         self._train_dl = self.__setup_dataloader_from_config(cfg)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/fastpitch_hifigan_e2e.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/tacotron2.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,436 +1,385 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import contextlib
 from dataclasses import dataclass
-from itertools import chain
-from typing import Any, Dict
+from typing import Any, Dict, List, Optional
 
-import numpy as np
 import torch
 from hydra.utils import instantiate
-from omegaconf import MISSING, DictConfig, OmegaConf
-from pytorch_lightning import Trainer
-from pytorch_lightning.loggers import LoggerCollection, TensorBoardLogger
+from omegaconf import MISSING, DictConfig, OmegaConf, open_dict
+from omegaconf.errors import ConfigAttributeError
+from pytorch_lightning.loggers import LoggerCollection, TensorBoardLogger, WandbLogger
+from torch import nn
 
-from nemo.collections.asr.data.audio_to_text import FastPitchDataset
 from nemo.collections.common.parts.preprocessing import parsers
-from nemo.collections.tts.helpers.helpers import plot_spectrogram_to_numpy, regulate_len
-from nemo.collections.tts.losses.fastpitchloss import DurationLoss, PitchLoss
-from nemo.collections.tts.losses.fastspeech2loss import L1MelLoss
-from nemo.collections.tts.losses.hifigan_losses import DiscriminatorLoss, FeatureMatchingLoss, GeneratorLoss
-from nemo.collections.tts.models.base import TextToWaveform
-from nemo.collections.tts.modules.hifigan_modules import MultiPeriodDiscriminator, MultiScaleDiscriminator
+from nemo.collections.tts.helpers.helpers import (
+    get_mask_from_lengths,
+    tacotron2_log_to_tb_func,
+    tacotron2_log_to_wandb_func,
+)
+from nemo.collections.tts.losses.tacotron2loss import Tacotron2Loss
+from nemo.collections.tts.models.base import SpectrogramGenerator
 from nemo.core.classes.common import PretrainedModelInfo, typecheck
 from nemo.core.neural_types.elements import (
     AudioSignal,
-    RegressionValuesType,
-    TokenDurationType,
-    TokenIndex,
-    TokenLogDurationType,
+    EmbeddedTextType,
+    LengthsType,
+    LogitsType,
+    MelSpectrogramType,
+    SequenceToSequenceAlignmentType,
 )
 from nemo.core.neural_types.neural_type import NeuralType
-from nemo.core.optim.lr_scheduler import NoamAnnealing
-from nemo.utils import logging
-from nemo.utils.decorators import deprecated
+from nemo.utils import logging, model_utils
 
 
 @dataclass
-class FastPitchHifiGanE2EConfig:
-    parser: Dict[Any, Any] = MISSING
-    preprocessor: Dict[Any, Any] = MISSING
-    input_fft: Dict[Any, Any] = MISSING
-    output_fft: Dict[Any, Any] = MISSING
-    duration_predictor: Dict[Any, Any] = MISSING
-    pitch_predictor: Dict[Any, Any] = MISSING
-
-
-@deprecated(version="1.9", explanation="FastPitchHifiGanE2EModel will be removed.")
-class FastPitchHifiGanE2EModel(TextToWaveform):
-    """An end-to-end speech synthesis model based on FastPitch and HiFiGan that converts strings to audio without using
-    the intermediate mel spectrogram representation.
-    """
+class Preprocessor:
+    _target_: str = MISSING
+    pad_value: float = MISSING
 
-    def __init__(self, cfg: DictConfig, trainer: Trainer = None):
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
 
-        self._parser = parsers.make_parser(
-            labels=cfg.labels,
-            name='en',
-            unk_id=-1,
-            blank_id=-1,
-            do_normalize=True,
-            abbreviation_version="fastpitch",
-            make_table=False,
-        )
+@dataclass
+class Tacotron2Config:
+    preprocessor: Preprocessor = Preprocessor()
+    encoder: Dict[Any, Any] = MISSING
+    decoder: Dict[Any, Any] = MISSING
+    postnet: Dict[Any, Any] = MISSING
+    labels: List = MISSING
+    train_ds: Optional[Dict[Any, Any]] = None
+    validation_ds: Optional[Dict[Any, Any]] = None
+
+
+class Tacotron2Model(SpectrogramGenerator):
+    """Tacotron 2 Model that is used to generate mel spectrograms from text"""
+
+    def __init__(self, cfg: DictConfig, trainer: 'Trainer' = None):
+        # Convert to Hydra 1.0 compatible DictConfig
+        cfg = model_utils.convert_model_config_to_dict_config(cfg)
+        cfg = model_utils.maybe_update_config_version(cfg)
+
+        # setup normalizer
+        self.normalizer = None
+        self.text_normalizer_call = None
+        self.text_normalizer_call_kwargs = {}
+        self._setup_normalizer(cfg)
+
+        # setup tokenizer
+        self.tokenizer = None
+        if hasattr(cfg, 'text_tokenizer'):
+            self._setup_tokenizer(cfg)
+
+            self.num_tokens = len(self.tokenizer.tokens)
+            self.tokenizer_pad = self.tokenizer.pad
+            self.tokenizer_unk = self.tokenizer.oov
+            # assert self.tokenizer is not None
+        else:
+            self.num_tokens = len(cfg.labels) + 3
 
         super().__init__(cfg=cfg, trainer=trainer)
 
-        schema = OmegaConf.structured(FastPitchHifiGanE2EConfig)
+        schema = OmegaConf.structured(Tacotron2Config)
         # ModelPT ensures that cfg is a DictConfig, but do this second check in case ModelPT changes
         if isinstance(cfg, dict):
             cfg = OmegaConf.create(cfg)
         elif not isinstance(cfg, DictConfig):
             raise ValueError(f"cfg was type: {type(cfg)}. Expected either a dict or a DictConfig")
         # Ensure passed cfg is compliant with schema
-        OmegaConf.merge(cfg, schema)
-
-        self.preprocessor = instantiate(cfg.preprocessor)
-        self.melspec_fn = instantiate(cfg.preprocessor, highfreq=None, use_grads=True)
-
-        self.encoder = instantiate(cfg.input_fft)
-        self.duration_predictor = instantiate(cfg.duration_predictor)
-        self.pitch_predictor = instantiate(cfg.pitch_predictor)
-
-        self.generator = instantiate(cfg.generator)
-        self.multiperioddisc = MultiPeriodDiscriminator()
-        self.multiscaledisc = MultiScaleDiscriminator()
-        self.mel_val_loss = L1MelLoss()
-        self.feat_matching_loss = FeatureMatchingLoss()
-        self.disc_loss = DiscriminatorLoss()
-        self.gen_loss = GeneratorLoss()
-
-        self.max_token_duration = cfg.max_token_duration
-
-        self.pitch_emb = torch.nn.Conv1d(
-            1,
-            cfg.symbols_embedding_dim,
-            kernel_size=cfg.pitch_embedding_kernel_size,
-            padding=int((cfg.pitch_embedding_kernel_size - 1) / 2),
-        )
-
-        # Store values precomputed from training data for convenience
-        self.register_buffer('pitch_mean', torch.zeros(1))
-        self.register_buffer('pitch_std', torch.zeros(1))
-
-        self.pitchloss = PitchLoss()
-        self.durationloss = DurationLoss()
-
-        self.mel_loss_coeff = cfg.mel_loss_coeff
-
-        self.log_train_images = False
-        self.logged_real_samples = False
-        self._tb_logger = None
-        self.hann_window = None
-        self.splice_length = cfg.splice_length
-        self.sample_rate = cfg.sample_rate
-        self.hop_size = cfg.hop_size
+        try:
+            OmegaConf.merge(cfg, schema)
+            self.pad_value = cfg.preprocessor.pad_value
+        except ConfigAttributeError:
+            self.pad_value = cfg.preprocessor.params.pad_value
+            logging.warning(
+                "Your config is using an old NeMo yaml configuration. Please ensure that the yaml matches the "
+                "current version in the main branch for future compatibility."
+            )
 
-    @property
-    def tb_logger(self):
-        if self._tb_logger is None:
-            if self.logger is None and self.logger.experiment is None:
-                return None
-            tb_logger = self.logger.experiment
-            if isinstance(self.logger, LoggerCollection):
-                for logger in self.logger:
-                    if isinstance(logger, TensorBoardLogger):
-                        tb_logger = logger.experiment
-                        break
-            self._tb_logger = tb_logger
-        return self._tb_logger
+        self._parser = None
+        self.audio_to_melspec_precessor = instantiate(cfg.preprocessor)
+        self.text_embedding = nn.Embedding(self.num_tokens, 512)
+        self.encoder = instantiate(self._cfg.encoder)
+        self.decoder = instantiate(self._cfg.decoder)
+        self.postnet = instantiate(self._cfg.postnet)
+        self.loss = Tacotron2Loss()
+        self.calculate_loss = True
 
     @property
     def parser(self):
         if self._parser is not None:
             return self._parser
 
-        self._parser = parsers.make_parser(
-            labels=self._cfg.labels,
-            name='en',
-            unk_id=-1,
-            blank_id=-1,
-            do_normalize=True,
-            abbreviation_version="fastpitch",
-            make_table=False,
-        )
-        return self._parser
+        ds_class_name = self._cfg.train_ds.dataset._target_.split(".")[-1]
+        if ds_class_name == "TTSDataset":
+            self._parser = None
+        elif hasattr(self._cfg, "labels"):
+            self._parser = parsers.make_parser(
+                labels=self._cfg.labels,
+                name='en',
+                unk_id=-1,
+                blank_id=-1,
+                do_normalize=True,
+                abbreviation_version="fastpitch",
+                make_table=False,
+            )
+        elif ds_class_name == "AudioToCharWithPriorAndPitchDataset":
+            self.parser = self.vocab.encode
+        else:
+            raise ValueError("Wanted to setup parser, but model does not have necessary paramaters")
 
-    def parse(self, str_input: str) -> torch.tensor:
-        if str_input[-1] not in [".", "!", "?"]:
-            str_input = str_input + "."
-
-        tokens = self.parser(str_input)
-
-        x = torch.tensor(tokens).unsqueeze_(0).long().to(self.device)
-        return x
-
-    def configure_optimizers(self):
-        gen_params = chain(
-            self.pitch_emb.parameters(),
-            self.encoder.parameters(),
-            self.duration_predictor.parameters(),
-            self.pitch_predictor.parameters(),
-            self.generator.parameters(),
-        )
-        disc_params = chain(self.multiscaledisc.parameters(), self.multiperioddisc.parameters())
-        opt1 = torch.optim.AdamW(disc_params, lr=self._cfg.lr)
-        opt2 = torch.optim.AdamW(gen_params, lr=self._cfg.lr)
-        num_procs = self._trainer.num_devices * self._trainer.num_nodes
-        num_samples = len(self._train_dl.dataset)
-        batch_size = self._train_dl.batch_size
-        iter_per_epoch = np.ceil(num_samples / (num_procs * batch_size))
-        max_steps = iter_per_epoch * self._trainer.max_epochs
-        logging.info(f"MAX STEPS: {max_steps}")
-        sch1 = NoamAnnealing(opt1, d_model=1, warmup_steps=1000, max_steps=max_steps, last_epoch=-1)
-        sch1_dict = {
-            'scheduler': sch1,
-            'interval': 'step',
-        }
-        sch2 = NoamAnnealing(opt2, d_model=1, warmup_steps=1000, max_steps=max_steps, last_epoch=-1)
-        sch2_dict = {
-            'scheduler': sch2,
-            'interval': 'step',
-        }
-        return [opt1, opt2], [sch1_dict, sch2_dict]
+        return self._parser
 
-    @typecheck(
-        input_types={
-            "text": NeuralType(('B', 'T'), TokenIndex()),
-            "durs": NeuralType(('B', 'T'), TokenDurationType(), optional=True),
-            "pitch": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-            "pace": NeuralType(optional=True),
-            "splice": NeuralType(optional=True),
-        },
-        output_types={
-            "audio": NeuralType(('B', 'S', 'T'), AudioSignal()),
-            "splices": NeuralType(),
-            "log_dur_preds": NeuralType(('B', 'T'), TokenLogDurationType()),
-            "pitch_preds": NeuralType(('B', 'T'), RegressionValuesType()),
-        },
-    )
-    def forward(self, *, text, durs=None, pitch=None, pace=1.0, splice=True):
+    def parse(self, text: str, normalize=True) -> torch.Tensor:
         if self.training:
-            assert durs is not None
-            assert pitch is not None
+            logging.warning("parse() is meant to be called in eval mode.")
+        if normalize and self.text_normalizer_call is not None:
+            text = self.text_normalizer_call(text, **self.text_normalizer_call_kwargs)
+
+        eval_phon_mode = contextlib.nullcontext()
+        if hasattr(self.tokenizer, "set_phone_prob"):
+            eval_phon_mode = self.tokenizer.set_phone_prob(prob=1.0)
+
+        with eval_phon_mode:
+            if self.tokenizer is not None:
+                tokens = self.tokenizer.encode(text)
+            else:
+                tokens = self.parser(text)
+                # Old parser doesn't add bos and eos ids, so maunally add it
+                tokens = [len(self._cfg.labels)] + tokens + [len(self._cfg.labels) + 1]
+        tokens_tensor = torch.tensor(tokens).unsqueeze_(0).to(self.device)
+        return tokens_tensor
 
-        # Input FFT
-        enc_out, enc_mask = self.encoder(input=text, conditioning=0)
+    @property
+    def input_types(self):
+        if self.training:
+            return {
+                "tokens": NeuralType(('B', 'T'), EmbeddedTextType()),
+                "token_len": NeuralType(('B'), LengthsType()),
+                "audio": NeuralType(('B', 'T'), AudioSignal()),
+                "audio_len": NeuralType(('B'), LengthsType()),
+            }
+        else:
+            return {
+                "tokens": NeuralType(('B', 'T'), EmbeddedTextType()),
+                "token_len": NeuralType(('B'), LengthsType()),
+                "audio": NeuralType(('B', 'T'), AudioSignal(), optional=True),
+                "audio_len": NeuralType(('B'), LengthsType(), optional=True),
+            }
 
-        # Embedded for predictors
-        pred_enc_out, pred_enc_mask = enc_out, enc_mask
+    @property
+    def output_types(self):
+        if not self.calculate_loss and not self.training:
+            return {
+                "spec_pred_dec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+                "spec_pred_postnet": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+                "gate_pred": NeuralType(('B', 'T'), LogitsType()),
+                "alignments": NeuralType(('B', 'T', 'T'), SequenceToSequenceAlignmentType()),
+                "pred_length": NeuralType(('B'), LengthsType()),
+            }
+        return {
+            "spec_pred_dec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+            "spec_pred_postnet": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+            "gate_pred": NeuralType(('B', 'T'), LogitsType()),
+            "spec_target": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+            "spec_target_len": NeuralType(('B'), LengthsType()),
+            "alignments": NeuralType(('B', 'T', 'T'), SequenceToSequenceAlignmentType()),
+        }
 
-        # Predict durations
-        log_durs_predicted = self.duration_predictor(pred_enc_out, pred_enc_mask)
-        durs_predicted = torch.clamp(torch.exp(log_durs_predicted) - 1, 0, self.max_token_duration)
-
-        # Predict pitch
-        pitch_predicted = self.pitch_predictor(enc_out, enc_mask)
-        if pitch is None:
-            pitch_emb = self.pitch_emb(pitch_predicted.unsqueeze(1))
+    @typecheck()
+    def forward(self, *, tokens, token_len, audio=None, audio_len=None):
+        if audio is not None and audio_len is not None:
+            spec_target, spec_target_len = self.audio_to_melspec_precessor(audio, audio_len)
+        token_embedding = self.text_embedding(tokens).transpose(1, 2)
+        encoder_embedding = self.encoder(token_embedding=token_embedding, token_len=token_len)
+        if self.training:
+            spec_pred_dec, gate_pred, alignments = self.decoder(
+                memory=encoder_embedding, decoder_inputs=spec_target, memory_lengths=token_len
+            )
         else:
-            pitch_emb = self.pitch_emb(pitch.unsqueeze(1))
-        enc_out = enc_out + pitch_emb.transpose(1, 2)
+            spec_pred_dec, gate_pred, alignments, pred_length = self.decoder(
+                memory=encoder_embedding, memory_lengths=token_len
+            )
+        spec_pred_postnet = self.postnet(mel_spec=spec_pred_dec)
 
-        if durs is None:
-            len_regulated, dec_lens = regulate_len(durs_predicted, enc_out, pace)
-        else:
-            len_regulated, dec_lens = regulate_len(durs, enc_out, pace)
+        if not self.calculate_loss:
+            return spec_pred_dec, spec_pred_postnet, gate_pred, alignments, pred_length
+        return spec_pred_dec, spec_pred_postnet, gate_pred, spec_target, spec_target_len, alignments
 
-        gen_in = len_regulated
-        splices = []
-        if splice:
-            output = []
-            for i, sample in enumerate(len_regulated):
-                start = np.random.randint(low=0, high=min(int(sample.size(0)), int(dec_lens[i])) - self.splice_length)
-                # Splice generated spec
-                output.append(sample[start : start + self.splice_length, :])
-                splices.append(start)
-            gen_in = torch.stack(output)
-
-        output = self.generator(x=gen_in.transpose(1, 2))
-
-        return output, torch.tensor(splices), log_durs_predicted, pitch_predicted
-
-    def training_step(self, batch, batch_idx, optimizer_idx):
-        audio, _, text, text_lens, durs, pitch, _ = batch
-
-        # train discriminator
-        if optimizer_idx == 0:
-            with torch.no_grad():
-                audio_pred, splices, _, _ = self(text=text, durs=durs, pitch=pitch)
-                real_audio = []
-                for i, splice in enumerate(splices):
-                    real_audio.append(audio[i, splice * self.hop_size : (splice + self.splice_length) * self.hop_size])
-                real_audio = torch.stack(real_audio).unsqueeze(1)
+    @typecheck(
+        input_types={"tokens": NeuralType(('B', 'T'), EmbeddedTextType())},
+        output_types={"spec": NeuralType(('B', 'D', 'T'), MelSpectrogramType())},
+    )
+    def generate_spectrogram(self, *, tokens):
+        self.eval()
+        self.calculate_loss = False
+        token_len = torch.tensor([len(i) for i in tokens]).to(self.device)
+        tensors = self(tokens=tokens, token_len=token_len)
+        spectrogram_pred = tensors[1]
+
+        if spectrogram_pred.shape[0] > 1:
+            # Silence all frames past the predicted end
+            mask = ~get_mask_from_lengths(tensors[-1])
+            mask = mask.expand(spectrogram_pred.shape[1], mask.size(0), mask.size(1))
+            mask = mask.permute(1, 0, 2)
+            spectrogram_pred.data.masked_fill_(mask, self.pad_value)
+
+        return spectrogram_pred
+
+    def training_step(self, batch, batch_idx):
+        audio, audio_len, tokens, token_len = batch
+        spec_pred_dec, spec_pred_postnet, gate_pred, spec_target, spec_target_len, _ = self.forward(
+            audio=audio, audio_len=audio_len, tokens=tokens, token_len=token_len
+        )
 
-            real_score_mp, gen_score_mp, _, _ = self.multiperioddisc(real_audio, audio_pred)
-            real_score_ms, gen_score_ms, _, _ = self.multiscaledisc(real_audio, audio_pred)
+        loss, _ = self.loss(
+            spec_pred_dec=spec_pred_dec,
+            spec_pred_postnet=spec_pred_postnet,
+            gate_pred=gate_pred,
+            spec_target=spec_target,
+            spec_target_len=spec_target_len,
+            pad_value=self.pad_value,
+        )
 
-            loss_mp, loss_mp_real, _ = self.disc_loss(
-                disc_real_outputs=real_score_mp, disc_generated_outputs=gen_score_mp
-            )
-            loss_ms, loss_ms_real, _ = self.disc_loss(
-                disc_real_outputs=real_score_ms, disc_generated_outputs=gen_score_ms
-            )
-            loss_mp /= len(loss_mp_real)
-            loss_ms /= len(loss_ms_real)
-            loss_disc = loss_mp + loss_ms
-
-            self.log("loss_discriminator", loss_disc, prog_bar=True)
-            self.log("loss_discriminator_ms", loss_ms)
-            self.log("loss_discriminator_mp", loss_mp)
-            return loss_disc
-
-        # train generator
-        elif optimizer_idx == 1:
-            audio_pred, splices, log_dur_preds, pitch_preds = self(text=text, durs=durs, pitch=pitch)
-            real_audio = []
-            for i, splice in enumerate(splices):
-                real_audio.append(audio[i, splice * self.hop_size : (splice + self.splice_length) * self.hop_size])
-            real_audio = torch.stack(real_audio).unsqueeze(1)
-
-            dur_loss = self.durationloss(log_durs_predicted=log_dur_preds, durs_tgt=durs, len=text_lens)
-            pitch_loss = self.pitchloss(pitch_predicted=pitch_preds, pitch_tgt=pitch,)
-
-            # Do HiFiGAN generator loss
-            audio_length = torch.tensor([self.splice_length * self.hop_size for _ in range(real_audio.shape[0])]).to(
-                real_audio.device
-            )
-            real_spliced_spec, _ = self.melspec_fn(real_audio.squeeze(), audio_length)
-            pred_spliced_spec, _ = self.melspec_fn(audio_pred.squeeze(), audio_length)
-            loss_mel = torch.nn.functional.l1_loss(real_spliced_spec, pred_spliced_spec)
-            loss_mel *= self.mel_loss_coeff
-            _, gen_score_mp, _, _ = self.multiperioddisc(real_audio, audio_pred)
-            _, gen_score_ms, _, _ = self.multiscaledisc(y=real_audio, y_hat=audio_pred)
-            loss_gen_mp, list_loss_gen_mp = self.gen_loss(disc_outputs=gen_score_mp)
-            loss_gen_ms, list_loss_gen_ms = self.gen_loss(disc_outputs=gen_score_ms)
-            loss_gen_mp /= len(list_loss_gen_mp)
-            loss_gen_ms /= len(list_loss_gen_ms)
-            total_loss = loss_gen_mp + loss_gen_ms + loss_mel
-            total_loss += dur_loss
-            total_loss += pitch_loss
-
-            self.log(name="loss_gen_mel", value=loss_mel)
-            self.log(name="loss_gen_disc", value=loss_gen_mp + loss_gen_ms)
-            self.log(name="loss_gen_disc_mp", value=loss_gen_mp)
-            self.log(name="loss_gen_disc_ms", value=loss_gen_ms)
-            self.log(name="loss_gen_duration", value=dur_loss)
-            self.log(name="loss_gen_pitch", value=pitch_loss)
-
-            # Log images to tensorboard
-            if self.log_train_images:
-                self.log_train_images = False
-
-                if self.logger is not None and self.logger.experiment is not None:
-                    self.tb_logger.add_image(
-                        "train_mel_target",
-                        plot_spectrogram_to_numpy(real_spliced_spec[0].data.cpu().numpy()),
-                        self.global_step,
-                        dataformats="HWC",
-                    )
-                    spec_predict = pred_spliced_spec[0].data.cpu().numpy()
-                    self.tb_logger.add_image(
-                        "train_mel_predicted",
-                        plot_spectrogram_to_numpy(spec_predict),
-                        self.global_step,
-                        dataformats="HWC",
-                    )
-            self.log(name="loss_gen", prog_bar=True, value=total_loss)
-            return total_loss
+        output = {
+            'loss': loss,
+            'progress_bar': {'training_loss': loss},
+            'log': {'loss': loss},
+        }
+        return output
 
     def validation_step(self, batch, batch_idx):
-        audio, audio_lens, text, _, _, _, _ = batch
-        mels, mel_lens = self.preprocessor(audio, audio_lens)
-
-        audio_pred, _, log_durs_predicted, _ = self(text=text, durs=None, pitch=None, splice=False)
-        audio_length = torch.sum(torch.clamp(torch.exp(log_durs_predicted - 1), 0), axis=1)
-        audio_pred.squeeze_()
-        pred_spec, _ = self.melspec_fn(audio_pred, audio_length)
-        loss = self.mel_val_loss(
-            spec_pred=pred_spec, spec_target=mels, spec_target_len=mel_lens, pad_value=-11.52, transpose=False
+        audio, audio_len, tokens, token_len = batch
+        spec_pred_dec, spec_pred_postnet, gate_pred, spec_target, spec_target_len, alignments = self.forward(
+            audio=audio, audio_len=audio_len, tokens=tokens, token_len=token_len
         )
 
+        loss, gate_target = self.loss(
+            spec_pred_dec=spec_pred_dec,
+            spec_pred_postnet=spec_pred_postnet,
+            gate_pred=gate_pred,
+            spec_target=spec_target,
+            spec_target_len=spec_target_len,
+            pad_value=self.pad_value,
+        )
         return {
             "val_loss": loss,
-            "audio_target": audio if batch_idx == 0 else None,
-            "audio_pred": audio_pred.squeeze() if batch_idx == 0 else None,
+            "mel_target": spec_target,
+            "mel_postnet": spec_pred_postnet,
+            "gate": gate_pred,
+            "gate_target": gate_target,
+            "alignments": alignments,
         }
 
     def validation_epoch_end(self, outputs):
-        if self.tb_logger is not None:
-            _, audio_target, audio_predict = outputs[0].values()
-            if not self.logged_real_samples:
-                self.tb_logger.add_audio("val_target", audio_target[0].data.cpu(), self.global_step, self.sample_rate)
-                self.logged_real_samples = True
-            audio_predict = audio_predict[0].data.cpu()
-            self.tb_logger.add_audio("val_pred", audio_predict, self.global_step, self.sample_rate)
+        if self.logger is not None and self.logger.experiment is not None:
+            logger = self.logger.experiment
+            if isinstance(self.logger, LoggerCollection):
+                for logger in self.logger:
+                    if isinstance(logger, TensorBoardLogger):
+                        logger = logger.experiment
+                        break
+            if isinstance(logger, TensorBoardLogger):
+                tacotron2_log_to_tb_func(
+                    logger, outputs[0].values(), self.global_step, tag="val", log_images=True, add_audio=False,
+                )
+            elif isinstance(logger, WandbLogger):
+                tacotron2_log_to_wandb_func(
+                    logger, outputs[0].values(), self.global_step, tag="val", log_images=True, add_audio=False,
+                )
         avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()  # This reduces across batches, not workers!
-        self.log('val_loss', avg_loss, sync_dist=True)
+        self.log('val_loss', avg_loss)
 
-        self.log_train_images = True
-
-    def _loader(self, cfg):
-        dataset = FastPitchDataset(
-            manifest_filepath=cfg['manifest_filepath'],
-            parser=self.parser,
-            sample_rate=cfg['sample_rate'],
-            int_values=cfg.get('int_values', False),
-            max_duration=cfg.get('max_duration', None),
-            min_duration=cfg.get('min_duration', None),
-            max_utts=cfg.get('max_utts', 0),
-            trim=cfg.get('trim_silence', True),
+    def _setup_normalizer(self, cfg):
+        if "text_normalizer" in cfg:
+            normalizer_kwargs = {}
+
+            if "whitelist" in cfg.text_normalizer:
+                normalizer_kwargs["whitelist"] = self.register_artifact(
+                    'text_normalizer.whitelist', cfg.text_normalizer.whitelist
+                )
+
+            self.normalizer = instantiate(cfg.text_normalizer, **normalizer_kwargs)
+            self.text_normalizer_call = self.normalizer.normalize
+            if "text_normalizer_call_kwargs" in cfg:
+                self.text_normalizer_call_kwargs = cfg.text_normalizer_call_kwargs
+
+    def _setup_tokenizer(self, cfg):
+        text_tokenizer_kwargs = {}
+        if "g2p" in cfg.text_tokenizer and cfg.text_tokenizer.g2p is not None:
+            g2p_kwargs = {}
+
+            if "phoneme_dict" in cfg.text_tokenizer.g2p:
+                g2p_kwargs["phoneme_dict"] = self.register_artifact(
+                    'text_tokenizer.g2p.phoneme_dict', cfg.text_tokenizer.g2p.phoneme_dict,
+                )
+
+            if "heteronyms" in cfg.text_tokenizer.g2p:
+                g2p_kwargs["heteronyms"] = self.register_artifact(
+                    'text_tokenizer.g2p.heteronyms', cfg.text_tokenizer.g2p.heteronyms,
+                )
+
+            text_tokenizer_kwargs["g2p"] = instantiate(cfg.text_tokenizer.g2p, **g2p_kwargs)
+
+        self.tokenizer = instantiate(cfg.text_tokenizer, **text_tokenizer_kwargs)
+
+    def __setup_dataloader_from_config(self, cfg, shuffle_should_be: bool = True, name: str = "train"):
+        if "dataset" not in cfg or not isinstance(cfg.dataset, DictConfig):
+            raise ValueError(f"No dataset for {name}")
+        if "dataloader_params" not in cfg or not isinstance(cfg.dataloader_params, DictConfig):
+            raise ValueError(f"No dataloder_params for {name}")
+        if shuffle_should_be:
+            if 'shuffle' not in cfg.dataloader_params:
+                logging.warning(
+                    f"Shuffle should be set to True for {self}'s {name} dataloader but was not found in its "
+                    "config. Manually setting to True"
+                )
+                with open_dict(cfg.dataloader_params):
+                    cfg.dataloader_params.shuffle = True
+            elif not cfg.dataloader_params.shuffle:
+                logging.error(f"The {name} dataloader for {self} has shuffle set to False!!!")
+        elif not shuffle_should_be and cfg.dataloader_params.shuffle:
+            logging.error(f"The {name} dataloader for {self} has shuffle set to True!!!")
+
+        dataset = instantiate(
+            cfg.dataset,
+            text_normalizer=self.normalizer,
+            text_normalizer_call_kwargs=self.text_normalizer_call_kwargs,
+            text_tokenizer=self.tokenizer,
         )
 
-        return torch.utils.data.DataLoader(
-            dataset=dataset,
-            batch_size=cfg['batch_size'],
-            collate_fn=dataset.collate_fn,
-            drop_last=cfg.get('drop_last', True),
-            shuffle=cfg['shuffle'],
-            num_workers=cfg.get('num_workers', 16),
-        )
+        return torch.utils.data.DataLoader(dataset, collate_fn=dataset.collate_fn, **cfg.dataloader_params)
 
     def setup_training_data(self, cfg):
-        self._train_dl = self._loader(cfg)
+        self._train_dl = self.__setup_dataloader_from_config(cfg)
 
     def setup_validation_data(self, cfg):
-        self._validation_dl = self._loader(cfg)
-
-    def setup_test_data(self, cfg):
-        """Omitted."""
-        pass
+        self._validation_dl = self.__setup_dataloader_from_config(cfg, shuffle_should_be=False, name="validation")
 
     @classmethod
     def list_available_models(cls) -> 'List[PretrainedModelInfo]':
         """
         This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
         Returns:
             List of available pre-trained models.
         """
         list_of_models = []
         model = PretrainedModelInfo(
-            pretrained_model_name="tts_en_e2e_fastpitchhifigan",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_e2e_fastpitchhifigan/versions/1.0.0/files/tts_en_e2e_fastpitchhifigan.nemo",
-            description="This model is trained on LJSpeech sampled at 22050Hz with and can be used to generate female English voices with an American accent.",
+            pretrained_model_name="tts_en_tacotron2",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_tacotron2/versions/1.0.0/files/tts_en_tacotron2.nemo",
+            description="This model is trained on LJSpeech sampled at 22050Hz, and can be used to generate female English voices with an American accent.",
             class_=cls,
+            aliases=["Tacotron2-22050Hz"],
         )
         list_of_models.append(model)
-
         return list_of_models
-
-    def convert_text_to_waveform(self, *, tokens):
-        """
-        Accepts tokens returned from self.parse() and returns a list of tensors. Note: The tensors in the list can have
-        different lengths.
-        """
-        self.eval()
-        audio, _, log_dur_pred, _ = self(text=tokens, splice=False)
-        audio = audio.squeeze(1)
-        durations = torch.sum(torch.clamp(torch.exp(log_dur_pred) - 1, 0, self.max_token_duration), 1).to(torch.int)
-        audio_list = []
-        for i, sample in enumerate(audio):
-            audio_list.append(sample[: durations[i] * self.hop_size])
-
-        return audio_list
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/fastspeech2.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/waveglow.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,276 +1,160 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import json
-import re
-from dataclasses import dataclass
-from typing import Any, Dict, Optional
 
 import torch
 from hydra.utils import instantiate
-from omegaconf import MISSING, DictConfig, OmegaConf, open_dict
+from omegaconf import DictConfig, open_dict
 from pytorch_lightning.loggers import LoggerCollection, TensorBoardLogger
 
-from nemo.collections.common.parts.preprocessing import parsers
-from nemo.collections.tts.helpers.helpers import plot_spectrogram_to_numpy
-from nemo.collections.tts.losses.fastspeech2loss import DurationLoss, L2MelLoss
-from nemo.collections.tts.models.base import SpectrogramGenerator
+from nemo.collections.tts.helpers.helpers import OperationMode, waveglow_log_to_tb_func
+from nemo.collections.tts.losses.waveglowloss import WaveGlowLoss
+from nemo.collections.tts.models.base import GlowVocoder
+from nemo.core.classes import Exportable
 from nemo.core.classes.common import PretrainedModelInfo, typecheck
-from nemo.core.neural_types.elements import *
+from nemo.core.neural_types.elements import (
+    AudioSignal,
+    LengthsType,
+    LogDeterminantType,
+    MelSpectrogramType,
+    NormalDistributionSamplesType,
+    VoidType,
+)
 from nemo.core.neural_types.neural_type import NeuralType
-from nemo.utils import logging
-from nemo.utils.decorators import deprecated
+from nemo.utils import logging, model_utils
 
 
-@dataclass
-class FastSpeech2Config:
-    preprocessor: Dict[Any, Any] = MISSING
-    encoder: Dict[Any, Any] = MISSING
-    decoder: Dict[Any, Any] = MISSING
-    variance_adaptor: Dict[Any, Any] = MISSING
-    train_ds: Optional[Dict[Any, Any]] = None
-    validation_ds: Optional[Dict[Any, Any]] = None
-
-
-@deprecated(version="1.9", explanation="FastSpeech2Model will be removed. Please, use FastPitchModel instead.")
-class FastSpeech2Model(SpectrogramGenerator):
-    """FastSpeech 2 model used to convert from text (phonemes) to mel-spectrograms."""
+class WaveGlowModel(GlowVocoder, Exportable):
+    """WaveGlow model (https://arxiv.org/abs/1811.00002) that is used to generate audio from mel spectrogram."""
 
     def __init__(self, cfg: DictConfig, trainer: 'Trainer' = None):
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
+        # Convert to Hydra 1.0 compatible DictConfig
+        cfg = model_utils.convert_model_config_to_dict_config(cfg)
+        cfg = model_utils.maybe_update_config_version(cfg)
+
         super().__init__(cfg=cfg, trainer=trainer)
 
-        schema = OmegaConf.structured(FastSpeech2Config)
-        # ModelPT ensures that cfg is a DictConfig, but do this second check in case ModelPT changes
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
-        elif not isinstance(cfg, DictConfig):
-            raise ValueError(f"cfg was type: {type(cfg)}. Expected either a dict or a DictConfig")
-        # Ensure passed cfg is compliant with schema
-        OmegaConf.merge(cfg, schema)
-
-        self.pitch = cfg.add_pitch_predictor
-        self.energy = cfg.add_energy_predictor
-        self.duration_coeff = cfg.duration_coeff
-
-        self.audio_to_melspec_preprocessor = instantiate(self._cfg.preprocessor)
-        self.encoder = instantiate(self._cfg.encoder)
-        self.mel_decoder = instantiate(self._cfg.decoder)
-        self.variance_adapter = instantiate(self._cfg.variance_adaptor)
-        self.loss = L2MelLoss()
-        self.mseloss = torch.nn.MSELoss()
-        self.durationloss = DurationLoss()
-
-        self.log_train_images = False
-
-        # Parser and mappings are used for inference only.
-        self.parser = parsers.make_parser(name='en')
-        if 'mappings_filepath' in cfg:
-            mappings_filepath = cfg.get('mappings_filepath')
+        self.sigma = self._cfg.sigma
+        self.audio_to_melspec_precessor = instantiate(self._cfg.preprocessor)
+        self.waveglow = instantiate(self._cfg.waveglow)
+        self.loss = WaveGlowLoss()
+
+    @GlowVocoder.mode.setter
+    def mode(self, new_mode):
+        if new_mode == OperationMode.training:
+            self.train()
         else:
-            logging.error(
-                "ERROR: You must specify a mappings.json file in the config file under model.mappings_filepath."
-            )
-        mappings_filepath = self.register_artifact('mappings_filepath', mappings_filepath)
-        with open(mappings_filepath, 'r', encoding='utf-8') as f:
-            mappings = json.load(f)
-            self.word2phones = mappings['word2phones']
-            self.phone2idx = mappings['phone2idx']
+            self.eval()
+        self._mode = new_mode
+        self.waveglow.mode = new_mode
+
+    @typecheck()
+    def forward(self, *, audio, audio_len, run_inverse=True):
+        if self.mode != self.waveglow.mode:
+            raise ValueError(
+                f"WaveGlowModel's mode {self.mode} does not match WaveGlowModule's mode {self.waveglow.mode}"
+            )
+        spec, spec_len = self.audio_to_melspec_precessor(audio, audio_len)
+        tensors = self.waveglow(spec=spec, audio=audio, run_inverse=run_inverse, sigma=self.sigma)
+        if self.mode == OperationMode.training:
+            return tensors[:-1]  # z, log_s_list, log_det_W_list
+        elif self.mode == OperationMode.validation:
+            z, log_s_list, log_det_W_list, audio_pred = tensors
+            return z, log_s_list, log_det_W_list, audio_pred, spec, spec_len
+        return tensors  # audio_pred
 
     @typecheck(
         input_types={
-            "text": NeuralType(('B', 'T'), TokenIndex()),
-            "text_length": NeuralType(('B'), LengthsType()),
-            "spec_len": NeuralType(('B'), LengthsType(), optional=True),
-            "durations": NeuralType(('B', 'T'), TokenDurationType(), optional=True),
-            "pitch": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-            "energies": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-        },
-        output_types={
-            "mel_spec": NeuralType(('B', 'T', 'C'), MelSpectrogramType()),
-            "log_dur_preds": NeuralType(('B', 'T'), TokenLogDurationType(), optional=True),
-            "pitch_preds": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-            "energy_preds": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-            "encoded_text_mask": NeuralType(('B', 'T', 'D'), MaskType()),
+            "spec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+            "sigma": NeuralType(optional=True),
+            "denoise": NeuralType(optional=True),
+            "denoiser_strength": NeuralType(optional=True),
         },
+        output_types={"audio": NeuralType(('B', 'T'), AudioSignal())},
     )
-    def forward(self, *, text, text_length, spec_len=None, durations=None, pitch=None, energies=None):
-        encoded_text, encoded_text_mask = self.encoder(text=text, text_length=text_length)
-        aligned_text, log_dur_preds, pitch_preds, energy_preds, spec_len = self.variance_adapter(
-            x=encoded_text,
-            x_len=text_length,
-            dur_target=durations,
-            pitch_target=pitch,
-            energy_target=energies,
-            spec_len=spec_len,
-        )
-        mel = self.mel_decoder(decoder_input=aligned_text, lengths=spec_len)
-        return mel, log_dur_preds, pitch_preds, energy_preds, encoded_text_mask
+    def convert_spectrogram_to_audio(
+        self, spec: torch.Tensor, sigma: float = 1.0, denoise: bool = True, denoiser_strength: float = 0.01
+    ) -> torch.Tensor:
+        with self.nemo_infer():
+            self.waveglow.remove_weightnorm()
+            audio = self.waveglow(spec=spec.to(self.waveglow.upsample.weight.dtype), sigma=sigma)
+            if denoise:
+                audio = self.denoise(audio=audio, strength=denoiser_strength)
 
-    def training_step(self, batch, batch_idx):
-        f, fl, t, tl, durations, pitch, energies = batch
-        spec, spec_len = self.audio_to_melspec_preprocessor(f, fl)
-        mel, log_dur_preds, pitch_preds, energy_preds, encoded_text_mask = self(
-            text=t, text_length=tl, spec_len=spec_len, durations=durations, pitch=pitch, energies=energies
-        )
-        total_loss = self.loss(
-            spec_pred=mel.transpose(1, 2), spec_target=spec, spec_target_len=spec_len, pad_value=-11.52
-        )
-        self.log(name="train_mel_loss", value=total_loss.clone().detach())
-
-        # Duration prediction loss
-        dur_loss = self.durationloss(
-            log_duration_pred=log_dur_preds, duration_target=durations.float(), mask=encoded_text_mask
-        )
-        dur_loss *= self.duration_coeff
-        self.log(name="train_dur_loss", value=dur_loss)
-        total_loss += dur_loss
-
-        # Pitch prediction loss
-        if self.pitch:
-            pitch_loss = self.mseloss(pitch_preds, pitch)
-            total_loss += pitch_loss
-            self.log(name="train_pitch_loss", value=pitch_loss)
-
-        # Energy prediction loss
-        if self.energy:
-            energy_loss = self.mseloss(energy_preds, energies)
-            total_loss += energy_loss
-            self.log(name="train_energy_loss", value=energy_loss)
-        self.log(name="train_loss", value=total_loss)
-        return {"loss": total_loss, "outputs": [spec, mel]}
-
-    def training_epoch_end(self, outputs):
-        if self.log_train_images and self.logger is not None and self.logger.experiment is not None:
-            tb_logger = self.logger.experiment
-            if isinstance(self.logger, LoggerCollection):
-                for logger in self.logger:
-                    if isinstance(logger, TensorBoardLogger):
-                        tb_logger = logger.experiment
-                        break
-            spec_target, spec_predict = outputs[0]["outputs"]
-            tb_logger.add_image(
-                "train_mel_target",
-                plot_spectrogram_to_numpy(spec_target[0].data.cpu().numpy()),
-                self.global_step,
-                dataformats="HWC",
-            )
-            spec_predict = spec_predict[0].data.cpu().numpy()
-            tb_logger.add_image(
-                "train_mel_predicted", plot_spectrogram_to_numpy(spec_predict.T), self.global_step, dataformats="HWC",
-            )
-            self.log_train_images = False
+        return audio
 
-            return super().training_epoch_end(outputs)
+    def training_step(self, batch, batch_idx):
+        self.mode = OperationMode.training
+        audio, audio_len = batch
+        z, log_s_list, log_det_W_list = self(audio=audio, audio_len=audio_len, run_inverse=False)
+
+        loss = self.loss(z=z, log_s_list=log_s_list, log_det_W_list=log_det_W_list, sigma=self.sigma)
+        output = {
+            'loss': loss,
+            'progress_bar': {'training_loss': loss},
+            'log': {'loss': loss},
+        }
+        return output
 
     def validation_step(self, batch, batch_idx):
-        f, fl, t, tl, _, _, _ = batch
-        spec, spec_len = self.audio_to_melspec_preprocessor(f, fl)
-        mel, _, _, _, _ = self(text=t, text_length=tl, spec_len=spec_len)
-        loss = self.loss(spec_pred=mel.transpose(1, 2), spec_target=spec, spec_target_len=spec_len, pad_value=-11.52)
+        self.mode = OperationMode.validation
+        audio, audio_len = batch
+        z, log_s_list, log_det_W_list, audio_pred, spec, spec_len = self(
+            audio=audio, audio_len=audio_len, run_inverse=(batch_idx == 0)
+        )
+        loss = self.loss(z=z, log_s_list=log_s_list, log_det_W_list=log_det_W_list, sigma=self.sigma)
         return {
             "val_loss": loss,
+            "audio_pred": audio_pred,
             "mel_target": spec,
-            "mel_pred": mel,
+            "mel_len": spec_len,
         }
 
     def validation_epoch_end(self, outputs):
         if self.logger is not None and self.logger.experiment is not None:
             tb_logger = self.logger.experiment
             if isinstance(self.logger, LoggerCollection):
                 for logger in self.logger:
                     if isinstance(logger, TensorBoardLogger):
                         tb_logger = logger.experiment
                         break
-            _, spec_target, spec_predict = outputs[0].values()
-            tb_logger.add_image(
-                "val_mel_target",
-                plot_spectrogram_to_numpy(spec_target[0].data.cpu().numpy()),
+            waveglow_log_to_tb_func(
+                tb_logger,
+                outputs[0].values(),
                 self.global_step,
-                dataformats="HWC",
+                tag="eval",
+                mel_fb=self.audio_to_melspec_precessor.fb,
             )
-            spec_predict = spec_predict[0].data.cpu().numpy()
-            tb_logger.add_image(
-                "val_mel_predicted", plot_spectrogram_to_numpy(spec_predict.T), self.global_step, dataformats="HWC",
-            )
-        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()  # This reduces across batches, not workers!
-        self.log('val_loss', avg_loss, sync_dist=True)
-
-        self.log_train_images = True
-
-    def parse(self, str_input: str, additional_word2phones=None) -> torch.tensor:
-        """
-        Parses text input and converts them to phoneme indices.
-
-        str_input (str): The input text to be converted.
-        additional_word2phones (dict): Optional dictionary mapping words to phonemes for updating the model's
-            word2phones.  This will not overwrite the existing dictionary, just update it with OOV or new mappings.
-            Defaults to None, which will keep the existing mapping.
-        """
-        # Update model's word2phones if applicable
-        if additional_word2phones is not None:
-            self.word2phones.update(additional_word2phones)
-
-        # Convert text -> normalized text -> list of phones per word -> indices
-        if str_input[-1] not in [".", "!", "?"]:
-            str_input = str_input + "."
-        norm_text = re.findall(r"""[\w']+|[.,!?;"]""", self.parser._normalize(str_input))
-
-        try:
-            phones = [self.word2phones[t] for t in norm_text]
-        except KeyError as error:
-            logging.error(
-                f"ERROR: The following word in the input is not in the model's dictionary and could not be converted"
-                f" to phonemes: ({error}).\n"
-                f"You can pass in an `additional_word2phones` dictionary with a conversion for"
-                f" this word, e.g. {{'{error}': \['phone1', 'phone2', ...\]}} to update the model's mapping."
-            )
-            raise
-
-        tokens = []
-        for phone_list in phones:
-            inds = [self.phone2idx[p] for p in phone_list]
-            tokens += inds
-
-        x = torch.tensor(tokens).unsqueeze_(0).long().to(self.device)
-        return x
-
-    @typecheck(output_types={"spect": NeuralType(('B', 'C', 'T'), MelSpectrogramType())})
-    def generate_spectrogram(self, tokens: torch.Tensor) -> torch.Tensor:
-        self.eval()
-        token_len = torch.tensor([tokens.shape[1]]).to(self.device)
-        spect, *_ = self(text=tokens, text_length=token_len)
-
-        return spect.transpose(1, 2)
+        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
+        self.log('val_loss', avg_loss)
 
     def __setup_dataloader_from_config(self, cfg, shuffle_should_be: bool = True, name: str = "train"):
         if "dataset" not in cfg or not isinstance(cfg.dataset, DictConfig):
             raise ValueError(f"No dataset for {name}")
         if "dataloader_params" not in cfg or not isinstance(cfg.dataloader_params, DictConfig):
             raise ValueError(f"No dataloder_params for {name}")
         if shuffle_should_be:
             if 'shuffle' not in cfg.dataloader_params:
                 logging.warning(
                     f"Shuffle should be set to True for {self}'s {name} dataloader but was not found in its "
                     "config. Manually setting to True"
                 )
-                with open_dict(cfg.dataloader_params):
+                with open_dict(cfg["dataloader_params"]):
                     cfg.dataloader_params.shuffle = True
             elif not cfg.dataloader_params.shuffle:
                 logging.error(f"The {name} dataloader for {self} has shuffle set to False!!!")
         elif not shuffle_should_be and cfg.dataloader_params.shuffle:
             logging.error(f"The {name} dataloader for {self} has shuffle set to True!!!")
 
         dataset = instantiate(cfg.dataset)
@@ -281,21 +165,78 @@
 
     def setup_validation_data(self, cfg):
         self._validation_dl = self.__setup_dataloader_from_config(cfg, shuffle_should_be=False, name="validation")
 
     @classmethod
     def list_available_models(cls) -> 'List[PretrainedModelInfo]':
         """
-        This method returns a list of pre-trained models which can be instantiated directly from NVIDIA's NGC cloud.
+        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
         Returns:
             List of available pre-trained models.
         """
         list_of_models = []
         model = PretrainedModelInfo(
-            pretrained_model_name="tts_en_fastspeech2",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_fastspeech_2/versions/1.0.0/files/tts_en_fastspeech2.nemo",
-            description="This model is trained on LJSpeech sampled at 22050Hz, and can be used to generate female English voices with an American accent.",
+            pretrained_model_name="tts_waveglow_268m",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_waveglow_268m/versions/1.0.0rc1/files/tts_waveglow_268m.nemo",
+            description="This model is trained on LJSpeech sampled at 22050Hz, and has been tested on generating female English voices with an American accent and Mandarin voices.",
             class_=cls,
-            aliases=["FastSpeech2-22050Hz"],
+        )
+        list_of_models.append(model)
+        model = PretrainedModelInfo(
+            pretrained_model_name="tts_waveglow_88m",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_waveglow_88m/versions/1.0.0/files/tts_waveglow.nemo",
+            description="This model is trained on LJSpeech sampled at 22050Hz, and has been tested on generating female English voices with an American accent and Mandarin voices.",
+            class_=cls,
+            aliases=["WaveGlow-22050Hz", "tts_waveglow"],
         )
         list_of_models.append(model)
         return list_of_models
+
+    def load_state_dict(self, state_dict, strict=True):
+        # Remove convinv.inv_conv weights since they are not initialized until forward is called during training
+        # and can be computed from convinv.conv.weight
+        # Ideally, we should remove this during saving instead of ignoring during loading
+        for i in range(self._cfg.waveglow.n_flows):
+            if f"waveglow.convinv.{i}.inv_conv.weight" in state_dict:
+                del state_dict[f"waveglow.convinv.{i}.inv_conv.weight"]
+        super().load_state_dict(state_dict, strict=strict)
+
+    # Methods for model exportability
+    @property
+    def input_module(self):
+        return self.waveglow
+
+    @property
+    def output_module(self):
+        return self.waveglow
+
+    def _prepare_for_export(self, **kwargs):
+        self.update_bias_spect()
+        self.waveglow._prepare_for_export(**kwargs)
+
+    @property
+    def input_types(self):
+        return {
+            "audio": NeuralType(('B', 'T'), AudioSignal()),
+            "audio_len": NeuralType(('B'), LengthsType()),
+            "run_inverse": NeuralType(optional=True),
+        }
+
+    @property
+    def output_types(self):
+        if self.mode == OperationMode.training or self.mode == OperationMode.validation:
+            output_dict = {
+                "pred_normal_dist": NeuralType(('B', 'flowgroup', 'T'), NormalDistributionSamplesType()),
+                "log_s_list": [NeuralType(('B', 'flowgroup', 'T'), VoidType())],  # TODO: Figure out a good typing
+                "log_det_W_list": [NeuralType(elements_type=LogDeterminantType())],
+            }
+            if self.mode == OperationMode.validation:
+                output_dict["audio_pred"] = NeuralType(('B', 'T'), AudioSignal())
+                output_dict["spec"] = NeuralType(('B', 'T', 'D'), MelSpectrogramType())
+                output_dict["spec_len"] = NeuralType(('B'), LengthsType())
+            return output_dict
+        return {
+            "audio_pred": NeuralType(('B', 'T'), AudioSignal()),
+        }
+
+    def forward_for_export(self, spec, z=None):
+        return self.waveglow(spec, z)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/fastspeech2_hifigan_e2e.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/hifigan.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,355 +1,329 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import json
-import re
-from itertools import chain
+import itertools
 
-import numpy as np
 import torch
+import torch.nn.functional as F
 from hydra.utils import instantiate
 from omegaconf import DictConfig, OmegaConf, open_dict
-from pytorch_lightning.loggers import LoggerCollection, TensorBoardLogger
+from pytorch_lightning.loggers.wandb import WandbLogger
 
-from nemo.collections.common.parts.preprocessing import parsers
-from nemo.collections.tts.helpers.helpers import plot_spectrogram_to_numpy
-from nemo.collections.tts.losses.fastspeech2loss import DurationLoss, L1MelLoss
+from nemo.collections.tts.helpers.helpers import get_batch_size, get_num_workers, plot_spectrogram_to_numpy
 from nemo.collections.tts.losses.hifigan_losses import DiscriminatorLoss, FeatureMatchingLoss, GeneratorLoss
-from nemo.collections.tts.models.base import TextToWaveform
+from nemo.collections.tts.models.base import Vocoder
 from nemo.collections.tts.modules.hifigan_modules import MultiPeriodDiscriminator, MultiScaleDiscriminator
+from nemo.collections.tts.torch.data import VocoderDataset
+from nemo.core.classes import Exportable
 from nemo.core.classes.common import PretrainedModelInfo, typecheck
-from nemo.core.neural_types.elements import (
-    AudioSignal,
-    LengthsType,
-    MaskType,
-    RegressionValuesType,
-    TokenDurationType,
-    TokenIndex,
-    TokenLogDurationType,
-)
+from nemo.core.neural_types.elements import AudioSignal, MelSpectrogramType
 from nemo.core.neural_types.neural_type import NeuralType
-from nemo.core.optim.lr_scheduler import NoamAnnealing
-from nemo.utils import logging
-from nemo.utils.decorators import deprecated
+from nemo.core.optim.lr_scheduler import CosineAnnealing, compute_max_steps
+from nemo.utils import logging, model_utils
 
+HAVE_WANDB = True
+try:
+    import wandb
+except ModuleNotFoundError:
+    HAVE_WANDB = False
 
-@deprecated(version="1.9", explanation="FastSpeech2HifiGanE2EModel will be removed.")
-class FastSpeech2HifiGanE2EModel(TextToWaveform):
-    """An end-to-end speech synthesis model based on FastSpeech2 and HiFiGan that converts strings to audio without
-    using the intermediate mel spectrogram representation."""
+
+class HifiGanModel(Vocoder, Exportable):
+    """HiFi-GAN model (https://arxiv.org/abs/2010.05646) that is used to generate audio from mel spectrogram."""
 
     def __init__(self, cfg: DictConfig, trainer: 'Trainer' = None):
-        if isinstance(cfg, dict):
-            cfg = OmegaConf.create(cfg)
+        # Convert to Hydra 1.0 compatible DictConfig
+        cfg = model_utils.convert_model_config_to_dict_config(cfg)
+        cfg = model_utils.maybe_update_config_version(cfg)
+
         super().__init__(cfg=cfg, trainer=trainer)
 
         self.audio_to_melspec_precessor = instantiate(cfg.preprocessor)
-        self.encoder = instantiate(cfg.encoder)
-        self.variance_adapter = instantiate(cfg.variance_adaptor)
-
+        # We use separate preprocessor for training, because we need to pass grads and remove pitch fmax limitation
+        self.trg_melspec_fn = instantiate(cfg.preprocessor, highfreq=None, use_grads=True)
         self.generator = instantiate(cfg.generator)
-        self.multiperioddisc = MultiPeriodDiscriminator()
-        self.multiscaledisc = MultiScaleDiscriminator()
+        self.mpd = MultiPeriodDiscriminator(debug=cfg.debug if "debug" in cfg else False)
+        self.msd = MultiScaleDiscriminator(debug=cfg.debug if "debug" in cfg else False)
+        self.feature_loss = FeatureMatchingLoss()
+        self.discriminator_loss = DiscriminatorLoss()
+        self.generator_loss = GeneratorLoss()
+
+        self.l1_factor = cfg.get("l1_loss_factor", 45)
+
+        self.sample_rate = self._cfg.preprocessor.sample_rate
+        self.stft_bias = None
+
+        self.input_as_mel = False
+        if self._train_dl:
+            self.input_as_mel = self._train_dl.dataset.load_precomputed_mel
+
+        self.automatic_optimization = False
+
+    def _get_max_steps(self):
+        return compute_max_steps(
+            max_epochs=self._cfg.max_epochs,
+            accumulate_grad_batches=self.trainer.accumulate_grad_batches,
+            limit_train_batches=self.trainer.limit_train_batches,
+            num_workers=get_num_workers(self.trainer),
+            num_samples=len(self._train_dl.dataset),
+            batch_size=get_batch_size(self._train_dl),
+            drop_last=self._train_dl.drop_last,
+        )
 
-        self.melspec_fn = instantiate(cfg.preprocessor, highfreq=None, use_grads=True)
-        self.mel_val_loss = L1MelLoss()
-        self.durationloss = DurationLoss()
-        self.feat_matching_loss = FeatureMatchingLoss()
-        self.disc_loss = DiscriminatorLoss()
-        self.gen_loss = GeneratorLoss()
-        self.mseloss = torch.nn.MSELoss()
-
-        self.energy = cfg.add_energy_predictor
-        self.pitch = cfg.add_pitch_predictor
-        self.mel_loss_coeff = cfg.mel_loss_coeff
-        self.pitch_loss_coeff = cfg.pitch_loss_coeff
-        self.energy_loss_coeff = cfg.energy_loss_coeff
-        self.splice_length = cfg.splice_length
-
-        self.use_energy_pred = False
-        self.use_pitch_pred = False
-        self.log_train_images = False
-        self.logged_real_samples = False
-        self._tb_logger = None
-        self.sample_rate = cfg.sample_rate
-        self.hop_size = cfg.hop_size
-
-        # Parser and mappings are used for inference only.
-        self.parser = parsers.make_parser(name='en')
-        if 'mappings_filepath' in cfg:
-            mappings_filepath = cfg.get('mappings_filepath')
-        else:
-            logging.error(
-                "ERROR: You must specify a mappings.json file in the config file under model.mappings_filepath."
-            )
-        mappings_filepath = self.register_artifact('mappings_filepath', mappings_filepath)
-        with open(mappings_filepath, 'r') as f:
-            mappings = json.load(f)
-            self.word2phones = mappings['word2phones']
-            self.phone2idx = mappings['phone2idx']
+    def _get_warmup_steps(self, max_steps, warmup_steps, warmup_ratio):
+        if warmup_steps is not None and warmup_ratio is not None:
+            raise ValueError(f'Either use warmup_steps or warmup_ratio for scheduler')
 
-    @property
-    def tb_logger(self):
-        if self._tb_logger is None:
-            if self.logger is None and self.logger.experiment is None:
-                return None
-            tb_logger = self.logger.experiment
-            if isinstance(self.logger, LoggerCollection):
-                for logger in self.logger:
-                    if isinstance(logger, TensorBoardLogger):
-                        tb_logger = logger.experiment
-                        break
-            self._tb_logger = tb_logger
-        return self._tb_logger
+        if warmup_steps is not None:
+            return warmup_steps
 
-    def configure_optimizers(self):
-        gen_params = chain(self.encoder.parameters(), self.generator.parameters(), self.variance_adapter.parameters(),)
-        disc_params = chain(self.multiscaledisc.parameters(), self.multiperioddisc.parameters())
-        opt1 = torch.optim.AdamW(disc_params, lr=self._cfg.lr)
-        opt2 = torch.optim.AdamW(gen_params, lr=self._cfg.lr)
-        num_procs = self._trainer.num_devices * self._trainer.num_nodes
-        num_samples = len(self._train_dl.dataset)
-        batch_size = self._train_dl.batch_size
-        iter_per_epoch = np.ceil(num_samples / (num_procs * batch_size))
-        max_steps = iter_per_epoch * self._trainer.max_epochs
-        logging.info(f"MAX STEPS: {max_steps}")
-        sch1 = NoamAnnealing(opt1, d_model=256, warmup_steps=3000, max_steps=max_steps, min_lr=1e-5)
-        sch1_dict = {
-            'scheduler': sch1,
-            'interval': 'step',
-        }
-        sch2 = NoamAnnealing(opt2, d_model=256, warmup_steps=3000, max_steps=max_steps, min_lr=1e-5)
-        sch2_dict = {
-            'scheduler': sch2,
-            'interval': 'step',
-        }
-        return [opt1, opt2], [sch1_dict, sch2_dict]
+        if warmup_ratio is not None:
+            return warmup_ratio * max_steps
 
-    @typecheck(
-        input_types={
-            "text": NeuralType(('B', 'T'), TokenIndex()),
-            "text_length": NeuralType(('B'), LengthsType()),
-            "splice": NeuralType(optional=True),
-            "spec_len": NeuralType(('B'), LengthsType(), optional=True),
-            "durations": NeuralType(('B', 'T'), TokenDurationType(), optional=True),
-            "pitch": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-            "energies": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-        },
-        output_types={
-            "audio": NeuralType(('B', 'S', 'T'), AudioSignal()),
-            "splices": NeuralType(),
-            "log_dur_preds": NeuralType(('B', 'T'), TokenLogDurationType()),
-            "pitch_preds": NeuralType(('B', 'T'), RegressionValuesType()),
-            "energy_preds": NeuralType(('B', 'T'), RegressionValuesType()),
-            "encoded_text_mask": NeuralType(('B', 'T', 'D'), MaskType()),
-        },
-    )
-    def forward(self, *, text, text_length, splice=True, durations=None, pitch=None, energies=None, spec_len=None):
-        encoded_text, encoded_text_mask = self.encoder(text=text, text_length=text_length)
+        raise ValueError(f'Specify warmup_steps or warmup_ratio for scheduler')
 
-        context, log_dur_preds, pitch_preds, energy_preds, spec_len = self.variance_adapter(
-            x=encoded_text,
-            x_len=text_length,
-            dur_target=durations,
-            pitch_target=pitch,
-            energy_target=energies,
-            spec_len=spec_len,
-        )
+    def configure_optimizers(self):
+        optim_config = self._cfg.optim.copy()
 
-        gen_in = context
-        splices = []
-        if splice:
-            # Splice generated spec
-            output = []
-            for i, sample in enumerate(context):
-                start = np.random.randint(low=0, high=min(int(sample.size(0)), int(spec_len[i])) - self.splice_length)
-                output.append(sample[start : start + self.splice_length, :])
-                splices.append(start)
-            gen_in = torch.stack(output)
-
-        output = self.generator(x=gen_in.transpose(1, 2))
-
-        return output, torch.tensor(splices), log_dur_preds, pitch_preds, energy_preds, encoded_text_mask
-
-    def training_step(self, batch, batch_idx, optimizer_idx):
-        f, fl, t, tl, durations, pitch, energies = batch
-        _, spec_len = self.audio_to_melspec_precessor(f, fl)
-
-        # train discriminator
-        if optimizer_idx == 0:
-            with torch.no_grad():
-                audio_pred, splices, _, _, _, _ = self(
-                    spec_len=spec_len,
-                    text=t,
-                    text_length=tl,
-                    durations=durations,
-                    pitch=pitch if not self.use_pitch_pred else None,
-                    energies=energies if not self.use_energy_pred else None,
-                )
-                real_audio = []
-                for i, splice in enumerate(splices):
-                    real_audio.append(f[i, splice * self.hop_size : (splice + self.splice_length) * self.hop_size])
-                real_audio = torch.stack(real_audio).unsqueeze(1)
+        OmegaConf.set_struct(optim_config, False)
+        sched_config = optim_config.pop("sched", None)
+        OmegaConf.set_struct(optim_config, True)
+
+        optim_g = instantiate(optim_config, params=self.generator.parameters(),)
+        optim_d = instantiate(optim_config, params=itertools.chain(self.msd.parameters(), self.mpd.parameters()),)
+
+        # Backward compatibility
+        if sched_config is None and 'sched' in self._cfg:
+            sched_config = self._cfg.sched
+
+        if sched_config is not None:
+            max_steps = self._cfg.get("max_steps", None)
+            if max_steps is None or max_steps < 0:
+                max_steps = self._get_max_steps()
+
+            warmup_steps = self._get_warmup_steps(
+                max_steps=max_steps,
+                warmup_steps=sched_config.get("warmup_steps", None),
+                warmup_ratio=sched_config.get("warmup_ratio", None),
+            )
 
-            real_score_mp, gen_score_mp, _, _ = self.multiperioddisc(real_audio, audio_pred)
-            real_score_ms, gen_score_ms, _, _ = self.multiscaledisc(y=real_audio, y_hat=audio_pred)
+            scheduler_g = CosineAnnealing(
+                optimizer=optim_g, max_steps=max_steps, min_lr=sched_config.min_lr, warmup_steps=warmup_steps,
+            )  # Use warmup to delay start
+            sch1_dict = {
+                'scheduler': scheduler_g,
+                'interval': 'step',
+            }
+
+            scheduler_d = CosineAnnealing(optimizer=optim_d, max_steps=max_steps, min_lr=sched_config.min_lr,)
+            sch2_dict = {
+                'scheduler': scheduler_d,
+                'interval': 'step',
+            }
 
-            loss_mp, loss_mp_real, _ = self.disc_loss(
-                disc_real_outputs=real_score_mp, disc_generated_outputs=gen_score_mp
-            )
-            loss_ms, loss_ms_real, _ = self.disc_loss(
-                disc_real_outputs=real_score_ms, disc_generated_outputs=gen_score_ms
-            )
-            loss_mp /= len(loss_mp_real)
-            loss_ms /= len(loss_ms_real)
-            loss_disc = loss_mp + loss_ms
-
-            self.log("loss_discriminator", loss_disc, prog_bar=True)
-            self.log("loss_discriminator_ms", loss_ms)
-            self.log("loss_discriminator_mp", loss_mp)
-            return loss_disc
-
-        # train generator
-        elif optimizer_idx == 1:
-            audio_pred, splices, log_dur_preds, pitch_preds, energy_preds, encoded_text_mask = self(
-                spec_len=spec_len,
-                text=t,
-                text_length=tl,
-                durations=durations,
-                pitch=pitch if not self.use_pitch_pred else None,
-                energies=energies if not self.use_energy_pred else None,
-            )
-            real_audio = []
-            for i, splice in enumerate(splices):
-                real_audio.append(f[i, splice * self.hop_size : (splice + self.splice_length) * self.hop_size])
-            real_audio = torch.stack(real_audio).unsqueeze(1)
-
-            # Do HiFiGAN generator loss
-            audio_length = torch.tensor([self.splice_length * self.hop_size for _ in range(real_audio.shape[0])]).to(
-                real_audio.device
-            )
-            real_spliced_spec, _ = self.melspec_fn(real_audio.squeeze(), seq_len=audio_length)
-            pred_spliced_spec, _ = self.melspec_fn(audio_pred.squeeze(), seq_len=audio_length)
-            loss_mel = torch.nn.functional.l1_loss(real_spliced_spec, pred_spliced_spec)
-            loss_mel *= self.mel_loss_coeff
-            _, gen_score_mp, real_feat_mp, gen_feat_mp = self.multiperioddisc(real_audio, audio_pred)
-            _, gen_score_ms, real_feat_ms, gen_feat_ms = self.multiscaledisc(y=real_audio, y_hat=audio_pred)
-            loss_gen_mp, list_loss_gen_mp = self.gen_loss(disc_outputs=gen_score_mp)
-            loss_gen_ms, list_loss_gen_ms = self.gen_loss(disc_outputs=gen_score_ms)
-            loss_gen_mp /= len(list_loss_gen_mp)
-            loss_gen_ms /= len(list_loss_gen_ms)
-            total_loss = loss_gen_mp + loss_gen_ms + loss_mel
-            loss_feat_mp = self.feat_matching_loss(fmap_r=real_feat_mp, fmap_g=gen_feat_mp)
-            loss_feat_ms = self.feat_matching_loss(fmap_r=real_feat_ms, fmap_g=gen_feat_ms)
-            total_loss += loss_feat_mp + loss_feat_ms
-            self.log(name="loss_gen_disc_feat", value=loss_feat_mp + loss_feat_ms)
-            self.log(name="loss_gen_disc_feat_ms", value=loss_feat_ms)
-            self.log(name="loss_gen_disc_feat_mp", value=loss_feat_mp)
-
-            self.log(name="loss_gen_mel", value=loss_mel)
-            self.log(name="loss_gen_disc", value=loss_gen_mp + loss_gen_ms)
-            self.log(name="loss_gen_disc_mp", value=loss_gen_mp)
-            self.log(name="loss_gen_disc_ms", value=loss_gen_ms)
+            return [optim_g, optim_d], [sch1_dict, sch2_dict]
+        else:
+            return [optim_g, optim_d]
 
-            dur_loss = self.durationloss(
-                log_duration_pred=log_dur_preds, duration_target=durations.float(), mask=encoded_text_mask
-            )
-            self.log(name="loss_gen_duration", value=dur_loss)
-            total_loss += dur_loss
-            if self.pitch:
-                pitch_loss = self.mseloss(pitch_preds, pitch.float()) * self.pitch_loss_coeff
-                total_loss += pitch_loss
-                self.log(name="loss_gen_pitch", value=pitch_loss)
-            if self.energy:
-                energy_loss = self.mseloss(energy_preds, energies) * self.energy_loss_coeff
-                total_loss += energy_loss
-                self.log(name="loss_gen_energy", value=energy_loss)
-
-            # Log images to tensorboard
-            if self.log_train_images:
-                self.log_train_images = False
-                if self.logger is not None and self.logger.experiment is not None:
-                    self.tb_logger.add_image(
-                        "train_mel_target",
-                        plot_spectrogram_to_numpy(real_spliced_spec[0].data.cpu().numpy()),
-                        self.global_step,
-                        dataformats="HWC",
-                    )
-                    spec_predict = pred_spliced_spec[0].data.cpu().numpy()
-                    self.tb_logger.add_image(
-                        "train_mel_predicted",
-                        plot_spectrogram_to_numpy(spec_predict),
-                        self.global_step,
-                        dataformats="HWC",
-                    )
-            self.log(name="loss_gen", prog_bar=True, value=total_loss)
-            return total_loss
+    @typecheck()
+    def forward(self, *, spec):
+        """
+        Runs the generator, for inputs and outputs see input_types, and output_types
+        """
+        return self.generator(x=spec)
 
-    def validation_step(self, batch, batch_idx):
-        f, fl, t, tl, _, _, _ = batch
-        spec, spec_len = self.audio_to_melspec_precessor(f, fl)
-        audio_pred, _, _, _, _, _ = self(spec_len=spec_len, text=t, text_length=tl, splice=False)
-        audio_pred.squeeze_()
-        pred_spec, _ = self.melspec_fn(audio_pred, seq_len=spec_len)
-        loss = self.mel_val_loss(spec_pred=pred_spec, spec_target=spec, spec_target_len=spec_len, pad_value=-11.52)
+    @typecheck(
+        input_types={"spec": NeuralType(('B', 'C', 'T'), MelSpectrogramType())},
+        output_types={"audio": NeuralType(('B', 'T'), AudioSignal())},
+    )
+    def convert_spectrogram_to_audio(self, spec: 'torch.tensor') -> 'torch.tensor':
+        return self(spec=spec).squeeze(1)
 
-        return {
-            "val_loss": loss,
-            "audio_target": f.squeeze() if batch_idx == 0 else None,
-            "audio_pred": audio_pred if batch_idx == 0 else None,
+    def training_step(self, batch, batch_idx):
+        if self.input_as_mel:
+            # Pre-computed spectrograms will be used as input
+            audio, audio_len, audio_mel = batch
+        else:
+            audio, audio_len = batch
+            audio_mel, _ = self.audio_to_melspec_precessor(audio, audio_len)
+
+        # Mel as input for L1 mel loss
+        audio_trg_mel, _ = self.trg_melspec_fn(audio, audio_len)
+        audio = audio.unsqueeze(1)
+
+        audio_pred = self.generator(x=audio_mel)
+        audio_pred_mel, _ = self.trg_melspec_fn(audio_pred.squeeze(1), audio_len)
+
+        optim_g, optim_d = self.optimizers()
+
+        # Train discriminator
+        optim_d.zero_grad()
+        mpd_score_real, mpd_score_gen, _, _ = self.mpd(y=audio, y_hat=audio_pred.detach())
+        loss_disc_mpd, _, _ = self.discriminator_loss(
+            disc_real_outputs=mpd_score_real, disc_generated_outputs=mpd_score_gen
+        )
+        msd_score_real, msd_score_gen, _, _ = self.msd(y=audio, y_hat=audio_pred.detach())
+        loss_disc_msd, _, _ = self.discriminator_loss(
+            disc_real_outputs=msd_score_real, disc_generated_outputs=msd_score_gen
+        )
+        loss_d = loss_disc_msd + loss_disc_mpd
+        self.manual_backward(loss_d)
+        optim_d.step()
+
+        # Train generator
+        optim_g.zero_grad()
+        loss_mel = F.l1_loss(audio_pred_mel, audio_trg_mel)
+        _, mpd_score_gen, fmap_mpd_real, fmap_mpd_gen = self.mpd(y=audio, y_hat=audio_pred)
+        _, msd_score_gen, fmap_msd_real, fmap_msd_gen = self.msd(y=audio, y_hat=audio_pred)
+        loss_fm_mpd = self.feature_loss(fmap_r=fmap_mpd_real, fmap_g=fmap_mpd_gen)
+        loss_fm_msd = self.feature_loss(fmap_r=fmap_msd_real, fmap_g=fmap_msd_gen)
+        loss_gen_mpd, _ = self.generator_loss(disc_outputs=mpd_score_gen)
+        loss_gen_msd, _ = self.generator_loss(disc_outputs=msd_score_gen)
+        loss_g = loss_gen_msd + loss_gen_mpd + loss_fm_msd + loss_fm_mpd + loss_mel * self.l1_factor
+        self.manual_backward(loss_g)
+        optim_g.step()
+
+        # Run schedulers
+        schedulers = self.lr_schedulers()
+        if schedulers is not None:
+            sch1, sch2 = schedulers
+            sch1.step()
+            sch2.step()
+
+        metrics = {
+            "g_loss_fm_mpd": loss_fm_mpd,
+            "g_loss_fm_msd": loss_fm_msd,
+            "g_loss_gen_mpd": loss_gen_mpd,
+            "g_loss_gen_msd": loss_gen_msd,
+            "g_loss": loss_g,
+            "d_loss_mpd": loss_disc_mpd,
+            "d_loss_msd": loss_disc_msd,
+            "d_loss": loss_d,
+            "global_step": self.global_step,
+            "lr": optim_g.param_groups[0]['lr'],
         }
+        self.log_dict(metrics, on_step=True, sync_dist=True)
+        self.log("g_l1_loss", loss_mel, prog_bar=True, logger=False, sync_dist=True)
 
-    def on_train_epoch_start(self):
-        # Switch to using energy predictions after 50% of training
-        if not self.use_energy_pred and self.current_epoch >= np.ceil(0.5 * self._trainer.max_epochs):
-            logging.info(f"Using energy predictions after epoch: {self.current_epoch}")
-            self.use_energy_pred = True
-
-        # Switch to using pitch predictions after 62.5% of training
-        if not self.use_pitch_pred and self.current_epoch >= np.ceil(0.625 * self._trainer.max_epochs):
-            logging.info(f"Using pitch predictions after epoch: {self.current_epoch}")
-            self.use_pitch_pred = True
-
-    def validation_epoch_end(self, outputs):
-        if self.tb_logger is not None:
-            _, audio_target, audio_predict = outputs[0].values()
-            if not self.logged_real_samples:
-                self.tb_logger.add_audio("val_target", audio_target[0].data.cpu(), self.global_step, self.sample_rate)
-                self.logged_real_samples = True
-            audio_predict = audio_predict[0].data.cpu()
-            self.tb_logger.add_audio("val_pred", audio_predict, self.global_step, self.sample_rate)
-        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()  # This reduces across batches, not workers!
-        self.log('val_loss', avg_loss, sync_dist=True)
+    def validation_step(self, batch, batch_idx):
+        if self.input_as_mel:
+            audio, audio_len, audio_mel = batch
+            audio_mel_len = [audio_mel.shape[1]] * audio_mel.shape[0]
+        else:
+            audio, audio_len = batch
+            audio_mel, audio_mel_len = self.audio_to_melspec_precessor(audio, audio_len)
+        audio_pred = self(spec=audio_mel)
+
+        # Perform bias denoising
+        pred_denoised = self._bias_denoise(audio_pred, audio_mel).squeeze(1)
+        pred_denoised_mel, _ = self.audio_to_melspec_precessor(pred_denoised, audio_len)
+
+        if self.input_as_mel:
+            gt_mel, gt_mel_len = self.audio_to_melspec_precessor(audio, audio_len)
+        audio_pred_mel, _ = self.audio_to_melspec_precessor(audio_pred.squeeze(1), audio_len)
+        loss_mel = F.l1_loss(audio_mel, audio_pred_mel)
+
+        self.log_dict({"val_loss": loss_mel}, on_epoch=True, sync_dist=True)
+
+        # Plot audio once per epoch
+        if batch_idx == 0 and isinstance(self.logger, WandbLogger) and HAVE_WANDB:
+            clips = []
+            specs = []
+            for i in range(min(5, audio.shape[0])):
+                clips += [
+                    wandb.Audio(
+                        audio[i, : audio_len[i]].data.cpu().numpy(),
+                        caption=f"real audio {i}",
+                        sample_rate=self.sample_rate,
+                    ),
+                    wandb.Audio(
+                        audio_pred[i, 0, : audio_len[i]].data.cpu().numpy().astype('float32'),
+                        caption=f"generated audio {i}",
+                        sample_rate=self.sample_rate,
+                    ),
+                    wandb.Audio(
+                        pred_denoised[i, : audio_len[i]].data.cpu().numpy(),
+                        caption=f"denoised audio {i}",
+                        sample_rate=self.sample_rate,
+                    ),
+                ]
+                specs += [
+                    wandb.Image(
+                        plot_spectrogram_to_numpy(audio_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                        caption=f"input mel {i}",
+                    ),
+                    wandb.Image(
+                        plot_spectrogram_to_numpy(audio_pred_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                        caption=f"output mel {i}",
+                    ),
+                    wandb.Image(
+                        plot_spectrogram_to_numpy(pred_denoised_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                        caption=f"denoised mel {i}",
+                    ),
+                ]
+                if self.input_as_mel:
+                    specs += [
+                        wandb.Image(
+                            plot_spectrogram_to_numpy(gt_mel[i, :, : audio_mel_len[i]].data.cpu().numpy()),
+                            caption=f"gt mel {i}",
+                        ),
+                    ]
+
+            self.logger.experiment.log({"audio": clips, "specs": specs})
+
+    def _bias_denoise(self, audio, mel):
+        def stft(x):
+            comp = torch.stft(x.squeeze(1), n_fft=1024, hop_length=256, win_length=1024)
+            real, imag = comp[..., 0], comp[..., 1]
+            mags = torch.sqrt(real ** 2 + imag ** 2)
+            phase = torch.atan2(imag, real)
+            return mags, phase
+
+        def istft(mags, phase):
+            comp = torch.stack([mags * torch.cos(phase), mags * torch.sin(phase)], dim=-1)
+            x = torch.istft(comp, n_fft=1024, hop_length=256, win_length=1024)
+            return x
+
+        # Create bias tensor
+        if self.stft_bias is None or self.stft_bias.shape[0] != audio.shape[0]:
+            audio_bias = self(spec=torch.zeros_like(mel, device=mel.device))
+            self.stft_bias, _ = stft(audio_bias)
+            self.stft_bias = self.stft_bias[:, :, 0][:, :, None]
+
+        audio_mags, audio_phase = stft(audio)
+        audio_mags = audio_mags - self.cfg.get("denoise_strength", 0.0025) * self.stft_bias
+        audio_mags = torch.clamp(audio_mags, 0.0)
+        audio_denoised = istft(audio_mags, audio_phase).unsqueeze(1)
 
-        self.log_train_images = True
+        return audio_denoised
 
     def __setup_dataloader_from_config(self, cfg, shuffle_should_be: bool = True, name: str = "train"):
         if "dataset" not in cfg or not isinstance(cfg.dataset, DictConfig):
             raise ValueError(f"No dataset for {name}")
         if "dataloader_params" not in cfg or not isinstance(cfg.dataloader_params, DictConfig):
             raise ValueError(f"No dataloder_params for {name}")
         if shuffle_should_be:
             if 'shuffle' not in cfg.dataloader_params:
                 logging.warning(
                     f"Shuffle should be set to True for {self}'s {name} dataloader but was not found in its "
                     "config. Manually setting to True"
                 )
-                with open_dict(cfg.dataloader_params):
+                with open_dict(cfg["dataloader_params"]):
                     cfg.dataloader_params.shuffle = True
             elif not cfg.dataloader_params.shuffle:
                 logging.error(f"The {name} dataloader for {self} has shuffle set to False!!!")
         elif not shuffle_should_be and cfg.dataloader_params.shuffle:
             logging.error(f"The {name} dataloader for {self} has shuffle set to True!!!")
 
         dataset = instantiate(cfg.dataset)
@@ -357,77 +331,90 @@
 
     def setup_training_data(self, cfg):
         self._train_dl = self.__setup_dataloader_from_config(cfg)
 
     def setup_validation_data(self, cfg):
         self._validation_dl = self.__setup_dataloader_from_config(cfg, shuffle_should_be=False, name="validation")
 
-    def parse(self, str_input: str, additional_word2phones=None) -> torch.tensor:
-        """
-        Parses text input and converts them to phoneme indices.
+    def setup_test_data(self, cfg):
+        pass
 
-        str_input (str): The input text to be converted.
-        additional_word2phones (dict): Optional dictionary mapping words to phonemes for updating the model's
-            word2phones.  This will not overwrite the existing dictionary, just update it with OOV or new mappings.
-            Defaults to None, which will keep the existing mapping.
-        """
-        # Update model's word2phones if applicable
-        if additional_word2phones is not None:
-            self.word2phones.update(additional_word2phones)
-
-        # Convert text -> normalized text -> list of phones per word -> indices
-        if str_input[-1] not in [".", "!", "?"]:
-            str_input = str_input + "."
-        norm_text = re.findall(r"""[\w']+|[.,!?;"]""", self.parser._normalize(str_input))
-
-        try:
-            phones = [self.word2phones[t] for t in norm_text]
-        except KeyError as error:
-            logging.error(
-                f"ERROR: The following word in the input is not in the model's dictionary and could not be converted"
-                f" to phonemes: ({error}).\n"
-                f"You can pass in an `additional_word2phones` dictionary with a conversion for"
-                f" this word, e.g. {{'{error}': \['phone1', 'phone2', ...\]}} to update the model's mapping."
-            )
-            raise
+    @classmethod
+    def list_available_models(cls) -> 'Optional[Dict[str, str]]':
+        list_of_models = []
+        model = PretrainedModelInfo(
+            pretrained_model_name="tts_hifigan",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_hifigan/versions/1.0.0rc1/files/tts_hifigan.nemo",
+            description="This model is trained on LJSpeech audio sampled at 22050Hz and mel spectrograms generated from Tacotron2, TalkNet, and FastPitch. This model has been tested on generating female English voices with an American accent.",
+            class_=cls,
+        )
+        list_of_models.append(model)
 
-        tokens = []
-        for phone_list in phones:
-            inds = [self.phone2idx[p] for p in phone_list]
-            tokens += inds
+        model = PretrainedModelInfo(
+            pretrained_model_name="tts_en_lj_hifigan_ft_mixertts",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_lj_hifigan/versions/1.6.0/files/tts_en_lj_hifigan_ft_mixertts.nemo",
+            description="This model is trained on LJSpeech audio sampled at 22050Hz and mel spectrograms generated from Mixer-TTS. This model has been tested on generating female English voices with an American accent.",
+            class_=cls,
+        )
+        list_of_models.append(model)
 
-        x = torch.tensor(tokens).unsqueeze_(0).long().to(self.device)
-        return x
+        model = PretrainedModelInfo(
+            pretrained_model_name="tts_en_lj_hifigan_ft_mixerttsx",
+            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_lj_hifigan/versions/1.6.0/files/tts_en_lj_hifigan_ft_mixerttsx.nemo",
+            description="This model is trained on LJSpeech audio sampled at 22050Hz and mel spectrograms generated from Mixer-TTS-X. This model has been tested on generating female English voices with an American accent.",
+            class_=cls,
+        )
+        list_of_models.append(model)
 
-    def convert_text_to_waveform(self, *, tokens):
-        """
-        Accepts tokens returned from self.parse() and returns a list of tensors. Note: The tensors in the list can have
-        different lengths.
-        """
-        self.eval()
-        token_len = torch.tensor([len(i) for i in tokens]).to(self.device)
-        audio, _, log_dur_pred, _, _, _ = self(text=tokens, text_length=token_len, splice=False)
-        audio = audio.squeeze(1)
-        durations = torch.sum(torch.exp(log_dur_pred) - 1, 1).to(torch.int)
-        audio_list = []
-        for i, sample in enumerate(audio):
-            audio_list.append(sample[: durations[i] * self.hop_size])
+        return list_of_models
 
-        return audio_list
+    def load_state_dict(self, state_dict, strict=True):
+        # Override load_state_dict to give us some flexibility to be backward-compatible with old checkpoints
+        new_state_dict = {}
+        num_resblocks = len(self.cfg['generator']['resblock_kernel_sizes'])
+        for k, v in state_dict.items():
+            new_k = k
+            if 'resblocks' in k:
+                parts = k.split(".")
+                # only do this is the checkpoint type is older
+                if len(parts) == 6:
+                    layer = int(parts[2])
+                    new_layer = f"{layer // num_resblocks}.{layer % num_resblocks}"
+                    new_k = f"generator.resblocks.{new_layer}.{'.'.join(parts[3:])}"
+            new_state_dict[new_k] = v
+        super().load_state_dict(new_state_dict, strict=strict)
+
+    # Methods for model exportability
+    def _prepare_for_export(self, **kwargs):
+        if self.generator is not None:
+            try:
+                self.generator.remove_weight_norm()
+            except ValueError:
+                return
 
-    @classmethod
-    def list_available_models(cls) -> 'List[PretrainedModelInfo]':
+    @property
+    def input_types(self):
+        return {
+            "spec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+        }
+
+    @property
+    def output_types(self):
+        return {
+            "audio": NeuralType(('B', 'S', 'T'), AudioSignal(self.sample_rate)),
+        }
+
+    def input_example(self, max_batch=1, max_dim=256):
         """
-        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
+        Generates input examples for tracing etc.
         Returns:
-            List of available pre-trained models.
+            A tuple of input examples.
         """
-        list_of_models = []
-        model = PretrainedModelInfo(
-            pretrained_model_name="tts_en_e2e_fastspeech2hifigan",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_en_e2e_fastspeech2hifigan/versions/1.0.0/files/tts_en_e2e_fastspeech2hifigan.nemo",
-            description="This model is trained on LJSpeech sampled at 22050Hz with and can be used to generate female English voices with an American accent.",
-            class_=cls,
-        )
-        list_of_models.append(model)
+        par = next(self.parameters())
+        mel = torch.randn((max_batch, self.cfg['preprocessor']['nfilt'], max_dim), device=self.device, dtype=par.dtype)
+        return ({'spec': mel},)
 
-        return list_of_models
+    def forward_for_export(self, spec):
+        """
+        Runs the generator, for inputs and outputs see input_types, and output_types
+        """
+        return self.generator(x=spec)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/mixer_tts.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/mixer_tts.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/two_stages.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/models/two_stages.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/models/waveglow.py` & `nemo_toolkit-1.9.0/nemo/utils/export_utils.py`

 * *Files 26% similar despite different names*

```diff
@@ -8,237 +8,277 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import os
+from enum import Enum
+from typing import Callable, Dict, Optional, Type
 
+import onnx
 import torch
-from hydra.utils import instantiate
-from omegaconf import DictConfig, open_dict
-from pytorch_lightning.loggers import LoggerCollection, TensorBoardLogger
-
-from nemo.collections.tts.helpers.helpers import OperationMode, waveglow_log_to_tb_func
-from nemo.collections.tts.losses.waveglowloss import WaveGlowLoss
-from nemo.collections.tts.models.base import GlowVocoder
-from nemo.core.classes import Exportable
-from nemo.core.classes.common import PretrainedModelInfo, typecheck
-from nemo.core.neural_types.elements import (
-    AudioSignal,
-    LengthsType,
-    LogDeterminantType,
-    MelSpectrogramType,
-    NormalDistributionSamplesType,
-    VoidType,
-)
-from nemo.core.neural_types.neural_type import NeuralType
-from nemo.utils import logging, model_utils
-
-
-class WaveGlowModel(GlowVocoder, Exportable):
-    """WaveGlow model (https://arxiv.org/abs/1811.00002) that is used to generate audio from mel spectrogram."""
-
-    def __init__(self, cfg: DictConfig, trainer: 'Trainer' = None):
-        # Convert to Hydra 1.0 compatible DictConfig
-        cfg = model_utils.convert_model_config_to_dict_config(cfg)
-        cfg = model_utils.maybe_update_config_version(cfg)
-
-        super().__init__(cfg=cfg, trainer=trainer)
-
-        self.sigma = self._cfg.sigma
-        self.audio_to_melspec_precessor = instantiate(self._cfg.preprocessor)
-        self.waveglow = instantiate(self._cfg.waveglow)
-        self.loss = WaveGlowLoss()
-
-    @GlowVocoder.mode.setter
-    def mode(self, new_mode):
-        if new_mode == OperationMode.training:
-            self.train()
+import torch.nn as nn
+
+from nemo.utils import logging
+
+try:
+    import onnxruntime
+
+    ort_available = True
+except (ImportError, ModuleNotFoundError):
+    ort_available = False
+
+
+class ExportFormat(Enum):
+    """Which format to use when exporting a Neural Module for deployment"""
+
+    ONNX = (1,)
+    TORCHSCRIPT = (2,)
+
+
+_EXT_DICT = {
+    ".pt": ExportFormat.TORCHSCRIPT,
+    ".ts": ExportFormat.TORCHSCRIPT,
+    ".onnx": ExportFormat.ONNX,
+}
+
+
+class CastToFloat(nn.Module):
+    def __init__(self, mod):
+        super(CastToFloat, self).__init__()
+        self.mod = mod
+
+    def forward(self, x):
+        if torch.is_autocast_enabled():
+            ret = self.mod.forward(x.to(torch.float)).to(x.dtype)
         else:
-            self.eval()
-        self._mode = new_mode
-        self.waveglow.mode = new_mode
-
-    @typecheck()
-    def forward(self, *, audio, audio_len, run_inverse=True):
-        if self.mode != self.waveglow.mode:
-            raise ValueError(
-                f"WaveGlowModel's mode {self.mode} does not match WaveGlowModule's mode {self.waveglow.mode}"
-            )
-        spec, spec_len = self.audio_to_melspec_precessor(audio, audio_len)
-        tensors = self.waveglow(spec=spec, audio=audio, run_inverse=run_inverse, sigma=self.sigma)
-        if self.mode == OperationMode.training:
-            return tensors[:-1]  # z, log_s_list, log_det_W_list
-        elif self.mode == OperationMode.validation:
-            z, log_s_list, log_det_W_list, audio_pred = tensors
-            return z, log_s_list, log_det_W_list, audio_pred, spec, spec_len
-        return tensors  # audio_pred
-
-    @typecheck(
-        input_types={
-            "spec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
-            "sigma": NeuralType(optional=True),
-            "denoise": NeuralType(optional=True),
-            "denoiser_strength": NeuralType(optional=True),
-        },
-        output_types={"audio": NeuralType(('B', 'T'), AudioSignal())},
-    )
-    def convert_spectrogram_to_audio(
-        self, spec: torch.Tensor, sigma: float = 1.0, denoise: bool = True, denoiser_strength: float = 0.01
-    ) -> torch.Tensor:
-        with self.nemo_infer():
-            self.waveglow.remove_weightnorm()
-            audio = self.waveglow(
-                spec=spec.to(self.waveglow.upsample.weight.dtype), run_inverse=True, audio=None, sigma=sigma
-            )
-            if denoise:
-                audio = self.denoise(audio=audio, strength=denoiser_strength)
-
-        return audio
-
-    def training_step(self, batch, batch_idx):
-        self.mode = OperationMode.training
-        audio, audio_len = batch
-        z, log_s_list, log_det_W_list = self(audio=audio, audio_len=audio_len, run_inverse=False)
-
-        loss = self.loss(z=z, log_s_list=log_s_list, log_det_W_list=log_det_W_list, sigma=self.sigma)
-        output = {
-            'loss': loss,
-            'progress_bar': {'training_loss': loss},
-            'log': {'loss': loss},
-        }
-        return output
-
-    def validation_step(self, batch, batch_idx):
-        self.mode = OperationMode.validation
-        audio, audio_len = batch
-        z, log_s_list, log_det_W_list, audio_pred, spec, spec_len = self(
-            audio=audio, audio_len=audio_len, run_inverse=(batch_idx == 0)
-        )
-        loss = self.loss(z=z, log_s_list=log_s_list, log_det_W_list=log_det_W_list, sigma=self.sigma)
-        return {
-            "val_loss": loss,
-            "audio_pred": audio_pred,
-            "mel_target": spec,
-            "mel_len": spec_len,
-        }
-
-    def validation_epoch_end(self, outputs):
-        if self.logger is not None and self.logger.experiment is not None:
-            tb_logger = self.logger.experiment
-            if isinstance(self.logger, LoggerCollection):
-                for logger in self.logger:
-                    if isinstance(logger, TensorBoardLogger):
-                        tb_logger = logger.experiment
-                        break
-            waveglow_log_to_tb_func(
-                tb_logger,
-                outputs[0].values(),
-                self.global_step,
-                tag="eval",
-                mel_fb=self.audio_to_melspec_precessor.fb,
-            )
-        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
-        self.log('val_loss', avg_loss)
-
-    def __setup_dataloader_from_config(self, cfg, shuffle_should_be: bool = True, name: str = "train"):
-        if "dataset" not in cfg or not isinstance(cfg.dataset, DictConfig):
-            raise ValueError(f"No dataset for {name}")
-        if "dataloader_params" not in cfg or not isinstance(cfg.dataloader_params, DictConfig):
-            raise ValueError(f"No dataloder_params for {name}")
-        if shuffle_should_be:
-            if 'shuffle' not in cfg.dataloader_params:
-                logging.warning(
-                    f"Shuffle should be set to True for {self}'s {name} dataloader but was not found in its "
-                    "config. Manually setting to True"
-                )
-                with open_dict(cfg["dataloader_params"]):
-                    cfg.dataloader_params.shuffle = True
-            elif not cfg.dataloader_params.shuffle:
-                logging.error(f"The {name} dataloader for {self} has shuffle set to False!!!")
-        elif not shuffle_should_be and cfg.dataloader_params.shuffle:
-            logging.error(f"The {name} dataloader for {self} has shuffle set to True!!!")
-
-        dataset = instantiate(cfg.dataset)
-        return torch.utils.data.DataLoader(dataset, collate_fn=dataset.collate_fn, **cfg.dataloader_params)
+            ret = self.mod.forward(x)
+        return ret
 
-    def setup_training_data(self, cfg):
-        self._train_dl = self.__setup_dataloader_from_config(cfg)
 
-    def setup_validation_data(self, cfg):
-        self._validation_dl = self.__setup_dataloader_from_config(cfg, shuffle_should_be=False, name="validation")
+def get_export_format(filename: str):
+    _, ext = os.path.splitext(filename)
+    try:
+        return _EXT_DICT[ext]
+    except KeyError:
+        raise ValueError(f"Export file {filename} extension does not correspond to any export format!")
+
+
+def augment_filename(output: str, prepend: str):
+    path, filename = os.path.split(output)
+    filename = f"{prepend}-{filename}"
+    return os.path.join(path, filename)
+
+
+def forward_method(self):
+    if hasattr(self, "forward_for_export"):
+        return self.forward_for_export
+    else:
+        return self.forward
+
+
+def wrap_forward_method(self):
+    tp = type(self)
+    old_forward_method = None
+    if hasattr(tp, "forward_for_export"):
+        forward_method = tp.forward_for_export
+        old_forward_method = tp.forward
+        tp.forward = forward_method
+    else:
+        forward_method = None
+    return forward_method, old_forward_method
+
+
+def parse_input_example(input_example):
+    input_list = list(input_example)
+    input_dict = {}
+    # process possible kwargs
+    if isinstance(input_list[-1], dict):
+        input_dict = input_list[-1]
+        input_list = input_list[:-1]
+    return input_list, input_dict
+
+
+def to_onnxrt_input(input_names, input_dict, input_list):
+    odict = {}
+    for k in reversed(input_names):
+        if k in input_dict:
+            odict[k] = input_dict[k].cpu().numpy()
+        else:
+            odict[k] = input_list.pop().cpu().numpy()
+    return odict
+
 
-    @classmethod
-    def list_available_models(cls) -> 'List[PretrainedModelInfo]':
+def verify_runtime(
+    output, input_list, input_dict, input_names, output_names, output_example, check_tolerance=0.01,
+):
+    # Verify the model can be read, and is valid
+
+    onnx_model = onnx.load(output)
+    input_names = [node.name for node in onnx_model.graph.input]
+
+    global ort_available
+    if not ort_available:
+        logging.warning(f"ONNX generated at {output}, not verified - please install onnxruntime_gpu package.\n")
+        onnx.checker.check_model(onnx_model, full_check=True)
+        return
+
+    onnx_session_opt = onnxruntime.SessionOptions()
+    onnx_session_opt.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL
+    sess = onnxruntime.InferenceSession(
+        onnx_model.SerializeToString(), sess_options=onnx_session_opt, providers=['CUDAExecutionProvider']
+    )
+    ort_out = sess.run(output_names, to_onnxrt_input(input_names, input_dict, input_list))
+    all_good = True
+
+    for i, out in enumerate(ort_out[0]):
+        expected = output_example[i]
+        if torch.is_tensor(expected):
+            tout = torch.from_numpy(out)
+            if not torch.allclose(tout, expected.cpu(), rtol=check_tolerance, atol=100 * check_tolerance):
+                all_good = False
+                logging.info(f"onnxruntime results mismatch! PyTorch(expected):\n{expected}\nONNXruntime:\n{tout}")
+    status = "SUCCESS" if all_good else "FAIL"
+    logging.info(f"ONNX generated at {output} verified with onnxruntime : " + status)
+    return all_good
+
+
+apex_available = True
+
+try:
+    from apex.normalization.fused_layer_norm import FusedLayerNorm, MixedFusedLayerNorm
+    from apex.contrib.layer_norm.layer_norm import FastLayerNorm
+
+    def replace_FusedLayerNorm(n: nn.Module) -> Optional[nn.BatchNorm2d]:
         """
-        This method returns a list of pre-trained model which can be instantiated directly from NVIDIA's NGC cloud.
+        Replaces Apex's FusedLayerNorm with nn.LayerNorm. This is required for ONNX export.
+        Args:
+           n: the FusedLayerNorm pytorch module to replace
         Returns:
-            List of available pre-trained models.
+           Equivalent LayerNorm module
         """
-        list_of_models = []
-        model = PretrainedModelInfo(
-            pretrained_model_name="tts_waveglow_268m",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_waveglow_268m/versions/1.0.0rc1/files/tts_waveglow_268m.nemo",
-            description="This model is trained on LJSpeech sampled at 22050Hz, and has been tested on generating female English voices with an American accent and Mandarin voices.",
-            class_=cls,
-        )
-        list_of_models.append(model)
-        model = PretrainedModelInfo(
-            pretrained_model_name="tts_waveglow_88m",
-            location="https://api.ngc.nvidia.com/v2/models/nvidia/nemo/tts_waveglow_88m/versions/1.0.0/files/tts_waveglow.nemo",
-            description="This model is trained on LJSpeech sampled at 22050Hz, and has been tested on generating female English voices with an American accent and Mandarin voices.",
-            class_=cls,
-            aliases=["WaveGlow-22050Hz", "tts_waveglow"],
-        )
-        list_of_models.append(model)
-        return list_of_models
-
-    def load_state_dict(self, state_dict, strict=True):
-        # Remove convinv.inv_conv weights since they are not initialized until forward is called during training
-        # and can be computed from convinv.conv.weight
-        # Ideally, we should remove this during saving instead of ignoring during loading
-        for i in range(self._cfg.waveglow.n_flows):
-            if f"waveglow.convinv.{i}.inv_conv.weight" in state_dict:
-                del state_dict[f"waveglow.convinv.{i}.inv_conv.weight"]
-        super().load_state_dict(state_dict, strict=strict)
-
-    # Methods for model exportability
-    @property
-    def input_module(self):
-        return self.waveglow
-
-    @property
-    def output_module(self):
-        return self.waveglow
-
-    def _prepare_for_export(self, **kwargs):
-        self.update_bias_spect()
-        self.waveglow._prepare_for_export(**kwargs)
-
-    @property
-    def input_types(self):
-        return {
-            "audio": NeuralType(('B', 'T'), AudioSignal()),
-            "audio_len": NeuralType(('B'), LengthsType()),
-            "run_inverse": NeuralType(optional=True),
-        }
-
-    @property
-    def output_types(self):
-        if self.mode == OperationMode.training or self.mode == OperationMode.validation:
-            output_dict = {
-                "pred_normal_dist": NeuralType(('B', 'flowgroup', 'T'), NormalDistributionSamplesType()),
-                "log_s_list": [NeuralType(('B', 'flowgroup', 'T'), VoidType())],  # TODO: Figure out a good typing
-                "log_det_W_list": [NeuralType(elements_type=LogDeterminantType())],
-            }
-            if self.mode == OperationMode.validation:
-                output_dict["audio_pred"] = NeuralType(('B', 'T'), AudioSignal())
-                output_dict["spec"] = NeuralType(('B', 'T', 'D'), MelSpectrogramType())
-                output_dict["spec_len"] = NeuralType(('B'), LengthsType())
-            return output_dict
-        return {
-            "audio_pred": NeuralType(('B', 'T'), AudioSignal()),
-        }
-
-    def forward_for_export(self, spec, z=None):
-        return self.waveglow(spec, z)
+        if (
+            not isinstance(n, FusedLayerNorm)
+            and not isinstance(n, FastLayerNorm)
+            and not isinstance(n, MixedFusedLayerNorm)
+        ):
+            return None
+
+        dev = next(n.parameters()).device
+        mod = nn.LayerNorm(n.normalized_shape, eps=n.eps, elementwise_affine=n.elementwise_affine,).to(dev)
+
+        n_state = n.state_dict()
+        mod.load_state_dict(n_state)
+        return mod
+
+    default_Apex_replacements = {
+        "FusedLayerNorm": replace_FusedLayerNorm,
+        "MixedFusedLayerNorm": replace_FusedLayerNorm,
+        "FastLayerNorm": replace_FusedLayerNorm,
+    }
+
+except Exception as e:
+    default_Apex_replacements = {}
+    apex_available = False
+
+
+def simple_replace(BaseT: Type[nn.Module], DestT: Type[nn.Module]) -> Callable[[nn.Module], Optional[nn.Module]]:
+    """
+    Generic function generator to replace BaseT module with DestT. BaseT and DestT should have same atrributes. No weights are copied.
+    Args:
+        BaseT : module type to replace
+        DestT : destination module type
+    Returns:
+        swap function to replace BaseT module with DestT
+    """
+
+    def expansion_fn(mod: nn.Module) -> Optional[nn.Module]:
+        if not isinstance(mod, BaseT):
+            return None
+        args = [getattr(mod, name, None) for name in mod.__constants__]
+        out = DestT(*args)
+        return out
+
+    return expansion_fn
+
+
+def wrap_module(BaseT: Type[nn.Module], DestT: Type[nn.Module]) -> Callable[[nn.Module], Optional[nn.Module]]:
+    """
+    Generic function generator to replace BaseT module with DestT wrapper. 
+    Args:
+        BaseT : module type to replace
+        DestT : destination module type
+    Returns:
+        swap function to replace BaseT module with DestT
+    """
+
+    def expansion_fn(mod: nn.Module) -> Optional[nn.Module]:
+        out = DestT(mod)
+        return out
+
+    return expansion_fn
+
+
+def swap_modules(model: nn.Module, mapping: Dict[str, nn.Module]):
+    """
+    This function swaps nested modules as specified by "dot paths" in mod with a desired replacement. This allows
+    for swapping nested modules through arbitrary levels if children
+
+    NOTE: This occurs in place, if you want to preserve model then make sure to copy it first.
+
+    """
+    for path, new_mod in mapping.items():
+        expanded_path = path.split(".")
+        parent_mod = model
+        for sub_path in expanded_path[:-1]:
+            parent_mod = parent_mod._modules[sub_path]  # noqa
+        parent_mod._modules[expanded_path[-1]] = new_mod  # noqa
+
+    return model
+
+
+def replace_modules(
+    model: nn.Module, expansions: Dict[str, Callable[[nn.Module], Optional[nn.Module]]] = None
+) -> nn.Module:
+    """
+    Top-level function to replace modules in model, specified by class name with a desired replacement.
+    NOTE: This occurs in place, if you want to preserve model then make sure to copy it first.
+    Args:
+        model : top level module
+        expansions : replacement dictionary: module class name -> replacement function generator
+    Returns:
+        model, possibly modified in-place
+    """
+    mapping: Dict[str, nn.Module] = {}
+    for name, m in model.named_modules():
+        m_type = type(m).__name__
+        if m_type in expansions:
+            swapped = expansions[m_type](m)
+            if swapped:
+                mapping[name] = swapped
+    if len(mapping) > 0:
+        logging.info(f"Swapped {len(mapping)} modules")
+    swap_modules(model, mapping)
+    return model
+
+
+default_replacements = {
+    "BatchNorm1d": wrap_module(nn.BatchNorm1d, CastToFloat),
+    "BatchNorm2d": wrap_module(nn.BatchNorm2d, CastToFloat),
+    "LayerNorm": wrap_module(nn.LayerNorm, CastToFloat),
+}
+
+
+def replace_for_export(model: nn.Module) -> nn.Module:
+    """
+    Top-level function to replace default set of modules in model
+    NOTE: This occurs in place, if you want to preserve model then make sure to copy it first.
+    Args:
+        model : top level module
+        replace_1D_2D : include 1D -> 2D replacements
+    Returns:
+        model, possibly modified in-place
+    """
+    replace_modules(model, default_Apex_replacements)
+    replace_modules(model, default_replacements)
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -8,20 +8,11 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.collections.tts.modules.degli import DegliModule
-from nemo.collections.tts.modules.ed_mel2spec import EDMel2SpecModule
-from nemo.collections.tts.modules.glow_tts import GlowTTSModule
-from nemo.collections.tts.modules.melgan_modules import (
-    MelGANDiscriminator,
-    MelGANGenerator,
-    MelGANMultiScaleDiscriminator,
-)
-from nemo.collections.tts.modules.squeezewave import SqueezeWaveModule
 from nemo.collections.tts.modules.tacotron2 import Decoder as Taco2Decoder
 from nemo.collections.tts.modules.tacotron2 import Encoder as Taco2Encoder
 from nemo.collections.tts.modules.tacotron2 import Postnet as Taco2Postnet
 from nemo.collections.tts.modules.waveglow import WaveGlowModule
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/aligner.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/aligner.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/fastspeech2.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/waveglow.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,314 +1,261 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-import numpy as np
 import torch
-import torch.nn as nn
 
-from nemo.collections.tts.helpers.helpers import get_mask_from_lengths
-from nemo.collections.tts.modules.fastspeech2_submodules import FFTransformer, LengthRegulator, VariancePredictor
-from nemo.core.classes import NeuralModule, typecheck
+from nemo.collections.tts.helpers.helpers import OperationMode, remove, split_view
+from nemo.collections.tts.modules.submodules import Invertible1x1Conv, WaveNet
+from nemo.core.classes import Exportable, NeuralModule, typecheck
 from nemo.core.neural_types.elements import (
-    EncodedRepresentation,
-    LengthsType,
-    MaskType,
+    AudioSignal,
+    IntType,
     MelSpectrogramType,
-    RegressionValuesType,
-    TokenDurationType,
-    TokenIndex,
+    NormalDistributionSamplesType,
+    VoidType,
 )
 from nemo.core.neural_types.neural_type import NeuralType
-from nemo.utils import logging
 
 
-class FastSpeech2Encoder(NeuralModule):
+class WaveGlowModule(NeuralModule, Exportable):
     def __init__(
         self,
-        d_model=256,
-        n_layers=4,
-        n_attn_heads=2,
-        d_attn_head=256,
-        d_inner=1024,
-        kernel_size=9,
-        dropout=0.1,
-        attn_dropout=0.1,
-        n_embed=84,
-        padding_idx=83,
+        n_mel_channels: int,
+        n_flows: int,
+        n_group: int,
+        n_early_every: int,
+        n_early_size: int,
+        n_wn_channels: int,
+        n_wn_layers: int,
+        wn_kernel_size: int,
     ):
         """
-        FastSpeech 2 encoder. Converts phoneme sequence to the phoneme hidden sequence.
-        Consists of a phoneme embedding lookup, positional encoding, and feed-forward
-        Transformer blocks (4 by default).
+        WaveGlow module
 
         Args:
-            d_model: Model input (embedding) dimension. Defaults to 256.
-            n_layers: Number of feed-forward Transformer layers in the encoder. Defaults to 4.
-            n_attn_heads: Number of attention heads for the feed-forward Transformer in the encoder.
-                Defaults to 2.
-            d_attn_head: Dimensionality of the attention heads. Defaults to 256.
-            d_inner: Encoder hidden dimension. Defaults to 1024.
-            kernel_size: Encoder Conv1d kernel size (kernel_size, 1). Defaults to 9.
-            dropout: Encoder feed-forward Transformer dropout. Defaults to 0.1.
-            attn_dropout: Encoder attention dropout. Defaults to 0.1.
-            n_embed: Embedding input dim, should match number of tokens. Defaults to 84.
-            padding_idx: Padding token index. Deafaults to 83.
+            n_mel_channels (int): Number of mel channels to output.
+            n_flows (int): Number of flow layers
+            n_group (int): Number of groups to respace the inputs
+            n_early_every (int): Every n_early_every layers, n_early_size gets skip connected to the output
+            n_early_size (int): The size of the chunk to be skip connected
+            n_wn_channels (int): Number of channels for the non-invertible wavenet transformation
+            n_wn_layers (int): Number of layers for the non-invertible wavenet transformation
+            wn_kernel_size (int): Kernel size for the non-invertible wavenet transformation
         """
         super().__init__()
 
-        self.encoder = FFTransformer(
-            n_layer=n_layers,
-            n_head=n_attn_heads,
-            d_model=d_model,
-            d_head=d_attn_head,
-            d_inner=d_inner,
-            kernel_size=(kernel_size, 1),
-            dropout=dropout,
-            dropatt=attn_dropout,  # Not in the FS2 paper
-            embed_input=True,  # For the encoder, need to do embedding lookup
-            n_embed=n_embed,
-            padding_idx=padding_idx,
-        )
-
-    @property
-    def input_types(self):  # phonemes
-        return {"text": NeuralType(('B', 'T'), TokenIndex()), "text_length": NeuralType(('B'), LengthsType())}
-
-    @property
-    def output_types(self):
-        return {
-            "out": NeuralType(('B', 'T', 'D'), EncodedRepresentation()),
-            "mask": NeuralType(('B', 'T', 'D'), MaskType()),
-        }
+        self.upsample = torch.nn.ConvTranspose1d(n_mel_channels, n_mel_channels, 1024, stride=256)
+        self.n_mel_channels = n_mel_channels
+        assert n_group % 2 == 0
+        self.n_flows = n_flows
+        self.n_group = n_group
+        self.n_early_every = n_early_every
+        self.n_early_size = n_early_size
+        self.wavenet = torch.nn.ModuleList()
+        self.convinv = torch.nn.ModuleList()
+        self.mode = OperationMode.infer
+
+        n_half = n_group // 2
+
+        # Set up layers with the right sizes based on how many dimensions
+        # have been output already
+        n_remaining_channels = n_group
+        for k in range(n_flows):
+            if k % self.n_early_every == 0 and k > 0:
+                n_half = n_half - int(self.n_early_size / 2)
+                n_remaining_channels = n_remaining_channels - self.n_early_size
+            self.convinv.append(Invertible1x1Conv(n_remaining_channels))
+            self.wavenet.append(
+                WaveNet(
+                    n_half,
+                    n_mel_channels * n_group,
+                    n_layers=n_wn_layers,
+                    n_channels=n_wn_channels,
+                    kernel_size=wn_kernel_size,
+                )
+            )
+        self.n_remaining_channels = n_remaining_channels
+        self.time_cutoff = self.upsample.stride[0] - self.upsample.kernel_size[0]
 
-    @typecheck()
-    def forward(self, *, text, text_length):
-        return self.encoder(text, seq_lens=text_length)
+        # Pre-calculating the sizes of noise to use so it's not dynamic
+        n_halves = []
+        n_half = self.n_remaining_channels // 2
+        for k in reversed(range(self.n_flows)):
+            n_halves.append(n_half)
+            if k % self.n_early_every == 0 and k > 0:
+                n_half = n_half + int(self.n_early_size / 2)
+        n_halves.reverse()
+        self.n_halves = n_halves
 
+        self.removed_weightnorm = False
 
-class VarianceAdaptor(NeuralModule):
-    def __init__(
-        self,
-        d_model=256,
-        dropout=0.2,
-        dur_d_hidden=256,
-        dur_kernel_size=3,
-        pitch=True,
-        log_pitch=True,
-        n_f0_bins=256,
-        pitch_kernel_size=3,
-        pitch_min=80.0,
-        pitch_max=800.0,
-        energy=True,
-        n_energy_bins=256,
-        energy_kernel_size=3,
-        energy_min=0.0,
-        energy_max=600.0,
-    ):
+    def _prepare_for_export(self, **kwargs):
         """
-        FastSpeech 2 variance adaptor, which adds information like duration, pitch, etc. to the phoneme encoding.
-        Sets of conv1D blocks with ReLU and dropout.
-
-        Args:
-            d_model: Input and hidden dimension. Defaults to 256 (default encoder output dim).
-            dropout: Variance adaptor dropout. Defaults to 0.2.
-            dur_d_hidden: Hidden dim of the duration predictor. Defaults to 256.
-            dur_kernel_size: Kernel size for the duration predictor. Defaults to 3.
-            pitch (bool): Whether or not to use the pitch predictor.
-            log_pitch (bool): If True, uses log pitch. Defaults to True.
-            n_f0_bins: Number of F0 bins for the pitch predictor. Defaults to 256.
-            pitch_kernel_size: Kernel size for the pitch predictor. Defaults to 3.
-            pitch_min: Defaults to 80.0.
-            pitch_max: Defaults to 800.0.
-            pitch_d_hidden: Hidden dim of the pitch predictor.
-            energy (bool): Whether or not to use the energy predictor.
-            n_energy_bins: Number of energy bins. Defaults to 256.
-            energy_kernel_size: Kernel size for the energy predictor. Defaults to 3.
-            energy_min: Defaults to 0.0.
-            energy_max: Defaults to 600.0.
+        Override this method to prepare module for export. This is in-place operation.
+        Base version does common necessary module replacements (Apex etc)
         """
-        super().__init__()
-
-        # -- Duration Setup --
-        self.duration_predictor = VariancePredictor(
-            d_model=d_model, d_inner=dur_d_hidden, kernel_size=dur_kernel_size, dropout=dropout
-        )
-        self.length_regulator = LengthRegulator()
-
-        self.pitch = pitch
-        self.energy = energy
+        self.remove_weightnorm()
+        super()._prepare_for_export(**kwargs)
 
-        # -- Pitch Setup --
-        # NOTE: Pitch is clamped to 1e-5 which gets mapped to bin 1. But it is padded with 0s that get mapped to bin 0.
-        if self.pitch:
-            if log_pitch:
-                pitch_min = np.log(pitch_min)
-                pitch_max = np.log(pitch_max)
-            pitch_operator = torch.exp if log_pitch else lambda x: x
-            pitch_bins = pitch_operator(torch.linspace(start=pitch_min, end=pitch_max, steps=n_f0_bins - 1))
-            # Prepend 0 for unvoiced frames
-            pitch_bins = torch.cat((torch.tensor([0.0]), pitch_bins))
-
-            self.register_buffer("pitch_bins", pitch_bins)
-            self.pitch_predictor = VariancePredictor(
-                d_model=d_model, d_inner=n_f0_bins, kernel_size=pitch_kernel_size, dropout=dropout
-            )
-            # Predictor outputs values directly rather than one-hot vectors, therefore Embedding
-            self.pitch_lookup = nn.Embedding(n_f0_bins, d_model)
-
-        # -- Energy Setup --
-        if self.energy:
-            self.register_buffer(  # Linear scale bins
-                "energy_bins", torch.linspace(start=energy_min, end=energy_max, steps=n_energy_bins - 1)
-            )
-            self.energy_predictor = VariancePredictor(
-                d_model=d_model, d_inner=n_energy_bins, kernel_size=energy_kernel_size, dropout=dropout,
-            )
-            self.energy_lookup = nn.Embedding(n_energy_bins, d_model)
+    @typecheck()
+    def forward(self, spec, z=None, audio=None, run_inverse=True, sigma=1.0):
+        """ TODO
+        """
+        if self.training and self.mode != OperationMode.training:
+            raise ValueError(f"{self} has self.training set to True but self.OperationMode was not set to training")
+        if not self.training and self.mode == OperationMode.training:
+            raise ValueError(f"{self} has self.training set to False but self.OperationMode was set to training")
+
+        audio_pred = torch.zeros((1, 1))
+        if audio is not None and self.mode != OperationMode.infer:
+            # audio_to_normal_dist is used to calculate loss so only run this in train or val model
+            z1, log_s_list, log_det_W_list = self.audio_to_normal_dist(spec=spec, audio=audio)
+        if run_inverse:
+            # norm_dist_to_audio is used to predict audio from spectrogram so only used in val or infer mode
+            # Could also log train audio but currently not done
+            audio_pred = self.norm_dist_to_audio(spec=spec, sigma=sigma, z=z)
+
+        # Return the necessary tensors
+        if self.mode == OperationMode.training or self.mode == OperationMode.validation:
+            return z1, log_s_list, log_det_W_list, audio_pred
+        return audio_pred
 
     @property
     def input_types(self):
-        return {
-            "x": NeuralType(('B', 'T', 'D'), EncodedRepresentation()),
-            "x_len": NeuralType(('B'), LengthsType()),
-            "dur_target": NeuralType(('B', 'T'), TokenDurationType(), optional=True),
-            "pitch_target": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-            "energy_target": NeuralType(('B', 'T'), RegressionValuesType(), optional=True),
-            "spec_len": NeuralType(('B'), LengthsType(), optional=True),
-        }
+        if self.mode == OperationMode.infer:
+            return {
+                "spec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+                "z": NeuralType(('B', 'D', 'T'), MelSpectrogramType(), optional=True),
+                "sigma": NeuralType(optional=True),
+            }
+        else:
+            return {
+                "spec": NeuralType(('B', 'D', 'T'), MelSpectrogramType()),
+                "z": NeuralType(('B', 'D', 'T'), MelSpectrogramType(), optional=True),
+                "audio": NeuralType(('B', 'T'), AudioSignal(), optional=True),
+                "run_inverse": NeuralType(elements_type=IntType(), optional=True),
+                "sigma": NeuralType(optional=True),
+            }
 
     @property
     def output_types(self):
-        return {
-            "out": NeuralType(('B', 'T', 'D'), EncodedRepresentation()),
-            "log_dur_preds": NeuralType(('B', 'T'), TokenDurationType()),
-            "pitch_preds": NeuralType(('B', 'T'), RegressionValuesType()),
-            "energy_preds": NeuralType(('B', 'T'), RegressionValuesType()),
-            "spec_len": NeuralType(('B'), LengthsType()),
-        }
-
-    @typecheck()
-    def forward(self, *, x, x_len, dur_target=None, pitch_target=None, energy_target=None, spec_len=None):
-        """
-        Args:
-            x: Input from the encoder.
-            x_len: Length of the input.
-            dur_target:  Duration targets for the duration predictor. Needs to be passed in during training.
-            pitch_target: Pitch targets for the pitch predictor. Needs to be passed in during training.
-            energy_target: Energy targets for the energy predictor. Needs to be passed in during training.
-            spec_len: Target spectrogram length. Needs to be passed in during training.
-        """
-        # Duration predictions (or ground truth) fed into Length Regulator to
-        # expand the hidden states of the encoder embedding
-        log_dur_preds = self.duration_predictor(x)
-        log_dur_preds.masked_fill_(~get_mask_from_lengths(x_len), 0)
-        # Output is Batch, Time
-        if dur_target is not None:
-            dur_out = self.length_regulator(x, dur_target)
+        if self.mode == OperationMode.training or self.mode == OperationMode.validation:
+            return {
+                "pred_normal_dist": NeuralType(('B', 'flowgroup', 'T'), NormalDistributionSamplesType()),
+                "log_s_list": [NeuralType(('B', 'flowgroup', 'T'), VoidType())],  # TODO: Figure out a good typing
+                "log_det_W_list": [NeuralType(elements_type=VoidType())],  # TODO: Figure out a good typing
+                "audio_pred": NeuralType(('B', 'T'), AudioSignal()),
+            }
         else:
-            dur_preds = torch.clamp_min(torch.round(torch.exp(log_dur_preds)) - 1, 0).long()
-            if not torch.sum(dur_preds, dim=1).bool().all():
-                logging.error("Duration prediction failed on this batch. Settings to 1s")
-                dur_preds += 1
-            dur_out = self.length_regulator(x, dur_preds)
-            spec_len = torch.sum(dur_preds, dim=1)
-        out = dur_out
-        out *= get_mask_from_lengths(spec_len).unsqueeze(-1)
-
-        # Pitch
-        pitch_preds = None
-        if self.pitch:
-            # Possible future work:
-            #   Add pitch spectrogram prediction & conversion back to pitch contour using iCWT
-            #   (see Appendix C of the FastSpeech 2/2s paper).
-            pitch_preds = self.pitch_predictor(dur_out)
-            pitch_preds.masked_fill_(~get_mask_from_lengths(spec_len), 0)
-            if pitch_target is not None:
-                pitch_out = self.pitch_lookup(torch.bucketize(pitch_target, self.pitch_bins))
-            else:
-                pitch_out = self.pitch_lookup(torch.bucketize(pitch_preds.detach(), self.pitch_bins))
-            out += pitch_out
-        out *= get_mask_from_lengths(spec_len).unsqueeze(-1)
-
-        # Energy
-        energy_preds = None
-        if self.energy:
-            energy_preds = self.energy_predictor(dur_out)
-            if energy_target is not None:
-                energy_out = self.energy_lookup(torch.bucketize(energy_target, self.energy_bins))
-            else:
-                energy_out = self.energy_lookup(torch.bucketize(energy_preds.detach(), self.energy_bins))
-            out += energy_out
-        out *= get_mask_from_lengths(spec_len).unsqueeze(-1)
+            return {
+                "audio": NeuralType(('B', 'T'), AudioSignal()),
+            }
 
-        return out, log_dur_preds, pitch_preds, energy_preds, spec_len
-
-
-class MelSpecDecoder(NeuralModule):
-    def __init__(
-        self,
-        d_model=256,
-        d_out=80,
-        n_layers=4,
-        n_attn_heads=2,
-        d_attn_head=256,
-        d_inner=1024,
-        kernel_size=9,
-        dropout=0.1,
-        attn_dropout=0.1,
-    ):
+    def input_example(self, max_batch=1, max_dim=256):
         """
-        FastSpeech 2 mel-spectrogram decoder. Converts adapted hidden sequence to a mel-spectrogram sequence.
-        Consists of four feed-forward Transformer blocks by default.
-
-        Args:
-            d_model: Input dimension. Defaults to 256.
-            d_out: Dimensionality of output. Defaults to 80.
-            n_layers: Number of feed-forward Transformer layers in the mel-spec decoder. Defaults to 4.
-            n_attn_heads: Number of attention heads for the feed-forward Transformer. Defaults to 2.
-            d_attn_head: Dimensionality of the attention heads. Defaults to 256.
-            d_inner: Mel-spec decoder hidden dimension. Defaults to 1024.
-            kernel_size: Mel-spec decoder Conv1d kernel size (kernel_size, 1). Defaults to 9.
-            dropout: Mel-spec decoder feed-forward Transformer dropout. Defaults to 0.1.
-            attn_dropout: Mel-spec decoder attention dropout. Defaults to 0.1.
+        Generates input examples for tracing etc.
+        Returns:
+            A tuple of input examples.
         """
-        super().__init__()
-
-        self.decoder = FFTransformer(
-            n_layer=n_layers,
-            n_head=n_attn_heads,
-            d_model=d_model,
-            d_head=d_attn_head,
-            d_inner=d_inner,
-            kernel_size=(kernel_size, 1),
-            dropout=dropout,
-            dropatt=attn_dropout,
-            embed_input=False,
+        par = next(self.parameters())
+        mel = torch.randn((max_batch, self.n_mel_channels, max_dim), device=par.device, dtype=par.dtype)
+        z = torch.randn(
+            (max_batch, self.n_mel_channels, max_dim * self.upsample.stride[0] // self.n_group),
+            device=par.device,
+            dtype=par.dtype,
         )
-        self.linear = nn.Linear(d_model, d_out)
+        return {"spec": mel, "z": z}
 
-    @property
-    def input_types(self):
-        return {
-            "decoder_input": NeuralType(('B', 'T', 'D'), EncodedRepresentation()),
-            "lengths": NeuralType(('B'), LengthsType()),
-        }
-
-    @property
-    def output_types(self):
-        return {"mel_spec": NeuralType(('B', 'T', 'C'), MelSpectrogramType())}
-
-    @typecheck()
-    def forward(self, *, decoder_input, lengths):
-        decoder_out, _ = self.decoder(decoder_input, lengths)
-        mel_out = self.linear(decoder_out)
-        return mel_out
+    def audio_to_normal_dist(self, *, spec: torch.Tensor, audio: torch.Tensor) -> (torch.Tensor, list, list):
+        #  Upsample spectrogram to size of audio
+        spec = self.upsample(spec)
+        assert spec.size(2) >= audio.size(1)
+        if spec.size(2) > audio.size(1):
+            spec = spec[:, :, : audio.size(1)]
+
+        # logging.debug(f"spec: {spec.shape}. n_group: {self.n_group}")
+        spec = split_view(spec, self.n_group, 2).permute(0, 2, 1, 3)
+        spec = spec.contiguous().view(spec.size(0), spec.size(1), -1)
+        spec = spec.permute(0, 2, 1)
+
+        audio = split_view(audio, self.n_group, 1).permute(0, 2, 1)
+        output_audio = []
+        log_s_list = []
+        log_det_W_list = []
+
+        for k in range(self.n_flows):
+            if k % self.n_early_every == 0 and k > 0:
+                output_audio.append(audio[:, : self.n_early_size, :])
+                audio = audio[:, self.n_early_size :, :]
+
+            audio, log_det_W = self.convinv[k](audio)
+            log_det_W_list.append(log_det_W)
+
+            n_half = int(audio.size(1) / 2)
+            audio_0 = audio[:, :n_half, :]
+            audio_1 = audio[:, n_half:, :]
+
+            output = self.wavenet[k]((audio_0, spec))
+            log_s = output[:, n_half:, :]
+            b = output[:, :n_half, :]
+            audio_1 = torch.exp(log_s) * audio_1 + b
+            log_s_list.append(log_s)
+
+            audio = torch.cat([audio_0, audio_1], 1)
+
+        output_audio.append(audio)
+        return torch.cat(output_audio, 1), log_s_list, log_det_W_list
+
+    def norm_dist_to_audio(self, *, spec, z=None, sigma: float = 1.0):
+        spec = self.upsample(spec)
+        spec = spec.contiguous().view(spec.size(0), spec.size(1), -1)
+        # trim conv artifacts. maybe pad spec to kernel multiple
+        if self.time_cutoff != 0:
+            spec = spec[:, :, : self.time_cutoff]
+
+        spec = split_view(spec, self.n_group, 2).permute(0, 2, 1, 3)
+        spec = spec.contiguous().view(spec.size(0), spec.size(1), -1)
+        spec = spec.permute(0, 2, 1)
+
+        z_size = torch.Size([spec.size(0), self.n_group, spec.size(2)])
+        if z is None:
+            z = sigma * torch.randn(z_size, device=spec.device).to(spec.dtype)
+
+        audio, z = torch.split(z, [self.n_remaining_channels, z.size(1) - self.n_remaining_channels], 1)
+
+        for k in reversed(range(self.n_flows)):
+            n_half = self.n_halves[k]
+            audio_0, audio_1 = torch.split(audio, [n_half, audio.size(1) - n_half], 1)
+
+            output = self.wavenet[k]((audio_0, spec))
+
+            b, s = torch.split(output, [n_half, output.size(1) - n_half], 1)
+
+            audio_1 = audio_1 - b
+            audio_1 = audio_1 / torch.exp(s)
+            audio = torch.cat((audio_0, audio_1), 1)
+
+            audio = self.convinv[k](audio, reverse=True)
+            if k % self.n_early_every == 0 and k > 0:
+                z1, z = torch.split(z, [self.n_early_size, z.size(1) - self.n_early_size], 1)
+                audio = torch.cat((z1, audio), 1)
+        return audio.permute(0, 2, 1).contiguous().view(audio.size(0), -1)
+
+    def remove_weightnorm(self):
+        if self.removed_weightnorm:
+            return
+        for wavenet in self.wavenet:
+            wavenet.start = torch.nn.utils.remove_weight_norm(wavenet.start)
+            wavenet.in_layers = remove(wavenet.in_layers)
+            wavenet.cond_layer = torch.nn.utils.remove_weight_norm(wavenet.cond_layer)
+            wavenet.res_skip_layers = remove(wavenet.res_skip_layers)
+        self.removed_weightnorm = True
```

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/hifigan_modules.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/hifigan_modules.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/mixer_tts.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/mixer_tts.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/submodules.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/submodules.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/tacotron2.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/tacotron2.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/transformer.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/transformer.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/modules/univnet_modules.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/modules/univnet_modules.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/data.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/data.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/de_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/de_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/en_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/en_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/g2ps.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/g2ps.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/helpers.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/helpers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/tts_data_types.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/tts_data_types.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/collections/tts/torch/tts_tokenizers.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/torch/tts_tokenizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/constants.py` & `nemo_toolkit-1.9.0/nemo/constants.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/__init__.py` & `nemo_toolkit-1.9.0/nemo/core/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/classes/__init__.py` & `nemo_toolkit-1.9.0/nemo/core/classes/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -25,10 +25,11 @@
     Typing,
     is_typecheck_enabled,
     typecheck,
 )
 from nemo.core.classes.dataset import Dataset, IterableDataset
 from nemo.core.classes.exportable import Exportable, ExportFormat
 from nemo.core.classes.loss import Loss
+from nemo.core.classes.mixins import adapter_mixins
 from nemo.core.classes.modelPT import ModelPT
 from nemo.core.classes.module import NeuralModule
 from nemo.utils import exceptions
```

### Comparing `nemo_toolkit-1.8.2/nemo/core/classes/common.py` & `nemo_toolkit-1.9.0/nemo/core/classes/common.py`

 * *Files 2% similar despite different names*

```diff
@@ -153,14 +153,15 @@
     def output_types(self) -> Optional[Dict[str, NeuralType]]:
         """Define these to enable output neural type checks"""
         return None
 
     def _validate_input_types(self, input_types=None, ignore_collections=False, **kwargs):
         """
         This function does a few things.
+
         1) It ensures that len(self.input_types <non-optional>) <= len(kwargs) <= len(self.input_types).
         2) For each (keyword name, keyword value) passed as input to the wrapped function:
             - Check if the keyword name exists in the list of valid self.input_types names.
             - Check if keyword value has the `neural_type` property.
                 - If it does, then perform a comparative check and assert that neural types
                     are compatible (SAME or GREATER).
             - Check if keyword value is a container type (list or tuple). If yes,
@@ -236,22 +237,23 @@
                         Initial depth is 1 as we consider the current loop to be the 1st step inside the nest.
                         """
                         self.__check_neural_type(val, metadata, depth=1, name=key)
 
     def _attach_and_validate_output_types(self, out_objects, ignore_collections=False, output_types=None):
         """
         This function does a few things.
+
         1) It ensures that len(out_object) == len(self.output_types).
         2) If the output is a tensor (or list/tuple of list/tuple ... of tensors), it
             attaches a neural_type to it. For objects without the neural_type attribute,
             such as python objects (dictionaries and lists, primitive data types, structs),
             no neural_type is attached.
 
-            Note: tensor.neural_type is only checked during _validate_input_types which is
-            called prior to forward().
+        Note: tensor.neural_type is only checked during _validate_input_types which is
+        called prior to forward().
 
         Args:
             output_types: Either the `output_types` defined at class level, or the local function
                 overridden type definition.
             ignore_collections: For backward compatibility, container support can be disabled explicitly
                 using this flag. When set to True, all nesting is ignored and nest-depth checks are skipped.
             out_objects: The outputs of the wrapped function.
@@ -260,15 +262,15 @@
         if output_types is not None:
             # Precompute metadata
             metadata = TypecheckMetadata(original_types=output_types, ignore_collections=ignore_collections)
             out_types_list = list(metadata.base_types.items())
             mandatory_out_types_list = list(metadata.mandatory_types.items())
 
             # First convert all outputs to list/tuple format to check correct number of outputs
-            if type(out_objects) in (list, tuple):
+            if isinstance(out_objects, (list, tuple)):
                 out_container = out_objects  # can be any rank nested structure
             else:
                 out_container = [out_objects]
 
             # If this neural type has a *single output*, with *support for nested outputs*,
             # then *do not* perform any check on the number of output items against the number
             # of neural types (in this case, 1).
@@ -343,15 +345,25 @@
                 # Therefore in such a case, we "start" the DFS at depth 0 - since the recursion is
                 # being applied on 1 neural type : 1 output struct (single or nested output).
                 # Since we are guarenteed that the outer tuple will be built by python,
                 # assuming initial depth of 0 is appropriate.
                 for ind, res in enumerate(out_objects):
                     self.__attach_neural_type(res, metadata, depth=0, name=out_types_list[ind][0])
 
-    def __check_neural_type(self, obj, metadata, depth, name=None):
+    def __check_neural_type(self, obj, metadata: TypecheckMetadata, depth: int, name: str = None):
+        """
+        Recursively tests whether the obj satisfies the semantic neural type assertion.
+        Can include shape checks if shape information is provided.
+
+        Args:
+            obj: Any python object that can be assigned a value.
+            metadata: TypecheckMetadata object.
+            depth: Current depth of recursion.
+            name: Optional name used of the source obj, used when an error occurs.
+        """
         if isinstance(obj, tuple) or isinstance(obj, list):
             for elem in obj:
                 self.__check_neural_type(elem, metadata, depth + 1, name=name)
             return  # after processing nest, return to avoid testing nest itself
 
         type_val = metadata.base_types[name]
 
@@ -382,15 +394,24 @@
             if type_shape is not None and len(value_shape) != len(type_shape):
                 raise TypeError(
                     f"Input shape mismatch occured for {name} in module {self.__class__.__name__} : \n"
                     f"Input shape expected = {type_shape} | \n"
                     f"Input shape found : {value_shape}"
                 )
 
-    def __attach_neural_type(self, obj, metadata, depth, name=None):
+    def __attach_neural_type(self, obj, metadata: TypecheckMetadata, depth: int, name: str = None):
+        """
+        Recursively attach neural types to a given object - as long as it can be assigned some value.
+
+        Args:
+            obj: Any python object that can be assigned a value.
+            metadata: TypecheckMetadata object.
+            depth: Current depth of recursion.
+            name: Optional name used of the source obj, used when an error occurs.
+        """
         if isinstance(obj, tuple) or isinstance(obj, list):
             for elem in obj:
                 self.__attach_neural_type(elem, metadata, depth=depth + 1, name=name)
             return  # after processing nest, return to avoid argument insertion into nest itself
 
         type_val = metadata.base_types[name]
 
@@ -515,29 +536,50 @@
                 return False
         else:
             return False
 
 
 class FileIO(ABC):
     def save_to(self, save_path: str):
-        """Saves module/model with weights"""
+        """
+        Standardized method to save a tarfile containing the checkpoint, config, and any additional artifacts.
+        Implemented via :meth:`nemo.core.connectors.save_restore_connector.SaveRestoreConnector.save_to`.
+
+        Args:
+            save_path: str, path to where the file should be saved.
+        """
         raise NotImplementedError()
 
     @classmethod
     def restore_from(
         cls,
         restore_path: str,
         override_config_path: Optional[str] = None,
         map_location: Optional['torch.device'] = None,
         strict: bool = True,
         return_config: bool = False,
         trainer: Optional['Trainer'] = None,
         save_restore_connector: SaveRestoreConnector = None,
     ):
-        """Restores module/model with weights"""
+        """
+        Restores model instance (weights and configuration) from a .nemo file
+
+        Args:
+            restore_path: path to .nemo file from which model should be instantiated
+            override_config_path: path to a yaml config that will override the internal
+                config file or an OmegaConf / DictConfig object representing the model config.
+            map_location: Optional torch.device() to map the instantiated model to a device.
+                By default (None), it will select a GPU if available, falling back to CPU otherwise.
+            strict: Passed to load_state_dict. By default True
+            return_config: If set to true, will return just the underlying config of the restored
+                model as an OmegaConf DictConfig object without instantiating the model.
+            trainer: An optional Trainer object, passed to the model constructor.
+            save_restore_connector: An optional SaveRestoreConnector object that defines the implementation
+                of the restore_from() method.
+        """
         raise NotImplementedError()
 
     @classmethod
     def from_config_file(cls, path2yaml_file: str):
         """
         Instantiates an instance of NeMo Model from YAML config file.
         Weights will be initialized randomly.
@@ -789,57 +831,65 @@
         # Default to current class, and perform basic class path resolution (handled via restore_from() + target class)
         class_ = cls
 
         return class_, path
 
 
 class typecheck:
-    class TypeState(Enum):
-        """
-        Placeholder to denote the default value of type information provided.
-        If the constructor of this decorator is used to override the class level type definition,
-        this enum value indicate that types will be overridden.
-        """
+    """
+    A decorator which performs input-output neural type checks, and attaches
+    neural types to the output of the function that it wraps.
 
-        UNINITIALIZED = 0
+    Requires that the class inherit from :class:`~nemo.core.Typing` in order to perform
+    type checking, and will raise an error if that is not the case.
 
-    def __init__(
-        self,
-        input_types: Union[TypeState, Dict[str, NeuralType]] = TypeState.UNINITIALIZED,
-        output_types: Union[TypeState, Dict[str, NeuralType]] = TypeState.UNINITIALIZED,
-        ignore_collections: bool = False,
-    ):
-        """
-        A decorator which performs input-output neural type checks, and attaches
-        neural types to the output of the function that it wraps.
+    # Usage (Class level type support)
 
-        Requires that the class inherit from `nemo.core.Typing` in order to perform
-        type checking, and will raise an error if that is not the case.
+    .. code-block:: python
 
-        # Usage (Class level type support)
         @typecheck()
         def fn(self, arg1, arg2, ...):
             ...
 
-        # Usage (Function level type support)
+    # Usage (Function level type support)
+
+    .. code-block:: python
+
         @typecheck(input_types=..., output_types=...)
         def fn(self, arg1, arg2, ...):
             ...
 
-        Points to be noted:
-        1) The brackets () in `@typecheck()` are necessary.
+    Points to be noted:
 
-            You will encounter a TypeError: __init__() takes 1 positional argument but X
-            were given without those brackets.
+    1) The brackets () in `@typecheck()` are necessary.
 
-        2) The function can take any number of positional arguments during definition.
+        You will encounter a TypeError: __init__() takes 1 positional argument but X
+        were given without those brackets.
 
-            When you call this function, all arguments must be passed using kwargs only.
+    2) The function can take any number of positional arguments during definition.
 
+        When you call this function, all arguments must be passed using kwargs only.
+
+    """
+
+    class TypeState(Enum):
         """
+        Placeholder to denote the default value of type information provided.
+        If the constructor of this decorator is used to override the class level type definition,
+        this enum value indicate that types will be overridden.
+        """
+
+        UNINITIALIZED = 0
+
+    def __init__(
+        self,
+        input_types: Union[TypeState, Dict[str, NeuralType]] = TypeState.UNINITIALIZED,
+        output_types: Union[TypeState, Dict[str, NeuralType]] = TypeState.UNINITIALIZED,
+        ignore_collections: bool = False,
+    ):
         self.input_types = input_types
         self.output_types = output_types
 
         if input_types == self.TypeState.UNINITIALIZED:
             self.input_override = False
         else:
             self.input_override = True
@@ -849,14 +899,27 @@
         else:
             self.output_override = True
 
         self.ignore_collections = ignore_collections
 
     @wrapt.decorator(enabled=is_typecheck_enabled)
     def __call__(self, wrapped, instance: Typing, args, kwargs):
+        """
+        Wrapper method that can be used on any function of a class that implements :class:`~nemo.core.Typing`.
+        By default, it will utilize the `input_types` and `output_types` properties of the class inheriting Typing.
+
+        Local function level overrides can be provided by supplying dictionaries as arguments to the decorator.
+
+        Args:
+            input_types: Union[TypeState, Dict[str, NeuralType]]. By default, uses the global `input_types`.
+            output_types: Union[TypeState, Dict[str, NeuralType]]. By default, uses the global `output_types`.
+            ignore_collections: Bool. Determines if container types should be asserted for depth checks, or
+                if depth checks are skipped entirely.
+
+        """
         if instance is None:
             raise RuntimeError("Only classes which inherit nemo.core.Typing can use this decorator !")
 
         if not isinstance(instance, Typing):
             raise RuntimeError("Only classes which inherit nemo.core.Typing can use this decorator !")
 
         if hasattr(instance, 'input_ports') or hasattr(instance, 'output_ports'):
@@ -901,18 +964,27 @@
             output_types=output_types, ignore_collections=self.ignore_collections, out_objects=outputs
         )
 
         return outputs
 
     @staticmethod
     def set_typecheck_enabled(enabled: bool = True):
+        """
+        Global method to enable/disable typechecking.
+
+        Args:
+            enabled: bool, when True will enable typechecking.
+        """
         global _TYPECHECK_ENABLED
         _TYPECHECK_ENABLED = enabled
 
     @staticmethod
     @contextmanager
     def disable_checks():
+        """
+        Context manager that temporarily disables type checking within its context.
+        """
         typecheck.set_typecheck_enabled(enabled=False)
         try:
             yield
         finally:
             typecheck.set_typecheck_enabled(enabled=True)
```

### Comparing `nemo_toolkit-1.8.2/nemo/core/classes/dataset.py` & `nemo_toolkit-1.9.0/nemo/core/classes/dataset.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/classes/exportable.py` & `nemo_toolkit-1.9.0/nemo/core/classes/exportable.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/classes/loss.py` & `nemo_toolkit-1.9.0/nemo/core/classes/loss.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/classes/modelPT.py` & `nemo_toolkit-1.9.0/nemo/core/classes/modelPT.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 from pathlib import Path
 from typing import Callable, Dict, List, Optional, Union
 
 import hydra
 import torch
 from omegaconf import DictConfig, OmegaConf, open_dict
 from pytorch_lightning import LightningModule, Trainer
-from pytorch_lightning.utilities import rank_zero_only
+from pytorch_lightning.utilities import model_summary, rank_zero_only
 
 from nemo import package_info
 from nemo.core import optim
 from nemo.core.classes.common import Model
 from nemo.core.connectors.save_restore_connector import SaveRestoreConnector
 from nemo.core.optim import prepare_lr_scheduler
 from nemo.utils import logging, model_utils
@@ -290,15 +290,19 @@
         Returns:
             An instance of type cls or its underlying config (if return_config is set).
         """
 
         if save_restore_connector is None:
             save_restore_connector = SaveRestoreConnector()
 
-        restore_path = os.path.abspath(os.path.expanduser(restore_path))
+        if save_restore_connector.model_extracted_dir is None:
+            restore_path = os.path.abspath(os.path.expanduser(restore_path))
+        else:
+            restore_path = os.path.abspath(os.path.expanduser(save_restore_connector.model_extracted_dir))
+
         if not path.exists(restore_path):
             raise FileNotFoundError(f"Can't find {restore_path}")
 
         app_state = AppState()
         app_state.model_restore_path = restore_path
 
         cls.update_save_restore_connector(save_restore_connector)
@@ -435,17 +439,16 @@
                 * "lr": mandatory key for learning rate. Will raise ValueError if not provided.
                 * "optimizer": string name pointing to one of the available optimizers in the registry. \
                 If not provided, defaults to "adam".
                 * "opt_args": Optional list of strings, in the format "arg_name=arg_value". \
                 The list of "arg_value" will be parsed and a dictionary of optimizer kwargs \
                 will be built and supplied to instantiate the optimizer.
         """
-
-        if self._optimizer_param_groups is None:
-            self.setup_optimizer_param_groups()
+        # Setup the optimizer parameter groups (by default use all parameters that are trainable)
+        self.setup_optimizer_param_groups()
 
         # If config was not explicitly passed to us
         if optim_config is None:
             # See if internal config has `optim` namespace
             if self._cfg is not None and hasattr(self._cfg, 'optim'):
                 optim_config = self._cfg.optim
 
@@ -479,29 +482,18 @@
             if not isinstance(self._trainer.accumulate_grad_batches, int):
                 raise ValueError("We do not currently support gradient acculumation that is not an integer.")
             if self._trainer.max_steps is None or self.trainer.max_steps < 0:
                 # Store information needed to calculate max_steps
                 optim_config['sched']['t_max_epochs'] = self._trainer.max_epochs
                 optim_config['sched']['t_accumulate_grad_batches'] = self._trainer.accumulate_grad_batches
                 optim_config['sched']['t_limit_train_batches'] = self._trainer.limit_train_batches
-                if self._trainer.accelerator is None:
-                    optim_config['sched']['t_num_workers'] = self._trainer.num_devices or 1
-                elif self._trainer.accelerator == "ddp_cpu":
-                    optim_config['sched']['t_num_workers'] = self._trainer.num_devices * self._trainer.num_nodes
-                elif self._trainer.accelerator == "ddp":
-                    optim_config['sched']['t_num_workers'] = self._trainer.num_devices * self._trainer.num_nodes
-                elif HAVE_NLPPLUGIN and isinstance(self._trainer.accelerator.training_type_plugin, NLPDDPPlugin):
+                optim_config['sched']['t_num_workers'] = self._trainer.num_devices * self._trainer.num_nodes
+                if HAVE_NLPPLUGIN and isinstance(self._trainer.accelerator.training_type_plugin, NLPDDPPlugin):
                     app = AppState()
                     optim_config['sched']['t_num_workers'] = app.data_parallel_size
-                else:
-                    logging.warning(
-                        f"The lightning trainer received accelerator: {self._trainer.accelerator}. We "
-                        "recommend to use 'ddp' instead."
-                    )
-                    optim_config['sched']['t_num_workers'] = self._trainer.num_devices * self._trainer.num_nodes
             else:
                 optim_config['sched']['max_steps'] = self._trainer.max_steps
 
         # Force into DictConfig from nested structure
         optim_config = OmegaConf.create(optim_config)
         # Get back nested dict so we its mutable
         optim_config = OmegaConf.to_container(optim_config, resolve=True)
@@ -1241,14 +1233,26 @@
                 if trainer.num_devices and trainer.num_nodes:
                     self.world_size = trainer.num_devices * trainer.num_nodes
             else:
                 logging.warning(f'World size can only be set by PyTorch Lightning Trainer.')
         app_state = AppState()
         app_state.world_size = self.world_size
 
+    def summarize(self, max_depth: int = 1) -> model_summary.ModelSummary:
+        """Summarize this LightningModule.
+
+        Args:
+            max_depth: The maximum depth of layer nesting that the summary will include. A value of 0 turns the
+                layer summary off. Default: 1.
+
+        Return:
+            The model summary object
+        """
+        return model_summary.summarize(self, max_depth=max_depth)
+
     def _update_dataset_config(self, dataset_name: str, config: Optional[Union[DictConfig, Dict]]):
         """
         Update the config (if not None) of the dataset by given name.
         Preserves said config after updating.
 
         Args:
             dataset_name: str name of the dataset whose config is being updated.
```

### Comparing `nemo_toolkit-1.8.2/nemo/core/classes/module.py` & `nemo_toolkit-1.9.0/nemo/core/classes/module.py`

 * *Files 11% similar despite different names*

```diff
@@ -65,13 +65,25 @@
         self.train()
 
     @contextmanager
     def as_frozen(self):
         """
         Context manager which temporarily freezes a module, yields control and finally unfreezes the module.
         """
-        self.freeze()
+        training_mode = self.training
+        grad_map = {}
+        for pname, param in self.named_parameters():
+            grad_map[pname] = param.requires_grad
 
+        self.freeze()
         try:
             yield
         finally:
             self.unfreeze()
+
+            for pname, param in self.named_parameters():
+                param.requires_grad = grad_map[pname]
+
+            if training_mode:
+                self.train()
+            else:
+                self.eval()
```

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/__init__.py` & `nemo_toolkit-1.9.0/nemo/core/config/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/base_config.py` & `nemo_toolkit-1.9.0/nemo/core/config/base_config.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/hydra_runner.py` & `nemo_toolkit-1.9.0/nemo/core/config/hydra_runner.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/modelPT.py` & `nemo_toolkit-1.9.0/nemo/core/config/modelPT.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/optimizers.py` & `nemo_toolkit-1.9.0/nemo/core/config/optimizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/pytorch.py` & `nemo_toolkit-1.9.0/nemo/core/config/pytorch.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/pytorch_lightning.py` & `nemo_toolkit-1.9.0/nemo/core/config/pytorch_lightning.py`

 * *Files 2% similar despite different names*

```diff
@@ -28,15 +28,15 @@
     """
     Configuration of PyTorch Lightning Trainer.
     It is not derived from Config as it is not a NeMo object (and in particular it doesn't need a name).
     ..warning:
         Picked just few params of the PTL trainer for now. This needs to be discussed.
     ..note:
         For the details on the function/meanings of the arguments, please refer to:
-        https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#
+        https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html
     """
 
     logger: Any = True
     checkpoint_callback: Any = True
     callbacks: Optional[Any] = None
     default_root_dir: Optional[str] = None
     gradient_clip_val: float = 0
```

### Comparing `nemo_toolkit-1.8.2/nemo/core/config/schedulers.py` & `nemo_toolkit-1.9.0/nemo/core/config/schedulers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/connectors/__init__.py` & `nemo_toolkit-1.9.0/nemo/core/connectors/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/connectors/save_restore_connector.py` & `nemo_toolkit-1.9.0/nemo/core/connectors/save_restore_connector.py`

 * *Files 6% similar despite different names*

```diff
@@ -31,14 +31,15 @@
 from nemo.utils.model_utils import inject_model_parallel_rank
 
 
 class SaveRestoreConnector:
     def __init__(self) -> None:
         self._model_config_yaml = "model_config.yaml"
         self._model_weights_ckpt = "model_weights.ckpt"
+        self._model_extracted_dir = None
 
     def save_to(self, model, save_path: str):
         """
         Saves model instance (weights and configuration) into .nemo file.
         You can use "restore_from" method to fully restore instance from .nemo file.
 
         .nemo file is an archive (tar.gz) with the following:
@@ -105,15 +106,29 @@
                 map_location = torch.device('cuda')
             else:
                 map_location = torch.device('cpu')
 
         app_state = AppState()
         with tempfile.TemporaryDirectory() as tmpdir:
             try:
-                self._unpack_nemo_file(path2file=restore_path, out_folder=tmpdir)
+                # Check if self.model_extracted_dir is set, and is a valid path
+                if self.model_extracted_dir is not None and os.path.isdir(self.model_extracted_dir):
+                    # Log that NeMo will use the provided `model_extracted_dir`
+                    logging.info(
+                        f"Restoration will occur within pre-extracted directory : " f"`{self.model_extracted_dir}`."
+                    )
+
+                    # Override `tmpdir` above with the pre-extracted `model_extracted_dir`
+                    tmpdir = self.model_extracted_dir
+
+                else:
+                    # Extract the nemo file into the temporary directory
+                    self._unpack_nemo_file(path2file=restore_path, out_folder=tmpdir)
+
+                # Change current working directory to
                 os.chdir(tmpdir)
                 if override_config_path is None:
                     config_yaml = os.path.join(tmpdir, self.model_config_yaml)
                 else:
                     # can be str path or OmegaConf / DictConfig object
                     config_yaml = override_config_path
                 if not isinstance(config_yaml, (OmegaConf, DictConfig)):
@@ -148,23 +163,41 @@
                 state_dict = self._load_state_dict_from_disk(model_weights, map_location=map_location)
             finally:
                 os.chdir(cwd)
 
         return (conf, instance, state_dict)
 
     def modify_state_dict(self, conf, state_dict):
+        """
+        Utility method that allows to modify the state dict before loading parameters into a model.
+
+        Args:
+            conf: A model level OmegaConf object.
+            state_dict: The state dict restored from the checkpoint.
+
+        Returns:
+            A potentially modified state dict.
+        """
         if conf.get('megatron_amp_O2', False):
             new_state_dict = {}
             for key in state_dict.keys():
                 new_key = key.replace('model.', 'model.module.', 1)
                 new_state_dict[new_key] = state_dict[key]
             state_dict = new_state_dict
         return state_dict
 
     def load_instance_with_state_dict(self, instance, state_dict, strict):
+        """
+        Utility method that loads a model instance with the (potentially modified) state dict.
+
+        Args:
+            instance: ModelPT subclass instance.
+            state_dict: The state dict (which may have been modified)
+            strict: Bool, whether to perform strict checks when loading the state dict.
+        """
         instance.load_state_dict(state_dict, strict=strict)
         instance._set_model_restore_state(is_being_restored=False)
 
     def restore_from(
         self,
         calling_cls,
         restore_path: str,
@@ -182,14 +215,15 @@
             override_config_path: path to a yaml config that will override the internal
                 config file or an OmegaConf / DictConfig object representing the model config.
             map_location: Optional torch.device() to map the instantiated model to a device.
                 By default (None), it will select a GPU if available, falling back to CPU otherwise.
             strict: Passed to load_state_dict. By default True
             return_config: If set to true, will return just the underlying config of the restored
                 model as an OmegaConf DictConfig object without instantiating the model.
+            trainer: An optional Trainer object, passed to the model constructor.
 
         Example:
             ```
             model = nemo.collections.asr.models.EncDecCTCModel.restore_from('asr.nemo')
             assert isinstance(model, nemo.collections.asr.models.EncDecCTCModel)
             ```
 
@@ -438,14 +472,15 @@
         with tarfile.open(filename, "w:") as tar:
             tar.add(source_dir, arcname=".")
 
     @staticmethod
     def _unpack_nemo_file(path2file: str, out_folder: str) -> str:
         if not os.path.exists(path2file):
             raise FileNotFoundError(f"{path2file} does not exist")
+
         # we start with an assumption of uncompressed tar,
         # which should be true for versions 1.7.0 and above
         tar_header = "r:"
         try:
             tar_test = tarfile.open(path2file, tar_header)
             tar_test.close()
         except tarfile.ReadError:
@@ -475,7 +510,15 @@
     @property
     def model_weights_ckpt(self) -> str:
         return self._model_weights_ckpt
 
     @model_weights_ckpt.setter
     def model_weights_ckpt(self, path: str):
         self._model_weights_ckpt = path
+
+    @property
+    def model_extracted_dir(self) -> Optional[str]:
+        return self._model_extracted_dir
+
+    @model_extracted_dir.setter
+    def model_extracted_dir(self, path: Optional[str]):
+        self._model_extracted_dir = path
```

### Comparing `nemo_toolkit-1.8.2/nemo/core/neural_types/__init__.py` & `nemo_toolkit-1.9.0/nemo/core/neural_types/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/neural_types/axes.py` & `nemo_toolkit-1.9.0/nemo/core/neural_types/axes.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/neural_types/comparison.py` & `nemo_toolkit-1.9.0/nemo/core/neural_types/comparison.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/neural_types/elements.py` & `nemo_toolkit-1.9.0/nemo/core/neural_types/elements.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/neural_types/neural_type.py` & `nemo_toolkit-1.9.0/nemo/core/neural_types/neural_type.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/optim/__init__.py` & `nemo_toolkit-1.9.0/nemo/core/optim/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/optim/adafactor.py` & `nemo_toolkit-1.9.0/nemo/core/optim/adafactor.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/optim/lr_scheduler.py` & `nemo_toolkit-1.9.0/nemo/core/optim/lr_scheduler.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/optim/novograd.py` & `nemo_toolkit-1.9.0/nemo/core/optim/novograd.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/optim/optimizer_with_main_params.py` & `nemo_toolkit-1.9.0/nemo/core/optim/optimizer_with_main_params.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/optim/optimizers.py` & `nemo_toolkit-1.9.0/nemo/core/optim/optimizers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/utils/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/tts/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo.core.utils import k2_utils, numba_utils
+import nemo.collections.tts.helpers
+import nemo.collections.tts.models
```

### Comparing `nemo_toolkit-1.8.2/nemo/core/utils/k2_utils.py` & `nemo_toolkit-1.9.0/nemo/core/utils/k2_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/utils/neural_type_utils.py` & `nemo_toolkit-1.9.0/nemo/core/utils/neural_type_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/core/utils/numba_utils.py` & `nemo_toolkit-1.9.0/nemo/core/utils/numba_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/package_info.py` & `nemo_toolkit-1.9.0/nemo/package_info.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,16 +10,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 
 MAJOR = 1
-MINOR = 8
-PATCH = 2
+MINOR = 9
+PATCH = 0
 PRE_RELEASE = ''
 
 # Use the following formatting: (major, minor, patch, pre-release)
 VERSION = (MAJOR, MINOR, PATCH, PRE_RELEASE)
 
 __shortversion__ = '.'.join(map(str, VERSION[:3]))
 __version__ = '.'.join(map(str, VERSION[:3])) + ''.join(VERSION[3:])
```

### Comparing `nemo_toolkit-1.8.2/nemo/utils/__init__.py` & `nemo_toolkit-1.9.0/nemo/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/app_state.py` & `nemo_toolkit-1.9.0/nemo/utils/app_state.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/arguments.py` & `nemo_toolkit-1.9.0/nemo/utils/arguments.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/cloud.py` & `nemo_toolkit-1.9.0/nemo/utils/cloud.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/config_utils.py` & `nemo_toolkit-1.9.0/nemo/utils/config_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/decorators/__init__.py` & `nemo_toolkit-1.9.0/nemo/utils/decorators/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/decorators/deprecated.py` & `nemo_toolkit-1.9.0/nemo/utils/decorators/deprecated.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/decorators/experimental.py` & `nemo_toolkit-1.9.0/nemo/utils/decorators/experimental.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/decorators/port_docs.py` & `nemo_toolkit-1.9.0/nemo/utils/decorators/port_docs.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/distributed.py` & `nemo_toolkit-1.9.0/nemo/utils/distributed.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/env_var_parsing.py` & `nemo_toolkit-1.9.0/nemo/utils/env_var_parsing.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/exceptions.py` & `nemo_toolkit-1.9.0/nemo/utils/exceptions.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/exp_manager.py` & `nemo_toolkit-1.9.0/nemo/utils/exp_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -112,14 +112,17 @@
     create_checkpoint_callback: Optional[bool] = True
     checkpoint_callback_params: Optional[CallbackParams] = CallbackParams()
     # Additional exp_manager arguments
     files_to_copy: Optional[List[str]] = None
     # logs timing of train/val/test steps
     log_step_timing: Optional[bool] = True
     step_timing_kwargs: Optional[StepTimingParams] = StepTimingParams()
+    # Configures creation of log files for different ranks
+    log_local_rank_0_only: Optional[bool] = False
+    log_global_rank_0_only: Optional[bool] = False
 
 
 class TimingCallback(Callback):
     """
     Logs execution time of train/val/test steps
     """
 
@@ -212,15 +215,18 @@
                 Defaults to None.
             - create_checkpoint_callback (bool): Whether to create a ModelCheckpoint callback and attach it to the
                 pytorch lightning trainer. The ModelCheckpoint saves the top 3 models with the best "val_loss", the most
                 recent checkpoint under *last.ckpt, and the final checkpoint after training completes under *end.ckpt.
                 Defaults to True.
             - files_to_copy (list): A list of files to copy to the experiment logging directory. Defaults to None which
                 copies no files.
-
+            - log_local_rank_0_only (bool): Whether to only create log files for local rank 0. Defaults to False.
+                Set this to True if you are using DDP with many GPUs and do not want many log files in your exp dir.
+            - log_global_rank_0_only (bool): Whether to only create log files for global rank 0. Defaults to False.
+                Set this to True if you are using DDP with many GPUs and do not want many log files in your exp dir.
     returns:
         log_dir (Path): The final logging directory where logging files are saved. Usually the concatenation of
             exp_dir, name, and version.
     """
     # Add rank information to logger
     # Note: trainer.global_rank and trainer.is_global_zero are not set until trainer.fit, so have to hack around it
     local_rank = int(os.environ.get("LOCAL_RANK", 0))
@@ -277,25 +283,33 @@
     app_state.checkpoint_callback_params = cfg.checkpoint_callback_params
 
     # Create the logging directory if it does not exist
     os.makedirs(log_dir, exist_ok=True)  # Cannot limit creation to global zero as all ranks write to own log file
     logging.info(f'Experiments will be logged at {log_dir}')
     trainer._default_root_dir = log_dir
 
+    if cfg.log_local_rank_0_only is True and cfg.log_global_rank_0_only is True:
+        raise ValueError(
+            f"Cannot set both log_local_rank_0_only and log_global_rank_0_only to True. Please set either one or neither."
+        )
+
+    # This is set if the env var NEMO_TESTING is set to True.
+    nemo_testing = get_envbool(NEMO_ENV_VARNAME_TESTING, False)
+
     # Handle logging to file
-    if get_envbool(NEMO_ENV_VARNAME_TESTING, False) or world_size <= 32:
-        # If NEMO_TESTING is set (debug mode) or if less than 32 ranks save all log files
+    # Logs local rank 0 only
+    if local_rank == 0 and cfg.log_local_rank_0_only is True and nemo_testing is False:
         log_file = log_dir / f'nemo_log_globalrank-{global_rank}_localrank-{local_rank}.txt'
         logging.add_file_handler(log_file)
-    elif world_size <= 256 and local_rank == 0:
-        # If less than 256 ranks, try to save 1 log file per "machine"
+    # Logs only on global rank 0
+    elif global_rank == 0 and cfg.log_global_rank_0_only is True and not nemo_testing is False:
         log_file = log_dir / f'nemo_log_globalrank-{global_rank}_localrank-{local_rank}.txt'
         logging.add_file_handler(log_file)
-    elif global_rank == 0:
-        # If running more than 256 ranks, only save 1 log file
+    # Logs on all ranks.
+    else:
         log_file = log_dir / f'nemo_log_globalrank-{global_rank}_localrank-{local_rank}.txt'
         logging.add_file_handler(log_file)
 
     # For some reason, LearningRateLogger requires trainer to have a logger. Safer to create logger on all ranks
     # not just global rank 0.
     if cfg.create_tensorboard_logger or cfg.create_wandb_logger:
         configure_loggers(
```

### Comparing `nemo_toolkit-1.8.2/nemo/utils/export_utils.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/models/dialogue/dialogue_nearest_neighbour_model.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,284 +1,219 @@
-# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.
+# Copyright 2022 The HuggingFace Inc. team.
+# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import os
-from enum import Enum
-from typing import Callable, Dict, Optional, Type
+from typing import Optional
 
-import onnx
+import numpy as np
 import torch
-import torch.nn as nn
-
+import torch.nn.functional as F
+from omegaconf import DictConfig
+from pytorch_lightning import Trainer
+from transformers import AutoModel
+
+from nemo.collections.nlp.data.dialogue import DialogueSGDDataProcessor
+from nemo.collections.nlp.data.dialogue.data_processor.assistant_data_processor import DialogueAssistantDataProcessor
+from nemo.collections.nlp.data.dialogue.data_processor.design_data_processor import DialogueDesignDataProcessor
+from nemo.collections.nlp.data.dialogue.dataset.dialogue_nearest_neighbour_dataset import (
+    DialogueNearestNeighbourDataset,
+)
+from nemo.collections.nlp.metrics.classification_report import ClassificationReport
+from nemo.collections.nlp.metrics.dialogue_metrics import DialogueGenerationMetrics
+from nemo.collections.nlp.models.nlp_model import NLPModel
+from nemo.core.classes.common import PretrainedModelInfo
 from nemo.utils import logging
 
-try:
-    import onnxruntime
-
-    ort_available = True
-except (ImportError, ModuleNotFoundError):
-    ort_available = False
-
-
-class ExportFormat(Enum):
-    """Which format to use when exporting a Neural Module for deployment"""
-
-    ONNX = (1,)
-    TORCHSCRIPT = (2,)
-
-
-_EXT_DICT = {
-    ".pt": ExportFormat.TORCHSCRIPT,
-    ".ts": ExportFormat.TORCHSCRIPT,
-    ".onnx": ExportFormat.ONNX,
-}
+__all__ = ['DialogueNearestNeighbourModel']
 
 
-class CastToFloat(nn.Module):
-    def __init__(self, mod):
-        super(CastToFloat, self).__init__()
-        self.mod = mod
+class DialogueNearestNeighbourModel(NLPModel):
+    """Dialogue Nearest Neighbour Model identifies the intent of an utterance using the cosine similarity between sentence embeddings of the utterance and various label descriptions """
 
-    def forward(self, x):
-        if torch.is_autocast_enabled():
-            ret = self.mod.forward(x.to(torch.float)).to(x.dtype)
+    def __init__(self, cfg: DictConfig, trainer: Trainer = None):
+        self.cfg = cfg
+        super().__init__(cfg=cfg, trainer=trainer)
+        if self.cfg.library == "huggingface":
+            self.language_model = AutoModel.from_pretrained(self.cfg.language_model.pretrained_model_name)
+
+    def _setup_dataloader_from_config(self, cfg: DictConfig, dataset_split) -> 'torch.utils.data.DataLoader':
+        if self._cfg.dataset.task == "zero_shot":
+            self.data_processor = DialogueAssistantDataProcessor(
+                self.cfg.data_dir, self.tokenizer, cfg=self.cfg.dataset
+            )
+        elif self._cfg.dataset.task == "design":
+            self.data_processor = DialogueDesignDataProcessor(
+                data_dir=self._cfg.dataset.data_dir, tokenizer=self.tokenizer, cfg=self._cfg.dataset
+            )
+        elif self._cfg.dataset.task == 'sgd':
+            self.data_processor = DialogueSGDDataProcessor(
+                data_dir=self._cfg.dataset.data_dir,
+                dialogues_example_dir=self._cfg.dataset.dialogues_example_dir,
+                tokenizer=self.tokenizer,
+                cfg=self._cfg.dataset,
+            )
         else:
-            ret = self.mod.forward(x)
-        return ret
+            raise ValueError("Only zero_shot, design and sgd supported for Zero Shot Intent Model")
 
+        dataset = DialogueNearestNeighbourDataset(
+            dataset_split,
+            self.data_processor,
+            self.tokenizer,
+            self.cfg.dataset,  # this is the model.dataset cfg, which is diff from train_ds cfg etc
+        )
+
+        return torch.utils.data.DataLoader(
+            dataset=dataset,
+            collate_fn=dataset.collate_fn,
+            batch_size=cfg.batch_size,
+            shuffle=cfg.shuffle,
+            num_workers=cfg.get("num_workers", 0),
+            pin_memory=cfg.get("pin_memory", False),
+            drop_last=cfg.get("drop_last", False),
+        )
+
+    def forward(self, input_ids, attention_mask):
+        if self.cfg.library == 'huggingface':
+            output = self.language_model(input_ids=input_ids, attention_mask=attention_mask)
+        return output
+
+    def training_step(self, batch, batch_idx):
+        raise NotImplementedError
+
+    def test_step(self, batch, batch_idx):
+        return self.validation_step(batch, batch_idx, mode='test')
+
+    @staticmethod
+    def mean_pooling(model_output, attention_mask):
+        token_embeddings = model_output[0]  # First element of model_output contains all token embeddings
+        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
+        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)
 
-def get_export_format(filename: str):
-    _, ext = os.path.splitext(filename)
-    try:
-        return _EXT_DICT[ext]
-    except KeyError:
-        raise ValueError(f"Export file {filename} extension does not correspond to any export format!")
-
-
-def augment_filename(output: str, prepend: str):
-    path, filename = os.path.split(output)
-    filename = f"{prepend}-{filename}"
-    return os.path.join(path, filename)
-
-
-def forward_method(self):
-    if hasattr(self, "forward_for_export"):
-        return self.forward_for_export
-    else:
-        return self.forward
-
-
-def wrap_forward_method(self):
-    tp = type(self)
-    old_forward_method = None
-    if hasattr(tp, "forward_for_export"):
-        forward_method = tp.forward_for_export
-        old_forward_method = tp.forward
-        tp.forward = forward_method
-    else:
-        forward_method = None
-    return forward_method, old_forward_method
-
-
-def parse_input_example(input_example):
-    input_list = list(input_example)
-    input_dict = {}
-    # process possible kwargs
-    if isinstance(input_list[-1], dict):
-        input_dict = input_list[-1]
-        input_list = input_list[:-1]
-    return input_list, input_dict
-
-
-def to_onnxrt_input(input_names, input_dict, input_list):
-    odict = {}
-    for k in reversed(input_names):
-        if k in input_dict:
-            odict[k] = input_dict[k].cpu().numpy()
-        else:
-            odict[k] = input_list.pop().cpu().numpy()
-    return odict
+    def validation_step(self, batch, batch_idx, mode='val'):
+        """
+        Lightning calls this inside the validation loop with the data from the validation dataloader
+        passed in as `batch`.
+        """
+        input_ids, input_mask, labels = batch
+        preds = []
+        gts = []
+        inputs = []
+        for i in range(input_ids.size(0)):
+            output = self.forward(input_ids=input_ids[i], attention_mask=input_mask[i])
+            sentence_embeddings = DialogueNearestNeighbourModel.mean_pooling(output, input_mask[i])
+            sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)
+            cos_sim = F.cosine_similarity(sentence_embeddings[:1, :], sentence_embeddings[1:, :])
+            pred = torch.argmax(cos_sim).item() + 1
+            gt = torch.argmax(labels[i][1:]).item() + 1
+
+            preds.append(input_ids[i, pred])
+            gts.append(input_ids[i, gt])
+            inputs.append(input_ids[i, 0])
 
+        return {'preds': torch.stack(preds), 'labels': torch.stack(gts), 'inputs': torch.stack(inputs)}
 
-def verify_runtime(
-    output, input_list, input_dict, input_names, output_names, output_example, check_tolerance=0.01,
-):
-    # Verify the model can be read, and is valid
-
-    onnx_model = onnx.load(output)
-    input_names = [node.name for node in onnx_model.graph.input]
-
-    global ort_available
-    if not ort_available:
-        logging.warning(f"ONNX generated at {output}, not verified - please install onnxruntime_gpu package.\n")
-        onnx.checker.check_model(onnx_model, full_check=True)
-        return
-
-    onnx_session_opt = onnxruntime.SessionOptions()
-    onnx_session_opt.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL
-    sess = onnxruntime.InferenceSession(
-        onnx_model.SerializeToString(), sess_options=onnx_session_opt, providers=['CUDAExecutionProvider']
-    )
-    ort_out = sess.run(output_names, to_onnxrt_input(input_names, input_dict, input_list))
-    all_good = True
-
-    for i, out in enumerate(ort_out[0]):
-        expected = output_example[i]
-        if torch.is_tensor(expected):
-            tout = torch.from_numpy(out)
-            if not torch.allclose(tout, expected.cpu(), rtol=check_tolerance, atol=100 * check_tolerance):
-                all_good = False
-                logging.info(f"onnxruntime results mismatch! PyTorch(expected):\n{expected}\nONNXruntime:\n{tout}")
-    status = "SUCCESS" if all_good else "FAIL"
-    logging.info(f"ONNX generated at {output} verified with onnxruntime : " + status)
-    return all_good
-
-
-apex_available = True
-
-try:
-    from apex.normalization.fused_layer_norm import FusedLayerNorm, MixedFusedLayerNorm
-    from apex.contrib.layer_norm.layer_norm import FastLayerNorm
+    def multi_test_epoch_end(self, outputs, dataloader_idx):
+        return self.validation_epoch_end(outputs)
 
-    def replace_FusedLayerNorm(n: nn.Module) -> Optional[nn.BatchNorm2d]:
+    def validation_epoch_end(self, outputs):
+        """
+        Get metrics based on the candidate label with the highest predicted likelihood and the ground truth label for intent
         """
-        Replaces Apex's FusedLayerNorm with nn.LayerNorm. This is required for ONNX export.
-        Args:
-           n: the FusedLayerNorm pytorch module to replace
+        output_preds = torch.cat([output['preds'] for output in outputs], dim=0)
+        output_labels = torch.cat([output['labels'] for output in outputs], dim=0)
+        inputs = torch.cat([output['inputs'] for output in outputs], dim=0)
+
+        decoded_preds = self.tokenizer.tokenizer.batch_decode(output_preds, skip_special_tokens=True)
+        decoded_labels = self.tokenizer.tokenizer.batch_decode(output_labels, skip_special_tokens=True)
+        decoded_inputs = self.tokenizer.tokenizer.batch_decode(inputs, skip_special_tokens=True)
+
+        prompt_len = len(self.cfg.dataset.prompt_template.strip())
+        predicted_labels = [i[prompt_len:].strip() for i in decoded_preds]
+        ground_truth_labels = [i[prompt_len:].strip() for i in decoded_labels]
+
+        os.makedirs(self.cfg.dataset.dialogues_example_dir, exist_ok=True)
+        filename = os.path.join(self.cfg.dataset.dialogues_example_dir, "test_predictions.jsonl")
+
+        DialogueGenerationMetrics.save_predictions(
+            filename, predicted_labels, ground_truth_labels, decoded_inputs,
+        )
+
+        label_to_ids = {label: idx for idx, label in enumerate(list(set(predicted_labels + ground_truth_labels)))}
+        self.classification_report = ClassificationReport(
+            num_classes=len(label_to_ids), mode='micro', label_ids=label_to_ids, dist_sync_on_step=True
+        ).to(output_preds[0].device)
+
+        predicted_label_ids = torch.tensor([label_to_ids[label] for label in predicted_labels]).to(
+            output_preds[0].device
+        )
+        ground_truth_label_ids = torch.tensor([label_to_ids[label] for label in ground_truth_labels]).to(
+            output_preds[0].device
+        )
+
+        tp, fn, fp, _ = self.classification_report(predicted_label_ids, ground_truth_label_ids)
+
+        precision, recall, f1, report = self.classification_report.compute()
+        label_acc = np.mean([int(predicted_labels[i] == ground_truth_labels[i]) for i in range(len(predicted_labels))])
+
+        logging.info(report)
+
+        self.log('unified_precision', precision)
+        self.log('unified_f1', f1)
+        self.log('unified_recall', recall)
+        self.log('unfied_accuracy', label_acc * 100)
+
+        self.classification_report.reset()
+
+    def setup_training_data(self, train_data_config: Optional[DictConfig]):
+        if not train_data_config:
+            logging.info(
+                f"Dataloader config or file_name for the training set is missing, so no data loader for test is created!"
+            )
+            self._test_dl = None
+            return
+        self._train_dl = self._setup_dataloader_from_config(train_data_config, "train")
+
+        # self.create_loss_module()
+
+    def setup_validation_data(self, val_data_config: Optional[DictConfig]):
+        if not val_data_config:
+            logging.info(
+                f"Dataloader config or file_path for the validation data set is missing, so no data loader for test is created!"
+            )
+            self._test_dl = None
+            return
+        self._validation_dl = self._setup_dataloader_from_config(val_data_config, "dev")
+
+    def setup_multiple_test_data(self, test_data_config: Optional[DictConfig]):
+        self.setup_test_data(test_data_config)
+
+    def setup_test_data(self, test_data_config: Optional[DictConfig]):
+        if not test_data_config:
+            logging.info(
+                f"Dataloader config or file_path for the test data set is missing, so no data loader for test is created!"
+            )
+            self._test_dl = None
+            return
+        self._test_dl = self._setup_dataloader_from_config(test_data_config, "test")
+
+    @classmethod
+    def list_available_models(cls) -> Optional[PretrainedModelInfo]:
+        """
+        This method returns a list of pre-trained models which can be instantiated directly from NVIDIA's NGC cloud.
+
         Returns:
-           Equivalent LayerNorm module
+            List of available pre-trained models.
         """
-        if (
-            not isinstance(n, FusedLayerNorm)
-            and not isinstance(n, FastLayerNorm)
-            and not isinstance(n, MixedFusedLayerNorm)
-        ):
-            return None
-
-        dev = next(n.parameters()).device
-        mod = nn.LayerNorm(n.normalized_shape, eps=n.eps, elementwise_affine=n.elementwise_affine,).to(dev)
-
-        n_state = n.state_dict()
-        mod.load_state_dict(n_state)
-        return mod
-
-    default_Apex_replacements = {
-        "FusedLayerNorm": replace_FusedLayerNorm,
-        "MixedFusedLayerNorm": replace_FusedLayerNorm,
-        "FastLayerNorm": replace_FusedLayerNorm,
-    }
-
-except Exception as e:
-    default_Apex_replacements = {}
-    apex_available = False
-
-
-def simple_replace(BaseT: Type[nn.Module], DestT: Type[nn.Module]) -> Callable[[nn.Module], Optional[nn.Module]]:
-    """
-    Generic function generator to replace BaseT module with DestT. BaseT and DestT should have same atrributes. No weights are copied.
-    Args:
-        BaseT : module type to replace
-        DestT : destination module type
-    Returns:
-        swap function to replace BaseT module with DestT
-    """
-
-    def expansion_fn(mod: nn.Module) -> Optional[nn.Module]:
-        if not isinstance(mod, BaseT):
-            return None
-        args = [getattr(mod, name, None) for name in mod.__constants__]
-        out = DestT(*args)
-        return out
-
-    return expansion_fn
-
-
-def wrap_module(BaseT: Type[nn.Module], DestT: Type[nn.Module]) -> Callable[[nn.Module], Optional[nn.Module]]:
-    """
-    Generic function generator to replace BaseT module with DestT wrapper. 
-    Args:
-        BaseT : module type to replace
-        DestT : destination module type
-    Returns:
-        swap function to replace BaseT module with DestT
-    """
-
-    def expansion_fn(mod: nn.Module) -> Optional[nn.Module]:
-        out = DestT(mod)
-        return out
-
-    return expansion_fn
-
-
-def swap_modules(model: nn.Module, mapping: Dict[str, nn.Module]):
-    """
-    This function swaps nested modules as specified by "dot paths" in mod with a desired replacement. This allows
-    for swapping nested modules through arbitrary levels if children
-
-    NOTE: This occurs in place, if you want to preserve model then make sure to copy it first.
-
-    """
-    for path, new_mod in mapping.items():
-        expanded_path = path.split(".")
-        parent_mod = model
-        for sub_path in expanded_path[:-1]:
-            parent_mod = parent_mod._modules[sub_path]  # noqa
-        parent_mod._modules[expanded_path[-1]] = new_mod  # noqa
-
-    return model
-
-
-def replace_modules(
-    model: nn.Module, expansions: Dict[str, Callable[[nn.Module], Optional[nn.Module]]] = None
-) -> nn.Module:
-    """
-    Top-level function to replace modules in model, specified by class name with a desired replacement.
-    NOTE: This occurs in place, if you want to preserve model then make sure to copy it first.
-    Args:
-        model : top level module
-        expansions : replacement dictionary: module class name -> replacement function generator
-    Returns:
-        model, possibly modified in-place
-    """
-    mapping: Dict[str, nn.Module] = {}
-    for name, m in model.named_modules():
-        m_type = type(m).__name__
-        if m_type in expansions:
-            swapped = expansions[m_type](m)
-            if swapped:
-                mapping[name] = swapped
-    if len(mapping) > 0:
-        logging.info(f"Swapped {len(mapping)} modules")
-    swap_modules(model, mapping)
-    return model
-
-
-default_replacements = {
-    "BatchNorm1d": wrap_module(nn.BatchNorm1d, CastToFloat),
-    "BatchNorm2d": wrap_module(nn.BatchNorm2d, CastToFloat),
-    "LayerNorm": wrap_module(nn.LayerNorm, CastToFloat),
-}
-
-
-def replace_for_export(model: nn.Module) -> nn.Module:
-    """
-    Top-level function to replace default set of modules in model
-    NOTE: This occurs in place, if you want to preserve model then make sure to copy it first.
-    Args:
-        model : top level module
-        replace_1D_2D : include 1D -> 2D replacements
-    Returns:
-        model, possibly modified in-place
-    """
-    replace_modules(model, default_Apex_replacements)
-    replace_modules(model, default_replacements)
+        result = []
+        return result
```

### Comparing `nemo_toolkit-1.8.2/nemo/utils/formatters/__init__.py` & `nemo_toolkit-1.9.0/nemo/utils/formatters/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/formatters/base.py` & `nemo_toolkit-1.9.0/nemo/utils/formatters/base.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/formatters/colors.py` & `nemo_toolkit-1.9.0/nemo/utils/formatters/colors.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/formatters/utils.py` & `nemo_toolkit-1.9.0/nemo/utils/formatters/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/get_rank.py` & `nemo_toolkit-1.9.0/nemo/utils/get_rank.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/lightning_logger_patch.py` & `nemo_toolkit-1.9.0/nemo/utils/lightning_logger_patch.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/metaclasses.py` & `nemo_toolkit-1.9.0/nemo/utils/metaclasses.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/model_utils.py` & `nemo_toolkit-1.9.0/nemo/utils/model_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/nemo_logging.py` & `nemo_toolkit-1.9.0/nemo/utils/nemo_logging.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo/utils/timers.py` & `nemo_toolkit-1.9.0/nemo/utils/timers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,14 +8,18 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+from nemo_text_processing.text_normalization.en.taggers.tokenize_and_classify import ClassifyFst
+from nemo_text_processing.text_normalization.en.verbalizers.verbalize import VerbalizeFst
+from nemo_text_processing.text_normalization.en.verbalizers.verbalize_final import VerbalizeFinalFst
+
 from nemo.utils import logging
 
 try:
     import pynini
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/tokenize_and_classify.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/taggers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/de/verbalizers/verbalize_final.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/clean_eval_data.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/clean_eval_data.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/currency.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/currency.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/measurements.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/measurements.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/numbers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/ordinals/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/ordinals/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/data/time/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/punctuation.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/punctuation.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/tokenize_and_classify.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/taggers/word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/verbalize_final.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/en/verbalizers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/en/verbalizers/word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/numbers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/teen.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/teen.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/ordinals/twenties.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/ordinals/twenties.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/data/time/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/punctuation.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/punctuation.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/tokenize_and_classify.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/taggers/word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/verbalize_final.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/es/verbalizers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/es/verbalizers/word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/fractions.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/fractions.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/measurements/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/measurements/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/money/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/money/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/money/currency_major.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/money/currency_major.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/numbers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/ordinals/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/roman/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/roman/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/data/time/minutes.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/data/time/minutes.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/graph_utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/graph_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/punctuation.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/punctuation.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/tokenize_and_classify.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/taggers/word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/verbalize_final.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/fr/verbalizers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/fr/verbalizers/word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/inverse_normalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/inverse_normalize.py`

 * *Files 21% similar despite different names*

```diff
@@ -12,15 +12,20 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from argparse import ArgumentParser
 from time import perf_counter
 from typing import List
 
-from nemo_text_processing.text_normalization.data_loader_utils import check_installation, get_installation_msg
+from nemo_text_processing.text_normalization.data_loader_utils import (
+    check_installation,
+    get_installation_msg,
+    load_file,
+    write_file,
+)
 from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.token_parser import TokenParser
 
 
 class InverseNormalizer(Normalizer):
     """
     Inverse normalizer that converts text from spoken to written form. Useful for ASR postprocessing. 
@@ -98,15 +103,18 @@
         Returns: written form
         """
         return self.normalize(text=text, verbose=verbose)
 
 
 def parse_args():
     parser = ArgumentParser()
-    parser.add_argument("input_string", help="input string", type=str)
+    input = parser.add_mutually_exclusive_group()
+    input.add_argument("--text", dest="input_string", help="input string", type=str)
+    input.add_argument("--input_file", dest="input_file", help="input file path", type=str)
+    parser.add_argument('--output_file', dest="output_file", help="output file path", type=str)
     parser.add_argument(
         "--language", help="language", choices=['en', 'de', 'es', 'ru', 'fr', 'vi'], default="en", type=str
     )
     parser.add_argument("--verbose", help="print info for debugging", action='store_true')
     parser.add_argument("--overwrite_cache", help="set to True to re-create .far grammar files", action="store_true")
     parser.add_argument(
         "--cache_dir",
@@ -120,10 +128,21 @@
 if __name__ == "__main__":
     args = parse_args()
     start_time = perf_counter()
     inverse_normalizer = InverseNormalizer(
         lang=args.language, cache_dir=args.cache_dir, overwrite_cache=args.overwrite_cache
     )
     print(f'Time to generate graph: {round(perf_counter() - start_time, 2)} sec')
-    start_time = perf_counter()
-    print(inverse_normalizer.inverse_normalize(args.input_string, verbose=args.verbose))
-    print(f'Execution time: {round(perf_counter() - start_time, 2)} sec')
+
+    if args.input_string:
+        print(inverse_normalizer.inverse_normalize(args.input_string, verbose=args.verbose))
+    elif args.input_file:
+        print("Loading data: " + args.input_file)
+        data = load_file(args.input_file)
+
+        print("- Data: " + str(len(data)) + " sentences")
+        prediction = inverse_normalizer.inverse_normalize_list(data, verbose=args.verbose)
+        if args.output_file:
+            write_file(args.output_file, prediction)
+            print(f"- Denormalized. Writing out to {args.output_file}")
+        else:
+            print(prediction)
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/decimals.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/decimals.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/tokenize_and_classify.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/taggers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/ru/verbalizers/verbalize_final.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/run_evaluate.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/run_evaluate.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/math/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/math/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/measurements.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/measurements.tsv`

 * *Files 2% similar despite different names*

```diff
@@ -41,14 +41,15 @@
 mg	mi li gam
 mg	mili gam
 kg	kilogram
 kg	kilo gram
 kg	ki lô gram
 kg	kilo gam
 kg	ki lô gam
+kg	kí lô
 kg	kí
 ghz	giga hẹc
 ghz	giga héc
 ghz	gi ga héc
 ghz	gi ga hẹc
 khz	kilo hẹc
 khz	kilo héc
@@ -56,19 +57,19 @@
 khz	ki lô hẹc
 mhz	mega héc
 mhz	mega hẹc
 mhz	mê ga hẹc
 mhz	mê ga héc
 v	vôn
 h	giờ
+phút	phút
 s	giây
 nm	nanomet
 nm	nano mét
 nm	na nô mét
-p	phút
 mA	milli ampe
 mA	mi li ampe
 mA	mi li am pe
 kwh	kilowatt giờ
 kwh	kilo watt giờ
 kwh	ki lô oát giờ
 kwh	ki lô goát giờ
@@ -90,20 +91,24 @@
 mw	mega watt
 mw	mê ga watt
 mw	mê ga oát
 mw	mê ga goát
 μm	micromet
 μm	micro mét
 μm	muy crô mét
-μm	muy cờ rô mset
-"	inch
+μm	mi crô mét
+μm	muy cờ rô mét
+μm	mi cờ rô mét
+inch	inch
 tb	terabyte
 tb	tera byte
 tb	te ra byte
+tb	te ra bai
 tb	tê ra byte
+tb	tê ra bai
 g	gram
 g	gam
 ω	ohm
 ω	ôm
 db	decibel
 db	deci ben
 db	đề xi ben
@@ -114,22 +119,29 @@
 μg	muy crô gam
 μg	muy cờ rô gam
 pg	petagram
 pg	peta gam
 pg	pê ta gam
 gb	gigabyte
 gb	giga byte
+gb	giga bai
 gb	gi ga byte
+gb	gi ga bai
 mb	megabyte
 mb	mega byte
+mb	mega bai
 mb	me ga byte
+mb	me ga bai
 mb	mê ga byte
+mb	mê ga bai
 kb	kilobyte
 kb	kilo byte
+kb	kilo bai
 kb	ki lô byte
+kb	ki lô bai
 kbps	kilobit trên giây
 mbps	megabit trên giây
 kv	kilovolt
 kv	kilo vôn
 kv	ki lô vôn
 mv	megavolt
 mv	mega vôn
@@ -160,12 +172,14 @@
 cm²	centimet vuông
 cm²	centi mét vuông
 cm²	xăng ti mét vuông
 cm²	xen ti mét vuông
 pb	peta byte
 pb	petabyte
 pb	pê ta byte
-kcal	kilo calo
+kcal	kilocalories
+kcal	kilocalo
+kcal	ki lô calo
 l	lít
 ml	millilit
 ml	mili lít
 ml	mi li lít
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/numbers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/ordinals/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/data/time/minutes.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/data/time/minutes.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/graph_utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/graph_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -28,17 +28,17 @@
 
     NEMO_DIGIT = byte.DIGIT
     NEMO_LOWER = pynini.union(*string.ascii_lowercase).optimize()
     NEMO_UPPER = pynini.union(*string.ascii_uppercase).optimize()
     NEMO_ALPHA = pynini.union(NEMO_LOWER, NEMO_UPPER).optimize()
     NEMO_ALNUM = pynini.union(NEMO_DIGIT, NEMO_ALPHA).optimize()
     NEMO_HEX = pynini.union(*string.hexdigits).optimize()
-    NEMO_NON_BREAKING_SPACE = u"\u00A0"
+    NEMO_NON_BREAKING_SPACE = "\u00A0"
     NEMO_SPACE = " "
-    NEMO_WHITE_SPACE = pynini.union(" ", "\t", "\n", "\r", u"\u00A0").optimize()
+    NEMO_WHITE_SPACE = pynini.union(" ", "\t", "\n", "\r", "\u00A0").optimize()
     NEMO_NOT_SPACE = pynini.difference(NEMO_CHAR, NEMO_WHITE_SPACE).optimize()
     NEMO_NOT_QUOTE = pynini.difference(NEMO_CHAR, r'"').optimize()
 
     NEMO_PUNCT = pynini.union(*map(pynini.escape, string.punctuation)).optimize()
     NEMO_GRAPH = pynini.union(NEMO_ALNUM, NEMO_PUNCT).optimize()
 
     NEMO_SIGMA = pynini.closure(NEMO_CHAR)
@@ -61,15 +61,15 @@
 
     NEMO_DIGIT = None
     NEMO_LOWER = None
     NEMO_UPPER = None
     NEMO_ALPHA = None
     NEMO_ALNUM = None
     NEMO_HEX = None
-    NEMO_NON_BREAKING_SPACE = u"\u00A0"
+    NEMO_NON_BREAKING_SPACE = "\u00A0"
     NEMO_SPACE = " "
     NEMO_WHITE_SPACE = None
     NEMO_NOT_SPACE = None
     NEMO_NOT_QUOTE = None
 
     NEMO_PUNCT = None
     NEMO_GRAPH = None
@@ -97,18 +97,18 @@
         file_name: exported file name
         graphs: Mapping of a rule name and Pynini WFST graph to be exported
     """
     exporter = export.Exporter(file_name)
     for rule, graph in graphs.items():
         exporter[rule] = graph.optimize()
     exporter.close()
-    print(f'Created {file_name}')
+    print(f"Created {file_name}")
 
 
-def convert_space(fst) -> 'pynini.FstLike':
+def convert_space(fst) -> "pynini.FstLike":
     """
     Converts space to nonbreaking space.
     Used only in tagger grammars for transducing token values within quotes, e.g. name: "hello kitty"
     This is making transducer significantly slower, so only use when there could be potential spaces within quotes, otherwise leave it.
 
     Args:
         fst: input fst
@@ -131,45 +131,45 @@
 
     def __init__(self, name: str, kind: str, deterministic: bool = True):
         self.name = name
         self.kind = str
         self._fst = None
         self.deterministic = deterministic
 
-        self.far_path = Path(os.path.dirname(__file__) + '/grammars/' + kind + '/' + name + '.far')
+        self.far_path = Path(os.path.dirname(__file__) + "/grammars/" + kind + "/" + name + ".far")
         if self.far_exist():
             self._fst = Far(self.far_path, mode="r", arc_type="standard", far_type="default").get_fst()
 
     def far_exist(self) -> bool:
         """
         Returns true if FAR can be loaded
         """
         return self.far_path.exists()
 
     @property
-    def fst(self) -> 'pynini.FstLike':
+    def fst(self) -> "pynini.FstLike":
         return self._fst
 
     @fst.setter
     def fst(self, fst):
         self._fst = fst
 
-    def add_tokens(self, fst) -> 'pynini.FstLike':
+    def add_tokens(self, fst) -> "pynini.FstLike":
         """
         Wraps class name around to given fst
 
         Args:
             fst: input fst
 
         Returns:
             Fst: fst
         """
         return pynutil.insert(f"{self.name} {{ ") + fst + pynutil.insert(" }")
 
-    def delete_tokens(self, fst) -> 'pynini.FstLike':
+    def delete_tokens(self, fst) -> "pynini.FstLike":
         """
         Deletes class name wrap around output of given fst
 
         Args:
             fst: input fst
 
         Returns:
@@ -180,8 +180,8 @@
             + delete_space
             + pynutil.delete("{")
             + delete_space
             + fst
             + delete_space
             + pynutil.delete("}")
         )
-        return res @ pynini.cdrewrite(pynini.cross(u"\u00A0", " "), "", "", NEMO_SIGMA)
+        return res @ pynini.cdrewrite(pynini.cross("\u00A0", " "), "", "", NEMO_SIGMA)
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/cardinal.py`

 * *Files 13% similar despite different names*

```diff
@@ -51,43 +51,50 @@
         graph_five = pynini.cross("lăm", "5")
         graph_half = pynini.cross("rưỡi", "5")
         graph_hundred = pynini.cross("trăm", "")
         graph_ten = pynini.cross("mươi", "")
         zero = pynini.cross(pynini.union("linh", "lẻ"), "0")
 
         optional_ten = pynini.closure(delete_space + graph_ten, 0, 1)
-        last_digit = graph_digit | graph_one | graph_four | graph_five
+        last_digit_exception = pynini.project(pynini.cross("năm", "5"), "input")
+        last_digit = pynini.union(
+            (pynini.project(graph_digit, "input") - last_digit_exception.arcsort()) @ graph_digit,
+            graph_one,
+            graph_four,
+            graph_five,
+        )
 
-        graph_hundred_component = (graph_digit | graph_zero) + delete_space + graph_hundred
-        graph_hundred_component += delete_space
-        graph_hundred_component += pynini.union(
+        graph_hundred_ties_component = (graph_digit | graph_zero) + delete_space + graph_hundred
+        graph_hundred_ties_component += delete_space
+        graph_hundred_ties_component += pynini.union(
             graph_teen,
-            graph_ties + optional_ten + ((delete_space + last_digit) | pynutil.insert("0")),
             (graph_half | graph_four | graph_one) + pynutil.insert("0"),
+            graph_ties + optional_ten + ((delete_space + last_digit) | pynutil.insert("0")),
             zero + delete_space + (graph_digit | graph_four),
-            graph_digit,
             pynutil.insert("00"),
         )
-        graph_hundred_component |= (
+        graph_hundred_ties_component |= (
             pynutil.insert("0")
             + delete_space
             + pynini.union(
                 graph_teen,
-                graph_ties + optional_ten + ((delete_space + last_digit) | pynutil.insert("0")),
+                graph_ties + optional_ten + delete_space + last_digit,
+                graph_ties + delete_space + graph_ten + pynutil.insert("0"),
                 zero + delete_space + (graph_digit | graph_four),
-                graph_digit,
             )
         )
+        graph_hundred_component = graph_hundred_ties_component | (pynutil.insert("00") + delete_space + graph_digit)
 
         graph_hundred_component_at_least_one_none_zero_digit = graph_hundred_component @ (
             pynini.closure(NEMO_DIGIT) + (NEMO_DIGIT - "0") + pynini.closure(NEMO_DIGIT)
         )
         self.graph_hundred_component_at_least_one_none_zero_digit = (
             graph_hundred_component_at_least_one_none_zero_digit
         )
+        graph_hundred_ties_zero = graph_hundred_ties_component | pynutil.insert("000")
 
         graph_thousands = pynini.union(
             graph_hundred_component_at_least_one_none_zero_digit
             + delete_space
             + pynutil.delete(pynini.union("nghìn", "ngàn")),
             pynutil.insert("000", weight=0.1),
         )
@@ -116,36 +123,37 @@
         graph = pynini.union(
             graph_billion
             + delete_space
             + graph_million
             + delete_space
             + graph_thousands
             + delete_space
-            + graph_hundred_component,
-            graph_ten_thousand + delete_space + graph_ten_thousand_suffix + delete_space + graph_hundred_component,
+            + graph_hundred_ties_zero,
+            graph_ten_thousand + delete_space + graph_ten_thousand_suffix + delete_space + graph_hundred_ties_zero,
             graph_hundred_component_at_least_one_none_zero_digit
             + delete_space
             + pynutil.delete(pynini.union("nghìn", "ngàn"))
             + delete_space
-            + ((last_digit + pynutil.insert("00")) | graph_hundred_component),
+            + (((last_digit | graph_half) + pynutil.insert("00")) | graph_hundred_ties_zero),
+            graph_digit,
             graph_zero,
         )
 
         graph = graph @ pynini.union(
-            pynutil.delete(pynini.closure("0")) + pynini.difference(NEMO_DIGIT, "0") + pynini.closure(NEMO_DIGIT), "0"
+            pynutil.delete(pynini.closure("0")) + pynini.difference(NEMO_DIGIT, "0") + pynini.closure(NEMO_DIGIT), "0",
         )
 
         # don't convert cardinals from zero to nine inclusive
-        graph_exception = pynini.project(pynini.union(graph_digit, graph_zero), 'input')
+        graph_exception = pynini.project(pynini.union(graph_digit, graph_zero), "input")
 
         self.graph_no_exception = graph
 
         self.graph = (pynini.project(graph, "input") - graph_exception.arcsort()) @ graph
 
         optional_minus_graph = pynini.closure(
-            pynutil.insert("negative: ") + pynini.cross(pynini.union("âm", "trừ"), "\"-\"") + NEMO_SPACE, 0, 1
+            pynutil.insert("negative: ") + pynini.cross(pynini.union("âm", "trừ"), '"-"') + NEMO_SPACE, 0, 1,
         )
 
-        final_graph = optional_minus_graph + pynutil.insert("integer: \"") + self.graph + pynutil.insert("\"")
+        final_graph = optional_minus_graph + pynutil.insert('integer: "') + self.graph + pynutil.insert('"')
 
         final_graph = self.add_tokens(final_graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/date.py`

 * *Files 6% similar despite different names*

```diff
@@ -50,36 +50,44 @@
     """
     graph_one = pynini.cross("mốt", "1")
     graph_four = pynini.cross("tư", "4")
     graph_five = pynini.cross("lăm", "5")
     graph_ten = pynini.cross("mươi", "")
     optional_ten = pynini.closure(delete_space + graph_ten, 0, 1)
 
-    graph = (
-        ties_graph
-        + optional_ten
-        + ((delete_space + (graph_digit | graph_one | graph_four | graph_five)) | pynutil.insert("0"))
+    graph = pynini.union(
+        ties_graph + optional_ten + delete_space + (graph_digit | graph_one | graph_four | graph_five),
+        ties_graph + delete_space + graph_ten + pynutil.insert("0"),
     )
     return graph
 
 
 def _get_year_graph():
     """
     Transducer for year, e.g. hai không hai mươi -> 2020
     """
 
     def _get_digits_graph():
-        zero = pynini.cross((pynini.accep("linh") | pynini.accep("lẻ")), "0")
+        zero = pynini.cross((pynini.union("linh", "lẻ")), "0")
         four = pynini.cross("tư", "4")
-        graph = pynini.union(zero + delete_space + (graph_digit | four), graph_zero + delete_space + graph_digit)
+        graph = pynini.union(zero + delete_space + (graph_digit | four), graph_zero + delete_space + graph_digit,)
         graph.optimize()
         return graph
 
-    def _get_thousands_graph():
-        graph_ties = _get_ties_graph()
+    def _get_hundreds_graph(graph_ties, graph_digits):
+        graph = (
+            graph_digit
+            + delete_space
+            + pynutil.delete("trăm")
+            + delete_space
+            + (graph_teen | graph_ties | graph_digits)
+        )
+        return graph
+
+    def _get_thousands_graph(graph_ties, graph_digits):
         graph_hundred_component = (
             (graph_digit | graph_zero) + delete_space + pynutil.delete("trăm")
         ) | pynutil.insert("0")
         graph = (
             graph_digit
             + delete_space
             + pynutil.delete(pynini.union("nghìn", "ngàn"))
@@ -88,24 +96,26 @@
             + delete_space
             + (graph_teen | graph_ties | graph_digits)
         )
         return graph
 
     graph_ties = _get_ties_graph()
     graph_digits = _get_digits_graph()
-    graph_thousands = _get_thousands_graph()
+    graph_hundreds = _get_hundreds_graph(graph_ties, graph_digits)
+    graph_thousands = _get_thousands_graph(graph_ties, graph_digits)
     year_graph = (
-        # 20 19, 40 12, 2012, 2 0 0 5, 2 0 17 - assuming no limit on the year
+        # 20 19, 40 12, 2012, 2 0 0 5, 2 0 17, 938 - assuming no limit on the year
         graph_digit
         + delete_space
         + (graph_digit | graph_zero)
         + delete_space
         + (graph_teen | graph_ties | graph_digits)
         | graph_thousands
-        | (graph_ties + pynutil.insert("0") + delete_space + (graph_ties | graph_digits | graph_teen))
+        | graph_hundreds
+        | (graph_digit + pynutil.insert("0") + delete_space + (graph_ties | graph_digits | graph_teen))
     )
     year_graph.optimize()
     return year_graph
 
 
 class DateFst(GraphFst):
     """
@@ -123,45 +133,36 @@
 
         cardinal_graph = cardinal.graph_no_exception
         year_graph = _get_year_graph()
         YEAR_WEIGHT = 0.001
         year_graph = pynutil.add_weight(year_graph, YEAR_WEIGHT)
         month_graph = _get_month_graph()
 
-        month_graph = pynutil.insert("month: \"") + month_graph + pynutil.insert("\"")
+        month_graph = pynutil.insert('month: "') + month_graph + pynutil.insert('"')
+        month_exception = pynini.project(pynini.cross("năm", "5"), "input")
+        month_graph_exception = (pynini.project(month_graph, "input") - month_exception.arcsort()) @ month_graph
+
+        day_graph = pynutil.insert('day: "') + cardinal_graph + pynutil.insert('"')
+        # day_suffix = pynini.union("ngày", "mùng")
+        # optional_day = pynini.closure(day_suffix + delete_space, 0, 1)
 
-        day_graph = pynutil.insert("day: \"") + cardinal_graph + pynutil.insert("\"")
-        optional_day = pynini.closure(pynutil.delete(pynini.union("ngày", "mùng") + delete_space), 0, 1)
+        graph_month = pynutil.delete("tháng") + delete_space + month_graph_exception
         graph_year = (
             delete_extra_space
             + pynutil.delete("năm")
             + delete_extra_space
-            + pynutil.insert("year: \"")
+            + pynutil.insert('year: "')
             + pynutil.add_weight(year_graph, -YEAR_WEIGHT)
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
         )
         optional_graph_year = pynini.closure(graph_year, 0, 1)
-        graph_mdy = (
-            pynutil.delete("tháng")
-            + delete_space
-            + month_graph
-            + (
-                (delete_space + pynutil.delete("ngày") + delete_extra_space + day_graph + optional_graph_year)
-                | optional_graph_year
-            )
-        )
+        graph_my = pynutil.delete("tháng") + delete_space + month_graph + graph_year
         graph_dmy = (
-            optional_day
-            + day_graph
-            + delete_space
-            + pynutil.delete("tháng")
-            + delete_extra_space
-            + month_graph
-            + optional_graph_year
+            day_graph + delete_space + pynutil.delete("tháng") + delete_extra_space + month_graph + optional_graph_year
         )
         graph_year = (
-            pynutil.delete("năm") + delete_extra_space + pynutil.insert("year: \"") + year_graph + pynutil.insert("\"")
+            pynutil.delete("năm") + delete_extra_space + pynutil.insert('year: "') + year_graph + pynutil.insert('"')
         )
 
-        final_graph = pynini.union((graph_dmy | graph_year) + pynutil.insert(" preserve_order: true"), graph_mdy)
+        final_graph = (graph_dmy | graph_my | graph_month | graph_year) + pynutil.insert(" preserve_order: true")
         final_graph = self.add_tokens(final_graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/electronic.py`

 * *Files 2% similar despite different names*

```diff
@@ -42,29 +42,29 @@
         )
 
         symbols = pynini.string_file(get_abs_path("data/electronic/symbols.tsv")).invert()
 
         accepted_username = alpha_num | symbols
         process_dot = pynini.cross("chấm", ".")
         username = (
-            pynutil.insert("username: \"")
+            pynutil.insert('username: "')
             + alpha_num
             + pynini.closure(delete_extra_space + accepted_username)
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
         )
         single_alphanum = pynini.closure(alpha_num + delete_extra_space) + alpha_num
         server = single_alphanum | pynini.string_file(get_abs_path("data/electronic/server_name.tsv"))
         domain = single_alphanum | pynini.string_file(get_abs_path("data/electronic/domain.tsv"))
         multi_domain = (
             pynini.closure(process_dot + delete_extra_space + domain + delete_extra_space)
             + process_dot
             + delete_extra_space
             + domain
         )
-        domain_graph = pynutil.insert("domain: \"") + server + delete_extra_space + multi_domain + pynutil.insert("\"")
+        domain_graph = pynutil.insert('domain: "') + server + delete_extra_space + multi_domain + pynutil.insert('"')
         graph = (
             username
             + delete_extra_space
             + pynutil.delete(pynini.union("a còng", "a móc", "a vòng"))
             + insert_space
             + delete_extra_space
             + domain_graph
@@ -87,13 +87,13 @@
             pynini.closure(protocol_start, 0, 1)
             + protocol_end
             + delete_extra_space
             + process_dot
             + pynini.closure(delete_extra_space + accepted_username, 1)
             + pynini.closure(ending, 1, 2)
         )
-        protocol = pynutil.insert("protocol: \"") + protocol + pynutil.insert("\"")
+        protocol = pynutil.insert('protocol: "') + protocol + pynutil.insert('"')
         graph |= protocol
         ########
 
         final_graph = self.add_tokens(graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/fraction.py`

 * *Files 3% similar despite different names*

```diff
@@ -38,26 +38,26 @@
     def __init__(self, cardinal: GraphFst):
         super().__init__(name="fraction", kind="classify")
         # integer_part # numerator # denominator
 
         graph_cardinal = cardinal.graph_no_exception
         graph_four = pynini.cross("tư", "4")
 
-        numerator = pynutil.insert("numerator: \"") + graph_cardinal + pynutil.insert("\"")
+        numerator = pynutil.insert('numerator: "') + graph_cardinal + pynutil.insert('"')
         fraction_component = pynutil.delete(pynini.union("phần", "trên", "chia"))
-        denominator = pynutil.insert("denominator: \"") + (graph_cardinal | graph_four) + pynutil.insert("\"")
+        denominator = pynutil.insert('denominator: "') + (graph_cardinal | graph_four) + pynutil.insert('"')
 
         graph_fraction_component = numerator + delete_space + fraction_component + delete_extra_space + denominator
         self.graph_fraction_component = graph_fraction_component
 
         graph = graph_fraction_component
         graph = graph.optimize()
         self.final_graph_wo_negative = graph
 
         optional_graph_negative = pynini.closure(
-            pynutil.insert("negative: ") + pynini.cross(pynini.union("âm", "trừ"), "\"true\"") + delete_extra_space,
+            pynutil.insert("negative: ") + pynini.cross(pynini.union("âm", "trừ"), '"true"') + delete_extra_space,
             0,
             1,
         )
         graph = optional_graph_negative + graph
         final_graph = self.add_tokens(graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/measure.py`

 * *Files 17% similar despite different names*

```diff
@@ -50,60 +50,60 @@
         graph_one = pynini.cross("mốt", "1")
         graph_half = pynini.cross("rưỡi", "5")
 
         graph_unit = pynini.string_file(get_abs_path("data/measurements.tsv"))
         graph_unit_singular = pynini.invert(graph_unit)  # singular -> abbr
 
         optional_graph_negative = pynini.closure(
-            pynutil.insert("negative: ") + pynini.cross(pynini.union("âm", "trừ"), "\"true\"") + delete_extra_space,
+            pynutil.insert("negative: ") + pynini.cross(pynini.union("âm", "trừ"), '"true"') + delete_extra_space,
             0,
             1,
         )
 
         unit_singular = convert_space(graph_unit_singular)
         unit_misc = pynutil.insert("/") + pynutil.delete("trên") + delete_space + convert_space(graph_unit_singular)
 
         unit_singular = (
-            pynutil.insert("units: \"")
+            pynutil.insert('units: "')
             + (unit_singular | unit_misc | pynutil.add_weight(unit_singular + delete_space + unit_misc, 0.01))
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
         )
 
         subgraph_decimal = (
             pynutil.insert("decimal { ")
             + optional_graph_negative
             + decimal.final_graph_wo_negative
             + pynutil.insert(" }")
             + delete_extra_space
             + unit_singular
         )
 
         subgraph_cardinal = (
             pynutil.insert("cardinal { ")
             + optional_graph_negative
-            + pynutil.insert("integer: \"")
+            + pynutil.insert('integer: "')
             + cardinal_graph
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
             + pynutil.insert(" }")
             + delete_extra_space
             + unit_singular
         )
         fraction_graph = (
             delete_extra_space
-            + pynutil.insert("fractional_part: \"")
+            + pynutil.insert('fractional_part: "')
             + (graph_digit | graph_half | graph_one | graph_four)
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
         )
 
         subgraph_cardinal |= (
             pynutil.insert("cardinal { ")
             + optional_graph_negative
-            + pynutil.insert("integer: \"")
+            + pynutil.insert('integer: "')
             + cardinal_graph
-            + pynutil.insert("\" }")
+            + pynutil.insert('" }')
             + delete_extra_space
             + unit_singular
             + fraction_graph
         )
         final_graph = subgraph_decimal | subgraph_cardinal
         final_graph = self.add_tokens(final_graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/money.py`

 * *Files 19% similar despite different names*

```diff
@@ -48,32 +48,32 @@
         cardinal_graph = cardinal.graph_no_exception
         graph_decimal_final = decimal.final_graph_wo_negative
         graph_half = pynini.cross("rưỡi", "5")
 
         unit = pynini.string_file(get_abs_path("data/currency.tsv"))
         unit_singular = pynini.invert(unit)
 
-        graph_unit_singular = pynutil.insert("currency: \"") + convert_space(unit_singular) + pynutil.insert("\"")
+        graph_unit_singular = pynutil.insert('currency: "') + convert_space(unit_singular) + pynutil.insert('"')
 
         add_leading_zero_to_double_digit = (NEMO_DIGIT + NEMO_DIGIT) | (pynutil.insert("0") + NEMO_DIGIT)
 
         # twelve dollars fifty, only after integer
         optional_cents_suffix = pynini.closure(
             delete_extra_space
-            + pynutil.insert("fractional_part: \"")
+            + pynutil.insert('fractional_part: "')
             + (pynutil.add_weight(cardinal_graph @ add_leading_zero_to_double_digit, -0.7) | graph_half)
-            + pynutil.insert("\""),
+            + pynutil.insert('"'),
             0,
             1,
         )
 
         graph_integer = (
-            pynutil.insert("integer_part: \"")
+            pynutil.insert('integer_part: "')
             + cardinal_graph
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
             + delete_extra_space
             + graph_unit_singular
             + optional_cents_suffix
         )
 
         graph_decimal = graph_decimal_final + delete_extra_space + graph_unit_singular + optional_cents_suffix
         final_graph = graph_integer | graph_decimal
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/ordinal.py`

 * *Files 3% similar despite different names*

```diff
@@ -35,10 +35,10 @@
         super().__init__(name="ordinal", kind="classify")
 
         graph_digit = pynini.string_file(get_abs_path("data/ordinals/digit.tsv"))
         graph_ordinal = pynini.cross("thứ", "")
         graph = graph_digit
 
         self.graph = graph
-        final_graph = pynutil.insert("integer: \"") + graph_ordinal + delete_space + self.graph + pynutil.insert("\"")
+        final_graph = pynutil.insert('integer: "') + graph_ordinal + delete_space + self.graph + pynutil.insert('"')
         final_graph = self.add_tokens(final_graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/punctuation.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/punctuation.py`

 * *Files 11% similar despite different names*

```diff
@@ -29,13 +29,13 @@
     Finite state transducer for classifying punctuation
         e.g. a, -> tokens { name: "a" } tokens { name: "," }
     """
 
     def __init__(self):
         super().__init__(name="punctuation", kind="classify")
 
-        s = "!#$%&\'()*+,-./:;<=>?@^_`{|}~"
+        s = "!#$%&'()*+,-./:;<=>?@^_`{|}~"
         punct = pynini.union(*s)
 
-        graph = pynutil.insert("name: \"") + punct + pynutil.insert("\"")
+        graph = pynutil.insert('name: "') + punct + pynutil.insert('"')
 
         self.fst = graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/telephone.py`

 * *Files 4% similar despite different names*

```diff
@@ -35,12 +35,12 @@
         super().__init__(name="telephone", kind="classify")
         graph_zero = pynini.string_file(get_abs_path("data/numbers/zero.tsv"))
         graph_digit = pynini.string_file(get_abs_path("data/numbers/digit.tsv"))
         digit = graph_digit | graph_zero
         last_digit = digit | pynini.cross("mốt", "1") | pynini.cross("tư", "4") | pynini.cross("lăm", "5")
 
         graph_number_part = pynini.closure(digit + delete_space, 2) + last_digit
-        number_part = pynutil.insert("number_part: \"") + graph_number_part + pynutil.insert("\"")
+        number_part = pynutil.insert('number_part: "') + graph_number_part + pynutil.insert('"')
 
         graph = number_part
         final_graph = self.add_tokens(graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/time.py`

 * *Files 27% similar despite different names*

```diff
@@ -53,63 +53,77 @@
 
         graph_half = pynini.cross("rưỡi", "30")
         oclock = pynini.cross("giờ", "")
         minute = pynini.cross("phút", "")
         optional_minute = pynini.closure(delete_space + minute, 0, 1)
         second = pynini.cross("giây", "")
 
-        final_graph_hour = pynutil.insert("hours: \"") + graph_hours + pynutil.insert("\"") + delete_space + oclock
+        final_graph_hour = pynutil.insert('hours: "') + graph_hours + pynutil.insert('"') + delete_space + oclock
         graph_minute = graph_minutes + optional_minute
-        graph_second = graph_minute + delete_space + second
+        graph_second = graph_minutes + delete_space + second
         final_time_zone_optional = pynini.closure(
             delete_space
             + insert_space
-            + pynutil.insert("zone: \"")
+            + pynutil.insert('zone: "')
             + convert_space(time_zone_graph)
-            + pynutil.insert("\""),
+            + pynutil.insert('"'),
             0,
             1,
         )
 
         graph_hm = (
             final_graph_hour
             + delete_extra_space
-            + pynutil.insert("minutes: \"")
+            + pynutil.insert('minutes: "')
             + (graph_minute | graph_half)
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
         )
 
-        graph_hms = graph_hm + delete_extra_space + pynutil.insert("seconds: \"") + graph_second + pynutil.insert("\"")
+        graph_hms = (
+            final_graph_hour
+            + delete_extra_space
+            + pynutil.insert('minutes: "')
+            + graph_minutes
+            + delete_space
+            + minute
+            + pynutil.insert('"')
+            + delete_extra_space
+            + pynutil.insert('seconds: "')
+            + graph_second
+            + pynutil.insert('"')
+        )
 
         graph_ms = (
-            pynutil.insert("minutes: \"")
-            + graph_minute
-            + pynutil.insert("\"")
+            pynutil.insert('minutes: "')
+            + graph_minutes
+            + delete_space
+            + minute
+            + pynutil.insert('"')
             + delete_extra_space
-            + pynutil.insert("seconds: \"")
+            + pynutil.insert('seconds: "')
             + (graph_second | graph_half)
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
         )
 
         graph_hours_to_component = graph_hours @ graph_hours_to
         graph_minutes_to_component = graph_minutes @ graph_minutes_to
 
         graph_time_to = (
-            pynutil.insert("hours: \"")
+            pynutil.insert('hours: "')
             + graph_hours_to_component
-            + pynutil.insert("\"")
+            + pynutil.insert('"')
             + delete_space
             + oclock
             + delete_space
             + pynutil.delete("kém")
             + delete_extra_space
-            + pynutil.insert("minutes: \"")
+            + pynutil.insert('minutes: "')
             + graph_minutes_to_component
+            + pynutil.insert('"')
             + optional_minute
-            + pynutil.insert("\"")
         )
 
         final_graph = (final_graph_hour | graph_hm | graph_hms) + final_time_zone_optional
         final_graph |= graph_ms
         final_graph |= graph_time_to
 
         final_graph = self.add_tokens(final_graph)
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/tokenize_and_classify.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/whitelist.py`

 * *Files 4% similar despite different names*

```diff
@@ -32,9 +32,9 @@
     This class has highest priority among all classifier grammars. Whitelisted tokens are defined and loaded from "data/whitelist.tsv".
     """
 
     def __init__(self):
         super().__init__(name="whitelist", kind="classify")
 
         whitelist = pynini.string_file(get_abs_path("data/whitelist.tsv")).invert()
-        graph = pynutil.insert("name: \"") + convert_space(whitelist) + pynutil.insert("\"")
+        graph = pynutil.insert('name: "') + convert_space(whitelist) + pynutil.insert('"')
         self.fst = graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/taggers/word.py`

 * *Files 6% similar despite different names*

```diff
@@ -28,9 +28,9 @@
     """
     Finite state transducer for classifying plain tokens, that do not belong to any special class. This can be considered as the default class.
         e.g. sleep -> tokens { name: "sleep" }
     """
 
     def __init__(self):
         super().__init__(name="word", kind="classify")
-        word = pynutil.insert("name: \"") + pynini.closure(NEMO_NOT_SPACE, 1) + pynutil.insert("\"")
+        word = pynutil.insert('name: "') + pynini.closure(NEMO_NOT_SPACE, 1) + pynutil.insert('"')
         self.fst = word.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,8 +20,8 @@
     Get absolute path
 
     Args:
         rel_path: relative path to this file
 
     Returns absolute path
     """
-    return os.path.dirname(os.path.abspath(__file__)) + '/' + rel_path
+    return os.path.dirname(os.path.abspath(__file__)) + "/" + rel_path
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/time.py`

 * *Files 17% similar despite different names*

```diff
@@ -8,47 +8,54 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.inverse_text_normalization.vi.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space, insert_space
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class CardinalFst(GraphFst):
+class TimeFst(GraphFst):
     """
-    Finite state transducer for verbalizing cardinal
-        e.g. cardinal { integer: "23" negative: "-" } -> -23
+    Finite state transducer for verbalizing electronic
+        e.g. time { hours: "два часа пятнадцать минут" } -> "два часа пятнадцать минут"
+
+    Args:
+        deterministic: if True will provide a single transduction option,
+        for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self):
-        super().__init__(name="cardinal", kind="verbalize")
-        optional_sign = pynini.closure(
-            pynutil.delete("negative:")
+    def __init__(self, deterministic: bool = True):
+        super().__init__(name="time", kind="verbalize", deterministic=deterministic)
+
+        hour = (
+            pynutil.delete("hours:")
             + delete_space
             + pynutil.delete("\"")
-            + NEMO_NOT_QUOTE
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
-            + delete_space,
-            0,
-            1,
         )
-        graph = (
-            pynutil.delete("integer:")
+        minutes = (
+            pynutil.delete("minutes:")
             + delete_space
             + pynutil.delete("\"")
             + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
         )
-        self.numbers = graph
-        graph = optional_sign + graph
-        delete_tokens = self.delete_tokens(graph)
+
+        self.graph = (
+            hour + delete_space + insert_space + minutes + delete_space + pynutil.delete("preserve_order: true")
+        )
+        self.graph |= hour + delete_space
+        self.graph |= minutes + delete_space + insert_space + hour + delete_space
+
+        delete_tokens = self.delete_tokens(self.graph)
         self.fst = delete_tokens.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/time.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,79 +1,95 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.inverse_text_normalization.vi.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space
+from nemo_text_processing.inverse_text_normalization.vi.graph_utils import (
+    NEMO_CHAR,
+    NEMO_DIGIT,
+    GraphFst,
+    delete_space,
+    insert_space,
+)
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class DateFst(GraphFst):
+class TimeFst(GraphFst):
     """
-    Finite state transducer for verbalizing date, e.g.
-        date { month: "1" year: "2012"} -> 1/2012
-        date { day: "5" month: "10" year: "2021" preserve_order: true } -> 5/10/2021
+    Finite state transducer for verbalizing time, e.g.
+        time { hours: "3" } -> 3h
+        time { hours: "12" minutes: "30" } -> 12:30
+        time { hours: "1" minutes: "12" second: "22"} -> 1:12:22
+        time { minutes: "36" second: "45"} -> 36p45s
+        time { hours: "2" zone: "gmt" } -> 2h gmt
     """
 
     def __init__(self):
-        super().__init__(name="date", kind="verbalize")
-        month = (
-            pynutil.delete("month:")
-            + delete_space
-            + pynutil.delete("\"")
-            + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+        super().__init__(name="time", kind="verbalize")
+        add_leading_zero_to_double_digit = (NEMO_DIGIT + NEMO_DIGIT) | (pynutil.insert("0") + NEMO_DIGIT)
+        hour = (
+            pynutil.delete("hours:")
+            + delete_space
+            + pynutil.delete('"')
+            + pynini.closure(NEMO_DIGIT, 1)
+            + pynutil.delete('"')
         )
-        day = (
-            pynutil.delete("day:")
+        minute = (
+            pynutil.delete("minutes:")
             + delete_space
-            + pynutil.delete("\"")
-            + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
+            + pynini.closure(NEMO_DIGIT, 1)
+            + pynutil.delete('"')
         )
-        year = (
-            pynutil.delete("year:")
-            + delete_space
-            + pynutil.delete("\"")
-            + pynini.closure(NEMO_NOT_QUOTE, 1)
+        second = (
+            pynutil.delete("seconds:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
+            + pynini.closure(NEMO_DIGIT, 1)
+            + pynutil.delete('"')
+        )
+        zone = (
+            delete_space
+            + insert_space
+            + pynutil.delete("zone:")
+            + delete_space
+            + pynutil.delete('"')
+            + pynini.closure(NEMO_CHAR - " ", 1)
+            + pynutil.delete('"')
+        )
+        optional_zone = pynini.closure(zone, 0, 1)
+        optional_second = pynini.closure(
+            delete_space + pynutil.insert(":") + (second @ add_leading_zero_to_double_digit), 0, 1,
         )
 
-        # (day) month year
-        # day month
-        graph_dm = day + delete_space + pynutil.insert("/") + month
-        graph_dmy = graph_dm + delete_space + pynutil.insert("/") + year
-        graph_m = pynutil.insert("tháng ") + month
-        graph_my = month + delete_space + pynutil.insert("/") + year
-        graph_y = pynutil.insert("năm ") + year
-
-        optional_preserve_order = pynini.closure(
-            pynutil.delete("preserve_order:") + delete_space + pynutil.delete("true") + delete_space
-            | pynutil.delete("field_order:")
-            + delete_space
-            + pynutil.delete("\"")
-            + NEMO_NOT_QUOTE
-            + pynutil.delete("\"")
+        graph_h = hour + pynutil.insert("h")
+        graph_hms = (
+            hour + delete_space + pynutil.insert(":") + (minute @ add_leading_zero_to_double_digit) + optional_second
+        )
+        graph_ms = (
+            minute
             + delete_space
+            + pynutil.insert("p")
+            + (second @ add_leading_zero_to_double_digit)
+            + pynutil.insert("s")
         )
 
-        final_graph = (graph_y | graph_m | graph_dm | graph_dmy | graph_my) + delete_space + optional_preserve_order
-
-        delete_tokens = self.delete_tokens(final_graph)
+        graph = (graph_h | graph_ms | graph_hms) + optional_zone
+        delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/decimal.py`

 * *Files 11% similar despite different names*

```diff
@@ -27,38 +27,38 @@
     """
     Finite state transducer for verbalizing decimal, e.g.
         decimal { negative: "true" integer_part: "12"  fractional_part: "5006" quantity: "tỷ" } -> -12.5006 tỷ
     """
 
     def __init__(self):
         super().__init__(name="decimal", kind="verbalize")
-        optionl_sign = pynini.closure(pynini.cross("negative: \"true\"", "-") + delete_space, 0, 1)
+        optionl_sign = pynini.closure(pynini.cross('negative: "true"', "-") + delete_space, 0, 1)
         integer = (
             pynutil.delete("integer_part:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
         optional_integer = pynini.closure(integer + delete_space, 0, 1)
         fractional = (
             pynutil.insert(".")
             + pynutil.delete("fractional_part:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
         optional_fractional = pynini.closure(fractional + delete_space, 0, 1)
         quantity = (
             pynutil.delete("quantity:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
         optional_quantity = pynini.closure(pynutil.insert(" ") + quantity + delete_space, 0, 1)
         graph = optional_integer + optional_fractional + optional_quantity
         self.numbers = graph
         graph = optionl_sign + graph
         delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/electronic.py`

 * *Files 16% similar despite different names*

```diff
@@ -30,32 +30,32 @@
     """
 
     def __init__(self):
         super().__init__(name="electronic", kind="verbalize")
         user_name = (
             pynutil.delete("username:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
         domain = (
             pynutil.delete("domain:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
 
         protocol = (
             pynutil.delete("protocol:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
 
         graph = user_name + delete_space + pynutil.insert("@") + domain
         graph |= protocol
 
         delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/fraction.py`

 * *Files 6% similar despite different names*

```diff
@@ -29,21 +29,21 @@
     Finite state transducer for verbalizing fraction,
         e.g. fraction { numerator: "2" denominator: "3" } } -> 2/3
         e.g. fraction { numerator: "20" denominator: "3" negative: "true"} } -> 2/3
     """
 
     def __init__(self):
         super().__init__(name="fraction", kind="verbalize")
-        optional_sign = pynini.closure(pynini.cross("negative: \"true\"", "-") + delete_space, 0, 1)
-        numerator = pynutil.delete("numerator: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
+        optional_sign = pynini.closure(pynini.cross('negative: "true"', "-") + delete_space, 0, 1)
+        numerator = pynutil.delete('numerator: "') + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete('"')
 
         denominator = (
-            pynutil.insert('/')
-            + pynutil.delete("denominator: \"")
+            pynutil.insert("/")
+            + pynutil.delete('denominator: "')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
 
         graph = (numerator + delete_space + denominator).optimize()
         self.numbers = graph
         delete_tokens = self.delete_tokens(optional_sign + graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/measure.py`

 * *Files 14% similar despite different names*

```diff
@@ -38,21 +38,21 @@
     Args:
         decimal: DecimalFst
         cardinal: CardinalFst
     """
 
     def __init__(self, decimal: GraphFst, cardinal: GraphFst):
         super().__init__(name="measure", kind="verbalize")
-        optional_sign = pynini.closure(pynini.cross("negative: \"true\"", "-"), 0, 1)
+        optional_sign = pynini.closure(pynini.cross('negative: "true"', "-"), 0, 1)
         unit = (
             pynutil.delete("units:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_CHAR - " ", 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + delete_space
         )
         graph_decimal = (
             pynutil.delete("decimal {")
             + delete_space
             + optional_sign
             + delete_space
@@ -69,17 +69,17 @@
             + delete_space
             + pynutil.delete("}")
         )
         fractional = (
             pynutil.insert(".")
             + pynutil.delete("fractional_part:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
         optional_fractional = pynini.closure(fractional + delete_space, 0, 1)
         graph = (
             (graph_cardinal | graph_decimal)
             + delete_space
             + optional_fractional
             + pynutil.insert(" ")
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/money.py`

 * *Files 9% similar despite different names*

```diff
@@ -35,14 +35,14 @@
     """
 
     def __init__(self, decimal: GraphFst):
         super().__init__(name="money", kind="verbalize")
         unit = (
             pynutil.delete("currency:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_CHAR - " ", 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
         graph = decimal.numbers + delete_space + unit
         delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/ordinal.py`

 * *Files 11% similar despite different names*

```diff
@@ -31,15 +31,15 @@
     """
 
     def __init__(self):
         super().__init__(name="ordinal", kind="verbalize")
         graph = (
             pynutil.delete("integer:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
 
         graph = pynutil.insert("thứ ") + graph
         delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/telephone.py`

 * *Files 12% similar despite different names*

```diff
@@ -30,10 +30,10 @@
         telephone { number_part: "1231235678" }
         -> 1231235678
     """
 
     def __init__(self):
         super().__init__(name="telephone", kind="verbalize")
 
-        number_part = pynutil.delete("number_part: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
+        number_part = pynutil.delete('number_part: "') + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete('"')
         delete_tokens = self.delete_tokens(number_part)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/time.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.inverse_text_normalization.vi.graph_utils import (
-    NEMO_CHAR,
-    NEMO_DIGIT,
+from nemo_text_processing.text_normalization.en.graph_utils import (
+    NEMO_NOT_QUOTE,
+    NEMO_SIGMA,
     GraphFst,
     delete_space,
     insert_space,
 )
 
 try:
     import pynini
@@ -29,67 +28,81 @@
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class TimeFst(GraphFst):
     """
     Finite state transducer for verbalizing time, e.g.
-        time { hours: "3" } -> 3h
-        time { hours: "12" minutes: "30" } -> 12:30
-        time { hours: "1" minutes: "12" second: "22"} -> 01:12:22
-        time { minutes: "36" second: "45"} -> 36:45s
-        time { hours: "2" zone: "gmt" } -> 2h gmt
+        time { hours: "twelve" minutes: "thirty" suffix: "a m" zone: "e s t" } -> twelve thirty a m e s t
+        time { hours: "twelve" } -> twelve o'clock
+
+    Args:
+        deterministic: if True will provide a single transduction option,
+            for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self):
-        super().__init__(name="time", kind="verbalize")
-        add_leading_zero_to_double_digit = (NEMO_DIGIT + NEMO_DIGIT) | (pynutil.insert("0") + NEMO_DIGIT)
+    def __init__(self, deterministic: bool = True):
+        super().__init__(name="time", kind="verbalize", deterministic=deterministic)
         hour = (
             pynutil.delete("hours:")
             + delete_space
             + pynutil.delete("\"")
-            + pynini.closure(NEMO_DIGIT, 1)
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
         )
         minute = (
             pynutil.delete("minutes:")
             + delete_space
             + pynutil.delete("\"")
-            + pynini.closure(NEMO_DIGIT, 1)
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
         )
-        second = (
-            pynutil.delete("seconds:")
+        suffix = (
+            pynutil.delete("suffix:")
             + delete_space
             + pynutil.delete("\"")
-            + pynini.closure(NEMO_DIGIT, 1)
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
         )
+        optional_suffix = pynini.closure(delete_space + insert_space + suffix, 0, 1)
         zone = (
-            delete_space
-            + insert_space
-            + pynutil.delete("zone:")
+            pynutil.delete("zone:")
             + delete_space
             + pynutil.delete("\"")
-            + pynini.closure(NEMO_CHAR - " ", 1)
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
         )
-        optional_zone = pynini.closure(zone, 0, 1)
-        optional_second = pynini.closure(
-            delete_space + pynutil.insert(":") + (second @ add_leading_zero_to_double_digit), 0, 1
+        optional_zone = pynini.closure(delete_space + insert_space + zone, 0, 1)
+        second = (
+            pynutil.delete("seconds:")
+            + delete_space
+            + pynutil.delete("\"")
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
+            + pynutil.delete("\"")
         )
-
-        graph_h = hour + pynutil.insert("h")
         graph_hms = (
-            hour + delete_space + pynutil.insert(":") + (minute @ add_leading_zero_to_double_digit) + optional_second
-        )
-        graph_ms = (
-            (minute @ add_leading_zero_to_double_digit)
+            hour
+            + pynutil.insert(" hours ")
             + delete_space
-            + pynutil.insert(":")
-            + (second @ add_leading_zero_to_double_digit)
-            + pynutil.insert("s")
-        )
-
-        graph = (graph_h | graph_ms | graph_hms) + optional_zone
+            + minute
+            + pynutil.insert(" minutes and ")
+            + delete_space
+            + second
+            + pynutil.insert(" seconds")
+            + optional_suffix
+            + optional_zone
+        )
+        graph_hms @= pynini.cdrewrite(
+            pynutil.delete("o ")
+            | pynini.cross("one minutes", "one minute")
+            | pynini.cross("one seconds", "one second")
+            | pynini.cross("one hours", "one hour"),
+            pynini.union(" ", "[BOS]"),
+            "",
+            NEMO_SIGMA,
+        )
+        graph = hour + delete_space + insert_space + minute + optional_suffix + optional_zone
+        graph |= hour + insert_space + pynutil.insert("o'clock") + optional_zone
+        graph |= hour + delete_space + insert_space + suffix + optional_zone
+        graph |= graph_hms
         delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/verbalize_final.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/whitelist.py`

 * *Files 3% similar despite different names*

```diff
@@ -37,13 +37,13 @@
     """
 
     def __init__(self):
         super().__init__(name="whitelist", kind="verbalize")
         graph = (
             pynutil.delete("name:")
             + delete_space
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
             + pynini.closure(NEMO_CHAR - " ", 1)
-            + pynutil.delete("\"")
+            + pynutil.delete('"')
         )
         graph = graph @ pynini.cdrewrite(pynini.cross(u"\u00A0", " "), "", "", NEMO_SIGMA)
         self.fst = graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/inverse_text_normalization/vi/verbalizers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/word.py`

 * *Files 8% similar despite different names*

```diff
@@ -34,11 +34,11 @@
     Finite state transducer for verbalizing plain tokens
         e.g. tokens { name: "sleep" } -> sleep
     """
 
     def __init__(self):
         super().__init__(name="word", kind="verbalize")
         chars = pynini.closure(NEMO_CHAR - " ", 1)
-        char = pynutil.delete("name:") + delete_space + pynutil.delete("\"") + chars + pynutil.delete("\"")
+        char = pynutil.delete("name:") + delete_space + pynutil.delete('"') + chars + pynutil.delete('"')
         graph = char @ pynini.cdrewrite(pynini.cross(u"\u00A0", " "), "", "", NEMO_SIGMA)
 
         self.fst = graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/word.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,28 +1,39 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-from nemo.utils import logging
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_SPACE, GraphFst
 
 try:
     import pynini
+    from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
-except (ModuleNotFoundError, ImportError):
-    logging.warning(
-        "`pynini` is not installed ! \n"
-        "Please run the `nemo_text_processing/setup.sh` script "
-        "prior to usage of this toolkit."
-    )
 
+except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
+
+
+class WordFst(GraphFst):
+    """
+    Finite state transducer for classifying word.
+        e.g. dormir -> tokens { name: "dormir" }
+
+    Args:
+        deterministic: if True will provide a single transduction option,
+            for False multiple transduction are generated (used for audio-based normalization)
+    """
+
+    def __init__(self, deterministic: bool = True):
+        super().__init__(name="word", kind="classify")
+        word = pynutil.insert("name: \"") + pynini.closure(NEMO_NOT_SPACE, 1) + pynutil.insert("\"")
+        self.fst = word.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/data_loader_utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/data_loader_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -37,15 +37,15 @@
     "ELECTRONIC",
     "FRACTION",
     "TIME",
     "ADDRESS",
 ]
 
 
-def load_kaggle_text_norm_file(file_path: str) -> List[Instance]:
+def _load_kaggle_text_norm_file(file_path: str) -> List[Instance]:
     """
     https://www.kaggle.com/richardwilliamsproat/text-normalization-for-english-russian-and-polish
     Loads text file in the Kaggle Google text normalization file format: <semiotic class>\t<unnormalized text>\t<`self` if trivial class or normalized text>
     E.g. 
     PLAIN   Brillantaisia   <self>
     PLAIN   is      <self>
     PLAIN   a       <self>
@@ -77,15 +77,15 @@
                 if l_type == PLAIN_TYPE:
                     res.append(Instance(token_type=l_type, un_normalized=l_token, normalized=l_token))
                 elif l_type != PUNCT_TYPE:
                     res.append(Instance(token_type=l_type, un_normalized=l_token, normalized=l_normalized))
     return res
 
 
-def load_files(file_paths: List[str], load_func=load_kaggle_text_norm_file) -> List[Instance]:
+def load_files(file_paths: List[str], load_func=_load_kaggle_text_norm_file) -> List[Instance]:
     """
     Load given list of text files using the `load_func` function.
 
     Args: 
         file_paths: list of file paths
         load_func: loading function
 
@@ -250,7 +250,37 @@
         PYNINI_AVAILABLE = False
     return PYNINI_AVAILABLE
 
 
 def get_installation_msg():
     msg = "`pynini` is not installed ! \n Please run the `nemo_text_processing/setup.sh` script prior to usage of this toolkit."
     return msg
+
+
+def load_file(file_path: str) -> List[str]:
+    """
+    Loads given text file with separate lines into list of string.
+
+    Args: 
+        file_path: file path
+
+    Returns: flat list of string
+    """
+    res = []
+    with open(file_path, 'r') as fp:
+        for line in fp:
+            res.append(line)
+    return res
+
+
+def write_file(file_path: str, data: List[str]):
+    """
+    Writes out list of string to file.
+
+    Args:
+        file_path: file path
+        data: list of string
+        
+    """
+    with open(file_path, 'w') as fp:
+        for line in data:
+            fp.write(line + '\n')
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/fractions.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/fractions.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/measure/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/measure/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/measure/measurements.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/measure/measurements.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/money/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/money/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/months/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/months/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/numbers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/ordinals/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/ordinals/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/data/time/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/tokenize_and_classify.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,14 +23,16 @@
 from nemo_text_processing.text_normalization.de.taggers.money import MoneyFst
 from nemo_text_processing.text_normalization.de.taggers.ordinal import OrdinalFst
 from nemo_text_processing.text_normalization.de.taggers.telephone import TelephoneFst
 from nemo_text_processing.text_normalization.de.taggers.time import TimeFst
 from nemo_text_processing.text_normalization.de.taggers.whitelist import WhiteListFst
 from nemo_text_processing.text_normalization.de.taggers.word import WordFst
 from nemo_text_processing.text_normalization.en.graph_utils import (
+    NEMO_CHAR,
+    NEMO_DIGIT,
     GraphFst,
     delete_extra_space,
     delete_space,
     generator_main,
 )
 from nemo_text_processing.text_normalization.en.taggers.punctuation import PunctuationFst
 
@@ -74,14 +76,16 @@
             os.makedirs(cache_dir, exist_ok=True)
             whitelist_file = os.path.basename(whitelist) if whitelist else ""
             far_file = os.path.join(
                 cache_dir, f"_{input_case}_de_tn_{deterministic}_deterministic{whitelist_file}.far"
             )
         if not overwrite_cache and far_file and os.path.exists(far_file):
             self.fst = pynini.Far(far_file, mode="r")["tokenize_and_classify"]
+            no_digits = pynini.closure(pynini.difference(NEMO_CHAR, NEMO_DIGIT))
+            self.fst_no_digits = pynini.compose(self.fst, no_digits).optimize()
             logging.info(f"ClassifyFst.fst was restored from {far_file}.")
         else:
             logging.info(f"Creating ClassifyFst grammars. This might take some time...")
 
             self.cardinal = CardinalFst(deterministic=deterministic)
             cardinal_graph = self.cardinal.fst
 
@@ -120,24 +124,27 @@
                 | pynutil.add_weight(fraction_graph, 1.1)
                 | pynutil.add_weight(date_graph, 1.1)
                 | pynutil.add_weight(ordinal_graph, 1.1)
                 | pynutil.add_weight(decimal_graph, 1.1)
                 | pynutil.add_weight(money_graph, 1.1)
                 | pynutil.add_weight(telephone_graph, 1.1)
                 | pynutil.add_weight(electronic_graph, 1.1)
-                | pynutil.add_weight(word_graph, 100)
             )
 
+            classify |= pynutil.add_weight(word_graph, 100)
+
             punct = pynutil.insert("tokens { ") + pynutil.add_weight(punct_graph, weight=1.1) + pynutil.insert(" }")
             token = pynutil.insert("tokens { ") + classify + pynutil.insert(" }")
             token_plus_punct = (
                 pynini.closure(punct + pynutil.insert(" ")) + token + pynini.closure(pynutil.insert(" ") + punct)
             )
 
             graph = token_plus_punct + pynini.closure(pynutil.add_weight(delete_extra_space, 1.1) + token_plus_punct)
             graph = delete_space + graph + delete_space
 
             self.fst = graph.optimize()
+            no_digits = pynini.closure(pynini.difference(NEMO_CHAR, NEMO_DIGIT))
+            self.fst_no_digits = pynini.compose(self.fst, no_digits).optimize()
 
             if far_file:
                 generator_main(far_file, {"tokenize_and_classify": self.fst})
                 logging.info(f"ClassifyFst grammars are saved to {far_file}.")
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/taggers/word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/de/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/verbalize_final.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,38 +1,38 @@
-# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-from nemo_text_processing.text_normalization.de.verbalizers.verbalize import VerbalizeFst
 from nemo_text_processing.text_normalization.en.graph_utils import GraphFst, delete_extra_space, delete_space
 from nemo_text_processing.text_normalization.en.verbalizers.word import WordFst
+from nemo_text_processing.text_normalization.es.verbalizers.verbalize import VerbalizeFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
+
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class VerbalizeFinalFst(GraphFst):
     """
     Finite state transducer that verbalizes an entire sentence
-    
+
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="verbalize_final", kind="verbalize", deterministic=deterministic)
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/__init__.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_measure.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,32 +1,36 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.taggers.tokenize_and_classify import ClassifyFst
-from nemo_text_processing.text_normalization.en.verbalizers.verbalize import VerbalizeFst
-from nemo_text_processing.text_normalization.en.verbalizers.verbalize_final import VerbalizeFinalFst
-
-from nemo.utils import logging
-
-try:
-    import pynini
-
-    PYNINI_AVAILABLE = True
-except (ModuleNotFoundError, ImportError):
-    logging.warning(
-        "`pynini` is not installed ! \n"
-        "Please run the `nemo_text_processing/setup.sh` script"
-        "prior to usage of this toolkit."
+
+import pytest
+from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
+from parameterized import parameterized
+
+from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
+
+
+class TestMeasure:
+    inverse_normalizer = (
+        InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    PYNINI_AVAILABLE = False
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_measure.txt'))
+    @pytest.mark.skipif(
+        not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
+    )
+    @pytest.mark.run_only_on('CPU')
+    @pytest.mark.unit
+    def test_denorm(self, test_input, expected):
+        pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
+        assert pred == expected
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/clean_eval_data.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/clean_eval_data.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/address/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/address/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/address/states.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/address/state.tsv`

 * *Files 22% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 Delaware	DE
 Florida	FL
 Georgia	GA
 Hawaii	HI
 Idaho	ID
 Illinois	IL
 Indiana	IN
+Indiana	IND
 Iowa	IA
 Kansas	KS
 Kentucky	KY
 Louisiana	LA
 Maine	ME
 Maryland	MD
 Massachusetts	MA
@@ -36,14 +37,15 @@
 Oklahoma	OK
 Oregon	OR
 Pennsylvania	PA
 Rhode Island	RI
 South Carolina	SC
 South Dakota	SD
 Tennessee	TN
+Tennessee	TENN
 Texas	TX
 Utah	UT
 Vermont	VT
 Virginia	VA
 Washington	WA
 West Virginia	WV
 Wisconsin	WI
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/currency/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/date/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/currency/currency.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/currency_major.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/measure/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/months/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/money/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/numbers/cardinal_number_name.far` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/number/cardinal_number_name.far`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/ordinals/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/ordinal/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/roman/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/roman/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/data/whitelist.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/asr.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/graph_utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/graph_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -43,14 +43,15 @@
 
     NEMO_PUNCT = pynini.union(*map(pynini.escape, string.punctuation)).optimize()
     NEMO_GRAPH = pynini.union(NEMO_ALNUM, NEMO_PUNCT).optimize()
 
     NEMO_SIGMA = pynini.closure(NEMO_CHAR)
 
     delete_space = pynutil.delete(pynini.closure(NEMO_WHITE_SPACE))
+    delete_zero_or_one_space = pynutil.delete(pynini.closure(NEMO_WHITE_SPACE, 0, 1))
     insert_space = pynutil.insert(" ")
     delete_extra_space = pynini.cross(pynini.closure(NEMO_WHITE_SPACE, 1), " ")
     delete_preserve_order = pynini.closure(
         pynutil.delete(" preserve_order: true")
         | (pynutil.delete(" field_order: \"") + NEMO_NOT_QUOTE + pynutil.delete("\""))
     )
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/abbreviation.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/abbreviation.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -40,16 +39,14 @@
         super().__init__(name="abbreviation", kind="classify", deterministic=deterministic)
 
         dot = pynini.accep(".")
         # A.B.C. -> A. B. C.
         graph = NEMO_UPPER + dot + pynini.closure(insert_space + NEMO_UPPER + dot, 1)
         # A.B.C. -> A.B.C.
         graph |= NEMO_UPPER + dot + pynini.closure(NEMO_UPPER + dot, 1)
-        # ABC -> ABC
-        graph |= NEMO_UPPER + pynini.closure(NEMO_UPPER, 1)
         # ABC -> A B C
         graph |= NEMO_UPPER + pynini.closure(insert_space + NEMO_UPPER, 1)
 
         # exclude words that are included in the whitelist
         graph = pynini.compose(
             pynini.difference(pynini.project(graph, "input"), pynini.project(whitelist.graph, "input")), graph
         )
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/cardinal.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,183 +1,152 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright 2017 Google Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+# Adapted from https://github.com/google/TextNormalizationCoveringGrammars
+# Russian minimally supervised number grammar.
 
 from nemo_text_processing.text_normalization.en.graph_utils import (
-    NEMO_ALPHA,
     NEMO_DIGIT,
-    NEMO_NOT_SPACE,
     NEMO_SIGMA,
+    NEMO_SPACE,
     GraphFst,
     insert_space,
 )
-from nemo_text_processing.text_normalization.en.taggers.date import get_hundreds_graph
-from nemo_text_processing.text_normalization.en.utils import get_abs_path
+from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA, TO_CYRILLIC
+from nemo_text_processing.text_normalization.ru.utils import get_abs_path
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class CardinalFst(GraphFst):
     """
     Finite state transducer for classifying cardinals, e.g. 
-        -23 -> cardinal { negative: "true"  integer: "twenty three" } }
+        "1 001" ->  cardinal { integer: "тысяча один" }
 
     Args:
+        number_names: number_names for cardinal and ordinal numbers
+        alternative_formats: alternative number formats
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self, deterministic: bool = True):
+    def __init__(self, number_names: dict, alternative_formats: dict, deterministic: bool = False):
         super().__init__(name="cardinal", kind="classify", deterministic=deterministic)
-        # TODO repalce to have "oh" as a default for "0"
-        graph = pynini.Far(get_abs_path("data/numbers/cardinal_number_name.far")).get_fst()
-        self.graph_hundred_component_at_least_one_none_zero_digit = (
-            pynini.closure(NEMO_DIGIT, 2, 3) | pynini.difference(NEMO_DIGIT, pynini.accep("0"))
-        ) @ graph
-        self.graph = (
-            pynini.closure(NEMO_DIGIT, 1, 3)
-            + pynini.closure(pynini.closure(pynutil.delete(","), 0, 1) + NEMO_DIGIT + NEMO_DIGIT + NEMO_DIGIT)
-        ) @ graph
 
-        graph_digit = pynini.string_file(get_abs_path("data/numbers/digit.tsv"))
-        graph_zero = pynini.string_file(get_abs_path("data/numbers/zero.tsv"))
+        self.cardinal_numbers_default = self.get_cardinal_numbers(number_names, alternative_formats, mode="all")
+        self.cardinal_numbers_nominative = self.get_cardinal_numbers(
+            number_names, alternative_formats, mode="nominative"
+        )
+        self.optional_graph_negative = pynini.closure(
+            pynutil.insert("negative: ") + pynini.cross("-", "\"true\"") + insert_space, 0, 1
+        )
+
+        self.cardinal_numbers_with_optional_negative = (
+            self.optional_graph_negative
+            + pynutil.insert("integer: \"")
+            + self.cardinal_numbers_default
+            + pynutil.insert("\"")
+        )
 
-        single_digits_graph = pynini.invert(graph_digit | graph_zero)
+        # "03" -> remove leading zeros and verbalize
+        leading_zeros = pynini.closure(pynini.cross("0", ""))
+        self.cardinal_numbers_with_leading_zeros = (leading_zeros + self.cardinal_numbers_default).optimize()
+
+        # "123" -> "один два три"
+        single_digits_graph = pynini.string_file(get_abs_path("data/numbers/cardinals_nominative_case.tsv")).optimize()
+        single_digits_graph = pynini.compose(NEMO_DIGIT, single_digits_graph)
         self.single_digits_graph = single_digits_graph + pynini.closure(insert_space + single_digits_graph)
 
-        if not deterministic:
-            # for a single token allow only the same normalization
-            # "007" -> {"oh oh seven", "zero zero seven"} not {"oh zero seven"}
-            single_digits_graph_zero = pynini.invert(graph_digit | graph_zero)
-            single_digits_graph_oh = pynini.invert(graph_digit) | pynini.cross("0", "oh")
-
-            self.single_digits_graph = single_digits_graph_zero + pynini.closure(
-                insert_space + single_digits_graph_zero
-            )
-            self.single_digits_graph |= single_digits_graph_oh + pynini.closure(insert_space + single_digits_graph_oh)
-
-            single_digits_graph_with_commas = pynini.closure(
-                self.single_digits_graph + insert_space, 1, 3
-            ) + pynini.closure(
-                pynutil.delete(",")
-                + single_digits_graph
-                + insert_space
-                + single_digits_graph
-                + insert_space
-                + single_digits_graph,
-                1,
-            )
-
-            self.range_graph = pynutil.insert("from ") + self.graph + pynini.cross("-", " to ") + self.graph
-            self.range_graph |= self.graph + (pynini.cross("x", " by ") | pynini.cross(" x ", " by ")) + self.graph
-            self.range_graph |= (
-                pynutil.insert("from ") + get_hundreds_graph() + pynini.cross("-", " to ") + get_hundreds_graph()
-            )
-            self.range_graph = self.range_graph.optimize()
+        optional_quantity = pynini.string_file(get_abs_path("data/numbers/quantity.tsv")).optimize()
+        optional_quantity = pynutil.insert("quantity: \"") + optional_quantity + pynutil.insert("\"")
+        optional_quantity = pynini.closure(
+            (pynutil.add_weight(pynini.accep(NEMO_SPACE), -0.1) | insert_space) + optional_quantity, 0, 1
+        )
 
         serial_graph = self.get_serial_graph()
-        optional_minus_graph = pynini.closure(pynutil.insert("negative: ") + pynini.cross("-", "\"true\" "), 0, 1)
-
-        if deterministic:
-            long_numbers = pynini.compose(NEMO_DIGIT ** (5, ...), self.single_digits_graph).optimize()
-            final_graph = self.graph | serial_graph | pynutil.add_weight(long_numbers, -0.001)
-            cardinal_with_leading_zeros = pynini.compose(
-                pynini.accep("0") + pynini.closure(NEMO_DIGIT), self.single_digits_graph
-            )
-            final_graph |= cardinal_with_leading_zeros
-        else:
-
-            leading_zeros = pynini.compose(pynini.closure(pynini.accep("0"), 1), self.single_digits_graph)
-            cardinal_with_leading_zeros = (
-                leading_zeros + pynutil.insert(" ") + pynini.compose(pynini.closure(NEMO_DIGIT), self.graph)
-            )
-
-            # add small weight to non-default graphs to make sure the deterministic option is listed first
-            final_graph = (
-                self.graph
-                | serial_graph
-                | self.range_graph
-                | pynutil.add_weight(self.single_digits_graph, 0.001)
-                | pynutil.add_weight(get_hundreds_graph(), 0.001)
-                | pynutil.add_weight(single_digits_graph_with_commas, 0.001)
-                | cardinal_with_leading_zeros
-            )
 
-        final_graph = optional_minus_graph + pynutil.insert("integer: \"") + final_graph + pynutil.insert("\"")
+        final_graph = (
+            self.optional_graph_negative
+            + pynutil.insert("integer: \"")
+            + self.cardinal_numbers_with_leading_zeros
+            + pynutil.insert("\"")
+            + optional_quantity
+        ).optimize()
+
+        final_graph = pynutil.add_weight(final_graph, -0.1)
+        final_graph |= pynutil.insert("integer: \"") + pynutil.add_weight(serial_graph, 10) + pynutil.insert("\"")
+        self.final_graph = final_graph
+
+        # to cover cases "2-х" -> "двух" (this is not covered by ordinal endings)
+        final_graph |= pynini.compose(
+            pynini.compose(NEMO_DIGIT ** (1, ...) + pynini.cross('-х', ''), final_graph),
+            NEMO_SIGMA + pynini.accep("х\"") + NEMO_SIGMA,
+        )
         final_graph = self.add_tokens(final_graph)
-
         self.fst = final_graph.optimize()
 
+    def get_cardinal_numbers(self, number_names: dict, alternative_formats: dict, mode: str = "all"):
+        """Returns cardinal numbers names graph.
+
+        Args:
+            number_names: number_names for cardinal and ordinal numbers
+            alternative_formats: alternative number formats
+            mode: "all" - to return graph that includes all Ru cases, "nominative" to return only the nominative form
+        """
+        if mode == "all":
+            cardinal_names = number_names['cardinal_number_names']
+        elif mode == "nominative":
+            cardinal_names = number_names['cardinal_names_nominative']
+        else:
+            raise ValueError(f'{mode} is not supported.')
+        one_thousand_alternative = alternative_formats['one_thousand_alternative']
+        separators = alternative_formats['separators']
+
+        cardinal_numbers = cardinal_names | pynini.compose(cardinal_names, one_thousand_alternative)
+        cardinal_numbers = pynini.compose(separators, cardinal_numbers)
+        return cardinal_numbers
+
     def get_serial_graph(self):
         """
-        Finite state transducer for classifying serial (handles only cases without delimiters,
-        values with delimiters are handled by default).
+        Finite state transducer for classifying serial.
             The serial is a combination of digits, letters and dashes, e.g.:
-            c325b -> tokens { cardinal { integer: "c three two five b" } }
+            c325-b -> tokens { cardinal { integer: "си три два пять би" } }
         """
         num_graph = self.single_digits_graph
 
-        if not self.deterministic:
-            num_graph |= self.graph
-
-        # add space between letter and digit
-        graph_with_space = pynini.compose(
-            pynini.cdrewrite(pynutil.insert(" "), NEMO_ALPHA, NEMO_DIGIT, NEMO_SIGMA),
-            pynini.cdrewrite(pynutil.insert(" "), NEMO_DIGIT, NEMO_ALPHA, NEMO_SIGMA),
-        )
-
-        # make sure at least one digit and letter is present
-        not_space = pynini.closure(NEMO_NOT_SPACE)
-        graph_with_space = pynini.compose(
-            (not_space + NEMO_ALPHA + not_space + NEMO_DIGIT + not_space)
-            | (not_space + NEMO_DIGIT + not_space + NEMO_ALPHA + not_space),
-            graph_with_space,
-        )
+        alpha = TO_CYRILLIC | RU_ALPHA
 
-        keep_space = pynini.accep(" ")
-        serial_graph = pynini.compose(
-            graph_with_space,
-            pynini.closure(pynini.closure(NEMO_ALPHA, 1) + keep_space, 1)
-            + num_graph
-            + pynini.closure(keep_space + pynini.closure(NEMO_ALPHA) + pynini.closure(keep_space + num_graph, 0, 1)),
-        )
-        serial_graph |= pynini.compose(
-            graph_with_space,
-            num_graph
-            + keep_space
-            + pynini.closure(NEMO_ALPHA, 1)
-            + pynini.closure(keep_space + num_graph + pynini.closure(keep_space + pynini.closure(NEMO_ALPHA), 0, 1)),
-        )
-
-        # serial graph with delimiter
-        delimiter = pynini.accep("-") | pynini.accep("/")
-        alphas = pynini.closure(NEMO_ALPHA, 1)
-        letter_num = alphas + delimiter + num_graph
-        num_letter = pynini.closure(num_graph + delimiter, 1) + alphas
-        next_alpha_or_num = pynini.closure(delimiter + (alphas | num_graph))
-        next_alpha_or_num |= pynini.closure(delimiter + num_graph + pynutil.insert(" ") + alphas)
-
-        serial_graph |= letter_num + next_alpha_or_num
-        serial_graph |= num_letter + next_alpha_or_num
+        delimiter = insert_space | pynini.cross("-", " ") | pynini.cross("/", " ")
+        letter_num = pynini.closure(alpha + delimiter, 1) + num_graph
+        num_letter = pynini.closure(num_graph + delimiter, 1) + alpha
+        num_delimiter_num = pynini.closure(num_graph + delimiter, 1) + num_graph
+        next_alpha_or_num = pynini.closure(delimiter + (alpha | num_graph))
+        serial_graph = (letter_num | num_letter | num_delimiter_num) + next_alpha_or_num
+
+        # at least 1 alpha and 1 digit is present
+        at_least_one_alpha_num = (
+            NEMO_SIGMA + (RU_ALPHA | pynini.project(TO_CYRILLIC, "input")) + NEMO_SIGMA + NEMO_DIGIT + NEMO_SIGMA
+        ) | (NEMO_SIGMA + NEMO_DIGIT + NEMO_SIGMA + (RU_ALPHA | pynini.project(TO_CYRILLIC, "input")) + NEMO_SIGMA)
+        serial_graph = pynini.compose(at_least_one_alpha_num, serial_graph.optimize()).optimize()
         # numbers only with 2+ delimiters
         serial_graph |= (
             num_graph + delimiter + num_graph + delimiter + num_graph + pynini.closure(delimiter + num_graph)
-        )
-        return pynutil.add_weight(serial_graph, 2)
+        ).optimize()
+        return serial_graph.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/date.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,25 +16,34 @@
     NEMO_CHAR,
     NEMO_DIGIT,
     NEMO_LOWER,
     NEMO_SIGMA,
     TO_LOWER,
     GraphFst,
     delete_extra_space,
+    delete_space,
     insert_space,
 )
-from nemo_text_processing.text_normalization.en.utils import get_abs_path, load_labels
+from nemo_text_processing.text_normalization.en.utils import (
+    augment_labels_with_punct_at_end,
+    get_abs_path,
+    load_labels,
+)
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
-    graph_teen = pynini.invert(pynini.string_file(get_abs_path("data/numbers/teen.tsv"))).optimize()
-    graph_digit = pynini.invert(pynini.string_file(get_abs_path("data/numbers/digit.tsv"))).optimize()
-    ties_graph = pynini.invert(pynini.string_file(get_abs_path("data/numbers/ties.tsv"))).optimize()
+    graph_teen = pynini.invert(pynini.string_file(get_abs_path("data/number/teen.tsv"))).optimize()
+    graph_digit = pynini.invert(pynini.string_file(get_abs_path("data/number/digit.tsv"))).optimize()
+    ties_graph = pynini.invert(pynini.string_file(get_abs_path("data/number/ty.tsv"))).optimize()
+    year_suffix = load_labels(get_abs_path("data/date/year_suffix.tsv"))
+    year_suffix.extend(augment_labels_with_punct_at_end(year_suffix))
+    year_suffix = pynini.string_map(year_suffix).optimize()
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     # Add placeholders for global variables
     graph_teen = None
     graph_digit = None
     ties_graph = None
@@ -56,61 +64,97 @@
         graph = graph | pynini.cross("0", "oh") + insert_space + graph_digit
     else:
         graph = graph | (pynini.cross("0", "oh") | pynini.cross("0", "zero")) + insert_space + graph_digit
 
     return graph.optimize()
 
 
-def get_hundreds_graph(deterministic: bool = True):
+def get_four_digit_year_graph(deterministic: bool = True):
     """
     Returns a four digit transducer which is combination of ties/teen or digits
     (using hundred instead of thousand format), e.g.
     1219 -> twelve nineteen
     3900 -> thirty nine hundred
     """
     graph_ties = get_ties_graph(deterministic)
+
+    graph_with_s = (
+        (graph_ties + insert_space + graph_ties)
+        | (graph_teen + insert_space + (ties_graph | pynini.cross("1", "ten")))
+    ) + pynutil.delete("0s")
+
+    graph_with_s |= (graph_teen | graph_ties) + insert_space + pynini.cross("00", "hundred") + pynutil.delete("s")
+    graph_with_s = graph_with_s @ pynini.cdrewrite(
+        pynini.cross("y", "ies") | pynutil.insert("s"), "", "[EOS]", NEMO_SIGMA
+    )
+
+    graph = graph_ties + insert_space + graph_ties
+    graph |= (graph_teen | graph_ties) + insert_space + pynini.cross("00", "hundred")
+
+    thousand_graph = (
+        graph_digit
+        + insert_space
+        + pynini.cross("00", "thousand")
+        + (pynutil.delete("0") | insert_space + graph_digit)
+    )
+    thousand_graph |= (
+        graph_digit
+        + insert_space
+        + pynini.cross("000", "thousand")
+        + pynini.closure(pynutil.delete(" "), 0, 1)
+        + pynini.accep("s")
+    )
+
+    graph |= graph_with_s
+    if deterministic:
+        graph = plurals._priority_union(thousand_graph, graph, NEMO_SIGMA)
+    else:
+        graph |= thousand_graph
+
+    return graph.optimize()
+
+
+def _get_two_digit_year_with_s_graph():
+    # to handle '70s -> seventies
     graph = (
-        graph_ties + insert_space + graph_ties
-        | graph_teen + insert_space + pynini.cross("00", "hundred")
-        | (graph_teen + insert_space + (ties_graph | pynini.cross("1", "ten")) + pynutil.delete("0s"))
-        @ pynini.cdrewrite(pynini.cross("y", "ies") | pynutil.insert("s"), "", "[EOS]", NEMO_SIGMA)
-        | pynutil.add_weight(
-            graph_digit
-            + insert_space
-            + pynini.cross("00", "thousand")
-            + (pynutil.delete("0") | insert_space + graph_digit),
-            weight=-0.001,
-        )
-        | pynutil.add_weight(
-            graph_digit
-            + insert_space
-            + pynini.cross("000", "thousand")
-            + pynini.closure(pynutil.delete(" "), 0, 1)
-            + pynini.accep("s"),
-            weight=-0.001,
+        pynini.closure(pynutil.delete("'"), 0, 1)
+        + pynini.compose(
+            ties_graph + pynutil.delete("0s"), pynini.cdrewrite(pynini.cross("y", "ies"), "", "[EOS]", NEMO_SIGMA)
         )
-    )
+    ).optimize()
     return graph
 
 
-def _get_year_graph(deterministic: bool = True):
+def _get_year_graph(cardinal_graph, deterministic: bool = True):
     """
     Transducer for year, only from 1000 - 2999 e.g.
     1290 -> twelve nineteen
     2000 - 2009 will be verbalized as two thousand.
+    
+    Transducer for 3 digit year, e.g. 123-> one twenty three
+    
+    Transducer for year with suffix
+    123 A.D., 4200 B.C
     """
-    graph = get_hundreds_graph(deterministic)
-    graph = (
-        pynini.union("1", "2")
-        + NEMO_DIGIT
-        + NEMO_DIGIT
-        + NEMO_DIGIT
-        + pynini.closure(pynini.cross(" s", "s") | "s", 0, 1)
-    ) @ graph
-    return graph
+    graph = get_four_digit_year_graph(deterministic)
+    graph = (pynini.union("1", "2") + (NEMO_DIGIT ** 3) + pynini.closure(pynini.cross(" s", "s") | "s", 0, 1)) @ graph
+
+    graph |= _get_two_digit_year_with_s_graph()
+
+    three_digit_year = (NEMO_DIGIT @ cardinal_graph) + insert_space + (NEMO_DIGIT ** 2) @ cardinal_graph
+    year_with_suffix = (
+        (get_four_digit_year_graph(deterministic=True) | three_digit_year) + delete_space + insert_space + year_suffix
+    )
+    graph |= year_with_suffix
+    return graph.optimize()
+
+
+def _get_two_digit_year(cardinal_graph, single_digits_graph):
+    wo_digit_year = NEMO_DIGIT ** (2) @ plurals._priority_union(cardinal_graph, single_digits_graph, NEMO_SIGMA)
+    return wo_digit_year
 
 
 class DateFst(GraphFst):
     """
     Finite state transducer for classifying date, e.g. 
         jan. 5, 2012 -> date { month: "january" day: "five" year: "twenty twelve" preserve_order: true }
         jan. 5 -> date { month: "january" day: "five" preserve_order: true }
@@ -122,42 +166,44 @@
 
     Args:
         cardinal: CardinalFst
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self, cardinal: GraphFst, deterministic: bool):
+    def __init__(self, cardinal: GraphFst, deterministic: bool, lm: bool = False):
         super().__init__(name="date", kind="classify", deterministic=deterministic)
 
-        month_graph = pynini.string_file(get_abs_path("data/months/names.tsv")).optimize()
+        # january
+        month_graph = pynini.string_file(get_abs_path("data/date/month_name.tsv")).optimize()
+        # January, JANUARY
         month_graph |= pynini.compose(TO_LOWER + pynini.closure(NEMO_CHAR), month_graph) | pynini.compose(
             TO_LOWER ** (2, ...), month_graph
         )
 
-        month_abbr_graph = pynini.string_file(get_abs_path("data/months/abbr.tsv")).optimize()
+        # jan
+        month_abbr_graph = pynini.string_file(get_abs_path("data/date/month_abbr.tsv")).optimize()
+        # jan, Jan, JAN
         month_abbr_graph = (
             month_abbr_graph
             | pynini.compose(TO_LOWER + pynini.closure(NEMO_LOWER, 1), month_abbr_graph).optimize()
             | pynini.compose(TO_LOWER ** (2, ...), month_abbr_graph).optimize()
         ) + pynini.closure(pynutil.delete("."), 0, 1)
         month_graph |= month_abbr_graph.optimize()
 
-        month_numbers_graph = pynini.string_file(get_abs_path("data/months/numbers.tsv")).optimize()
+        month_numbers_labels = pynini.string_file(get_abs_path("data/date/month_number.tsv")).optimize()
         cardinal_graph = cardinal.graph_hundred_component_at_least_one_none_zero_digit
 
-        year_graph = _get_year_graph(deterministic)
+        year_graph = _get_year_graph(cardinal_graph=cardinal_graph, deterministic=deterministic)
 
-        YEAR_WEIGHT = 0.001
-        year_graph_standalone = (
-            pynutil.insert("year: \"") + pynutil.add_weight(year_graph, YEAR_WEIGHT) + pynutil.insert("\"")
-        )
+        # three_digit_year = (NEMO_DIGIT @ cardinal_graph) + insert_space + (NEMO_DIGIT ** 2) @ cardinal_graph
+        # year_graph |= three_digit_year
 
         month_graph = pynutil.insert("month: \"") + month_graph + pynutil.insert("\"")
-        month_numbers_graph = pynutil.insert("month: \"") + month_numbers_graph + pynutil.insert("\"")
+        month_numbers_graph = pynutil.insert("month: \"") + month_numbers_labels + pynutil.insert("\"")
 
         endings = ["rd", "th", "st", "nd"]
         endings += [x.upper() for x in endings]
         endings = pynini.union(*endings)
 
         day_graph = (
             pynutil.insert("day: \"")
@@ -166,72 +212,116 @@
                 ((pynini.union("1", "2") + NEMO_DIGIT) | NEMO_DIGIT | (pynini.accep("3") + pynini.union("0", "1")))
                 + pynini.closure(pynutil.delete(endings), 0, 1)
             )
             @ cardinal_graph
             + pynutil.insert("\"")
         )
 
-        two_digit_year = NEMO_DIGIT ** (2) @ (cardinal.single_digits_graph | cardinal_graph)
+        two_digit_year = _get_two_digit_year(
+            cardinal_graph=cardinal_graph, single_digits_graph=cardinal.single_digits_graph
+        )
         two_digit_year = pynutil.insert("year: \"") + two_digit_year + pynutil.insert("\"")
+
+        # if lm:
+        #     two_digit_year = pynini.compose(pynini.difference(NEMO_DIGIT, "0") + NEMO_DIGIT ** (3), two_digit_year)
+        #     year_graph = pynini.compose(pynini.difference(NEMO_DIGIT, "0") + NEMO_DIGIT ** (2), year_graph)
+        #     year_graph |= pynini.compose(pynini.difference(NEMO_DIGIT, "0") + NEMO_DIGIT ** (4, ...), year_graph)
+
         graph_year = pynutil.insert(" year: \"") + pynutil.delete(" ") + year_graph + pynutil.insert("\"")
+        graph_year |= (
+            pynutil.insert(" year: \"")
+            + pynini.accep(",")
+            + pynini.closure(pynini.accep(" "), 0, 1)
+            + year_graph
+            + pynutil.insert("\"")
+        )
         optional_graph_year = pynini.closure(graph_year, 0, 1)
+
         year_graph = pynutil.insert("year: \"") + year_graph + pynutil.insert("\"")
 
         graph_mdy = month_graph + (
             (delete_extra_space + day_graph)
             | (pynini.accep(" ") + day_graph)
             | graph_year
             | (delete_extra_space + day_graph + graph_year)
         )
 
-        delete_sep = pynutil.delete(pynini.union("-", "/", "."))
         graph_mdy |= (
-            month_numbers_graph
-            + delete_sep
-            + insert_space
-            + pynini.closure(pynutil.delete("0"), 0, 1)
+            month_graph
+            + pynini.cross("-", " ")
             + day_graph
-            + delete_sep
-            + insert_space
-            + (year_graph | two_digit_year)
+            + pynini.closure(((pynini.cross("-", " ") + NEMO_SIGMA) @ graph_year), 0, 1)
         )
 
+        for x in ["-", "/", "."]:
+            delete_sep = pynutil.delete(x)
+            graph_mdy |= (
+                month_numbers_graph
+                + delete_sep
+                + insert_space
+                + pynini.closure(pynutil.delete("0"), 0, 1)
+                + day_graph
+                + delete_sep
+                + insert_space
+                + (year_graph | two_digit_year)
+            )
+
         graph_dmy = day_graph + delete_extra_space + month_graph + optional_graph_year
-        graph_ymd = (
-            (year_graph | two_digit_year)
-            + delete_sep
-            + insert_space
-            + month_numbers_graph
-            + delete_sep
-            + insert_space
-            + pynini.closure(pynutil.delete("0"), 0, 1)
-            + day_graph
-        )
+        day_ex_month = (NEMO_DIGIT ** 2 - pynini.project(month_numbers_graph, "input")) @ day_graph
+        for x in ["-", "/", "."]:
+            delete_sep = pynutil.delete(x)
+            graph_dmy |= (
+                day_ex_month
+                + delete_sep
+                + insert_space
+                + month_numbers_graph
+                + delete_sep
+                + insert_space
+                + (year_graph | two_digit_year)
+            )
+
+        graph_ymd = pynini.accep("")
+        for x in ["-", "/", "."]:
+            delete_sep = pynutil.delete(x)
+            graph_ymd |= (
+                (year_graph | two_digit_year)
+                + delete_sep
+                + insert_space
+                + month_numbers_graph
+                + delete_sep
+                + insert_space
+                + pynini.closure(pynutil.delete("0"), 0, 1)
+                + day_graph
+            )
 
         final_graph = graph_mdy | graph_dmy
 
-        if deterministic:
-            final_graph += pynutil.insert(" preserve_order: true")
-        else:
+        if not deterministic or lm:
             final_graph += pynini.closure(pynutil.insert(" preserve_order: true"), 0, 1)
             m_sep_d = (
-                month_numbers_graph + delete_sep + insert_space + pynini.closure(pynutil.delete("0"), 0, 1) + day_graph
+                month_numbers_graph
+                + pynutil.delete(pynini.union("-", "/"))
+                + insert_space
+                + pynini.closure(pynutil.delete("0"), 0, 1)
+                + day_graph
             )
             final_graph |= m_sep_d
+        else:
+            final_graph += pynutil.insert(" preserve_order: true")
 
-        final_graph |= graph_ymd | year_graph_standalone
+        final_graph |= graph_ymd | year_graph
 
-        if not deterministic:
+        if not deterministic or lm:
             ymd_to_mdy_graph = None
             ymd_to_dmy_graph = None
             mdy_to_dmy_graph = None
             md_to_dm_graph = None
 
-            for month in [x[0] for x in load_labels(get_abs_path("data/months/names.tsv"))]:
-                for day in [x[0] for x in load_labels(get_abs_path("data/months/days.tsv"))]:
+            for month in [x[0] for x in load_labels(get_abs_path("data/date/month_name.tsv"))]:
+                for day in [x[0] for x in load_labels(get_abs_path("data/date/day.tsv"))]:
                     ymd_to_mdy_curr = (
                         pynutil.insert("month: \"" + month + "\" day: \"" + day + "\" ")
                         + pynini.accep('year:')
                         + NEMO_SIGMA
                         + pynutil.delete(" month: \"" + month + "\" day: \"" + day + "\"")
                     )
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/decimal.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,57 +1,72 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_SIGMA, GraphFst, delete_extra_space
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_SIGMA, TO_UPPER, GraphFst, get_abs_path
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     delete_space = pynutil.delete(" ")
+    quantities = pynini.string_file(get_abs_path("data/number/thousand.tsv"))
+    quantities_abbr = pynini.string_file(get_abs_path("data/number/quantity_abbr.tsv"))
+    quantities_abbr |= TO_UPPER @ quantities_abbr
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-def get_quantity(decimal: 'pynini.FstLike', cardinal_up_to_hundred: 'pynini.FstLike') -> 'pynini.FstLike':
+def get_quantity(
+    decimal: 'pynini.FstLike', cardinal_up_to_hundred: 'pynini.FstLike', include_abbr: bool
+) -> 'pynini.FstLike':
     """
     Returns FST that transforms either a cardinal or decimal followed by a quantity into a numeral,
     e.g. 1 million -> integer_part: "one" quantity: "million"
     e.g. 1.5 million -> integer_part: "one" fractional_part: "five" quantity: "million"
 
     Args: 
         decimal: decimal FST
         cardinal_up_to_hundred: cardinal FST
     """
-    numbers = cardinal_up_to_hundred
-    suffix = pynini.union("million", "billion", "trillion", "quadrillion", "quintillion", "sextillion")
+    quantity_wo_thousand = pynini.project(quantities, "input") - pynini.union("k", "K", "thousand")
+    if include_abbr:
+        quantity_wo_thousand |= pynini.project(quantities_abbr, "input") - pynini.union("k", "K", "thousand")
     res = (
         pynutil.insert("integer_part: \"")
-        + numbers
+        + cardinal_up_to_hundred
         + pynutil.insert("\"")
-        + delete_extra_space
+        + pynini.closure(pynutil.delete(" "), 0, 1)
         + pynutil.insert("quantity: \"")
-        + suffix
+        + (quantity_wo_thousand @ (quantities | quantities_abbr))
+        + pynutil.insert("\"")
+    )
+    if include_abbr:
+        quantity = quantities | quantities_abbr
+    else:
+        quantity = quantities
+    res |= (
+        decimal
+        + pynini.closure(pynutil.delete(" "), 0, 1)
+        + pynutil.insert("quantity: \"")
+        + quantity
         + pynutil.insert("\"")
     )
-    res |= decimal + delete_extra_space + pynutil.insert("quantity: \"") + (suffix | "thousand") + pynutil.insert("\"")
     return res
 
 
 class DecimalFst(GraphFst):
     """
     Finite state transducer for classifying decimal, e.g. 
         -12.5006 billion -> decimal { negative: "true" integer_part: "12"  fractional_part: "five o o six" quantity: "billion" }
@@ -59,15 +74,15 @@
 
     cardinal: CardinalFst
     """
 
     def __init__(self, cardinal: GraphFst, deterministic: bool):
         super().__init__(name="decimal", kind="classify", deterministic=deterministic)
 
-        cardinal_graph = cardinal.graph
+        cardinal_graph = cardinal.graph_with_and
         cardinal_graph_hundred_component_at_least_one_none_zero_digit = (
             cardinal.graph_hundred_component_at_least_one_none_zero_digit
         )
 
         self.graph = cardinal.single_digits_graph.optimize()
 
         if not deterministic:
@@ -81,17 +96,22 @@
         final_graph_wo_sign = (
             pynini.closure(self.graph_integer + pynutil.insert(" "), 0, 1)
             + point
             + pynutil.insert(" ")
             + self.graph_fractional
         )
 
-        self.final_graph_wo_negative = final_graph_wo_sign | get_quantity(
-            final_graph_wo_sign, cardinal_graph_hundred_component_at_least_one_none_zero_digit
+        quantity_w_abbr = get_quantity(
+            final_graph_wo_sign, cardinal_graph_hundred_component_at_least_one_none_zero_digit, include_abbr=True
+        )
+        quantity_wo_abbr = get_quantity(
+            final_graph_wo_sign, cardinal_graph_hundred_component_at_least_one_none_zero_digit, include_abbr=False
         )
+        self.final_graph_wo_negative_w_abbr = final_graph_wo_sign | quantity_w_abbr
+        self.final_graph_wo_negative = final_graph_wo_sign | quantity_wo_abbr
 
         # reduce options for non_deterministic and allow either "oh" or "zero", but not combination
         if not deterministic:
             no_oh_zero = pynini.difference(
                 NEMO_SIGMA,
                 (NEMO_SIGMA + "oh" + NEMO_SIGMA + "zero" + NEMO_SIGMA)
                 | (NEMO_SIGMA + "zero" + NEMO_SIGMA + "oh" + NEMO_SIGMA),
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/electronic.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,77 +1,84 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_ALPHA, NEMO_DIGIT, GraphFst, get_abs_path
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_ALPHA, NEMO_DIGIT, GraphFst, insert_space
+from nemo_text_processing.text_normalization.es.utils import get_abs_path, load_labels
 
 try:
     import pynini
     from pynini.lib import pynutil
 
+    common_domains = [x[0] for x in load_labels(get_abs_path("data/electronic/domain.tsv"))]
+    symbols = [x[0] for x in load_labels(get_abs_path("data/electronic/symbols.tsv"))]
+
     PYNINI_AVAILABLE = True
+
 except (ModuleNotFoundError, ImportError):
+    common_domains = None
+    symbols = None
+
     PYNINI_AVAILABLE = False
 
 
 class ElectronicFst(GraphFst):
     """
-    Finite state transducer for classifying electronic: as URLs, email addresses, etc.
-        e.g. cdf1@abc.edu -> tokens { electronic { username: "cdf1" domain: "abc.edu" } }
+    Finite state transducer for classifying electronic: email addresses
+        e.g. "abc@hotmail.com" -> electronic { username: "abc" domain: "hotmail.com" preserve_order: true }
+        e.g. "www.abc.com/123" -> electronic { protocol: "www." domain: "abc.com/123" preserve_order: true }
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="electronic", kind="classify", deterministic=deterministic)
 
-        def get_input_symbols(f):
-            accepted_symbols = []
-            with open(f, 'r', encoding='utf-8') as f:
-                for line in f:
-                    symbol, _ = line.split('\t')
-                    accepted_symbols.append(pynini.accep(symbol))
-            return accepted_symbols
-
-        accepted_symbols = get_input_symbols(get_abs_path("data/electronic/symbols.tsv"))
-        accepted_common_domains = get_input_symbols(get_abs_path("data/electronic/domain.tsv"))
-        accepted_symbols = NEMO_ALPHA + pynini.closure(NEMO_ALPHA | NEMO_DIGIT | pynini.union(*accepted_symbols))
-        graph_symbols = pynini.string_file(get_abs_path("data/electronic/symbols.tsv")).optimize()
-
-        username = pynutil.insert("username: \"") + accepted_symbols + pynutil.insert("\"") + pynini.cross('@', ' ')
-        domain_graph = accepted_symbols + pynini.accep('.') + accepted_symbols
+        dot = pynini.accep(".")
+        accepted_common_domains = pynini.union(*common_domains)
+        accepted_symbols = pynini.union(*symbols) - dot
+        accepted_characters = pynini.closure(NEMO_ALPHA | NEMO_DIGIT | accepted_symbols)
+        acceepted_characters_with_dot = pynini.closure(NEMO_ALPHA | NEMO_DIGIT | accepted_symbols | dot)
+
+        # email
+        username = (
+            pynutil.insert("username: \"")
+            + acceepted_characters_with_dot
+            + pynutil.insert("\"")
+            + pynini.cross('@', ' ')
+        )
+        domain_graph = accepted_characters + dot + accepted_characters
         domain_graph = pynutil.insert("domain: \"") + domain_graph + pynutil.insert("\"")
         domain_common_graph = (
             pynutil.insert("domain: \"")
-            + accepted_symbols
-            + pynini.union(*accepted_common_domains)
+            + accepted_characters
+            + accepted_common_domains
+            + pynini.closure((accepted_symbols | dot) + pynini.closure(accepted_characters, 1), 0, 1)
             + pynutil.insert("\"")
         )
+        graph = (username + domain_graph) | domain_common_graph
 
+        # url
         protocol_start = pynini.accep("https://") | pynini.accep("http://")
-        protocol_symbols = pynini.closure(
-            (NEMO_ALPHA | pynutil.add_weight(graph_symbols | pynini.cross(":", "colon"), -0.1)) + pynutil.insert(" ")
+        protocol_end = (
+            pynini.accep("www.")
+            if deterministic
+            else pynini.accep("www.") | pynini.cross("www.", "doble ve doble ve doble ve.")
         )
-        protocol_end = pynini.accep("www.")
         protocol = protocol_start | protocol_end | (protocol_start + protocol_end)
-        protocol = pynini.compose(protocol, protocol_symbols)
         protocol = pynutil.insert("protocol: \"") + protocol + pynutil.insert("\"")
-        graph = username + domain_graph
-        graph |= domain_common_graph
-        graph |= protocol + pynutil.insert(" ") + domain_graph
+        graph |= protocol + insert_space + (domain_graph | domain_common_graph)
+        self.graph = graph
 
-        final_graph = self.add_tokens(graph)
+        final_graph = self.add_tokens(self.graph + pynutil.insert(" preserve_order: true"))
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/fraction.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
+from nemo_text_processing.text_normalization.en.graph_utils import GraphFst, get_abs_path
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
@@ -25,31 +24,38 @@
 
 
 class FractionFst(GraphFst):
     """
     Finite state transducer for classifying fraction
     "23 4/5" ->
     tokens { fraction { integer: "twenty three" numerator: "four" denominator: "five" } }
+    "23 4/5th" ->
+    tokens { fraction { integer: "twenty three" numerator: "four" denominator: "five" } }
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, cardinal, deterministic: bool = True):
         super().__init__(name="fraction", kind="classify", deterministic=deterministic)
         cardinal_graph = cardinal.graph
 
-        integer = pynutil.insert("integer_part: \"") + cardinal_graph + pynutil.insert("\"") + pynini.accep(" ")
+        integer = pynutil.insert("integer_part: \"") + cardinal_graph + pynutil.insert("\"")
         numerator = (
             pynutil.insert("numerator: \"") + cardinal_graph + (pynini.cross("/", "\" ") | pynini.cross(" / ", "\" "))
         )
 
         endings = ["rd", "th", "st", "nd"]
         endings += [x.upper() for x in endings]
         optional_end = pynini.closure(pynini.cross(pynini.union(*endings), ""), 0, 1)
 
         denominator = pynutil.insert("denominator: \"") + cardinal_graph + optional_end + pynutil.insert("\"")
 
-        self.graph = pynini.closure(integer, 0, 1) + numerator + denominator
+        graph = pynini.closure(integer + pynini.accep(" "), 0, 1) + (numerator + denominator)
+        graph |= pynini.closure(integer + (pynini.accep(" ") | pynutil.insert(" ")), 0, 1) + pynini.compose(
+            pynini.string_file(get_abs_path("data/number/fraction.tsv")), (numerator + denominator)
+        )
+
+        self.graph = graph
         final_graph = self.add_tokens(self.graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/measure.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,27 +14,32 @@
 
 from nemo_text_processing.text_normalization.en.graph_utils import (
     NEMO_ALPHA,
     NEMO_DIGIT,
     NEMO_NON_BREAKING_SPACE,
     NEMO_SIGMA,
     NEMO_SPACE,
+    NEMO_UPPER,
     SINGULAR_TO_PLURAL,
     TO_LOWER,
     GraphFst,
     convert_space,
     delete_space,
+    delete_zero_or_one_space,
+    insert_space,
 )
 from nemo_text_processing.text_normalization.en.taggers.ordinal import OrdinalFst as OrdinalTagger
-from nemo_text_processing.text_normalization.en.utils import get_abs_path
+from nemo_text_processing.text_normalization.en.taggers.whitelist import get_formats
+from nemo_text_processing.text_normalization.en.utils import get_abs_path, load_labels
 from nemo_text_processing.text_normalization.en.verbalizers.ordinal import OrdinalFst as OrdinalVerbalizer
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class MeasureFst(GraphFst):
@@ -51,30 +55,35 @@
         fraction: FractionFst
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, cardinal: GraphFst, decimal: GraphFst, fraction: GraphFst, deterministic: bool = True):
         super().__init__(name="measure", kind="classify", deterministic=deterministic)
-        cardinal_graph = cardinal.graph
+        cardinal_graph = cardinal.graph_with_and | self.get_range(cardinal.graph_with_and)
 
+        graph_unit = pynini.string_file(get_abs_path("data/measure/unit.tsv"))
         if not deterministic:
-            cardinal_graph |= cardinal.range_graph
+            graph_unit |= pynini.string_file(get_abs_path("data/measure/unit_alternatives.tsv"))
 
-        graph_unit = pynini.string_file(get_abs_path("data/measurements.tsv"))
-        graph_unit |= pynini.compose(pynini.closure(TO_LOWER, 1) + pynini.closure(NEMO_ALPHA), graph_unit)
+        graph_unit |= pynini.compose(
+            pynini.closure(TO_LOWER, 1) + (NEMO_ALPHA | TO_LOWER) + pynini.closure(NEMO_ALPHA | TO_LOWER), graph_unit
+        ).optimize()
 
         graph_unit_plural = convert_space(graph_unit @ SINGULAR_TO_PLURAL)
         graph_unit = convert_space(graph_unit)
+
         optional_graph_negative = pynini.closure(pynutil.insert("negative: ") + pynini.cross("-", "\"true\" "), 0, 1)
 
-        graph_unit2 = pynini.cross("/", "per") + delete_space + pynutil.insert(NEMO_NON_BREAKING_SPACE) + graph_unit
+        graph_unit2 = (
+            pynini.cross("/", "per") + delete_zero_or_one_space + pynutil.insert(NEMO_NON_BREAKING_SPACE) + graph_unit
+        )
 
         optional_graph_unit2 = pynini.closure(
-            delete_space + pynutil.insert(NEMO_NON_BREAKING_SPACE) + graph_unit2, 0, 1,
+            delete_zero_or_one_space + pynutil.insert(NEMO_NON_BREAKING_SPACE) + graph_unit2, 0, 1,
         )
 
         unit_plural = (
             pynutil.insert("units: \"")
             + (graph_unit_plural + optional_graph_unit2 | graph_unit2)
             + pynutil.insert("\"")
         )
@@ -88,14 +97,25 @@
             + optional_graph_negative
             + decimal.final_graph_wo_negative
             + delete_space
             + pynutil.insert(" } ")
             + unit_plural
         )
 
+        # support radio FM/AM
+        subgraph_decimal |= (
+            pynutil.insert("decimal { ")
+            + decimal.final_graph_wo_negative
+            + delete_space
+            + pynutil.insert(" } ")
+            + pynutil.insert("units: \"")
+            + pynini.union("AM", "FM")
+            + pynutil.insert("\"")
+        )
+
         subgraph_cardinal = (
             pynutil.insert("cardinal { ")
             + optional_graph_negative
             + pynutil.insert("integer: \"")
             + ((NEMO_SIGMA - "1") @ cardinal_graph)
             + delete_space
             + pynutil.insert("\"")
@@ -110,31 +130,21 @@
             + pynini.cross("1", "one")
             + delete_space
             + pynutil.insert("\"")
             + pynutil.insert(" } ")
             + unit_singular
         )
 
-        cardinal_dash_alpha = (
-            pynutil.insert("cardinal { integer: \"")
-            + cardinal_graph
-            + pynini.accep('-')
-            + pynutil.insert("\" } units: \"")
-            + pynini.closure(NEMO_ALPHA, 1)
-            + pynutil.insert("\"")
-        )
-
-        alpha_dash_cardinal = (
-            pynutil.insert("units: \"")
-            + pynini.closure(NEMO_ALPHA, 1)
-            + pynini.accep('-')
-            + pynutil.insert("\"")
-            + pynutil.insert(" cardinal { integer: \"")
-            + cardinal_graph
-            + pynutil.insert("\" } preserve_order: true")
+        unit_graph = (
+            pynutil.insert("cardinal { integer: \"-\" } units: \"")
+            + pynini.cross(pynini.union("/", "per"), "per")
+            + delete_zero_or_one_space
+            + pynutil.insert(NEMO_NON_BREAKING_SPACE)
+            + graph_unit
+            + pynutil.insert("\" preserve_order: true")
         )
 
         decimal_dash_alpha = (
             pynutil.insert("decimal { ")
             + decimal.final_graph_wo_negative
             + pynini.cross('-', '')
             + pynutil.insert(" } units: \"")
@@ -167,48 +177,66 @@
         address = self.get_address_graph(cardinal)
         address = (
             pynutil.insert("units: \"address\" cardinal { integer: \"")
             + address
             + pynutil.insert("\" } preserve_order: true")
         )
 
-        math_operations = pynini.string_file(get_abs_path("data/math_operations.tsv"))
+        math_operations = pynini.string_file(get_abs_path("data/measure/math_operation.tsv"))
         delimiter = pynini.accep(" ") | pynutil.insert(" ")
 
         math = (
-            cardinal_graph
+            (cardinal_graph | NEMO_ALPHA)
             + delimiter
             + math_operations
-            + delimiter
+            + (delimiter | NEMO_ALPHA)
             + cardinal_graph
             + delimiter
             + pynini.cross("=", "equals")
             + delimiter
-            + cardinal_graph
+            + (cardinal_graph | NEMO_ALPHA)
         )
         math = (
             pynutil.insert("units: \"math\" cardinal { integer: \"")
             + math
             + pynutil.insert("\" } preserve_order: true")
         )
         final_graph = (
             subgraph_decimal
             | subgraph_cardinal
-            | cardinal_dash_alpha
-            | alpha_dash_cardinal
+            | unit_graph
             | decimal_dash_alpha
             | decimal_times
             | alpha_dash_decimal
             | subgraph_fraction
             | address
             | math
         )
+
         final_graph = self.add_tokens(final_graph)
         self.fst = final_graph.optimize()
 
+    def get_range(self, cardinal: GraphFst):
+        """
+        Returns range forms for measure tagger, e.g. 2-3, 2x3, 2*2
+
+        Args:
+            cardinal: cardinal GraphFst
+        """
+        range_graph = cardinal + pynini.cross(pynini.union("-", " - "), " to ") + cardinal
+
+        for x in [" x ", "x"]:
+            range_graph |= cardinal + pynini.cross(x, " by ") + cardinal
+            if not self.deterministic:
+                range_graph |= cardinal + pynini.cross(x, " times ") + cardinal
+
+        for x in ["*", " * "]:
+            range_graph |= cardinal + pynini.cross(x, " times ") + cardinal
+        return range_graph.optimize()
+
     def get_address_graph(self, cardinal):
         """
         Finite state transducer for classifying serial.
             The serial is a combination of digits, letters and dashes, e.g.:
             2788 San Tomas Expy, Santa Clara, CA 95051 ->
                 units: "address" cardinal
                 { integer: "two seven eight eight San Tomas Expressway Santa Clara California nine five zero five one" }
@@ -216,50 +244,54 @@
         """
         ordinal_verbalizer = OrdinalVerbalizer().graph
         ordinal_tagger = OrdinalTagger(cardinal=cardinal).graph
         ordinal_num = pynini.compose(
             pynutil.insert("integer: \"") + ordinal_tagger + pynutil.insert("\""), ordinal_verbalizer
         )
 
-        address_num = pynini.closure(NEMO_DIGIT, 1) @ cardinal.single_digits_graph
+        address_num = NEMO_DIGIT ** (1, 2) @ cardinal.graph_hundred_component_at_least_one_none_zero_digit
+        address_num += insert_space + NEMO_DIGIT ** 2 @ (
+            pynini.closure(pynini.cross("0", "zero "), 0, 1)
+            + cardinal.graph_hundred_component_at_least_one_none_zero_digit
+        )
+        # to handle the rest of the numbers
+        address_num = pynini.compose(NEMO_DIGIT ** (3, 4), address_num)
+        address_num = plurals._priority_union(address_num, cardinal.graph, NEMO_SIGMA)
 
         direction = (
             pynini.cross("E", "East")
             | pynini.cross("S", "South")
             | pynini.cross("W", "West")
             | pynini.cross("N", "North")
-        )
-        direction = pynini.closure(pynutil.add_weight(pynini.accep(NEMO_SPACE) + direction, -1), 0, 1)
+        ) + pynini.closure(pynutil.delete("."), 0, 1)
 
-        address_words = pynini.string_file(get_abs_path("data/address/address_words.tsv"))
+        direction = pynini.closure(pynini.accep(NEMO_SPACE) + direction, 0, 1)
+        address_words = get_formats(get_abs_path("data/address/address_word.tsv"))
         address_words = (
             pynini.accep(NEMO_SPACE)
-            + pynini.closure(ordinal_num, 0, 1)
-            + pynini.closure(NEMO_ALPHA | NEMO_SPACE, 1)
+            + (pynini.closure(ordinal_num, 0, 1) | NEMO_UPPER + pynini.closure(NEMO_ALPHA, 1))
+            + NEMO_SPACE
+            + pynini.closure(NEMO_UPPER + pynini.closure(NEMO_ALPHA) + NEMO_SPACE)
             + address_words
         )
 
         city = pynini.closure(NEMO_ALPHA | pynini.accep(NEMO_SPACE), 1)
-        city = pynini.closure(pynini.cross(",", "") + pynini.accep(NEMO_SPACE) + city, 0, 1)
+        city = pynini.closure(pynini.accep(",") + pynini.accep(NEMO_SPACE) + city, 0, 1)
+
+        states = load_labels(get_abs_path("data/address/state.tsv"))
 
-        state = pynini.invert(pynini.string_file(get_abs_path("data/address/states.tsv")))
-        state = pynini.closure(pynini.cross(",", "") + pynini.accep(NEMO_SPACE) + state, 0, 1)
+        additional_options = []
+        for x, y in states:
+            additional_options.append((x, f"{y[0]}.{y[1:]}"))
+        states.extend(additional_options)
+        state_graph = pynini.string_map(states)
+        state = pynini.invert(state_graph)
+        state = pynini.closure(pynini.accep(",") + pynini.accep(NEMO_SPACE) + state, 0, 1)
 
         zip_code = pynini.compose(NEMO_DIGIT ** 5, cardinal.single_digits_graph)
-        zip_code = pynini.closure(
-            pynutil.add_weight(
-                pynini.closure(pynini.cross(",", ""), 0, 1) + pynini.accep(NEMO_SPACE) + zip_code, -100
-            ),
-            0,
-            1,
-        )
+        zip_code = pynini.closure(pynini.closure(pynini.accep(","), 0, 1) + pynini.accep(NEMO_SPACE) + zip_code, 0, 1,)
+
+        address = address_num + direction + address_words + pynini.closure(city + state + zip_code, 0, 1)
+
+        address |= address_num + direction + address_words + pynini.closure(pynini.cross(".", ""), 0, 1)
 
-        address = (
-            address_num
-            + direction
-            + address_words
-            + pynini.closure(pynini.cross(".", ""), 0, 1)
-            + city
-            + state
-            + zip_code
-        )
         return address
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/money.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -24,17 +23,17 @@
 )
 from nemo_text_processing.text_normalization.en.utils import get_abs_path, load_labels
 
 try:
     import pynini
     from pynini.lib import pynutil
 
-    min_singular = pynini.string_file(get_abs_path("data/currency/currency_minor_singular.tsv"))
-    min_plural = pynini.string_file(get_abs_path("data/currency/currency_minor_plural.tsv"))
-    maj_singular = pynini.string_file((get_abs_path("data/currency/currency.tsv")))
+    min_singular = pynini.string_file(get_abs_path("data/money/currency_minor_singular.tsv"))
+    min_plural = pynini.string_file(get_abs_path("data/money/currency_minor_plural.tsv"))
+    maj_singular = pynini.string_file((get_abs_path("data/money/currency_major.tsv")))
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class MoneyFst(GraphFst):
@@ -54,18 +53,18 @@
         decimal: DecimalFst
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, cardinal: GraphFst, decimal: GraphFst, deterministic: bool = True):
         super().__init__(name="money", kind="classify", deterministic=deterministic)
-        cardinal_graph = cardinal.graph
-        graph_decimal_final = decimal.final_graph_wo_negative
+        cardinal_graph = cardinal.graph_with_and
+        graph_decimal_final = decimal.final_graph_wo_negative_w_abbr
 
-        maj_singular_labels = load_labels(get_abs_path("data/currency/currency.tsv"))
+        maj_singular_labels = load_labels(get_abs_path("data/money/currency_major.tsv"))
         maj_unit_plural = convert_space(maj_singular @ SINGULAR_TO_PLURAL)
         maj_unit_singular = convert_space(maj_singular)
 
         graph_maj_singular = pynutil.insert("currency_maj: \"") + maj_unit_singular + pynutil.insert("\"")
         graph_maj_plural = pynutil.insert("currency_maj: \"") + maj_unit_plural + pynutil.insert("\"")
 
         optional_delete_fractional_zeros = pynini.closure(
@@ -183,15 +182,15 @@
                 decimal_default_reordered = (
                     decimal_default_reordered_curr
                     if decimal_default_reordered is None
                     else pynini.union(decimal_default_reordered, decimal_default_reordered_curr)
                 ).optimize()
 
         # weight for SH
-        final_graph |= pynutil.add_weight(decimal_graph_with_minor, -0.001)
+        final_graph |= pynutil.add_weight(decimal_graph_with_minor, -0.0001)
 
         if not deterministic:
             final_graph |= integer_graph_reordered | decimal_default_reordered
             # to handle "$2.00" cases
             final_graph |= pynini.compose(
                 NEMO_SIGMA + pynutil.delete(".") + pynini.closure(pynutil.delete("0"), 1), integer_graph_reordered
             )
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/cardinal.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,49 +1,50 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_DIGIT, GraphFst
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
-except (ImportError, ModuleNotFoundError):
+except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class OrdinalFst(GraphFst):
+class CardinalFst(GraphFst):
     """
-    Finite state transducer for classifying ordinal, e.g.
-        13th -> ordinal { integer: "thirteen" }
-        
+    Finite state transducer for verbalizing cardinals
+        e.g. cardinal { integer: "тысяча один" } -> "тысяча один"
+
     Args:
-        cardinal: CardinalFst
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self, cardinal: GraphFst, deterministic: bool = True):
-        super().__init__(name="ordinal", kind="classify", deterministic=deterministic)
-
-        cardinal_graph = cardinal.graph
-        endings = ["rd", "th", "st", "nd"]
-        endings += [x.upper() for x in endings]
-        self.graph = (
-            (pynini.closure(NEMO_DIGIT | pynini.accep(",")) + pynutil.delete(pynini.union(*endings))) @ cardinal_graph
-        ).optimize()
-        final_graph = pynutil.insert("integer: \"") + self.graph + pynutil.insert("\"")
-        final_graph = self.add_tokens(final_graph)
-        self.fst = final_graph.optimize()
+    def __init__(self, deterministic: bool = True):
+        super().__init__(name="cardinal", kind="verbalize", deterministic=deterministic)
+        optional_sign = pynini.closure(pynini.cross("negative: \"true\" ", "минус "), 0, 1)
+        optional_quantity_part = pynini.closure(
+            pynini.accep(" ")
+            + pynutil.delete("quantity: \"")
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
+            + pynutil.delete("\""),
+            0,
+            1,
+        )
+        integer = pynutil.delete("integer: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
+        self.graph = optional_sign + integer + optional_quantity_part
+        delete_tokens = self.delete_tokens(self.graph)
+        self.fst = delete_tokens.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/punctuation.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/punctuation.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,19 +11,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import sys
 from unicodedata import category
 
-from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_SPACE, NEMO_SIGMA, GraphFst
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class PunctuationFst(GraphFst):
@@ -36,17 +36,26 @@
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
 
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="punctuation", kind="classify", deterministic=deterministic)
-
         s = "!#%&\'()*+,-./:;<=>?@^_`{|}~\""
 
-        punct_unicode = [chr(i) for i in range(sys.maxunicode) if category(chr(i)).startswith("P")]
-        punct_unicode.remove('[')
-        punct_unicode.remove(']')
+        punct_unicode = [
+            chr(i) for i in range(sys.maxunicode) if category(chr(i)).startswith("P") and chr(i) not in "[]"
+        ]
         punct = pynini.union(*s) | pynini.union(*punct_unicode)
 
+        emphasis = (
+            pynini.accep("<")
+            + (
+                (pynini.closure(NEMO_NOT_SPACE - pynini.union("<", ">"), 1) + pynini.closure(pynini.accep("/"), 0, 1))
+                | (pynini.accep("/") + pynini.closure(NEMO_NOT_SPACE - pynini.union("<", ">"), 1))
+            )
+            + pynini.accep(">")
+        )
+        punct = plurals._priority_union(emphasis, punct, NEMO_SIGMA)
+
         self.graph = punct
         self.fst = (pynutil.insert("name: \"") + self.graph + pynutil.insert("\"")).optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/roman.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/ordinal.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,67 +1,59 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_CHAR, GraphFst, insert_space
-from nemo_text_processing.text_normalization.en.taggers.cardinal import CardinalFst
-from nemo_text_processing.text_normalization.en.utils import get_abs_path, load_labels
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, NEMO_SIGMA, GraphFst, delete_space
+from nemo_text_processing.text_normalization.en.utils import get_abs_path
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class RomanFst(GraphFst):
+class OrdinalFst(GraphFst):
     """
-    Finite state transducer for classifying roman numbers:
-        e.g. "IV" -> tokens { roman { integer: "four" } }
+    Finite state transducer for verbalizing ordinal, e.g.
+        ordinal { integer: "thirteen" } } -> thirteenth
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="roman", kind="classify", deterministic=deterministic)
+        super().__init__(name="ordinal", kind="verbalize", deterministic=deterministic)
 
-        def _load_roman(file: str):
-            roman = load_labels(get_abs_path(file))
-            roman_numerals = [(x, y) for x, y in roman] + [(x.upper(), y) for x, y in roman]
-            return pynini.string_map(roman_numerals)
-
-        cardinal_graph = CardinalFst(deterministic=True).graph
-        digit_teen = _load_roman("data/roman/digit_teen.tsv") @ cardinal_graph
-        ties = _load_roman("data/roman/ties.tsv") @ cardinal_graph
-        hundreds = _load_roman("data/roman/hundreds.tsv") @ cardinal_graph
+        graph_digit = pynini.string_file(get_abs_path("data/ordinal/digit.tsv")).invert()
+        graph_teens = pynini.string_file(get_abs_path("data/ordinal/teen.tsv")).invert()
 
         graph = (
-            (ties | digit_teen | hundreds)
-            | (ties + insert_space + digit_teen)
-            | (hundreds + pynini.closure(insert_space + ties, 0, 1) + pynini.closure(insert_space + digit_teen, 0, 1))
-        ).optimize()
-
-        # add a higher weight when roman number consists of a single symbol
-        graph = pynini.compose(pynini.closure(NEMO_CHAR, 2), graph) | pynutil.add_weight(
-            pynini.compose(NEMO_CHAR, graph), 101
+            pynutil.delete("integer:")
+            + delete_space
+            + pynutil.delete("\"")
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
+            + pynutil.delete("\"")
         )
-        graph = graph.optimize() + pynini.closure(pynutil.delete("."), 0, 1)
+        convert_rest = pynutil.insert("th")
 
-        graph = pynutil.insert("integer: \"") + graph + pynutil.insert("\"")
-        graph = self.add_tokens(graph)
-        self.fst = graph.optimize()
+        suffix = pynini.cdrewrite(
+            graph_digit | graph_teens | pynini.cross("ty", "tieth") | convert_rest, "", "[EOS]", NEMO_SIGMA,
+        ).optimize()
+        self.graph = pynini.compose(graph, suffix)
+        self.suffix = suffix
+        delete_tokens = self.delete_tokens(self.graph)
+        self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/telephone.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,32 +11,35 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from nemo_text_processing.text_normalization.en.graph_utils import (
     NEMO_ALPHA,
     NEMO_DIGIT,
+    NEMO_SIGMA,
     GraphFst,
+    delete_extra_space,
     delete_space,
     insert_space,
+    plurals,
 )
 from nemo_text_processing.text_normalization.en.utils import get_abs_path
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class TelephoneFst(GraphFst):
     """
-    Finite state transducer for classifying telephone, which includes country code, number part and extension 
+    Finite state transducer for classifying telephone, and IP, and SSN which includes country code, number part and extension 
     country code optional: +*** 
     number part: ***-***-****, or (***) ***-****
     extension optional: 1-9999
     E.g 
     +1 123-123-5678-1 -> telephone { country_code: "one" number_part: "one two three, one two three, five six seven eight" extension: "one" }
     1-800-GO-U-HAUL -> telephone { country_code: "one" number_part: "one, eight hundred GO U HAUL" }
     Args:
@@ -45,32 +47,35 @@
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="telephone", kind="classify", deterministic=deterministic)
 
         add_separator = pynutil.insert(", ")  # between components
-        digit = pynini.invert(pynini.string_file(get_abs_path("data/numbers/digit.tsv"))).optimize() | pynini.cross(
-            "0", "o"
-        )
+        zero = pynini.cross("0", "zero")
+        if not deterministic:
+            zero |= pynini.cross("0", pynini.union("o", "oh"))
+        digit = pynini.invert(pynini.string_file(get_abs_path("data/number/digit.tsv"))).optimize() | zero
 
+        telephone_prompts = pynini.string_file(get_abs_path("data/telephone/telephone_prompt.tsv"))
         country_code = (
-            pynutil.insert("country_code: \"")
-            + pynini.closure(pynutil.delete("+"), 0, 1)
+            pynini.closure(telephone_prompts + delete_extra_space, 0, 1)
+            + pynini.closure(pynini.cross("+", "plus "), 0, 1)
             + pynini.closure(digit + insert_space, 0, 2)
             + digit
-            + pynutil.insert("\"")
-        )
-        optional_country_code = pynini.closure(
-            country_code + pynini.closure(pynutil.delete("-"), 0, 1) + delete_space + insert_space, 0, 1
+            + pynutil.insert(",")
         )
+        country_code |= telephone_prompts
+        country_code = pynutil.insert("country_code: \"") + country_code + pynutil.insert("\"")
+        country_code = country_code + pynini.closure(pynutil.delete("-"), 0, 1) + delete_space + insert_space
 
-        area_part_common = pynutil.add_weight(pynini.cross("800", "eight hundred"), -1.1)
         area_part_default = pynini.closure(digit + insert_space, 2, 2) + digit
-        area_part = area_part_default | area_part_common
+        area_part = pynini.cross("800", "eight hundred") | pynini.compose(
+            pynini.difference(NEMO_SIGMA, "800"), area_part_default
+        )
 
         area_part = (
             (area_part + pynutil.delete("-"))
             | (pynutil.delete("(") + area_part + (pynutil.delete(") ") | pynutil.delete(")-")))
         ) + add_separator
 
         del_separator = pynini.closure(pynini.union("-", " "), 0, 1)
@@ -82,20 +87,44 @@
         )
         number_words = pynini.compose(number_length, number_words)
         number_part = area_part + number_words
         number_part = pynutil.insert("number_part: \"") + number_part + pynutil.insert("\"")
         extension = (
             pynutil.insert("extension: \"") + pynini.closure(digit + insert_space, 0, 3) + digit + pynutil.insert("\"")
         )
-        optional_extension = pynini.closure(insert_space + extension, 0, 1)
+        extension = pynini.closure(insert_space + extension, 0, 1)
 
-        graph = optional_country_code + number_part + optional_extension
+        graph = plurals._priority_union(country_code + number_part, number_part, NEMO_SIGMA).optimize()
+        graph = plurals._priority_union(country_code + number_part + extension, graph, NEMO_SIGMA).optimize()
+        graph = plurals._priority_union(number_part + extension, graph, NEMO_SIGMA).optimize()
 
         # ip
-        digit_to_str_graph = pynini.compose(
-            NEMO_DIGIT ** (1, 3), digit + pynini.closure(pynutil.insert(" ") + digit)
-        ).optimize()
+        ip_prompts = pynini.string_file(get_abs_path("data/telephone/ip_prompt.tsv"))
+        digit_to_str_graph = digit + pynini.closure(pynutil.insert(" ") + digit, 0, 2)
         ip_graph = digit_to_str_graph + (pynini.cross(".", " dot ") + digit_to_str_graph) ** 3
-        graph |= pynutil.insert("number_part: \"") + ip_graph.optimize() + pynutil.insert("\"")
+        graph |= (
+            pynini.closure(
+                pynutil.insert("country_code: \"") + ip_prompts + pynutil.insert("\"") + delete_extra_space, 0, 1
+            )
+            + pynutil.insert("number_part: \"")
+            + ip_graph.optimize()
+            + pynutil.insert("\"")
+        )
+        # ssn
+        ssn_prompts = pynini.string_file(get_abs_path("data/telephone/ssn_prompt.tsv"))
+        three_digit_part = digit + (pynutil.insert(" ") + digit) ** 2
+        two_digit_part = digit + pynutil.insert(" ") + digit
+        four_digit_part = digit + (pynutil.insert(" ") + digit) ** 3
+        ssn_separator = pynini.cross("-", ", ")
+        ssn_graph = three_digit_part + ssn_separator + two_digit_part + ssn_separator + four_digit_part
+
+        graph |= (
+            pynini.closure(
+                pynutil.insert("country_code: \"") + ssn_prompts + pynutil.insert("\"") + delete_extra_space, 0, 1
+            )
+            + pynutil.insert("number_part: \"")
+            + ssn_graph.optimize()
+            + pynutil.insert("\"")
+        )
 
         final_graph = self.add_tokens(graph)
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/time.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +16,19 @@
 from nemo_text_processing.text_normalization.en.graph_utils import (
     NEMO_DIGIT,
     GraphFst,
     convert_space,
     delete_space,
     insert_space,
 )
-from nemo_text_processing.text_normalization.en.utils import get_abs_path
+from nemo_text_processing.text_normalization.en.utils import (
+    augment_labels_with_punct_at_end,
+    get_abs_path,
+    load_labels,
+)
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
@@ -48,16 +51,19 @@
         cardinal: CardinalFst
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, cardinal: GraphFst, deterministic: bool = True):
         super().__init__(name="time", kind="classify", deterministic=deterministic)
-        suffix_graph = pynini.string_file(get_abs_path("data/time_suffix.tsv"))
-        time_zone_graph = pynini.string_file(get_abs_path("data/time_zone.tsv"))
+        suffix_labels = load_labels(get_abs_path("data/time/suffix.tsv"))
+        suffix_labels.extend(augment_labels_with_punct_at_end(suffix_labels))
+        suffix_graph = pynini.string_map(suffix_labels)
+
+        time_zone_graph = pynini.string_file(get_abs_path("data/time/zone.tsv"))
 
         # only used for < 1000 thousand -> 0 weight
         cardinal = cardinal.graph
 
         labels_hour = [str(x) for x in range(0, 24)]
         labels_minute_single = [str(x) for x in range(1, 10)]
         labels_minute_double = [str(x) for x in range(10, 60)]
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/tokenize_and_classify.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,125 +17,121 @@
 from nemo_text_processing.text_normalization.en.graph_utils import (
     NEMO_WHITE_SPACE,
     GraphFst,
     delete_extra_space,
     delete_space,
     generator_main,
 )
-from nemo_text_processing.text_normalization.en.taggers.abbreviation import AbbreviationFst
-from nemo_text_processing.text_normalization.en.taggers.cardinal import CardinalFst
-from nemo_text_processing.text_normalization.en.taggers.date import DateFst
-from nemo_text_processing.text_normalization.en.taggers.decimal import DecimalFst
-from nemo_text_processing.text_normalization.en.taggers.electronic import ElectronicFst
-from nemo_text_processing.text_normalization.en.taggers.fraction import FractionFst
-from nemo_text_processing.text_normalization.en.taggers.measure import MeasureFst
-from nemo_text_processing.text_normalization.en.taggers.money import MoneyFst
-from nemo_text_processing.text_normalization.en.taggers.ordinal import OrdinalFst
 from nemo_text_processing.text_normalization.en.taggers.punctuation import PunctuationFst
-from nemo_text_processing.text_normalization.en.taggers.roman import RomanFst
-from nemo_text_processing.text_normalization.en.taggers.telephone import TelephoneFst
-from nemo_text_processing.text_normalization.en.taggers.time import TimeFst
-from nemo_text_processing.text_normalization.en.taggers.whitelist import WhiteListFst
-from nemo_text_processing.text_normalization.en.taggers.word import WordFst
+from nemo_text_processing.text_normalization.es.taggers.cardinal import CardinalFst
+from nemo_text_processing.text_normalization.es.taggers.date import DateFst
+from nemo_text_processing.text_normalization.es.taggers.decimals import DecimalFst
+from nemo_text_processing.text_normalization.es.taggers.electronic import ElectronicFst
+from nemo_text_processing.text_normalization.es.taggers.fraction import FractionFst
+from nemo_text_processing.text_normalization.es.taggers.measure import MeasureFst
+from nemo_text_processing.text_normalization.es.taggers.money import MoneyFst
+from nemo_text_processing.text_normalization.es.taggers.ordinal import OrdinalFst
+from nemo_text_processing.text_normalization.es.taggers.telephone import TelephoneFst
+from nemo_text_processing.text_normalization.es.taggers.time import TimeFst
+from nemo_text_processing.text_normalization.es.taggers.whitelist import WhiteListFst
+from nemo_text_processing.text_normalization.es.taggers.word import WordFst
 
 from nemo.utils import logging
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
+
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class ClassifyFst(GraphFst):
     """
-    Final class that composes all other classification grammars. This class can process an entire sentence including punctuation.
-    For deployment, this grammar will be compiled and exported to OpenFst Finate State Archiv (FAR) File. 
+    Final class that composes all other classification grammars. This class can process an entire sentence, that is lower cased.
+    For deployment, this grammar will be compiled and exported to OpenFst Finate State aRchive (FAR) File.
     More details to deployment at NeMo/tools/text_processing_deployment.
-    
+
     Args:
         input_case: accepting either "lower_cased" or "cased" input.
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
         cache_dir: path to a dir with .far grammar file. Set to None to avoid using cache.
         overwrite_cache: set to True to overwrite .far files
         whitelist: path to a file with whitelist replacements
     """
 
     def __init__(
         self,
         input_case: str,
-        deterministic: bool = True,
+        deterministic: bool = False,
         cache_dir: str = None,
         overwrite_cache: bool = False,
         whitelist: str = None,
     ):
         super().__init__(name="tokenize_and_classify", kind="classify", deterministic=deterministic)
-
         far_file = None
         if cache_dir is not None and cache_dir != "None":
             os.makedirs(cache_dir, exist_ok=True)
             whitelist_file = os.path.basename(whitelist) if whitelist else ""
             far_file = os.path.join(
-                cache_dir, f"_{input_case}_en_tn_{deterministic}_deterministic{whitelist_file}.far"
+                cache_dir, f"_{input_case}_es_tn_{deterministic}_deterministic{whitelist_file}.far"
             )
         if not overwrite_cache and far_file and os.path.exists(far_file):
             self.fst = pynini.Far(far_file, mode="r")["tokenize_and_classify"]
-            logging.info(f'ClassifyFst.fst was restored from {far_file}.')
+            logging.info(f"ClassifyFst.fst was restored from {far_file}.")
         else:
-            logging.info(f"Creating ClassifyFst grammars.")
-            cardinal = CardinalFst(deterministic=deterministic)
-            cardinal_graph = cardinal.fst
-
-            ordinal = OrdinalFst(cardinal=cardinal, deterministic=deterministic)
-            ordinal_graph = ordinal.fst
-
-            decimal = DecimalFst(cardinal=cardinal, deterministic=deterministic)
-            decimal_graph = decimal.fst
-            fraction = FractionFst(deterministic=deterministic, cardinal=cardinal)
-            fraction_graph = fraction.fst
-
-            measure = MeasureFst(cardinal=cardinal, decimal=decimal, fraction=fraction, deterministic=deterministic)
-            measure_graph = measure.fst
-            date_graph = DateFst(cardinal=cardinal, deterministic=deterministic).fst
+            logging.info(f"Creating ClassifyFst grammars. This might take some time...")
+
+            self.cardinal = CardinalFst(deterministic=deterministic)
+            cardinal_graph = self.cardinal.fst
+
+            self.ordinal = OrdinalFst(cardinal=self.cardinal, deterministic=deterministic)
+            ordinal_graph = self.ordinal.fst
+
+            self.decimal = DecimalFst(cardinal=self.cardinal, deterministic=deterministic)
+            decimal_graph = self.decimal.fst
+
+            self.fraction = FractionFst(cardinal=self.cardinal, ordinal=self.ordinal, deterministic=deterministic)
+            fraction_graph = self.fraction.fst
+            self.measure = MeasureFst(
+                cardinal=self.cardinal, decimal=self.decimal, fraction=self.fraction, deterministic=deterministic
+            )
+            measure_graph = self.measure.fst
+            self.date = DateFst(cardinal=self.cardinal, deterministic=deterministic)
+            date_graph = self.date.fst
             word_graph = WordFst(deterministic=deterministic).fst
-            time_graph = TimeFst(cardinal=cardinal, deterministic=deterministic).fst
-            telephone_graph = TelephoneFst(deterministic=deterministic).fst
-            electonic_graph = ElectronicFst(deterministic=deterministic).fst
-            money_graph = MoneyFst(cardinal=cardinal, decimal=decimal, deterministic=deterministic).fst
-            whitelist_graph = WhiteListFst(
-                input_case=input_case, deterministic=deterministic, input_file=whitelist
-            ).fst
+            self.time = TimeFst(self.cardinal, deterministic=deterministic)
+            time_graph = self.time.fst
+            self.telephone = TelephoneFst(deterministic=deterministic)
+            telephone_graph = self.telephone.fst
+            self.electronic = ElectronicFst(deterministic=deterministic)
+            electronic_graph = self.electronic.fst
+            self.money = MoneyFst(cardinal=self.cardinal, decimal=self.decimal, deterministic=deterministic)
+            money_graph = self.money.fst
+            self.whitelist = WhiteListFst(input_case=input_case, deterministic=deterministic, input_file=whitelist)
+            whitelist_graph = self.whitelist.fst
             punct_graph = PunctuationFst(deterministic=deterministic).fst
 
             classify = (
                 pynutil.add_weight(whitelist_graph, 1.01)
-                | pynutil.add_weight(time_graph, 1.1)
-                | pynutil.add_weight(date_graph, 1.09)
-                | pynutil.add_weight(decimal_graph, 1.1)
-                | pynutil.add_weight(measure_graph, 1.1)
+                | pynutil.add_weight(time_graph, 1.09)
+                | pynutil.add_weight(measure_graph, 1.08)
                 | pynutil.add_weight(cardinal_graph, 1.1)
+                | pynutil.add_weight(fraction_graph, 1.09)
+                | pynutil.add_weight(date_graph, 1.1)
                 | pynutil.add_weight(ordinal_graph, 1.1)
+                | pynutil.add_weight(decimal_graph, 1.1)
                 | pynutil.add_weight(money_graph, 1.1)
                 | pynutil.add_weight(telephone_graph, 1.1)
-                | pynutil.add_weight(electonic_graph, 1.1)
-                | pynutil.add_weight(fraction_graph, 1.1)
-                | pynutil.add_weight(word_graph, 100)
+                | pynutil.add_weight(electronic_graph, 1.1)
+                | pynutil.add_weight(word_graph, 200)
             )
-
-            if not deterministic:
-                roman_graph = RomanFst(deterministic=deterministic).fst
-                # the weight matches the word_graph weight for "I" cases in long sentences with multiple semiotic tokens
-                classify |= pynutil.add_weight(roman_graph, 100)
-
-                abbreviation_graph = AbbreviationFst(deterministic=deterministic).fst
-                classify |= pynutil.add_weight(abbreviation_graph, 100)
-
             punct = pynutil.insert("tokens { ") + pynutil.add_weight(punct_graph, weight=2.1) + pynutil.insert(" }")
             punct = pynini.closure(
                 pynini.compose(pynini.closure(NEMO_WHITE_SPACE, 1), delete_extra_space)
                 | (pynutil.insert(" ") + punct),
                 1,
             )
             token = pynutil.insert("tokens { ") + classify + pynutil.insert(" }")
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify_with_audio.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify_with_audio.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -31,15 +30,17 @@
 from nemo_text_processing.text_normalization.en.taggers.decimal import DecimalFst
 from nemo_text_processing.text_normalization.en.taggers.electronic import ElectronicFst
 from nemo_text_processing.text_normalization.en.taggers.fraction import FractionFst
 from nemo_text_processing.text_normalization.en.taggers.measure import MeasureFst
 from nemo_text_processing.text_normalization.en.taggers.money import MoneyFst
 from nemo_text_processing.text_normalization.en.taggers.ordinal import OrdinalFst
 from nemo_text_processing.text_normalization.en.taggers.punctuation import PunctuationFst
+from nemo_text_processing.text_normalization.en.taggers.range import RangeFst as RangeFst
 from nemo_text_processing.text_normalization.en.taggers.roman import RomanFst
+from nemo_text_processing.text_normalization.en.taggers.serial import SerialFst
 from nemo_text_processing.text_normalization.en.taggers.telephone import TelephoneFst
 from nemo_text_processing.text_normalization.en.taggers.time import TimeFst
 from nemo_text_processing.text_normalization.en.taggers.whitelist import WhiteListFst
 from nemo_text_processing.text_normalization.en.taggers.word import WordFst
 from nemo_text_processing.text_normalization.en.verbalizers.abbreviation import AbbreviationFst as vAbbreviation
 from nemo_text_processing.text_normalization.en.verbalizers.cardinal import CardinalFst as vCardinal
 from nemo_text_processing.text_normalization.en.verbalizers.date import DateFst as vDate
@@ -48,14 +49,15 @@
 from nemo_text_processing.text_normalization.en.verbalizers.fraction import FractionFst as vFraction
 from nemo_text_processing.text_normalization.en.verbalizers.measure import MeasureFst as vMeasure
 from nemo_text_processing.text_normalization.en.verbalizers.money import MoneyFst as vMoney
 from nemo_text_processing.text_normalization.en.verbalizers.ordinal import OrdinalFst as vOrdinal
 from nemo_text_processing.text_normalization.en.verbalizers.roman import RomanFst as vRoman
 from nemo_text_processing.text_normalization.en.verbalizers.telephone import TelephoneFst as vTelephone
 from nemo_text_processing.text_normalization.en.verbalizers.time import TimeFst as vTime
+from nemo_text_processing.text_normalization.en.verbalizers.word import WordFst as vWord
 
 from nemo.utils import logging
 
 try:
     import pynini
     from pynini.lib import pynutil
 
@@ -63,15 +65,15 @@
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class ClassifyFst(GraphFst):
     """
     Final class that composes all other classification grammars. This class can process an entire sentence including punctuation.
-    For deployment, this grammar will be compiled and exported to OpenFst Finate State Archiv (FAR) File. 
+    For deployment, this grammar will be compiled and exported to OpenFst Finite State Archive (FAR) File.
     More details to deployment at NeMo/tools/text_processing_deployment.
     
     Args:
         input_case: accepting either "lower_cased" or "cased" input.
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
         cache_dir: path to a dir with .far grammar file. Set to None to avoid using cache.
@@ -104,14 +106,15 @@
         else:
             logging.info(f'Creating ClassifyFst grammars. This might take some time...')
             # TAGGERS
             cardinal = CardinalFst(deterministic=deterministic)
             cardinal_graph = cardinal.fst
 
             ordinal = OrdinalFst(cardinal=cardinal, deterministic=deterministic)
+            deterministic_ordinal = OrdinalFst(cardinal=cardinal, deterministic=True)
             ordinal_graph = ordinal.fst
 
             decimal = DecimalFst(cardinal=cardinal, deterministic=deterministic)
             decimal_graph = decimal.fst
             fraction = FractionFst(deterministic=deterministic, cardinal=cardinal)
             fraction_graph = fraction.fst
 
@@ -122,14 +125,15 @@
             time_graph = TimeFst(cardinal=cardinal, deterministic=deterministic).fst
             telephone_graph = TelephoneFst(deterministic=deterministic).fst
             electronic_graph = ElectronicFst(deterministic=deterministic).fst
             money_graph = MoneyFst(cardinal=cardinal, decimal=decimal, deterministic=deterministic).fst
             whitelist = WhiteListFst(input_case=input_case, deterministic=deterministic, input_file=whitelist)
             whitelist_graph = whitelist.graph
             punct_graph = PunctuationFst(deterministic=deterministic).graph
+            serial_graph = SerialFst(cardinal=cardinal, ordinal=deterministic_ordinal, deterministic=deterministic).fst
 
             # VERBALIZERS
             cardinal = vCardinal(deterministic=deterministic)
             v_cardinal_graph = cardinal.fst
             decimal = vDecimal(cardinal=cardinal, deterministic=deterministic)
             v_decimal_graph = decimal.fst
             ordinal = vOrdinal(deterministic=deterministic)
@@ -142,38 +146,56 @@
             v_measure_graph = measure.fst
             v_time_graph = vTime(deterministic=deterministic).fst
             v_date_graph = vDate(ordinal=ordinal, deterministic=deterministic).fst
             v_money_graph = vMoney(decimal=decimal, deterministic=deterministic).fst
             v_roman_graph = vRoman(deterministic=deterministic).fst
             v_abbreviation = vAbbreviation(deterministic=deterministic).fst
 
+            det_v_time_graph = vTime(deterministic=True).fst
+            det_v_date_graph = vDate(ordinal=vOrdinal(deterministic=True), deterministic=True).fst
+            time_final = pynini.compose(time_graph, det_v_time_graph)
+            date_final = pynini.compose(date_graph, det_v_date_graph)
+            range_graph = RangeFst(
+                time=time_final, date=date_final, cardinal=CardinalFst(deterministic=True), deterministic=deterministic
+            ).fst
+            v_word_graph = vWord(deterministic=deterministic).fst
+
+            sem_w = 1
+            word_w = 100
+            punct_w = 2
             classify_and_verbalize = (
-                pynutil.add_weight(whitelist_graph, 1.01)
-                | pynutil.add_weight(pynini.compose(time_graph, v_time_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(decimal_graph, v_decimal_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(measure_graph, v_measure_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(cardinal_graph, v_cardinal_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(ordinal_graph, v_ordinal_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(telephone_graph, v_telephone_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(electronic_graph, v_electronic_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(fraction_graph, v_fraction_graph), 1.1)
-                | pynutil.add_weight(pynini.compose(money_graph, v_money_graph), 1.1)
-                | pynutil.add_weight(word_graph, 100)
-                | pynutil.add_weight(pynini.compose(date_graph, v_date_graph), 1.09)
+                pynutil.add_weight(whitelist_graph, sem_w)
+                | pynutil.add_weight(pynini.compose(time_graph, v_time_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(decimal_graph, v_decimal_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(measure_graph, v_measure_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(cardinal_graph, v_cardinal_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(ordinal_graph, v_ordinal_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(telephone_graph, v_telephone_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(electronic_graph, v_electronic_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(fraction_graph, v_fraction_graph), sem_w)
+                | pynutil.add_weight(pynini.compose(money_graph, v_money_graph), sem_w)
+                | pynutil.add_weight(word_graph, word_w)
+                | pynutil.add_weight(pynini.compose(date_graph, v_date_graph), sem_w - 0.01)
+                | pynutil.add_weight(pynini.compose(range_graph, v_word_graph), sem_w)
+                | pynutil.add_weight(
+                    pynini.compose(serial_graph, v_word_graph), 1.1001
+                )  # should be higher than the rest of the classes
             ).optimize()
 
             if not deterministic:
                 roman_graph = RomanFst(deterministic=deterministic).fst
                 # the weight matches the word_graph weight for "I" cases in long sentences with multiple semiotic tokens
-                classify_and_verbalize |= pynutil.add_weight(pynini.compose(roman_graph, v_roman_graph), 100)
+                classify_and_verbalize |= pynutil.add_weight(pynini.compose(roman_graph, v_roman_graph), word_w)
 
                 abbreviation_graph = AbbreviationFst(whitelist=whitelist, deterministic=deterministic).fst
-                classify_and_verbalize |= pynutil.add_weight(pynini.compose(abbreviation_graph, v_abbreviation), 100)
+                classify_and_verbalize |= pynutil.add_weight(
+                    pynini.compose(abbreviation_graph, v_abbreviation), word_w
+                )
 
-            punct_only = pynutil.add_weight(punct_graph, weight=2.1)
+            punct_only = pynutil.add_weight(punct_graph, weight=punct_w)
             punct = pynini.closure(
                 pynini.compose(pynini.closure(NEMO_WHITE_SPACE, 1), delete_extra_space)
                 | (pynutil.insert(" ") + punct_only),
                 1,
             )
 
             token_plus_punct = (
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/whitelist.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,42 +1,37 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
 from nemo_text_processing.text_normalization.en.graph_utils import GraphFst, convert_space
-from nemo_text_processing.text_normalization.en.utils import get_abs_path, load_labels
+from nemo_text_processing.text_normalization.es.utils import get_abs_path, load_labels
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
+
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class WhiteListFst(GraphFst):
     """
     Finite state transducer for classifying whitelist, e.g.
-        misses -> tokens { name: "mrs" }
-        for non-deterministic case: "Dr. Abc" ->
-            tokens { name: "drive" } tokens { name: "Abc" }
-            tokens { name: "doctor" } tokens { name: "Abc" }
-            tokens { name: "Dr." } tokens { name: "Abc" }
+        "sr." -> tokens { name: "señor" }
     This class has highest priority among all classifier grammars. Whitelisted tokens are defined and loaded from "data/whitelist.tsv".
 
     Args:
         input_case: accepting either "lower_cased" or "cased" input.
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
         input_file: path to a file with whitelist replacements
@@ -44,33 +39,31 @@
 
     def __init__(self, input_case: str, deterministic: bool = True, input_file: str = None):
         super().__init__(name="whitelist", kind="classify", deterministic=deterministic)
 
         def _get_whitelist_graph(input_case, file):
             whitelist = load_labels(file)
             if input_case == "lower_cased":
-                whitelist = [(x.lower(), y) for x, y in whitelist]
-            else:
-                whitelist = [(x, y) for x, y in whitelist]
+                whitelist = [[x[0].lower()] + x[1:] for x in whitelist]
             graph = pynini.string_map(whitelist)
             return graph
 
-        def _get_whitelist_non_deterministic_graph(file="data/whitelist_alternatives.tsv"):
-            whitelist = load_labels(get_abs_path(file))
-            whitelist_lower = [(x.lower(), y.lower()) for x, y in whitelist]
-            whitelist_cased = [(x, y) for x, y in whitelist]
-            graph = pynini.string_map(whitelist_lower + whitelist_cased)
-            return graph
-
         graph = _get_whitelist_graph(input_case, get_abs_path("data/whitelist.tsv"))
-        if not deterministic:
-            graph |= _get_whitelist_non_deterministic_graph()
+        if not deterministic and input_case != "lower_cased":
+            graph |= pynutil.add_weight(
+                _get_whitelist_graph("lower_cased", get_abs_path("data/whitelist.tsv")), weight=0.0001
+            )
 
         if input_file:
             whitelist_provided = _get_whitelist_graph(input_case, input_file)
             if not deterministic:
                 graph |= whitelist_provided
             else:
                 graph = whitelist_provided
 
-        self.graph = (convert_space(graph)).optimize()
-        self.fst = (pynutil.insert("name: \"") + self.graph + pynutil.insert("\"")).optimize()
+        if not deterministic:
+            units_graph = _get_whitelist_graph(input_case, file=get_abs_path("data/measures/measurements.tsv"))
+            graph |= units_graph
+
+        self.graph = graph
+        self.final_graph = convert_space(self.graph).optimize()
+        self.fst = (pynutil.insert("name: \"") + self.final_graph + pynutil.insert("\"")).optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/measure.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,49 +1,54 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_DIGIT, NEMO_NOT_SPACE, GraphFst
-from nemo_text_processing.text_normalization.en.taggers.punctuation import PunctuationFst
+from nemo_text_processing.text_normalization.en.graph_utils import (
+    NEMO_NON_BREAKING_SPACE,
+    NEMO_SPACE,
+    GraphFst,
+    delete_space,
+)
+from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class WordFst(GraphFst):
+class MeasureFst(GraphFst):
     """
-    Finite state transducer for classifying word. Considers sentence boundary exceptions.
-        e.g. sleep -> tokens { name: "sleep" }
-
+    Finite state transducer for verbalizing measure, e.g.
+        measure { cardinal { integer: "два килограма" } } -> "два килограма"
+    
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="word", kind="classify", deterministic=deterministic)
-
-        punct = PunctuationFst().graph
-        self.graph = pynini.closure(pynini.difference(NEMO_NOT_SPACE, punct.project("input")), 1)
+        super().__init__(name="measure", kind="verbalize", deterministic=deterministic)
 
-        if not deterministic:
-            self.graph = pynini.closure(
-                pynini.difference(self.graph, pynini.union("$", "€", "₩", "£", "¥") + pynini.closure(NEMO_DIGIT, 1)), 1
-            )
+        graph = (
+            pynutil.delete(" cardinal { integer: \"")
+            + pynini.closure(RU_ALPHA | NEMO_SPACE | NEMO_NON_BREAKING_SPACE)
+            + pynutil.delete("\"")
+            + delete_space
+            + pynutil.delete("}")
+        )
 
-        self.fst = (pynutil.insert("name: \"") + self.graph + pynutil.insert("\"")).optimize()
+        delete_tokens = self.delete_tokens(graph)
+        self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,25 +18,25 @@
 
 def get_abs_path(rel_path):
     """
     Get absolute path
 
     Args:
         rel_path: relative path to this file
-        
+
     Returns absolute path
     """
     return os.path.dirname(os.path.abspath(__file__)) + '/' + rel_path
 
 
 def load_labels(abs_path):
     """
     loads relative path file as dictionary
 
     Args:
         abs_path: absolute path
 
     Returns dictionary of mappings
     """
-    label_tsv = open(abs_path, encoding="utf-8")
+    label_tsv = open(abs_path)
     labels = list(csv.reader(label_tsv, delimiter="\t"))
     return labels
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/data/whitelist/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/abbreviation.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/abbreviation.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/decimal.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,37 +19,39 @@
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class CardinalFst(GraphFst):
+class DecimalFst(GraphFst):
     """
-    Finite state transducer for verbalizing cardinal, e.g.
-        cardinal { negative: "true" integer: "23" } -> minus twenty three
+    Finite state transducer for verbalizing decimal, e.g.
+        tokens { decimal { integer_part: "одно целая" fractional_part: "восемь сотых} } ->
+            "одно целая восемь сотых"
 
     Args:
         deterministic: if True will provide a single transduction option,
-            for False multiple options (used for audio-based normalization)
+            for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="cardinal", kind="verbalize", deterministic=deterministic)
+        super().__init__(name="decimal", kind="verbalize", deterministic=deterministic)
 
-        self.optional_sign = pynini.closure(pynini.cross("negative: \"true\"", "minus ") + delete_space, 0, 1)
-
-        if deterministic:
-            integer = pynini.closure(NEMO_NOT_QUOTE, 1)
-        else:
-            integer = (
-                pynini.closure(NEMO_NOT_QUOTE)
-                + pynini.closure(pynini.cross("hundred ", "hundred and ") | pynini.cross("hundred ", " "), 0, 1)
-                + pynini.closure(NEMO_NOT_QUOTE)
-            )
-
-        self.integer = delete_space + pynutil.delete("\"") + integer + pynutil.delete("\"")
-        integer = pynutil.delete("integer:") + self.integer
-
-        self.numbers = self.optional_sign + integer
-        delete_tokens = self.delete_tokens(self.numbers)
+        optional_sign = pynini.closure(pynini.cross("negative: \"true\" ", "минус "), 0, 1)
+        integer = pynutil.delete(" \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
+        integer_part = pynutil.delete("integer_part:") + integer
+        fractional_part = pynutil.delete("fractional_part:") + integer
+        optional_quantity_part = pynini.closure(
+            pynini.accep(" ")
+            + pynutil.delete("quantity: \"")
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
+            + pynutil.delete("\""),
+            0,
+            1,
+        )
+
+        self.graph = (
+            optional_sign + integer_part + pynini.accep(" ") + fractional_part + optional_quantity_part + delete_space
+        )
+        delete_tokens = self.delete_tokens(self.graph)
         self.fst = delete_tokens.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/date.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,22 +10,24 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from nemo_text_processing.text_normalization.en.graph_utils import (
     NEMO_NOT_QUOTE,
+    NEMO_SIGMA,
     GraphFst,
     delete_extra_space,
     delete_space,
 )
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class DateFst(GraphFst):
@@ -37,15 +38,15 @@
 
     Args:
         ordinal: OrdinalFst
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self, ordinal: GraphFst, deterministic: bool = True):
+    def __init__(self, ordinal: GraphFst, deterministic: bool = True, lm: bool = False):
         super().__init__(name="date", kind="verbalize", deterministic=deterministic)
 
         month = pynini.closure(NEMO_NOT_QUOTE, 1)
         day_cardinal = (
             pynutil.delete("day:")
             + delete_space
             + pynutil.delete("\"")
@@ -65,15 +66,16 @@
             + pynutil.delete("\"")
         )
 
         # month (day) year
         graph_mdy = (
             month + pynini.closure(delete_extra_space + day, 0, 1) + pynini.closure(delete_extra_space + year, 0, 1)
         )
-        if not deterministic:
+        # may 5 -> may five
+        if not deterministic and not lm:
             graph_mdy |= (
                 month
                 + pynini.closure(delete_extra_space + day_cardinal, 0, 1)
                 + pynini.closure(delete_extra_space + year, 0, 1)
             )
 
         # day month year
@@ -93,12 +95,13 @@
             + pynutil.delete("\"")
             + NEMO_NOT_QUOTE
             + pynutil.delete("\"")
             + delete_space
         )
 
         final_graph = (
-            (graph_mdy | year | pynutil.add_weight(graph_dmy, 0.001)) + delete_space + optional_preserve_order
+            (plurals._priority_union(graph_mdy, pynutil.add_weight(graph_dmy, 0.0001), NEMO_SIGMA) | year)
+            + delete_space
+            + optional_preserve_order
         )
-
         delete_tokens = self.delete_tokens(final_graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/decimal.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -32,16 +31,18 @@
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, cardinal, deterministic: bool = True):
         super().__init__(name="decimal", kind="verbalize", deterministic=deterministic)
-
-        self.optional_sign = pynini.closure(pynini.cross("negative: \"true\"", "minus ") + delete_space, 0, 1)
+        self.optional_sign = pynini.cross("negative: \"true\"", "minus ")
+        if not deterministic:
+            self.optional_sign |= pynini.cross("negative: \"true\"", "negative ")
+        self.optional_sign = pynini.closure(self.optional_sign + delete_space, 0, 1)
         self.integer = pynutil.delete("integer_part:") + cardinal.integer
         self.optional_integer = pynini.closure(self.integer + delete_space + insert_space, 0, 1)
         self.fractional_default = (
             pynutil.delete("fractional_part:")
             + delete_space
             + pynutil.delete("\"")
             + pynini.closure(NEMO_NOT_QUOTE, 1)
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/electronic.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,28 +1,36 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space, insert_space
+from nemo_text_processing.text_normalization.en.graph_utils import (
+    NEMO_NOT_QUOTE,
+    NEMO_SIGMA,
+    TO_UPPER,
+    GraphFst,
+    delete_extra_space,
+    delete_space,
+    insert_space,
+)
 from nemo_text_processing.text_normalization.en.utils import get_abs_path
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class ElectronicFst(GraphFst):
@@ -33,62 +41,59 @@
     Args:
         deterministic: if True will provide a single transduction option,
         for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="electronic", kind="verbalize", deterministic=deterministic)
-        graph_digit_no_zero = pynini.invert(pynini.string_file(get_abs_path("data/numbers/digit.tsv"))).optimize()
+        graph_digit_no_zero = pynini.invert(pynini.string_file(get_abs_path("data/number/digit.tsv"))).optimize()
         graph_zero = pynini.cross("0", "zero")
 
         if not deterministic:
             graph_zero |= pynini.cross("0", "o") | pynini.cross("0", "oh")
 
         graph_digit = graph_digit_no_zero | graph_zero
-        graph_symbols = pynini.string_file(get_abs_path("data/electronic/symbols.tsv")).optimize()
+        graph_symbols = pynini.string_file(get_abs_path("data/electronic/symbol.tsv")).optimize()
+
+        default_chars_symbols = pynini.cdrewrite(
+            pynutil.insert(" ") + (graph_symbols | graph_digit) + pynutil.insert(" "), "", "", NEMO_SIGMA
+        )
+
         user_name = (
             pynutil.delete("username:")
             + delete_space
             + pynutil.delete("\"")
-            + (
-                pynini.closure(
-                    pynutil.add_weight(graph_digit + insert_space, 1.09)
-                    | pynutil.add_weight(pynini.closure(graph_symbols + pynutil.insert(" ")), 1.09)
-                    | pynutil.add_weight(NEMO_NOT_QUOTE + insert_space, 1.1)
-                )
-            )
+            + default_chars_symbols
             + pynutil.delete("\"")
         )
 
-        server_common = pynini.string_file(get_abs_path("data/electronic/server_name.tsv"))
         domain_common = pynini.string_file(get_abs_path("data/electronic/domain.tsv"))
 
-        convert_defaults = (
-            NEMO_NOT_QUOTE | pynutil.add_weight(domain_common, -0.1) | pynutil.add_weight(server_common, -0.1)
-        )
-        domain = convert_defaults + pynini.closure(pynutil.insert(" ") + convert_defaults)
-        domain = pynini.compose(
-            domain,
-            pynini.closure(
-                pynutil.add_weight(graph_symbols, -0.1) | pynutil.add_weight(graph_digit, -0.1) | NEMO_NOT_QUOTE
-            ),
+        domain = (
+            default_chars_symbols
+            + insert_space
+            + plurals._priority_union(
+                domain_common, pynutil.add_weight(pynini.cross(".", "dot"), weight=0.0001), NEMO_SIGMA
+            )
+            + pynini.closure(
+                insert_space + (pynini.cdrewrite(TO_UPPER, "", "", NEMO_SIGMA) @ default_chars_symbols), 0, 1
+            )
         )
-
         domain = (
             pynutil.delete("domain:")
             + delete_space
             + pynutil.delete("\"")
             + domain
             + delete_space
             + pynutil.delete("\"")
-        )
+        ).optimize()
 
         protocol = pynutil.delete("protocol: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
         graph = (
             pynini.closure(protocol + delete_space, 0, 1)
-            + pynini.closure(user_name + delete_space + pynutil.insert("at ") + delete_space, 0, 1)
+            + pynini.closure(user_name + delete_space + pynutil.insert(" at ") + delete_space, 0, 1)
             + domain
             + delete_space
-        )
+        ).optimize() @ pynini.cdrewrite(delete_extra_space, "", "", NEMO_SIGMA)
 
         delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/fraction.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,76 +1,94 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst, insert_space
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, NEMO_SIGMA, GraphFst, insert_space
 from nemo_text_processing.text_normalization.en.verbalizers.ordinal import OrdinalFst
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class FractionFst(GraphFst):
     """
     Finite state transducer for verbalizing fraction
         e.g. tokens { fraction { integer: "twenty three" numerator: "four" denominator: "five" } } ->
-        twenty three four fifth
+        twenty three and four fifth
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self, deterministic: bool = True):
+    def __init__(self, deterministic: bool = True, lm: bool = False):
         super().__init__(name="fraction", kind="verbalize", deterministic=deterministic)
         suffix = OrdinalFst().suffix
 
         integer = pynutil.delete("integer_part: \"") + pynini.closure(NEMO_NOT_QUOTE) + pynutil.delete("\" ")
-        numerator = pynutil.delete("numerator: \"") + pynini.closure(NEMO_NOT_QUOTE) + pynutil.delete("\" ")
+        denominator_one = pynini.cross("denominator: \"one\"", "over one")
+        denominator_half = pynini.cross("denominator: \"two\"", "half")
+        denominator_quarter = pynini.cross("denominator: \"four\"", "quarter")
+
+        denominator_rest = (
+            pynutil.delete("denominator: \"") + pynini.closure(NEMO_NOT_QUOTE) @ suffix + pynutil.delete("\"")
+        )
+
+        denominators = plurals._priority_union(
+            denominator_one,
+            plurals._priority_union(
+                denominator_half,
+                plurals._priority_union(denominator_quarter, denominator_rest, NEMO_SIGMA),
+                NEMO_SIGMA,
+            ),
+            NEMO_SIGMA,
+        ).optimize()
+        if not deterministic:
+            denominators |= pynutil.delete("denominator: \"") + (pynini.accep("four") @ suffix) + pynutil.delete("\"")
+
         numerator_one = pynutil.delete("numerator: \"") + pynini.accep("one") + pynutil.delete("\" ")
-        denominator = pynutil.delete("denominator: \"") + (
-            pynini.closure(NEMO_NOT_QUOTE) @ suffix | pynutil.add_weight(pynini.cross('four', 'quarter'), -1)
+        numerator_one = numerator_one + insert_space + denominators
+        numerator_rest = (
+            pynutil.delete("numerator: \"")
+            + (pynini.closure(NEMO_NOT_QUOTE) - pynini.accep("one"))
+            + pynutil.delete("\" ")
+        )
+        numerator_rest = numerator_rest + insert_space + denominators
+        numerator_rest @= pynini.cdrewrite(
+            plurals._priority_union(pynini.cross("half", "halves"), pynutil.insert("s"), NEMO_SIGMA),
+            "",
+            "[EOS]",
+            NEMO_SIGMA,
         )
 
+        graph = numerator_one | numerator_rest
+
         conjunction = pynutil.insert("and ")
-        if not deterministic:
+        if not deterministic and not lm:
             conjunction = pynini.closure(conjunction, 0, 1)
 
         integer = pynini.closure(integer + insert_space + conjunction, 0, 1)
 
-        denominator_half = pynutil.add_weight(
-            pynini.cross("numerator: \"one\" denominator: \"two\"", "a half"), -0.001
-        )
-        denominator_one_two = pynini.cross("denominator: \"one\"", "over one") | pynini.cross(
-            "denominator: \"two\"", "halves"
-        )
-        fraction_default = pynutil.add_weight(
-            numerator + insert_space + denominator + pynutil.insert("s") + pynutil.delete("\""), 0.001
-        )
-
-        fraction_with_one = pynutil.add_weight(
-            numerator_one + insert_space + denominator + pynutil.delete("\""), 0.0001
+        graph = integer + graph
+        graph @= pynini.cdrewrite(
+            pynini.cross("and one half", "and a half") | pynini.cross("over ones", "over one"), "", "[EOS]", NEMO_SIGMA
         )
 
-        graph = integer + (denominator_half | fraction_with_one | fraction_default)
-        graph |= pynutil.add_weight(pynini.cross("numerator: \"one\" denominator: \"two\"", "one half"), -1)
-        graph |= integer + (numerator | numerator_one) + insert_space + denominator_one_two
-
         self.graph = graph
         delete_tokens = self.delete_tokens(self.graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/measure.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_CHAR, GraphFst, delete_space, insert_space
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space, insert_space
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
@@ -40,19 +39,22 @@
     """
 
     def __init__(self, decimal: GraphFst, cardinal: GraphFst, fraction: GraphFst, deterministic: bool = True):
         super().__init__(name="measure", kind="verbalize", deterministic=deterministic)
         optional_sign = cardinal.optional_sign
         unit = (
             pynutil.delete("units: \"")
-            + pynini.difference(pynini.closure(NEMO_CHAR - " ", 1), pynini.union("address", "math"))
+            + pynini.difference(pynini.closure(NEMO_NOT_QUOTE, 1), pynini.union("address", "math"))
             + pynutil.delete("\"")
             + delete_space
         )
 
+        if not deterministic:
+            unit |= pynini.compose(unit, pynini.cross(pynini.union("inch", "inches"), "\""))
+
         graph_decimal = (
             pynutil.delete("decimal {")
             + delete_space
             + optional_sign
             + delete_space
             + decimal.numbers
             + delete_space
@@ -73,14 +75,23 @@
         )
 
         graph = (graph_cardinal | graph_decimal | graph_fraction) + delete_space + insert_space + unit
 
         # SH adds "preserve_order: true" by default
         preserve_order = pynutil.delete("preserve_order:") + delete_space + pynutil.delete("true") + delete_space
         graph |= unit + insert_space + (graph_cardinal | graph_decimal) + delete_space + pynini.closure(preserve_order)
+        # for only unit
+        graph |= (
+            pynutil.delete("cardinal { integer: \"-\"")
+            + delete_space
+            + pynutil.delete("}")
+            + delete_space
+            + unit
+            + pynini.closure(preserve_order)
+        )
         address = (
             pynutil.delete("units: \"address\" ")
             + delete_space
             + graph_cardinal
             + delete_space
             + pynini.closure(preserve_order)
         )
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/money.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -39,54 +38,41 @@
         decimal: DecimalFst
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, decimal: GraphFst, deterministic: bool = True):
         super().__init__(name="money", kind="verbalize", deterministic=deterministic)
-        if deterministic or True:
-            keep_space = pynini.accep(" ")
-            maj = pynutil.delete("currency_maj: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
-            min = pynutil.delete("currency_min: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
-
-            fractional_part = (
-                pynutil.delete("fractional_part: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
-            )
-
-            integer_part = (
-                pynutil.delete("integer_part: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
-            )
-
-            if not deterministic:
-                integer_part |= (
-                    pynutil.delete("integer_part: \"")
-                    + pynini.closure(NEMO_NOT_QUOTE, 1)
-                    + pynini.cross("hundred ", "hundred and ")
-                    + pynini.closure(NEMO_NOT_QUOTE, 1)
-                    + pynutil.delete("\"")
-                )
-
-            optional_add_and = pynini.closure(pynutil.insert("and "), 0, 1)
-
-            #  *** currency_maj
-            graph_integer = integer_part + keep_space + maj
-
-            #  *** currency_maj + (***) | ((and) *** current_min)
-            fractional = optional_add_and + fractional_part + delete_extra_space + min
-
-            graph_integer_with_minor = (
-                integer_part + keep_space + maj + keep_space + fractional + delete_preserve_order
-            )
-
-            # *** point *** currency_maj
-            graph_decimal = decimal.numbers + keep_space + maj
+        keep_space = pynini.accep(" ")
+        maj = pynutil.delete("currency_maj: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
+        min = pynutil.delete("currency_min: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
 
-            # *** current_min
-            graph_minor = fractional_part + delete_extra_space + min + delete_preserve_order
+        fractional_part = (
+            pynutil.delete("fractional_part: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
+        )
 
-            graph = graph_integer | graph_integer_with_minor | graph_decimal | graph_minor
+        integer_part = decimal.integer
 
-            if not deterministic:
-                graph |= graph_integer + delete_preserve_order
+        #  *** currency_maj
+        graph_integer = integer_part + keep_space + maj
+
+        #  *** currency_maj + (***) | ((and) *** current_min)
+        fractional = fractional_part + delete_extra_space + min
+
+        if not deterministic:
+            fractional |= pynutil.insert("and ") + fractional
+
+        graph_integer_with_minor = integer_part + keep_space + maj + keep_space + fractional + delete_preserve_order
+
+        # *** point *** currency_maj
+        graph_decimal = decimal.numbers + keep_space + maj
+
+        # *** current_min
+        graph_minor = fractional_part + delete_extra_space + min + delete_preserve_order
+
+        graph = graph_integer | graph_integer_with_minor | graph_decimal | graph_minor
+
+        if not deterministic:
+            graph |= graph_integer + delete_preserve_order
 
         delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/ordinal.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,63 +1,42 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, NEMO_SIGMA, GraphFst, delete_space
-from nemo_text_processing.text_normalization.en.utils import get_abs_path
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class OrdinalFst(GraphFst):
     """
-    Finite state transducer for verbalizing ordinal, e.g.
-        ordinal { integer: "thirteen" } } -> thirteenth
+    Finite state transducer for verbalizing roman numerals
+        e.g. ordinal { integer: "второе" } } -> "второе"
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="ordinal", kind="verbalize", deterministic=deterministic)
 
-        graph_digit = pynini.string_file(get_abs_path("data/ordinals/digit.tsv")).invert()
-        graph_teens = pynini.string_file(get_abs_path("data/ordinals/teen.tsv")).invert()
-
-        graph = (
-            pynutil.delete("integer:")
-            + delete_space
-            + pynutil.delete("\"")
-            + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\"")
-        )
-        convert_rest = pynutil.insert("th", weight=0.01)
-
-        suffix = pynini.cdrewrite(
-            graph_digit | graph_teens | pynutil.add_weight(pynini.cross("ty", "tieth"), weight=0.001) | convert_rest,
-            "",
-            "[EOS]",
-            NEMO_SIGMA,
-        ).optimize()
-        self.graph = pynini.compose(graph, suffix)
-        self.suffix = suffix
-        delete_tokens = self.delete_tokens(self.graph)
+        value = pynini.closure(NEMO_NOT_QUOTE)
+        graph = pynutil.delete("integer: \"") + value + pynutil.delete("\"")
+        delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/roman.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/telephone.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,46 +1,42 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
 from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst
-from nemo_text_processing.text_normalization.en.verbalizers.ordinal import OrdinalFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
+
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class RomanFst(GraphFst):
+class TelephoneFst(GraphFst):
     """
-    Finite state transducer for verbalizing roman numerals
-        e.g. tokens { roman { integer: "one" } } -> one
+    Finite state transducer for verbalizing telephone, e.g.
+        telephone { number_part: "uno dos tres uno dos tres cinco seis siete ocho" }
+        -> uno dos tres uno dos tres cinco seis siete ocho
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="roman", kind="verbalize", deterministic=deterministic)
-        suffix = OrdinalFst().suffix
+        super().__init__(name="telephone", kind="verbalize")
 
-        integer = pynini.closure(NEMO_NOT_QUOTE)
-        integer |= pynini.closure(pynutil.insert("the "), 0, 1) + integer @ suffix
-        graph = pynutil.delete("integer: \"") + integer + pynutil.delete("\"")
-        delete_tokens = self.delete_tokens(graph)
+        number_part = pynutil.delete("number_part: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
+        delete_tokens = self.delete_tokens(number_part)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/telephone.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -34,31 +33,28 @@
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="telephone", kind="verbalize", deterministic=deterministic)
 
-        add_separator = pynutil.insert(",")  # between components
-
         optional_country_code = pynini.closure(
             pynutil.delete("country_code: \"")
             + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
             + delete_space
-            + add_separator
             + insert_space,
             0,
             1,
         )
 
         number_part = (
             pynutil.delete("number_part: \"")
             + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynini.closure(pynutil.add_weight(pynutil.delete(" "), -0.1), 0, 1)
+            + pynini.closure(pynutil.add_weight(pynutil.delete(" "), -0.0001), 0, 1)
             + pynutil.delete("\"")
         )
 
         optional_extension = pynini.closure(
             delete_space
             + insert_space
             + pynutil.delete("extension: \"")
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/verbalize.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -69,15 +68,15 @@
             | cardinal_graph
             | telephone_graph
             | electronic_graph
             | fraction_graph
             | whitelist_graph
         )
 
-        if not deterministic:
-            roman_graph = RomanFst(deterministic=deterministic).fst
-            graph |= roman_graph
+        # roman_graph = RomanFst(deterministic=deterministic).fst
+        # graph |= roman_graph
 
+        if not deterministic:
             abbreviation_graph = AbbreviationFst(deterministic=deterministic).fst
             graph |= abbreviation_graph
 
         self.fst = graph
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/verbalize_final.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/whitelist.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/en/verbalizers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/word.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/dates/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/dates/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo/collections/nlp/data/dialogue/data_processor/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/fractions/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/fractions/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/measures/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/measures/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/money/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/money/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/numbers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/ordinals/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/ordinals/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/roman/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/time/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/data/whitelist.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/data/whitelist.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/graph_utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/graph_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/decimals.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/decimals.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/electronic.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,84 +1,93 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_ALPHA, NEMO_DIGIT, GraphFst, insert_space
-from nemo_text_processing.text_normalization.es.utils import get_abs_path, load_labels
+
+
+from nemo_text_processing.text_normalization.en.graph_utils import (
+    NEMO_ALPHA,
+    NEMO_DIGIT,
+    NEMO_SIGMA,
+    GraphFst,
+    get_abs_path,
+    insert_space,
+)
 
 try:
     import pynini
     from pynini.lib import pynutil
 
-    common_domains = [x[0] for x in load_labels(get_abs_path("data/electronic/domain.tsv"))]
-    symbols = [x[0] for x in load_labels(get_abs_path("data/electronic/symbols.tsv"))]
-
     PYNINI_AVAILABLE = True
-
 except (ModuleNotFoundError, ImportError):
-    common_domains = None
-    symbols = None
-
     PYNINI_AVAILABLE = False
 
 
 class ElectronicFst(GraphFst):
     """
-    Finite state transducer for classifying electronic: email addresses
-        e.g. "abc@hotmail.com" -> electronic { username: "abc" domain: "hotmail.com" preserve_order: true }
-        e.g. "www.abc.com/123" -> electronic { protocol: "www." domain: "abc.com/123" preserve_order: true }
+    Finite state transducer for classifying electronic: as URLs, email addresses, etc.
+        e.g. cdf1@abc.edu -> tokens { electronic { username: "cdf1" domain: "abc.edu" } }
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="electronic", kind="classify", deterministic=deterministic)
 
-        dot = pynini.accep(".")
-        accepted_common_domains = pynini.union(*common_domains)
-        accepted_symbols = pynini.union(*symbols) - dot
-        accepted_characters = pynini.closure(NEMO_ALPHA | NEMO_DIGIT | accepted_symbols)
-        acceepted_characters_with_dot = pynini.closure(NEMO_ALPHA | NEMO_DIGIT | accepted_symbols | dot)
+        accepted_symbols = pynini.project(pynini.string_file(get_abs_path("data/electronic/symbol.tsv")), "input")
+        accepted_common_domains = pynini.project(
+            pynini.string_file(get_abs_path("data/electronic/domain.tsv")), "input"
+        )
+        all_accepted_symbols = NEMO_ALPHA + pynini.closure(NEMO_ALPHA | NEMO_DIGIT | accepted_symbols)
+        graph_symbols = pynini.string_file(get_abs_path("data/electronic/symbol.tsv")).optimize()
 
-        # email
         username = (
-            pynutil.insert("username: \"")
-            + acceepted_characters_with_dot
+            pynutil.insert("username: \"") + all_accepted_symbols + pynutil.insert("\"") + pynini.cross('@', ' ')
+        )
+        domain_graph = all_accepted_symbols + pynini.accep('.') + all_accepted_symbols
+        protocol_symbols = pynini.closure((graph_symbols | pynini.cross(":", "semicolon")) + pynutil.insert(" "))
+        protocol_start = (pynini.cross("https", "HTTPS ") | pynini.cross("http", "HTTP ")) + (
+            pynini.accep("://") @ protocol_symbols
+        )
+        protocol_file_start = pynini.accep("file") + insert_space + (pynini.accep(":///") @ protocol_symbols)
+
+        protocol_end = pynini.cross("www", "WWW ") + pynini.accep(".") @ protocol_symbols
+        protocol = protocol_file_start | protocol_start | protocol_end | (protocol_start + protocol_end)
+
+        domain_graph = (
+            pynutil.insert("domain: \"")
+            + pynini.difference(domain_graph, pynini.project(protocol, "input") + NEMO_SIGMA)
             + pynutil.insert("\"")
-            + pynini.cross('@', ' ')
         )
-        domain_graph = accepted_characters + dot + accepted_characters
-        domain_graph = pynutil.insert("domain: \"") + domain_graph + pynutil.insert("\"")
         domain_common_graph = (
             pynutil.insert("domain: \"")
-            + accepted_characters
-            + accepted_common_domains
-            + pynini.closure((accepted_symbols | dot) + pynini.closure(accepted_characters, 1), 0, 1)
+            + pynini.difference(
+                all_accepted_symbols
+                + accepted_common_domains
+                + pynini.closure(accepted_symbols + pynini.closure(NEMO_ALPHA | NEMO_DIGIT | accepted_symbols), 0, 1),
+                pynini.project(protocol, "input") + NEMO_SIGMA,
+            )
             + pynutil.insert("\"")
         )
-        graph = (username + domain_graph) | domain_common_graph
 
-        # url
-        protocol_start = pynini.accep("https://") | pynini.accep("http://")
-        protocol_end = (
-            pynini.accep("www.")
-            if deterministic
-            else pynini.accep("www.") | pynini.cross("www.", "doble ve doble ve doble ve.")
-        )
-        protocol = protocol_start | protocol_end | (protocol_start + protocol_end)
         protocol = pynutil.insert("protocol: \"") + protocol + pynutil.insert("\"")
-        graph |= protocol + insert_space + (domain_graph | domain_common_graph)
-        self.graph = graph
+        # email
+        graph = username + domain_graph
+        # abc.com, abc.com/123-sm
+        graph |= domain_common_graph
+        # www.abc.com/sdafsdf, or https://www.abc.com/asdfad or www.abc.abc/asdfad
+        graph |= protocol + pynutil.insert(" ") + domain_graph
+
+        final_graph = self.add_tokens(graph)
 
-        final_graph = self.add_tokens(self.graph + pynutil.insert(" preserve_order: true"))
         self.fst = final_graph.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/tokenize_and_classify.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,50 +11,48 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import os
 
 from nemo_text_processing.text_normalization.en.graph_utils import (
-    NEMO_WHITE_SPACE,
     GraphFst,
     delete_extra_space,
     delete_space,
     generator_main,
 )
 from nemo_text_processing.text_normalization.en.taggers.punctuation import PunctuationFst
-from nemo_text_processing.text_normalization.es.taggers.cardinal import CardinalFst
-from nemo_text_processing.text_normalization.es.taggers.date import DateFst
-from nemo_text_processing.text_normalization.es.taggers.decimals import DecimalFst
-from nemo_text_processing.text_normalization.es.taggers.electronic import ElectronicFst
-from nemo_text_processing.text_normalization.es.taggers.fraction import FractionFst
-from nemo_text_processing.text_normalization.es.taggers.measure import MeasureFst
-from nemo_text_processing.text_normalization.es.taggers.money import MoneyFst
-from nemo_text_processing.text_normalization.es.taggers.ordinal import OrdinalFst
-from nemo_text_processing.text_normalization.es.taggers.telephone import TelephoneFst
-from nemo_text_processing.text_normalization.es.taggers.time import TimeFst
-from nemo_text_processing.text_normalization.es.taggers.whitelist import WhiteListFst
-from nemo_text_processing.text_normalization.es.taggers.word import WordFst
+from nemo_text_processing.text_normalization.ru.taggers.cardinal import CardinalFst
+from nemo_text_processing.text_normalization.ru.taggers.date import DateFst
+from nemo_text_processing.text_normalization.ru.taggers.decimals import DecimalFst
+from nemo_text_processing.text_normalization.ru.taggers.electronic import ElectronicFst
+from nemo_text_processing.text_normalization.ru.taggers.measure import MeasureFst
+from nemo_text_processing.text_normalization.ru.taggers.money import MoneyFst
+from nemo_text_processing.text_normalization.ru.taggers.number_names import get_alternative_formats, get_number_names
+from nemo_text_processing.text_normalization.ru.taggers.ordinal import OrdinalFst
+from nemo_text_processing.text_normalization.ru.taggers.telephone import TelephoneFst
+from nemo_text_processing.text_normalization.ru.taggers.time import TimeFst
+from nemo_text_processing.text_normalization.ru.taggers.whitelist import WhiteListFst
+from nemo_text_processing.text_normalization.ru.taggers.word import WordFst
 
 from nemo.utils import logging
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
-
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class ClassifyFst(GraphFst):
     """
     Final class that composes all other classification grammars. This class can process an entire sentence, that is lower cased.
-    For deployment, this grammar will be compiled and exported to OpenFst Finate State aRchive (FAR) File.
+    For deployment, this grammar will be compiled and exported to OpenFst Finite State Archive (FAR) File.
     More details to deployment at NeMo/tools/text_processing_deployment.
 
     Args:
         input_case: accepting either "lower_cased" or "cased" input.
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
         cache_dir: path to a dir with .far grammar file. Set to None to avoid using cache.
@@ -67,91 +65,84 @@
         input_case: str,
         deterministic: bool = False,
         cache_dir: str = None,
         overwrite_cache: bool = False,
         whitelist: str = None,
     ):
         super().__init__(name="tokenize_and_classify", kind="classify", deterministic=deterministic)
+        if deterministic:
+            raise ValueError(
+                'Ru TN only supports non-deterministic cases and produces multiple normalization options.'
+            )
         far_file = None
         if cache_dir is not None and cache_dir != "None":
             os.makedirs(cache_dir, exist_ok=True)
             whitelist_file = os.path.basename(whitelist) if whitelist else ""
             far_file = os.path.join(
-                cache_dir, f"_{input_case}_es_tn_{deterministic}_deterministic{whitelist_file}.far"
+                cache_dir, f"_{input_case}_ru_tn_{deterministic}_deterministic{whitelist_file}.far"
             )
         if not overwrite_cache and far_file and os.path.exists(far_file):
             self.fst = pynini.Far(far_file, mode="r")["tokenize_and_classify"]
             logging.info(f"ClassifyFst.fst was restored from {far_file}.")
         else:
             logging.info(f"Creating ClassifyFst grammars. This might take some time...")
+            number_names = get_number_names()
+            alternative_formats = get_alternative_formats()
 
-            self.cardinal = CardinalFst(deterministic=deterministic)
+            self.cardinal = CardinalFst(
+                number_names=number_names, alternative_formats=alternative_formats, deterministic=deterministic
+            )
             cardinal_graph = self.cardinal.fst
 
-            self.ordinal = OrdinalFst(cardinal=self.cardinal, deterministic=deterministic)
+            self.ordinal = OrdinalFst(
+                number_names=number_names, alternative_formats=alternative_formats, deterministic=deterministic
+            )
             ordinal_graph = self.ordinal.fst
 
             self.decimal = DecimalFst(cardinal=self.cardinal, deterministic=deterministic)
             decimal_graph = self.decimal.fst
 
-            self.fraction = FractionFst(cardinal=self.cardinal, ordinal=self.ordinal, deterministic=deterministic)
-            fraction_graph = self.fraction.fst
-            self.measure = MeasureFst(
-                cardinal=self.cardinal, decimal=self.decimal, fraction=self.fraction, deterministic=deterministic
-            )
+            self.measure = MeasureFst(cardinal=self.cardinal, decimal=self.decimal, deterministic=deterministic)
             measure_graph = self.measure.fst
-            self.date = DateFst(cardinal=self.cardinal, deterministic=deterministic)
+            self.date = DateFst(number_names=number_names, deterministic=deterministic)
             date_graph = self.date.fst
             word_graph = WordFst(deterministic=deterministic).fst
-            self.time = TimeFst(self.cardinal, deterministic=deterministic)
+            self.time = TimeFst(number_names=number_names, deterministic=deterministic)
             time_graph = self.time.fst
-            self.telephone = TelephoneFst(deterministic=deterministic)
+            self.telephone = TelephoneFst(number_names=number_names, deterministic=deterministic)
             telephone_graph = self.telephone.fst
             self.electronic = ElectronicFst(deterministic=deterministic)
             electronic_graph = self.electronic.fst
             self.money = MoneyFst(cardinal=self.cardinal, decimal=self.decimal, deterministic=deterministic)
             money_graph = self.money.fst
             self.whitelist = WhiteListFst(input_case=input_case, deterministic=deterministic, input_file=whitelist)
             whitelist_graph = self.whitelist.fst
             punct_graph = PunctuationFst(deterministic=deterministic).fst
 
             classify = (
                 pynutil.add_weight(whitelist_graph, 1.01)
-                | pynutil.add_weight(time_graph, 1.09)
-                | pynutil.add_weight(measure_graph, 1.08)
+                | pynutil.add_weight(time_graph, 1.1)
+                | pynutil.add_weight(date_graph, 1.09)
+                | pynutil.add_weight(decimal_graph, 1.1)
+                | pynutil.add_weight(measure_graph, 0.9)
                 | pynutil.add_weight(cardinal_graph, 1.1)
-                | pynutil.add_weight(fraction_graph, 1.09)
-                | pynutil.add_weight(date_graph, 1.1)
                 | pynutil.add_weight(ordinal_graph, 1.1)
-                | pynutil.add_weight(decimal_graph, 1.1)
                 | pynutil.add_weight(money_graph, 1.1)
                 | pynutil.add_weight(telephone_graph, 1.1)
                 | pynutil.add_weight(electronic_graph, 1.1)
-                | pynutil.add_weight(word_graph, 200)
-            )
-            punct = pynutil.insert("tokens { ") + pynutil.add_weight(punct_graph, weight=2.1) + pynutil.insert(" }")
-            punct = pynini.closure(
-                pynini.compose(pynini.closure(NEMO_WHITE_SPACE, 1), delete_extra_space)
-                | (pynutil.insert(" ") + punct),
-                1,
+                | pynutil.add_weight(word_graph, 100)
             )
+
+            punct = pynutil.insert("tokens { ") + pynutil.add_weight(punct_graph, weight=1.1) + pynutil.insert(" }")
             token = pynutil.insert("tokens { ") + classify + pynutil.insert(" }")
             token_plus_punct = (
                 pynini.closure(punct + pynutil.insert(" ")) + token + pynini.closure(pynutil.insert(" ") + punct)
             )
 
-            graph = token_plus_punct + pynini.closure(
-                (
-                    pynini.compose(pynini.closure(NEMO_WHITE_SPACE, 1), delete_extra_space)
-                    | (pynutil.insert(" ") + punct + pynutil.insert(" "))
-                )
-                + token_plus_punct
-            )
-
+            graph = token_plus_punct + pynini.closure(pynutil.add_weight(delete_extra_space, 1.1) + token_plus_punct)
             graph = delete_space + graph + delete_space
-            graph |= punct
 
             self.fst = graph.optimize()
 
             if far_file:
                 generator_main(far_file, {"tokenize_and_classify": self.fst})
                 logging.info(f"ClassifyFst grammars are saved to {far_file}.")
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/whitelist.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,37 +1,42 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from nemo_text_processing.text_normalization.en.graph_utils import GraphFst, convert_space
-from nemo_text_processing.text_normalization.es.utils import get_abs_path, load_labels
+
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_CHAR, GraphFst, convert_space
+from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA, TO_CYRILLIC
+from nemo_text_processing.text_normalization.ru.utils import get_abs_path, load_labels
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
-
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class WhiteListFst(GraphFst):
     """
     Finite state transducer for classifying whitelist, e.g.
-        "sr." -> tokens { name: "señor" }
+        misses -> tokens { name: "mrs" }
+        for non-deterministic case: "Dr. Abc" ->
+            tokens { name: "drive" } tokens { name: "Abc" }
+            tokens { name: "doctor" } tokens { name: "Abc" }
+            tokens { name: "Dr." } tokens { name: "Abc" }
     This class has highest priority among all classifier grammars. Whitelisted tokens are defined and loaded from "data/whitelist.tsv".
 
     Args:
         input_case: accepting either "lower_cased" or "cased" input.
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
         input_file: path to a file with whitelist replacements
@@ -40,30 +45,25 @@
     def __init__(self, input_case: str, deterministic: bool = True, input_file: str = None):
         super().__init__(name="whitelist", kind="classify", deterministic=deterministic)
 
         def _get_whitelist_graph(input_case, file):
             whitelist = load_labels(file)
             if input_case == "lower_cased":
                 whitelist = [[x[0].lower()] + x[1:] for x in whitelist]
+            else:
+                whitelist = [[x[0].lower()] + x[1:] for x in whitelist]
             graph = pynini.string_map(whitelist)
             return graph
 
         graph = _get_whitelist_graph(input_case, get_abs_path("data/whitelist.tsv"))
-        if not deterministic and input_case != "lower_cased":
-            graph |= pynutil.add_weight(
-                _get_whitelist_graph("lower_cased", get_abs_path("data/whitelist.tsv")), weight=0.0001
-            )
 
         if input_file:
-            whitelist_provided = _get_whitelist_graph(input_case, input_file)
-            if not deterministic:
-                graph |= whitelist_provided
-            else:
-                graph = whitelist_provided
+            graph = _get_whitelist_graph(input_case, input_file)
 
-        if not deterministic:
-            units_graph = _get_whitelist_graph(input_case, file=get_abs_path("data/measures/measurements.tsv"))
-            graph |= units_graph
+        units_graph = _get_whitelist_graph(input_case, file=get_abs_path("data/measurements.tsv"))
+        # do not replace single letter units, like `м`, `°` and `%` will be replaced
+        units_graph = pynini.compose((NEMO_CHAR ** (2, ...) | pynini.difference(NEMO_CHAR, RU_ALPHA)), units_graph)
+        graph |= units_graph.optimize()
+        graph |= TO_CYRILLIC + pynini.closure(pynutil.insert(" ") + TO_CYRILLIC)
 
-        self.graph = graph
-        self.final_graph = convert_space(self.graph).optimize()
+        self.final_graph = convert_space(graph)
         self.fst = (pynutil.insert("name: \"") + self.final_graph + pynutil.insert("\"")).optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/word.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+
 from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_SPACE, GraphFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
-
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class WordFst(GraphFst):
     """
     Finite state transducer for classifying word.
-        e.g. dormir -> tokens { name: "dormir" }
+        e.g. sleep -> tokens { name: "sleep" }
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/utils.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,32 +11,38 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import csv
 import os
 
+from nemo.utils import logging
+
 
 def get_abs_path(rel_path):
     """
     Get absolute path
 
     Args:
         rel_path: relative path to this file
-
+        
     Returns absolute path
     """
-    return os.path.dirname(os.path.abspath(__file__)) + '/' + rel_path
+    abs_path = os.path.dirname(os.path.abspath(__file__)) + os.sep + rel_path
+
+    if not os.path.exists(abs_path):
+        logging.warning(f'{abs_path} does not exist')
+    return abs_path
 
 
 def load_labels(abs_path):
     """
     loads relative path file as dictionary
 
     Args:
         abs_path: absolute path
 
     Returns dictionary of mappings
     """
-    label_tsv = open(abs_path)
+    label_tsv = open(abs_path, encoding='utf-8')
     labels = list(csv.reader(label_tsv, delimiter="\t"))
     return labels
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/decimals.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/decimals.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/fraction.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/inverse_text_normalization/vi/verbalizers/cardinal.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,42 +1,54 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst
+
+from nemo_text_processing.inverse_text_normalization.vi.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
-
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class TelephoneFst(GraphFst):
+class CardinalFst(GraphFst):
     """
-    Finite state transducer for verbalizing telephone, e.g.
-        telephone { number_part: "uno dos tres uno dos tres cinco seis siete ocho" }
-        -> uno dos tres uno dos tres cinco seis siete ocho
-
-    Args:
-        deterministic: if True will provide a single transduction option,
-            for False multiple transduction are generated (used for audio-based normalization)
+    Finite state transducer for verbalizing cardinal
+        e.g. cardinal { integer: "23" negative: "-" } -> -23
     """
 
-    def __init__(self, deterministic: bool = True):
-        super().__init__(name="telephone", kind="verbalize")
-
-        number_part = pynutil.delete("number_part: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
-        delete_tokens = self.delete_tokens(number_part)
+    def __init__(self):
+        super().__init__(name="cardinal", kind="verbalize")
+        optional_sign = pynini.closure(
+            pynutil.delete("negative:")
+            + delete_space
+            + pynutil.delete('"')
+            + NEMO_NOT_QUOTE
+            + pynutil.delete('"')
+            + delete_space,
+            0,
+            1,
+        )
+        graph = (
+            pynutil.delete("integer:")
+            + delete_space
+            + pynutil.delete('"')
+            + pynini.closure(NEMO_NOT_QUOTE, 1)
+            + pynutil.delete('"')
+        )
+        self.numbers = graph
+        graph = optional_sign + graph
+        delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/es/verbalizers/verbalize.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/es/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/de/verbalizers/verbalize_final.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,47 +1,48 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+
+from nemo_text_processing.text_normalization.de.verbalizers.verbalize import VerbalizeFst
 from nemo_text_processing.text_normalization.en.graph_utils import GraphFst, delete_extra_space, delete_space
 from nemo_text_processing.text_normalization.en.verbalizers.word import WordFst
-from nemo_text_processing.text_normalization.es.verbalizers.verbalize import VerbalizeFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
-
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class VerbalizeFinalFst(GraphFst):
     """
     Finite state transducer that verbalizes an entire sentence
-
+    
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
         super().__init__(name="verbalize_final", kind="verbalize", deterministic=deterministic)
         verbalize = VerbalizeFst(deterministic=deterministic).fst
         word = WordFst(deterministic=deterministic).fst
+
         types = verbalize | word
         graph = (
             pynutil.delete("tokens")
             + delete_space
             + pynutil.delete("{")
             + delete_space
             + types
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/normalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/normalize.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,15 +16,20 @@
 import os
 import re
 from argparse import ArgumentParser
 from collections import OrderedDict
 from math import factorial
 from typing import Dict, List, Union
 
-from nemo_text_processing.text_normalization.data_loader_utils import get_installation_msg, pre_process
+from nemo_text_processing.text_normalization.data_loader_utils import (
+    get_installation_msg,
+    load_file,
+    pre_process,
+    write_file,
+)
 from nemo_text_processing.text_normalization.token_parser import PRESERVE_ORDER_KEY, TokenParser
 from tqdm import tqdm
 
 try:
     import pynini
 
     PYNINI_AVAILABLE = True
@@ -33,15 +38,15 @@
     PYNINI_AVAILABLE = False
 
 try:
     from nemo.collections.common.tokenizers.moses_tokenizers import MosesProcessor
     from nemo.collections.nlp.data.text_normalization.utils import post_process_punct
 
     NLP_AVAILABLE = True
-except (ModuleNotFoundError, ImportError):
+except (ModuleNotFoundError, ImportError) as e:
     NLP_AVAILABLE = False
 
 
 SPACE_DUP = re.compile(' {2,}')
 
 
 class Normalizer:
@@ -61,25 +66,31 @@
         self,
         input_case: str,
         lang: str = 'en',
         deterministic: bool = True,
         cache_dir: str = None,
         overwrite_cache: bool = False,
         whitelist: str = None,
+        lm: bool = False,
     ):
         assert input_case in ["lower_cased", "cased"]
 
         if not PYNINI_AVAILABLE:
             raise ImportError(get_installation_msg())
 
         if lang == 'en' and deterministic:
             from nemo_text_processing.text_normalization.en.taggers.tokenize_and_classify import ClassifyFst
             from nemo_text_processing.text_normalization.en.verbalizers.verbalize_final import VerbalizeFinalFst
         elif lang == 'en' and not deterministic:
-            from nemo_text_processing.text_normalization.en.taggers.tokenize_and_classify_with_audio import ClassifyFst
+            if lm:
+                from nemo_text_processing.text_normalization.en.taggers.tokenize_and_classify_lm import ClassifyFst
+            else:
+                from nemo_text_processing.text_normalization.en.taggers.tokenize_and_classify_with_audio import (
+                    ClassifyFst,
+                )
             from nemo_text_processing.text_normalization.en.verbalizers.verbalize_final import VerbalizeFinalFst
         elif lang == 'ru':
             # Ru TN only support non-deterministic cases and produces multiple normalization options
             # use normalize_with_audio.py
             from nemo_text_processing.text_normalization.ru.taggers.tokenize_and_classify import ClassifyFst
             from nemo_text_processing.text_normalization.ru.verbalizers.verbalize_final import VerbalizeFinalFst
         elif lang == 'de':
@@ -101,28 +112,32 @@
 
         if NLP_AVAILABLE:
             self.processor = MosesProcessor(lang_id=lang)
         else:
             self.processor = None
             print("NeMo NLP is not available. Moses de-tokenization will be skipped.")
 
-    def normalize_list(self, texts: List[str], verbose=False, punct_post_process: bool = False) -> List[str]:
+    def normalize_list(
+        self, texts: List[str], verbose=False, punct_pre_process: bool = False, punct_post_process: bool = False
+    ) -> List[str]:
         """
         NeMo text normalizer
 
         Args:
             texts: list of input strings
             verbose: whether to print intermediate meta information
 
         Returns converted list input strings
         """
         res = []
         for input in tqdm(texts):
             try:
-                text = self.normalize(input, verbose=verbose, punct_post_process=punct_post_process)
+                text = self.normalize(
+                    input, verbose=verbose, punct_pre_process=punct_pre_process, punct_post_process=punct_post_process
+                )
             except:
                 print(input)
                 raise Exception
             res.append(text)
         return res
 
     def _estimate_number_of_permutations_in_nested_dict(
@@ -357,15 +372,18 @@
         """
         output = pynini.shortestpath(lattice, nshortest=1, unique=True).string()
         return output
 
 
 def parse_args():
     parser = ArgumentParser()
-    parser.add_argument("input_string", help="input string", type=str)
+    input = parser.add_mutually_exclusive_group()
+    input.add_argument("--text", dest="input_string", help="input string", type=str)
+    input.add_argument("--input_file", dest="input_file", help="input file path", type=str)
+    parser.add_argument('--output_file', dest="output_file", help="output file path", type=str)
     parser.add_argument("--language", help="language", choices=["en", "de", "es"], default="en", type=str)
     parser.add_argument(
         "--input_case", help="input capitalization", choices=["lower_cased", "cased"], default="cased", type=str
     )
     parser.add_argument("--verbose", help="print info for debugging", action='store_true')
     parser.add_argument(
         "--punct_post_process", help="set to True to enable punctuation post processing", action="store_true"
@@ -383,22 +401,40 @@
     )
     return parser.parse_args()
 
 
 if __name__ == "__main__":
     args = parse_args()
     whitelist = os.path.abspath(args.whitelist) if args.whitelist else None
+
     normalizer = Normalizer(
         input_case=args.input_case,
         cache_dir=args.cache_dir,
         overwrite_cache=args.overwrite_cache,
         whitelist=whitelist,
         lang=args.language,
     )
-    print(
-        normalizer.normalize(
-            args.input_string,
+    if args.input_string:
+        print(
+            normalizer.normalize(
+                args.input_string,
+                verbose=args.verbose,
+                punct_pre_process=args.punct_pre_process,
+                punct_post_process=args.punct_post_process,
+            )
+        )
+    elif args.input_file:
+        print("Loading data: " + args.input_file)
+        data = load_file(args.input_file)
+
+        print("- Data: " + str(len(data)) + " sentences")
+        normalizer_prediction = normalizer.normalize_list(
+            data,
             verbose=args.verbose,
             punct_pre_process=args.punct_pre_process,
             punct_post_process=args.punct_post_process,
         )
-    )
+        if args.output_file:
+            write_file(args.output_file, normalizer_prediction)
+            print(f"- Normalized. Writing out to {args.output_file}")
+        else:
+            print(normalizer_prediction)
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/normalize_with_audio.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/normalize_with_audio.py`

 * *Files 3% similar despite different names*

```diff
@@ -95,24 +95,27 @@
     def __init__(
         self,
         input_case: str,
         lang: str = 'en',
         cache_dir: str = None,
         overwrite_cache: bool = False,
         whitelist: str = None,
+        lm: bool = False,
     ):
 
         super().__init__(
             input_case=input_case,
             lang=lang,
             deterministic=False,
             cache_dir=cache_dir,
             overwrite_cache=overwrite_cache,
             whitelist=whitelist,
+            lm=lm,
         )
+        self.lm = lm
 
     def normalize(self, text: str, n_tagged: int, punct_post_process: bool = True, verbose: bool = False,) -> str:
         """
         Main function. Normalizes tokens from written to spoken form
             e.g. 12 kg -> twelve kilograms
 
         Args:
@@ -125,40 +128,53 @@
             normalized text options (usually there are multiple ways of normalizing a given semiotic class)
         """
 
         assert (
             len(text.split()) < 500
         ), "Your input is too long. Please split up the input into sentences, or strings with fewer than 500 words"
         original_text = text
+        text = pre_process(text)  # to handle []
 
-        if self.lang == "en":
-            text = pre_process(text)
         text = text.strip()
         if not text:
             if verbose:
                 print(text)
             return text
         text = pynini.escape(text)
 
-        if n_tagged == -1:
+        if self.lm:
+            if self.lang not in ["en"]:
+                raise ValueError(f"{self.lang} is not supported in LM mode")
+
             if self.lang == "en":
                 try:
-                    tagged_texts = rewrite.rewrites(text, self.tagger.fst_no_digits)
+                    lattice = rewrite.rewrite_lattice(text, self.tagger.fst_no_digits)
                 except pynini.lib.rewrite.Error:
+                    lattice = rewrite.rewrite_lattice(text, self.tagger.fst)
+                lattice = rewrite.lattice_to_nshortest(lattice, n_tagged)
+                tagged_texts = [(x[1], float(x[2])) for x in lattice.paths().items()]
+                tagged_texts.sort(key=lambda x: x[1])
+                tagged_texts, weights = list(zip(*tagged_texts))
+        else:
+            if n_tagged == -1:
+                if self.lang == "en":
+                    try:
+                        tagged_texts = rewrite.rewrites(text, self.tagger.fst_no_digits)
+                    except pynini.lib.rewrite.Error:
+                        tagged_texts = rewrite.rewrites(text, self.tagger.fst)
+                else:
                     tagged_texts = rewrite.rewrites(text, self.tagger.fst)
             else:
-                tagged_texts = rewrite.rewrites(text, self.tagger.fst)
-        else:
-            if self.lang == "en":
-                try:
-                    tagged_texts = rewrite.top_rewrites(text, self.tagger.fst_no_digits, nshortest=n_tagged)
-                except pynini.lib.rewrite.Error:
+                if self.lang == "en":
+                    try:
+                        tagged_texts = rewrite.top_rewrites(text, self.tagger.fst_no_digits, nshortest=n_tagged)
+                    except pynini.lib.rewrite.Error:
+                        tagged_texts = rewrite.top_rewrites(text, self.tagger.fst, nshortest=n_tagged)
+                else:
                     tagged_texts = rewrite.top_rewrites(text, self.tagger.fst, nshortest=n_tagged)
-            else:
-                tagged_texts = rewrite.top_rewrites(text, self.tagger.fst, nshortest=n_tagged)
 
         # non-deterministic Eng normalization uses tagger composed with verbalizer, no permutation in between
         if self.lang == "en":
             normalized_texts = tagged_texts
         else:
             normalized_texts = []
             for tagged_text in tagged_texts:
@@ -171,14 +187,17 @@
             # do post-processing based on Moses detokenizer
             if self.processor:
                 normalized_texts = [self.processor.detokenize([t]) for t in normalized_texts]
                 normalized_texts = [
                     post_process_punct(input=original_text, normalized_text=t) for t in normalized_texts
                 ]
 
+        if self.lm:
+            return normalized_texts, weights
+
         normalized_texts = set(normalized_texts)
         return normalized_texts
 
     def _verbalize(self, tagged_text: str, normalized_texts: List[str], verbose: bool = False):
         """
         Verbalizes tagged text
 
@@ -312,14 +331,17 @@
     parser.add_argument(
         "--cache_dir",
         help="path to a dir with .far grammar file. Set to None to avoid using cache",
         default=None,
         type=str,
     )
     parser.add_argument("--n_jobs", default=-2, type=int, help="The maximum number of concurrently running jobs")
+    parser.add_argument(
+        "--lm", action="store_true", help="Set to True for WFST+LM. Only available for English right now."
+    )
     parser.add_argument("--batch_size", default=200, type=int, help="Number of examples for each process")
     return parser.parse_args()
 
 
 def _normalize_line(normalizer: NormalizerWithAudio, n_tagged, verbose, line: str, remove_punct, punct_post_process):
     line = json.loads(line)
     pred_text = line["pred_text"]
@@ -411,14 +433,15 @@
     if args.text is not None:
         normalizer = NormalizerWithAudio(
             input_case=args.input_case,
             lang=args.language,
             cache_dir=args.cache_dir,
             overwrite_cache=args.overwrite_cache,
             whitelist=args.whitelist,
+            lm=args.lm,
         )
 
         if os.path.exists(args.text):
             with open(args.text, 'r') as f:
                 args.text = f.read().strip()
         normalized_texts = normalizer.normalize(
             text=args.text,
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/alphabet.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/alphabet.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/currency/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/currency/currency_plural.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/currency/currency_plural.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/currency/currency_singular.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/currency/currency_singular.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/electronic/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/electronic/symbols.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/electronic/symbols.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/measurements.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/measurements.tsv`

 * *Files 10% similar despite different names*

```diff
@@ -80,25 +80,47 @@
 га	гектаров
 га	гектару
 га	гектарам
 га	гектаром
 га	гектарами
 га	гектаре
 га	гектарах
-м²	квадратный метр	-0.1
-м²	квадратные метры	-0.1
-м²	квадратного метра	-0.1
-м²	квадратных метров	-0.1
-м²	квадратному метру	-0.1
-м²	квадратным метрам	-0.1
-м²	квадратные метры	-0.1
-м²	квадратным метром	-0.1
-м²	квадратными метрами	-0.1
-м²	квадратном метре	-0.1
-м²	квадратных метрах	-0.1
+м²	квадратный метр	-0.11
+м²	квадратные метры	-0.11
+м²	квадратного метра	-0.11
+м²	квадратных метров	-0.11
+м²	квадратному метру	-0.11
+м²	квадратным метрам	-0.11
+м²	квадратные метры	-0.11
+м²	квадратным метром	-0.11
+м²	квадратными метрами	-0.11
+м²	квадратном метре	-0.11
+м²	квадратных метрах	-0.11
+кв. м.	квадратный метр	-0.1
+кв. м.	квадратные метры	-0.1
+кв. м.	квадратного метра	-0.1
+кв. м.	квадратных метров	-0.1
+кв. м.	квадратному метру	-0.1
+кв. м.	квадратным метрам	-0.1
+кв. м.	квадратные метры	-0.1
+кв. м.	квадратным метром	-0.1
+кв. м.	квадратными метрами	-0.1
+кв. м.	квадратном метре	-0.1
+кв.м.	квадратных метрах	-0.1
+кв.м.	квадратный метр	-0.1
+кв.м.	квадратные метры	-0.1
+кв.м.	квадратного метра	-0.1
+кв.м.	квадратных метров	-0.1
+кв.м.	квадратному метру	-0.1
+кв.м.	квадратным метрам	-0.1
+кв.м.	квадратные метры	-0.1
+кв.м.	квадратным метром	-0.1
+кв.м.	квадратными метрами	-0.1
+кв.м.	квадратном метре	-0.1
+кв.м.	квадратных метрах	-0.1
 м2	квадратный метр	0.1
 м2	квадратные метры	0.1
 м2	квадратного метра	0.1
 м2	квадратных метров	0.1
 м2	квадратному метру	0.1
 м2	квадратным метрам	0.1
 м2	квадратные метры	0.1
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/months/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/currency/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/months/abbr_to_name.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/months/abbr_to_name.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/1_cardinals_nominative.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/1_cardinals_nominative.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/2_cardinals_genitive.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/2_cardinals_genitive.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/3_cardinals_dative.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/3_cardinals_dative.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/4_cardinals_accusative.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/4_cardinals_accusative.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/5_cardinals_instrumental.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/5_cardinals_instrumental.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/6_cardinals_prepositional.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/6_cardinals_prepositional.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/electronic/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_alternatives.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_alternatives.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_nominative_case.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/cardinals_nominative_case.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/decimal_delimiter.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/decimal_delimiter.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/decimal_endings.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/decimal_endings.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/ordinals.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/ordinals.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/numbers/quantity.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/quantity.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/months/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/increment_hour_ordinal.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/increment_hour_ordinal.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/time/minutes_to_hour.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/minutes_to_hour.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/numbers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/g.fst` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/g.fst`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/universal_thousands_punct.far` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/universal_thousands_punct.far`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/util_arithmetic.far` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/util_arithmetic.far`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/utils/util_byte.far` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/util_byte.far`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/data/whitelist.tsv` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/whitelist.tsv`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/time/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/cardinal.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,152 +1,143 @@
-# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
-# Copyright 2017 Google Inc.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-# Adapted from https://github.com/google/TextNormalizationCoveringGrammars
-# Russian minimally supervised number grammar.
 
 from nemo_text_processing.text_normalization.en.graph_utils import (
     NEMO_DIGIT,
+    NEMO_NOT_QUOTE,
     NEMO_SIGMA,
-    NEMO_SPACE,
     GraphFst,
     insert_space,
 )
-from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA, TO_CYRILLIC
-from nemo_text_processing.text_normalization.ru.utils import get_abs_path
+from nemo_text_processing.text_normalization.en.taggers.date import get_four_digit_year_graph
+from nemo_text_processing.text_normalization.en.utils import get_abs_path
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class CardinalFst(GraphFst):
     """
     Finite state transducer for classifying cardinals, e.g. 
-        "1 001" ->  cardinal { integer: "тысяча один" }
+        -23 -> cardinal { negative: "true"  integer: "twenty three" } }
 
     Args:
-        number_names: number_names for cardinal and ordinal numbers
-        alternative_formats: alternative number formats
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self, number_names: dict, alternative_formats: dict, deterministic: bool = False):
+    def __init__(self, deterministic: bool = True, lm: bool = False):
         super().__init__(name="cardinal", kind="classify", deterministic=deterministic)
 
-        self.cardinal_numbers_default = self.get_cardinal_numbers(number_names, alternative_formats, mode="all")
-        self.cardinal_numbers_nominative = self.get_cardinal_numbers(
-            number_names, alternative_formats, mode="nominative"
-        )
-        self.optional_graph_negative = pynini.closure(
-            pynutil.insert("negative: ") + pynini.cross("-", "\"true\"") + insert_space, 0, 1
-        )
-
-        self.cardinal_numbers_with_optional_negative = (
-            self.optional_graph_negative
-            + pynutil.insert("integer: \"")
-            + self.cardinal_numbers_default
-            + pynutil.insert("\"")
-        )
-
-        # "03" -> remove leading zeros and verbalize
-        leading_zeros = pynini.closure(pynini.cross("0", ""))
-        self.cardinal_numbers_with_leading_zeros = (leading_zeros + self.cardinal_numbers_default).optimize()
-
-        # "123" -> "один два три"
-        single_digits_graph = pynini.string_file(get_abs_path("data/numbers/cardinals_nominative_case.tsv")).optimize()
-        single_digits_graph = pynini.compose(NEMO_DIGIT, single_digits_graph)
+        self.lm = lm
+        self.deterministic = deterministic
+        # TODO replace to have "oh" as a default for "0"
+        graph = pynini.Far(get_abs_path("data/number/cardinal_number_name.far")).get_fst()
+        self.graph_hundred_component_at_least_one_none_zero_digit = (
+            pynini.closure(NEMO_DIGIT, 2, 3) | pynini.difference(NEMO_DIGIT, pynini.accep("0"))
+        ) @ graph
+
+        graph_digit = pynini.string_file(get_abs_path("data/number/digit.tsv"))
+        graph_zero = pynini.string_file(get_abs_path("data/number/zero.tsv"))
+
+        single_digits_graph = pynini.invert(graph_digit | graph_zero)
         self.single_digits_graph = single_digits_graph + pynini.closure(insert_space + single_digits_graph)
 
-        optional_quantity = pynini.string_file(get_abs_path("data/numbers/quantity.tsv")).optimize()
-        optional_quantity = pynutil.insert("quantity: \"") + optional_quantity + pynutil.insert("\"")
-        optional_quantity = pynini.closure(
-            (pynutil.add_weight(pynini.accep(NEMO_SPACE), -0.1) | insert_space) + optional_quantity, 0, 1
-        )
-
-        serial_graph = self.get_serial_graph()
-
-        final_graph = (
-            self.optional_graph_negative
-            + pynutil.insert("integer: \"")
-            + self.cardinal_numbers_with_leading_zeros
-            + pynutil.insert("\"")
-            + optional_quantity
-        ).optimize()
+        if not deterministic:
+            # for a single token allow only the same normalization
+            # "007" -> {"oh oh seven", "zero zero seven"} not {"oh zero seven"}
+            single_digits_graph_zero = pynini.invert(graph_digit | graph_zero)
+            single_digits_graph_oh = pynini.invert(graph_digit) | pynini.cross("0", "oh")
+
+            self.single_digits_graph = single_digits_graph_zero + pynini.closure(
+                insert_space + single_digits_graph_zero
+            )
+            self.single_digits_graph |= single_digits_graph_oh + pynini.closure(insert_space + single_digits_graph_oh)
+
+            single_digits_graph_with_commas = pynini.closure(
+                self.single_digits_graph + insert_space, 1, 3
+            ) + pynini.closure(
+                pynutil.delete(",")
+                + single_digits_graph
+                + insert_space
+                + single_digits_graph
+                + insert_space
+                + single_digits_graph,
+                1,
+            )
+
+        optional_minus_graph = pynini.closure(pynutil.insert("negative: ") + pynini.cross("-", "\"true\" "), 0, 1)
+
+        graph = (
+            pynini.closure(NEMO_DIGIT, 1, 3)
+            + (pynini.closure(pynutil.delete(",") + NEMO_DIGIT ** 3) | pynini.closure(NEMO_DIGIT ** 3))
+        ) @ graph
+
+        self.graph = graph
+        self.graph_with_and = self.add_optional_and(graph)
+
+        if deterministic:
+            long_numbers = pynini.compose(NEMO_DIGIT ** (5, ...), self.single_digits_graph).optimize()
+            final_graph = plurals._priority_union(long_numbers, self.graph_with_and, NEMO_SIGMA).optimize()
+            cardinal_with_leading_zeros = pynini.compose(
+                pynini.accep("0") + pynini.closure(NEMO_DIGIT), self.single_digits_graph
+            )
+            final_graph |= cardinal_with_leading_zeros
+        else:
+            leading_zeros = pynini.compose(pynini.closure(pynini.accep("0"), 1), self.single_digits_graph)
+            cardinal_with_leading_zeros = (
+                leading_zeros + pynutil.insert(" ") + pynini.compose(pynini.closure(NEMO_DIGIT), self.graph_with_and)
+            )
+
+            # add small weight to non-default graphs to make sure the deterministic option is listed first
+            final_graph = (
+                self.graph_with_and
+                | pynutil.add_weight(self.single_digits_graph, 0.0001)
+                | get_four_digit_year_graph()  # allows e.g. 4567 be pronouced as forty five sixty seven
+                | pynutil.add_weight(single_digits_graph_with_commas, 0.0001)
+                | cardinal_with_leading_zeros
+            )
 
-        final_graph = pynutil.add_weight(final_graph, -0.1)
-        final_graph |= pynutil.insert("integer: \"") + pynutil.add_weight(serial_graph, 10) + pynutil.insert("\"")
-        self.final_graph = final_graph
-
-        # to cover cases "2-х" -> "двух" (this is not covered by ordinal endings)
-        final_graph |= pynini.compose(
-            pynini.compose(NEMO_DIGIT ** (1, ...) + pynini.cross('-х', ''), final_graph),
-            NEMO_SIGMA + pynini.accep("х\"") + NEMO_SIGMA,
-        )
+        final_graph = optional_minus_graph + pynutil.insert("integer: \"") + final_graph + pynutil.insert("\"")
         final_graph = self.add_tokens(final_graph)
         self.fst = final_graph.optimize()
 
-    def get_cardinal_numbers(self, number_names: dict, alternative_formats: dict, mode: str = "all"):
-        """Returns cardinal numbers names graph.
+    def add_optional_and(self, graph):
+        if not self.deterministic:
+            graph = pynini.compose(
+                graph, NEMO_SIGMA + pynini.closure(pynini.cross("hundred ", " "), 0, 1) + NEMO_SIGMA
+            )
+
+        not_quote = pynini.closure(NEMO_NOT_QUOTE)
+        no_thousand_million = pynini.difference(
+            not_quote, not_quote + pynini.union("thousand", "million") + not_quote
+        ).optimize()
+        integer = (
+            not_quote + pynutil.add_weight(pynini.cross("hundred ", "hundred and ") + no_thousand_million, -0.0001)
+        ).optimize()
 
-        Args:
-            number_names: number_names for cardinal and ordinal numbers
-            alternative_formats: alternative number formats
-            mode: "all" - to return graph that includes all Ru cases, "nominative" to return only the nominative form
-        """
-        if mode == "all":
-            cardinal_names = number_names['cardinal_number_names']
-        elif mode == "nominative":
-            cardinal_names = number_names['cardinal_names_nominative']
-        else:
-            raise ValueError(f'{mode} is not supported.')
-        one_thousand_alternative = alternative_formats['one_thousand_alternative']
-        separators = alternative_formats['separators']
-
-        cardinal_numbers = cardinal_names | pynini.compose(cardinal_names, one_thousand_alternative)
-        cardinal_numbers = pynini.compose(separators, cardinal_numbers)
-        return cardinal_numbers
-
-    def get_serial_graph(self):
-        """
-        Finite state transducer for classifying serial.
-            The serial is a combination of digits, letters and dashes, e.g.:
-            c325-b -> tokens { cardinal { integer: "си три два пять би" } }
-        """
-        num_graph = self.single_digits_graph
-
-        alpha = TO_CYRILLIC | RU_ALPHA
-
-        delimiter = insert_space | pynini.cross("-", " ") | pynini.cross("/", " ")
-        letter_num = pynini.closure(alpha + delimiter, 1) + num_graph
-        num_letter = pynini.closure(num_graph + delimiter, 1) + alpha
-        num_delimiter_num = pynini.closure(num_graph + delimiter, 1) + num_graph
-        next_alpha_or_num = pynini.closure(delimiter + (alpha | num_graph))
-        serial_graph = (letter_num | num_letter | num_delimiter_num) + next_alpha_or_num
-
-        # at least 1 alpha and 1 digit is present
-        at_least_one_alpha_num = (
-            NEMO_SIGMA + (RU_ALPHA | pynini.project(TO_CYRILLIC, "input")) + NEMO_SIGMA + NEMO_DIGIT + NEMO_SIGMA
-        ) | (NEMO_SIGMA + NEMO_DIGIT + NEMO_SIGMA + (RU_ALPHA | pynini.project(TO_CYRILLIC, "input")) + NEMO_SIGMA)
-        serial_graph = pynini.compose(at_least_one_alpha_num, serial_graph.optimize()).optimize()
-        # numbers only with 2+ delimiters
-        serial_graph |= (
-            num_graph + delimiter + num_graph + delimiter + num_graph + pynini.closure(delimiter + num_graph)
+        no_hundred = pynini.difference(NEMO_SIGMA, not_quote + pynini.accep("hundred") + not_quote).optimize()
+        integer |= (
+            not_quote + pynutil.add_weight(pynini.cross("thousand ", "thousand and ") + no_hundred, -0.0001)
         ).optimize()
-        return serial_graph.optimize()
+
+        graph_with_and = pynini.compose(graph, integer).optimize() | pynutil.add_weight(graph, 0.00001)
+
+        return graph_with_and
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/decimals.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/decimals.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/measure.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/money.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/number_names.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/number_names.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/ordinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/ordinal.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/telephone.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/telephone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/tokenize_and_classify.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify.py`

 * *Files 20% similar despite different names*

```diff
@@ -11,138 +11,168 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import os
 
 from nemo_text_processing.text_normalization.en.graph_utils import (
+    NEMO_WHITE_SPACE,
     GraphFst,
     delete_extra_space,
     delete_space,
     generator_main,
 )
+from nemo_text_processing.text_normalization.en.taggers.abbreviation import AbbreviationFst
+from nemo_text_processing.text_normalization.en.taggers.cardinal import CardinalFst
+from nemo_text_processing.text_normalization.en.taggers.date import DateFst
+from nemo_text_processing.text_normalization.en.taggers.decimal import DecimalFst
+from nemo_text_processing.text_normalization.en.taggers.electronic import ElectronicFst
+from nemo_text_processing.text_normalization.en.taggers.fraction import FractionFst
+from nemo_text_processing.text_normalization.en.taggers.measure import MeasureFst
+from nemo_text_processing.text_normalization.en.taggers.money import MoneyFst
+from nemo_text_processing.text_normalization.en.taggers.ordinal import OrdinalFst
 from nemo_text_processing.text_normalization.en.taggers.punctuation import PunctuationFst
-from nemo_text_processing.text_normalization.ru.taggers.cardinal import CardinalFst
-from nemo_text_processing.text_normalization.ru.taggers.date import DateFst
-from nemo_text_processing.text_normalization.ru.taggers.decimals import DecimalFst
-from nemo_text_processing.text_normalization.ru.taggers.electronic import ElectronicFst
-from nemo_text_processing.text_normalization.ru.taggers.measure import MeasureFst
-from nemo_text_processing.text_normalization.ru.taggers.money import MoneyFst
-from nemo_text_processing.text_normalization.ru.taggers.number_names import get_alternative_formats, get_number_names
-from nemo_text_processing.text_normalization.ru.taggers.ordinal import OrdinalFst
-from nemo_text_processing.text_normalization.ru.taggers.telephone import TelephoneFst
-from nemo_text_processing.text_normalization.ru.taggers.time import TimeFst
-from nemo_text_processing.text_normalization.ru.taggers.whitelist import WhiteListFst
-from nemo_text_processing.text_normalization.ru.taggers.word import WordFst
+from nemo_text_processing.text_normalization.en.taggers.range import RangeFst as RangeFst
+from nemo_text_processing.text_normalization.en.taggers.roman import RomanFst
+from nemo_text_processing.text_normalization.en.taggers.serial import SerialFst
+from nemo_text_processing.text_normalization.en.taggers.telephone import TelephoneFst
+from nemo_text_processing.text_normalization.en.taggers.time import TimeFst
+from nemo_text_processing.text_normalization.en.taggers.whitelist import WhiteListFst
+from nemo_text_processing.text_normalization.en.taggers.word import WordFst
+from nemo_text_processing.text_normalization.en.verbalizers.date import DateFst as vDateFst
+from nemo_text_processing.text_normalization.en.verbalizers.ordinal import OrdinalFst as vOrdinalFst
+from nemo_text_processing.text_normalization.en.verbalizers.time import TimeFst as vTimeFst
 
 from nemo.utils import logging
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
 class ClassifyFst(GraphFst):
     """
-    Final class that composes all other classification grammars. This class can process an entire sentence, that is lower cased.
-    For deployment, this grammar will be compiled and exported to OpenFst Finite State Archive (FAR) File.
+    Final class that composes all other classification grammars. This class can process an entire sentence including punctuation.
+    For deployment, this grammar will be compiled and exported to OpenFst Finate State Archiv (FAR) File. 
     More details to deployment at NeMo/tools/text_processing_deployment.
-
+    
     Args:
         input_case: accepting either "lower_cased" or "cased" input.
         deterministic: if True will provide a single transduction option,
             for False multiple options (used for audio-based normalization)
         cache_dir: path to a dir with .far grammar file. Set to None to avoid using cache.
         overwrite_cache: set to True to overwrite .far files
         whitelist: path to a file with whitelist replacements
     """
 
     def __init__(
         self,
         input_case: str,
-        deterministic: bool = False,
+        deterministic: bool = True,
         cache_dir: str = None,
         overwrite_cache: bool = False,
         whitelist: str = None,
     ):
         super().__init__(name="tokenize_and_classify", kind="classify", deterministic=deterministic)
-        if deterministic:
-            raise ValueError(
-                'Ru TN only supports non-deterministic cases and produces multiple normalization options.'
-            )
+
         far_file = None
         if cache_dir is not None and cache_dir != "None":
             os.makedirs(cache_dir, exist_ok=True)
             whitelist_file = os.path.basename(whitelist) if whitelist else ""
             far_file = os.path.join(
-                cache_dir, f"_{input_case}_ru_tn_{deterministic}_deterministic{whitelist_file}.far"
+                cache_dir, f"_{input_case}_en_tn_{deterministic}_deterministic{whitelist_file}.far"
             )
         if not overwrite_cache and far_file and os.path.exists(far_file):
             self.fst = pynini.Far(far_file, mode="r")["tokenize_and_classify"]
-            logging.info(f"ClassifyFst.fst was restored from {far_file}.")
+            logging.info(f'ClassifyFst.fst was restored from {far_file}.')
         else:
-            logging.info(f"Creating ClassifyFst grammars. This might take some time...")
-            number_names = get_number_names()
-            alternative_formats = get_alternative_formats()
-
-            self.cardinal = CardinalFst(
-                number_names=number_names, alternative_formats=alternative_formats, deterministic=deterministic
-            )
-            cardinal_graph = self.cardinal.fst
-
-            self.ordinal = OrdinalFst(
-                number_names=number_names, alternative_formats=alternative_formats, deterministic=deterministic
-            )
-            ordinal_graph = self.ordinal.fst
-
-            self.decimal = DecimalFst(cardinal=self.cardinal, deterministic=deterministic)
-            decimal_graph = self.decimal.fst
-
-            self.measure = MeasureFst(cardinal=self.cardinal, decimal=self.decimal, deterministic=deterministic)
-            measure_graph = self.measure.fst
-            self.date = DateFst(number_names=number_names, deterministic=deterministic)
-            date_graph = self.date.fst
+            logging.info(f"Creating ClassifyFst grammars.")
+            cardinal = CardinalFst(deterministic=deterministic)
+            cardinal_graph = cardinal.fst
+
+            ordinal = OrdinalFst(cardinal=cardinal, deterministic=deterministic)
+            ordinal_graph = ordinal.fst
+
+            decimal = DecimalFst(cardinal=cardinal, deterministic=deterministic)
+            decimal_graph = decimal.fst
+            fraction = FractionFst(deterministic=deterministic, cardinal=cardinal)
+            fraction_graph = fraction.fst
+
+            measure = MeasureFst(cardinal=cardinal, decimal=decimal, fraction=fraction, deterministic=deterministic)
+            measure_graph = measure.fst
+            date_graph = DateFst(cardinal=cardinal, deterministic=deterministic).fst
             word_graph = WordFst(deterministic=deterministic).fst
-            self.time = TimeFst(number_names=number_names, deterministic=deterministic)
-            time_graph = self.time.fst
-            self.telephone = TelephoneFst(number_names=number_names, deterministic=deterministic)
-            telephone_graph = self.telephone.fst
-            self.electronic = ElectronicFst(deterministic=deterministic)
-            electronic_graph = self.electronic.fst
-            self.money = MoneyFst(cardinal=self.cardinal, decimal=self.decimal, deterministic=deterministic)
-            money_graph = self.money.fst
-            self.whitelist = WhiteListFst(input_case=input_case, deterministic=deterministic, input_file=whitelist)
-            whitelist_graph = self.whitelist.fst
+            time_graph = TimeFst(cardinal=cardinal, deterministic=deterministic).fst
+            telephone_graph = TelephoneFst(deterministic=deterministic).fst
+            electonic_graph = ElectronicFst(deterministic=deterministic).fst
+            money_graph = MoneyFst(cardinal=cardinal, decimal=decimal, deterministic=deterministic).fst
+            whitelist_graph = WhiteListFst(
+                input_case=input_case, deterministic=deterministic, input_file=whitelist
+            ).fst
             punct_graph = PunctuationFst(deterministic=deterministic).fst
+            serial_graph = SerialFst(cardinal=cardinal, ordinal=ordinal, deterministic=deterministic).fst
+
+            v_time_graph = vTimeFst(deterministic=deterministic).fst
+            v_ordinal_graph = vOrdinalFst(deterministic=deterministic)
+            v_date_graph = vDateFst(ordinal=v_ordinal_graph, deterministic=deterministic).fst
+            time_final = pynini.compose(time_graph, v_time_graph)
+            date_final = pynini.compose(date_graph, v_date_graph)
+            range_graph = RangeFst(
+                time=time_final, date=date_final, cardinal=cardinal, deterministic=deterministic
+            ).fst
 
             classify = (
                 pynutil.add_weight(whitelist_graph, 1.01)
                 | pynutil.add_weight(time_graph, 1.1)
                 | pynutil.add_weight(date_graph, 1.09)
                 | pynutil.add_weight(decimal_graph, 1.1)
-                | pynutil.add_weight(measure_graph, 0.9)
+                | pynutil.add_weight(measure_graph, 1.1)
                 | pynutil.add_weight(cardinal_graph, 1.1)
                 | pynutil.add_weight(ordinal_graph, 1.1)
                 | pynutil.add_weight(money_graph, 1.1)
                 | pynutil.add_weight(telephone_graph, 1.1)
-                | pynutil.add_weight(electronic_graph, 1.1)
-                | pynutil.add_weight(word_graph, 100)
+                | pynutil.add_weight(electonic_graph, 1.1)
+                | pynutil.add_weight(fraction_graph, 1.1)
+                | pynutil.add_weight(range_graph, 1.1)
+                | pynutil.add_weight(serial_graph, 1.1001)  # should be higher than the rest of the classes
+            )
+
+            # roman_graph = RomanFst(deterministic=deterministic).fst
+            # classify |= pynutil.add_weight(roman_graph, 1.1)
+
+            if not deterministic:
+                abbreviation_graph = AbbreviationFst(deterministic=deterministic).fst
+                classify |= pynutil.add_weight(abbreviation_graph, 100)
+
+            punct = pynutil.insert("tokens { ") + pynutil.add_weight(punct_graph, weight=2.1) + pynutil.insert(" }")
+            punct = pynini.closure(
+                pynini.compose(pynini.closure(NEMO_WHITE_SPACE, 1), delete_extra_space)
+                | (pynutil.insert(" ") + punct),
+                1,
             )
 
-            punct = pynutil.insert("tokens { ") + pynutil.add_weight(punct_graph, weight=1.1) + pynutil.insert(" }")
+            classify |= pynutil.add_weight(word_graph, 100)
             token = pynutil.insert("tokens { ") + classify + pynutil.insert(" }")
             token_plus_punct = (
                 pynini.closure(punct + pynutil.insert(" ")) + token + pynini.closure(pynutil.insert(" ") + punct)
             )
 
-            graph = token_plus_punct + pynini.closure(pynutil.add_weight(delete_extra_space, 1.1) + token_plus_punct)
+            graph = token_plus_punct + pynini.closure(
+                (
+                    pynini.compose(pynini.closure(NEMO_WHITE_SPACE, 1), delete_extra_space)
+                    | (pynutil.insert(" ") + punct + pynutil.insert(" "))
+                )
+                + token_plus_punct
+            )
+
             graph = delete_space + graph + delete_space
+            graph |= punct
 
             self.fst = graph.optimize()
 
             if far_file:
                 generator_main(far_file, {"tokenize_and_classify": self.fst})
                 logging.info(f"ClassifyFst grammars are saved to {far_file}.")
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/whitelist.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/taggers/word.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,70 +1,68 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_CHAR, GraphFst, convert_space
-from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA, TO_CYRILLIC
-from nemo_text_processing.text_normalization.ru.utils import get_abs_path, load_labels
+from nemo_text_processing.text_normalization.en.graph_utils import (
+    NEMO_ALPHA,
+    NEMO_DIGIT,
+    NEMO_NOT_SPACE,
+    NEMO_SIGMA,
+    GraphFst,
+    convert_space,
+)
+from nemo_text_processing.text_normalization.en.taggers.punctuation import PunctuationFst
 
 try:
     import pynini
     from pynini.lib import pynutil
+    from pynini.examples import plurals
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class WhiteListFst(GraphFst):
+class WordFst(GraphFst):
     """
-    Finite state transducer for classifying whitelist, e.g.
-        misses -> tokens { name: "mrs" }
-        for non-deterministic case: "Dr. Abc" ->
-            tokens { name: "drive" } tokens { name: "Abc" }
-            tokens { name: "doctor" } tokens { name: "Abc" }
-            tokens { name: "Dr." } tokens { name: "Abc" }
-    This class has highest priority among all classifier grammars. Whitelisted tokens are defined and loaded from "data/whitelist.tsv".
+    Finite state transducer for classifying word. Considers sentence boundary exceptions.
+        e.g. sleep -> tokens { name: "sleep" }
 
     Args:
-        input_case: accepting either "lower_cased" or "cased" input.
         deterministic: if True will provide a single transduction option,
-            for False multiple options (used for audio-based normalization)
-        input_file: path to a file with whitelist replacements
+            for False multiple transduction are generated (used for audio-based normalization)
     """
 
-    def __init__(self, input_case: str, deterministic: bool = True, input_file: str = None):
-        super().__init__(name="whitelist", kind="classify", deterministic=deterministic)
+    def __init__(self, deterministic: bool = True):
+        super().__init__(name="word", kind="classify", deterministic=deterministic)
 
-        def _get_whitelist_graph(input_case, file):
-            whitelist = load_labels(file)
-            if input_case == "lower_cased":
-                whitelist = [[x[0].lower()] + x[1:] for x in whitelist]
-            else:
-                whitelist = [[x[0].lower()] + x[1:] for x in whitelist]
-            graph = pynini.string_map(whitelist)
-            return graph
-
-        graph = _get_whitelist_graph(input_case, get_abs_path("data/whitelist.tsv"))
-
-        if input_file:
-            graph = _get_whitelist_graph(input_case, input_file)
-
-        units_graph = _get_whitelist_graph(input_case, file=get_abs_path("data/measurements.tsv"))
-        # do not replace single letter units, like `м`, `°` and `%` will be replaced
-        units_graph = pynini.compose((NEMO_CHAR ** (2, ...) | pynini.difference(NEMO_CHAR, RU_ALPHA)), units_graph)
-        graph |= units_graph.optimize()
-        graph |= TO_CYRILLIC + pynini.closure(pynutil.insert(" ") + TO_CYRILLIC)
+        punct = PunctuationFst().graph
+        self.graph = pynini.closure(pynini.difference(NEMO_NOT_SPACE, punct.project("input")), 1)
 
-        self.final_graph = convert_space(graph)
-        self.fst = (pynutil.insert("name: \"") + self.final_graph + pynutil.insert("\"")).optimize()
+        if not deterministic:
+            self.graph = pynini.closure(
+                pynini.difference(
+                    self.graph, pynini.union("$", "€", "₩", "£", "¥", "#", "$", "%") + pynini.closure(NEMO_DIGIT, 1)
+                ),
+                1,
+            )
+
+        # leave phones of format [HH AH0 L OW1] untouched
+        phoneme_unit = pynini.closure(NEMO_ALPHA, 1) + pynini.closure(NEMO_DIGIT)
+        phoneme = (
+            pynini.accep(pynini.escape("["))
+            + pynini.closure(phoneme_unit + pynini.accep(" "))
+            + phoneme_unit
+            + pynini.accep(pynini.escape("]"))
+        )
+        self.graph = plurals._priority_union(convert_space(phoneme), self.graph, NEMO_SIGMA)
+        self.fst = (pynutil.insert("name: \"") + self.graph + pynutil.insert("\"")).optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/taggers/word.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/money.py`

 * *Files 15% similar despite different names*

```diff
@@ -8,32 +8,36 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_SPACE, GraphFst
+from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
+from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
+
     PYNINI_AVAILABLE = False
 
 
-class WordFst(GraphFst):
+class MoneyFst(GraphFst):
     """
-    Finite state transducer for classifying word.
-        e.g. sleep -> tokens { name: "sleep" }
+    Finite state transducer for verbalizing money, e.g.
+        money {  "пять рублей" } -> пять рублей
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="word", kind="classify")
-        word = pynutil.insert("name: \"") + pynini.closure(NEMO_NOT_SPACE, 1) + pynutil.insert("\"")
-        self.fst = word.optimize()
+        super().__init__(name="money", kind="verbalize", deterministic=deterministic)
+
+        graph = pynini.closure(RU_ALPHA | " ")
+        delete_tokens = self.delete_tokens(pynutil.delete("integer_part: \"") + graph + pynutil.delete("\""))
+        self.fst = delete_tokens.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/data/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/cardinal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/electronic.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,51 +1,42 @@
-# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst
+from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
+from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class CardinalFst(GraphFst):
+class ElectronicFst(GraphFst):
     """
-    Finite state transducer for verbalizing cardinals
-        e.g. cardinal { integer: "тысяча один" } -> "тысяча один"
+    Finite state transducer for verbalizing electronic
+        e.g. electronic { username: "эй би собака эн ди точка ру" } -> "эй би собака эн ди точка ру"
 
     Args:
         deterministic: if True will provide a single transduction option,
-            for False multiple transduction are generated (used for audio-based normalization)
+        for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="cardinal", kind="verbalize", deterministic=deterministic)
-        optional_sign = pynini.closure(pynini.cross("negative: \"true\" ", "минус "), 0, 1)
-        optional_quantity_part = pynini.closure(
-            pynini.accep(" ")
-            + pynutil.delete("quantity: \"")
-            + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\""),
-            0,
-            1,
-        )
-        integer = pynutil.delete("integer: \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
-        self.graph = optional_sign + integer + optional_quantity_part
-        delete_tokens = self.delete_tokens(self.graph)
+        super().__init__(name="electronic", kind="verbalize", deterministic=deterministic)
+
+        graph = pynutil.delete("username: \"") + pynini.closure(RU_ALPHA | " ") + pynutil.delete("\"")
+        delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/date.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/date.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/decimal.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/telephone.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,58 +1,43 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space
+from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
+from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
+
     PYNINI_AVAILABLE = False
 
 
-class DecimalFst(GraphFst):
+class TelephoneFst(GraphFst):
     """
-    Finite state transducer for verbalizing decimal, e.g.
-        tokens { decimal { integer_part: "одно целая" fractional_part: "восемь сотых} } ->
-            "одно целая восемь сотых"
+    Finite state transducer for verbalizing telephone, e.g.
+        telephone { number_part: "восемь девятьсот тринадцать девятьсот восемьдесят три пятьдесят шесть ноль один" } -> "восемь девятьсот тринадцать девятьсот восемьдесят три пятьдесят шесть ноль один"
 
     Args:
         deterministic: if True will provide a single transduction option,
             for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="decimal", kind="verbalize", deterministic=deterministic)
+        super().__init__(name="telephone", kind="verbalize", deterministic=deterministic)
 
-        optional_sign = pynini.closure(pynini.cross("negative: \"true\" ", "минус "), 0, 1)
-        integer = pynutil.delete(" \"") + pynini.closure(NEMO_NOT_QUOTE, 1) + pynutil.delete("\"")
-        integer_part = pynutil.delete("integer_part:") + integer
-        fractional_part = pynutil.delete("fractional_part:") + integer
-        optional_quantity_part = pynini.closure(
-            pynini.accep(" ")
-            + pynutil.delete("quantity: \"")
-            + pynini.closure(NEMO_NOT_QUOTE, 1)
-            + pynutil.delete("\""),
-            0,
-            1,
-        )
-
-        self.graph = (
-            optional_sign + integer_part + pynini.accep(" ") + fractional_part + optional_quantity_part + delete_space
-        )
-        delete_tokens = self.delete_tokens(self.graph)
+        graph = pynutil.delete("number_part: \"") + pynini.closure(RU_ALPHA | " ", 1) + pynutil.delete("\"")
+        delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/electronic.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/verbalize_final.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,43 +1,53 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
-from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
+from nemo_text_processing.text_normalization.en.graph_utils import GraphFst, delete_extra_space, delete_space
+from nemo_text_processing.text_normalization.en.verbalizers.word import WordFst
+from nemo_text_processing.text_normalization.ru.verbalizers.verbalize import VerbalizeFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class ElectronicFst(GraphFst):
+class VerbalizeFinalFst(GraphFst):
     """
-    Finite state transducer for verbalizing electronic
-        e.g. electronic { username: "эй би собака эн ди точка ру" } -> "эй би собака эн ди точка ру"
+    Finite state transducer that verbalizes an entire sentence, e.g. 
+    tokens { name: "its" } tokens { time { hours: "12" minutes: "30" } } tokens { name: "now" } -> its 12:30 now
 
     Args:
         deterministic: if True will provide a single transduction option,
-        for False multiple transduction are generated (used for audio-based normalization)
+            for False multiple options (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="electronic", kind="verbalize", deterministic=deterministic)
-
-        graph = pynutil.delete("username: \"") + pynini.closure(RU_ALPHA | " ") + pynutil.delete("\"")
-        delete_tokens = self.delete_tokens(graph)
-        self.fst = delete_tokens.optimize()
+        super().__init__(name="verbalize_final", kind="verbalize", deterministic=deterministic)
+        verbalize = VerbalizeFst().fst
+        word = WordFst().fst
+        types = verbalize | word
+        graph = (
+            pynutil.delete("tokens")
+            + delete_space
+            + pynutil.delete("{")
+            + delete_space
+            + types
+            + delete_space
+            + pynutil.delete("}")
+        )
+        graph = delete_space + pynini.closure(graph + delete_extra_space) + graph + delete_space
+        self.fst = graph
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/measure.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_range.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,55 +1,50 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import (
-    NEMO_NON_BREAKING_SPACE,
-    NEMO_SPACE,
-    GraphFst,
-    delete_space,
-)
-from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
-
-try:
-    import pynini
-    from pynini.lib import pynutil
-
-    PYNINI_AVAILABLE = True
-except (ModuleNotFoundError, ImportError):
-    PYNINI_AVAILABLE = False
-
-
-class MeasureFst(GraphFst):
-    """
-    Finite state transducer for verbalizing measure, e.g.
-        measure { cardinal { integer: "два килограма" } } -> "два килограма"
-    
-    Args:
-        deterministic: if True will provide a single transduction option,
-            for False multiple transduction are generated (used for audio-based normalization)
-    """
-
-    def __init__(self, deterministic: bool = True):
-        super().__init__(name="measure", kind="verbalize", deterministic=deterministic)
-
-        graph = (
-            pynutil.delete(" cardinal { integer: \"")
-            + pynini.closure(RU_ALPHA | NEMO_SPACE | NEMO_NON_BREAKING_SPACE)
-            + pynutil.delete("\"")
-            + delete_space
-            + pynutil.delete("}")
-        )
-
-        delete_tokens = self.delete_tokens(graph)
-        self.fst = delete_tokens.optimize()
+import pytest
+from nemo_text_processing.text_normalization.normalize import Normalizer
+from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
+from parameterized import parameterized
+
+from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
+
+
+class TestRange:
+    normalizer_en = (
+        Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
+        if PYNINI_AVAILABLE
+        else None
+    )
+    normalizer_with_audio_en = (
+        NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
+        if PYNINI_AVAILABLE and CACHE_DIR
+        else None
+    )
+
+    # address is tagged by the measure class
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_range.txt'))
+    @pytest.mark.skipif(
+        not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
+    )
+    @pytest.mark.run_only_on('CPU')
+    @pytest.mark.unit
+    def test_norm(self, test_input, expected):
+        pred = self.normalizer_en.normalize(test_input, verbose=False)
+        assert pred == expected
+
+        if self.normalizer_with_audio_en:
+            pred_non_deterministic = self.normalizer_with_audio_en.normalize(
+                test_input, n_tagged=30, punct_post_process=False,
+            )
+            assert expected in pred_non_deterministic
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/money.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_word.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,44 +1,36 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
-from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
 
-try:
-    import pynini
-    from pynini.lib import pynutil
-
-    PYNINI_AVAILABLE = True
-except (ModuleNotFoundError, ImportError):
-
-    PYNINI_AVAILABLE = False
-
-
-class MoneyFst(GraphFst):
-    """
-    Finite state transducer for verbalizing money, e.g.
-        money {  "пять рублей" } -> пять рублей
-
-    Args:
-        deterministic: if True will provide a single transduction option,
-            for False multiple transduction are generated (used for audio-based normalization)
-    """
-
-    def __init__(self, deterministic: bool = True):
-        super().__init__(name="money", kind="verbalize", deterministic=deterministic)
-
-        graph = pynini.closure(RU_ALPHA | " ")
-        delete_tokens = self.delete_tokens(pynutil.delete("integer_part: \"") + graph + pynutil.delete("\""))
-        self.fst = delete_tokens.optimize()
+import pytest
+from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
+from parameterized import parameterized
+
+from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
+
+
+class TestWord:
+    inverse_normalizer = (
+        InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+    )
+
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_word.txt'))
+    @pytest.mark.skipif(
+        not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
+    )
+    @pytest.mark.run_only_on('CPU')
+    @pytest.mark.unit
+    def test_denorm(self, test_input, expected):
+        pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
+        assert pred == expected
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/telephone.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_date.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,44 +1,35 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import GraphFst
-from nemo_text_processing.text_normalization.ru.alphabet import RU_ALPHA
-
-try:
-    import pynini
-    from pynini.lib import pynutil
-
-    PYNINI_AVAILABLE = True
-except (ModuleNotFoundError, ImportError):
-
-    PYNINI_AVAILABLE = False
-
-
-class TelephoneFst(GraphFst):
-    """
-    Finite state transducer for verbalizing telephone, e.g.
-        telephone { number_part: "восемь девятьсот тринадцать девятьсот восемьдесят три пятьдесят шесть ноль один" } -> "восемь девятьсот тринадцать девятьсот восемьдесят три пятьдесят шесть ноль один"
-
-    Args:
-        deterministic: if True will provide a single transduction option,
-            for False multiple transduction are generated (used for audio-based normalization)
-    """
-
-    def __init__(self, deterministic: bool = True):
-        super().__init__(name="telephone", kind="verbalize", deterministic=deterministic)
-
-        graph = pynutil.delete("number_part: \"") + pynini.closure(RU_ALPHA | " ", 1) + pynutil.delete("\"")
-        delete_tokens = self.delete_tokens(graph)
-        self.fst = delete_tokens.optimize()
+import pytest
+from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
+from parameterized import parameterized
+
+from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
+
+
+class TestDate:
+    inverse_normalizer = (
+        InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+    )
+
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_date.txt'))
+    @pytest.mark.skipif(
+        not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
+    )
+    @pytest.mark.run_only_on('CPU')
+    @pytest.mark.unit
+    def test_denorm(self, test_input, expected):
+        pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
+        assert pred == expected
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/time.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/en/verbalizers/roman.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,62 +1,74 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst, delete_space, insert_space
+from nemo_text_processing.text_normalization.en.graph_utils import NEMO_NOT_QUOTE, GraphFst
+from nemo_text_processing.text_normalization.en.verbalizers.ordinal import OrdinalFst
 
 try:
     import pynini
     from pynini.lib import pynutil
 
     PYNINI_AVAILABLE = True
 except (ModuleNotFoundError, ImportError):
     PYNINI_AVAILABLE = False
 
 
-class TimeFst(GraphFst):
+class RomanFst(GraphFst):
     """
-    Finite state transducer for verbalizing electronic
-        e.g. time { hours: "два часа пятнадцать минут" } -> "два часа пятнадцать минут"
+    Finite state transducer for verbalizing roman numerals
+        e.g. tokens { roman { integer: "one" } } -> one
 
     Args:
         deterministic: if True will provide a single transduction option,
-        for False multiple transduction are generated (used for audio-based normalization)
+            for False multiple transduction are generated (used for audio-based normalization)
     """
 
     def __init__(self, deterministic: bool = True):
-        super().__init__(name="time", kind="verbalize", deterministic=deterministic)
+        super().__init__(name="roman", kind="verbalize", deterministic=deterministic)
+        suffix = OrdinalFst().suffix
 
-        hour = (
-            pynutil.delete("hours:")
-            + delete_space
-            + pynutil.delete("\"")
+        cardinal = pynini.closure(NEMO_NOT_QUOTE)
+        ordinal = pynini.compose(cardinal, suffix)
+
+        graph = (
+            pynutil.delete("key_cardinal: \"")
             + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
-        )
-        minutes = (
-            pynutil.delete("minutes:")
-            + delete_space
+            + pynini.accep(" ")
+            + pynutil.delete("integer: \"")
+            + cardinal
             + pynutil.delete("\"")
+        ).optimize()
+
+        graph |= (
+            pynutil.delete("default_cardinal: \"default\" integer: \"") + cardinal + pynutil.delete("\"")
+        ).optimize()
+
+        graph |= (
+            pynutil.delete("default_ordinal: \"default\" integer: \"") + ordinal + pynutil.delete("\"")
+        ).optimize()
+
+        graph |= (
+            pynutil.delete("key_the_ordinal: \"")
             + pynini.closure(NEMO_NOT_QUOTE, 1)
             + pynutil.delete("\"")
-        )
-
-        self.graph = (
-            hour + delete_space + insert_space + minutes + delete_space + pynutil.delete("preserve_order: true")
-        )
-        self.graph |= hour + delete_space
-        self.graph |= minutes + delete_space + insert_space + hour + delete_space
+            + pynini.accep(" ")
+            + pynutil.delete("integer: \"")
+            + pynini.closure(pynutil.insert("the "), 0, 1)
+            + ordinal
+            + pynutil.delete("\"")
+        ).optimize()
 
-        delete_tokens = self.delete_tokens(self.graph)
+        delete_tokens = self.delete_tokens(graph)
         self.fst = delete_tokens.optimize()
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/verbalize.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/verbalize.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 # Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/ru/verbalizers/verbalize_final.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_decimal.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,54 +1,35 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
-# Copyright 2015 and onwards Google, Inc.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-from nemo_text_processing.text_normalization.en.graph_utils import GraphFst, delete_extra_space, delete_space
-from nemo_text_processing.text_normalization.en.verbalizers.word import WordFst
-from nemo_text_processing.text_normalization.ru.verbalizers.verbalize import VerbalizeFst
-
-try:
-    import pynini
-    from pynini.lib import pynutil
-
-    PYNINI_AVAILABLE = True
-except (ModuleNotFoundError, ImportError):
-    PYNINI_AVAILABLE = False
-
-
-class VerbalizeFinalFst(GraphFst):
-    """
-    Finite state transducer that verbalizes an entire sentence, e.g. 
-    tokens { name: "its" } tokens { time { hours: "12" minutes: "30" } } tokens { name: "now" } -> its 12:30 now
-
-    Args:
-        deterministic: if True will provide a single transduction option,
-            for False multiple options (used for audio-based normalization)
-    """
-
-    def __init__(self, deterministic: bool = True):
-        super().__init__(name="verbalize_final", kind="verbalize", deterministic=deterministic)
-        verbalize = VerbalizeFst().fst
-        word = WordFst().fst
-        types = verbalize | word
-        graph = (
-            pynutil.delete("tokens")
-            + delete_space
-            + pynutil.delete("{")
-            + delete_space
-            + types
-            + delete_space
-            + pynutil.delete("}")
-        )
-        graph = delete_space + pynini.closure(graph + delete_extra_space) + graph + delete_space
-        self.fst = graph
+import pytest
+from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
+from parameterized import parameterized
+
+from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
+
+
+class TestDecimal:
+    inverse_normalizer = (
+        InverseNormalizer(lang='fr', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+    )
+
+    @parameterized.expand(parse_test_case_file('fr/data_inverse_text_normalization/test_cases_decimal.txt'))
+    @pytest.mark.skipif(
+        not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
+    )
+    @pytest.mark.run_only_on('CPU')
+    @pytest.mark.unit
+    def test_denorm(self, test_input, expected):
+        pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
+        assert pred == expected
```

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/run_evaluate.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/run_evaluate.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_text_processing/text_normalization/token_parser.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/token_parser.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/nemo_toolkit.egg-info/PKG-INFO` & `nemo_toolkit-1.9.0/nemo_toolkit.egg-info/PKG-INFO`

 * *Files 9% similar despite different names*

```diff
@@ -1,20 +1,19 @@
 Metadata-Version: 2.1
 Name: nemo-toolkit
-Version: 1.8.2
+Version: 1.9.0
 Summary: NeMo - a toolkit for Conversational AI
 Home-page: https://github.com/nvidia/nemo
 Download-URL: https://github.com/NVIDIA/NeMo/releases
 Author: NVIDIA
 Author-email: nemo-toolkit@nvidia.com
 Maintainer: NVIDIA
 Maintainer-email: nemo-toolkit@nvidia.com
 License: Apache2
 Keywords: deep learning,machine learning,gpu,NLP,NeMo,nvidia,pytorch,torch,tts,speech,language
-Platform: UNKNOWN
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research
 Classifier: Intended Audience :: Information Technology
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Image Recognition
@@ -27,15 +26,15 @@
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Environment :: Console
 Classifier: Natural Language :: English
 Classifier: Operating System :: OS Independent
 Description-Content-Type: text/markdown
 Provides-Extra: test
-Provides-Extra: text_processing
+Provides-Extra: nemo_text_processing
 Provides-Extra: core
 Provides-Extra: common
 Provides-Extra: asr
 Provides-Extra: cv
 Provides-Extra: nlp
 Provides-Extra: tts
 Provides-Extra: all
@@ -46,9 +45,7 @@
 **NeMo Core** provides common APIs all modules and models have to implement.
 
 **NeMo Collections**
 
 * ASR - collection of modules and models for building speech recognition networks
 * TTS - collection of modules and models for building speech synthesis networks
 * NLP - collection of modules and models for building NLP networks
-
-
```

### Comparing `nemo_toolkit-1.8.2/nemo_toolkit.egg-info/SOURCES.txt` & `nemo_toolkit-1.9.0/nemo_toolkit.egg-info/SOURCES.txt`

 * *Files 2% similar despite different names*

```diff
@@ -67,14 +67,15 @@
 nemo/collections/asr/parts/k2/graph_compilers.py
 nemo/collections/asr/parts/k2/graph_decoders.py
 nemo/collections/asr/parts/k2/map_loss.py
 nemo/collections/asr/parts/k2/ml_loss.py
 nemo/collections/asr/parts/k2/topologies.py
 nemo/collections/asr/parts/k2/utils.py
 nemo/collections/asr/parts/mixins/__init__.py
+nemo/collections/asr/parts/mixins/asr_adapter_mixins.py
 nemo/collections/asr/parts/mixins/mixins.py
 nemo/collections/asr/parts/numba/__init__.py
 nemo/collections/asr/parts/numba/rnnt_loss/__init__.py
 nemo/collections/asr/parts/numba/rnnt_loss/rnnt.py
 nemo/collections/asr/parts/numba/rnnt_loss/rnnt_numpy.py
 nemo/collections/asr/parts/numba/rnnt_loss/rnnt_pytorch.py
 nemo/collections/asr/parts/numba/rnnt_loss/utils/__init__.py
@@ -130,14 +131,15 @@
 nemo/collections/common/losses/smoothed_cross_entropy.py
 nemo/collections/common/losses/spanning_loss.py
 nemo/collections/common/metrics/__init__.py
 nemo/collections/common/metrics/classification_accuracy.py
 nemo/collections/common/metrics/global_average_loss_metric.py
 nemo/collections/common/metrics/perplexity.py
 nemo/collections/common/parts/__init__.py
+nemo/collections/common/parts/adapter_modules.py
 nemo/collections/common/parts/multi_layer_perceptron.py
 nemo/collections/common/parts/patch_utils.py
 nemo/collections/common/parts/ptl_overrides.py
 nemo/collections/common/parts/rnn.py
 nemo/collections/common/parts/transformer_utils.py
 nemo/collections/common/parts/utils.py
 nemo/collections/common/parts/preprocessing/__init__.py
@@ -170,27 +172,46 @@
 nemo/collections/cv/losses/nll_loss.py
 nemo/collections/cv/models/__init__.py
 nemo/collections/cv/models/mnist_lenet5.py
 nemo/collections/cv/modules/__init__.py
 nemo/collections/cv/modules/lenet5.py
 nemo/collections/nlp/__init__.py
 nemo/collections/nlp/data/__init__.py
+nemo/collections/nlp/data/common/__init__.py
+nemo/collections/nlp/data/common/sequence_to_sequence_dataset.py
 nemo/collections/nlp/data/data_utils/__init__.py
 nemo/collections/nlp/data/data_utils/data_preprocessing.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/__init__.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/__init__.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/assistant_data_processor.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/data_processor.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/dialogue_bert_dataset.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/dialogue_gpt_dataset.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/evaluate.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/input_example.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/metrics.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/prediction_utils.py
-nemo/collections/nlp/data/dialogue_state_tracking_generative/sgd/schema.py
+nemo/collections/nlp/data/dialogue/__init__.py
+nemo/collections/nlp/data/dialogue/data_processor/__init__.py
+nemo/collections/nlp/data/dialogue/data_processor/assistant_data_processor.py
+nemo/collections/nlp/data/dialogue/data_processor/data_processor.py
+nemo/collections/nlp/data/dialogue/data_processor/design_data_processor.py
+nemo/collections/nlp/data/dialogue/data_processor/mellon_qa_data_processor.py
+nemo/collections/nlp/data/dialogue/data_processor/ms_marco_data_processor.py
+nemo/collections/nlp/data/dialogue/data_processor/sgd_data_processor.py
+nemo/collections/nlp/data/dialogue/dataset/__init__.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_bert_dataset.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_dataset.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_gpt_classification_dataset.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_gpt_generation_dataset.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_nearest_neighbour_dataset.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_s2s_generation_dataset.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_sgd_bert_dataset.py
+nemo/collections/nlp/data/dialogue/dataset/dialogue_zero_shot_intent_dataset.py
+nemo/collections/nlp/data/dialogue/input_example/__init__.py
+nemo/collections/nlp/data/dialogue/input_example/assistant_input_example.py
+nemo/collections/nlp/data/dialogue/input_example/design_input_example.py
+nemo/collections/nlp/data/dialogue/input_example/input_example.py
+nemo/collections/nlp/data/dialogue/input_example/mellon_qa_input_example.py
+nemo/collections/nlp/data/dialogue/input_example/ms_marco_input_example.py
+nemo/collections/nlp/data/dialogue/input_example/sgd_input_example.py
+nemo/collections/nlp/data/dialogue/sgd/__init__.py
+nemo/collections/nlp/data/dialogue/sgd/evaluate.py
+nemo/collections/nlp/data/dialogue/sgd/prediction_utils.py
+nemo/collections/nlp/data/dialogue/sgd/schema.py
 nemo/collections/nlp/data/entity_linking/__init__.py
 nemo/collections/nlp/data/entity_linking/entity_linking_dataset.py
 nemo/collections/nlp/data/glue_benchmark/__init__.py
 nemo/collections/nlp/data/glue_benchmark/data_processors.py
 nemo/collections/nlp/data/glue_benchmark/glue_benchmark_dataset.py
 nemo/collections/nlp/data/glue_benchmark/gpt_ptune_dataset.py
 nemo/collections/nlp/data/glue_benchmark/t5_ptune_dataset.py
@@ -210,15 +231,15 @@
 nemo/collections/nlp/data/language_modeling/megatron/bart_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/base_dataset_utils.py
 nemo/collections/nlp/data/language_modeling/megatron/bert_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/blendable_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/data_samplers.py
 nemo/collections/nlp/data/language_modeling/megatron/dataset_utils.py
 nemo/collections/nlp/data/language_modeling/megatron/gpt_dataset.py
-nemo/collections/nlp/data/language_modeling/megatron/gpt_prompt_tuning_dataset.py
+nemo/collections/nlp/data/language_modeling/megatron/gpt_prompt_learning_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/helpers.cpp
 nemo/collections/nlp/data/language_modeling/megatron/indexed_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/lm_adapted_t5_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/megatron_batch_samplers.py
 nemo/collections/nlp/data/language_modeling/megatron/megatron_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/request_dataset.py
 nemo/collections/nlp/data/language_modeling/megatron/t5_dataset.py
@@ -235,35 +256,45 @@
 nemo/collections/nlp/data/text_classification/text_classification_dataset.py
 nemo/collections/nlp/data/text_normalization/__init__.py
 nemo/collections/nlp/data/text_normalization/constants.py
 nemo/collections/nlp/data/text_normalization/decoder_dataset.py
 nemo/collections/nlp/data/text_normalization/tagger_dataset.py
 nemo/collections/nlp/data/text_normalization/test_dataset.py
 nemo/collections/nlp/data/text_normalization/utils.py
+nemo/collections/nlp/data/text_normalization_as_tagging/__init__.py
+nemo/collections/nlp/data/text_normalization_as_tagging/bert_example.py
+nemo/collections/nlp/data/text_normalization_as_tagging/tagging.py
+nemo/collections/nlp/data/text_normalization_as_tagging/thutmose_tagger_dataset.py
+nemo/collections/nlp/data/text_normalization_as_tagging/utils.py
 nemo/collections/nlp/data/token_classification/__init__.py
 nemo/collections/nlp/data/token_classification/punctuation_capitalization_dataset.py
 nemo/collections/nlp/data/token_classification/punctuation_capitalization_infer_dataset.py
 nemo/collections/nlp/data/token_classification/punctuation_capitalization_tarred_dataset.py
 nemo/collections/nlp/data/token_classification/token_classification_dataset.py
 nemo/collections/nlp/data/token_classification/token_classification_utils.py
 nemo/collections/nlp/data/zero_shot_intent_recognition/__init__.py
 nemo/collections/nlp/data/zero_shot_intent_recognition/zero_shot_intent_dataset.py
 nemo/collections/nlp/losses/__init__.py
 nemo/collections/nlp/losses/sgd_loss.py
 nemo/collections/nlp/metrics/__init__.py
 nemo/collections/nlp/metrics/classification_report.py
+nemo/collections/nlp/metrics/dialogue_metrics.py
 nemo/collections/nlp/metrics/sequence_perplexity.py
+nemo/collections/nlp/metrics/sgd_metrics.py
 nemo/collections/nlp/models/__init__.py
 nemo/collections/nlp/models/enc_dec_nlp_model.py
 nemo/collections/nlp/models/nlp_model.py
-nemo/collections/nlp/models/dialogue_state_tracking_generative/__init__.py
-nemo/collections/nlp/models/dialogue_state_tracking_generative/dialogue_gpt_model.py
-nemo/collections/nlp/models/dialogue_state_tracking_generative/dialogue_metrics.py
-nemo/collections/nlp/models/dialogue_state_tracking_sgdqa/__init__.py
-nemo/collections/nlp/models/dialogue_state_tracking_sgdqa/sgdqa_model.py
+nemo/collections/nlp/models/dialogue/__init__.py
+nemo/collections/nlp/models/dialogue/dialogue_gpt_classification_model.py
+nemo/collections/nlp/models/dialogue/dialogue_gpt_generation_model.py
+nemo/collections/nlp/models/dialogue/dialogue_nearest_neighbour_model.py
+nemo/collections/nlp/models/dialogue/dialogue_s2s_generation_model.py
+nemo/collections/nlp/models/dialogue/dialogue_zero_shot_intent_model.py
+nemo/collections/nlp/models/dialogue/intent_slot_classification_model.py
+nemo/collections/nlp/models/dialogue/sgdqa_model.py
 nemo/collections/nlp/models/duplex_text_normalization/__init__.py
 nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py
 nemo/collections/nlp/models/duplex_text_normalization/duplex_tagger.py
 nemo/collections/nlp/models/duplex_text_normalization/duplex_tn.py
 nemo/collections/nlp/models/duplex_text_normalization/utils.py
 nemo/collections/nlp/models/entity_linking/__init__.py
 nemo/collections/nlp/models/entity_linking/entity_linking_model.py
@@ -273,25 +304,24 @@
 nemo/collections/nlp/models/information_retrieval/__init__.py
 nemo/collections/nlp/models/information_retrieval/base_ir_model.py
 nemo/collections/nlp/models/information_retrieval/bert_dpr_model.py
 nemo/collections/nlp/models/information_retrieval/bert_joint_ir_model.py
 nemo/collections/nlp/models/intent_slot_classification/__init__.py
 nemo/collections/nlp/models/intent_slot_classification/intent_slot_classification_model.py
 nemo/collections/nlp/models/intent_slot_classification/multi_label_intent_slot_classification_model.py
-nemo/collections/nlp/models/intent_slot_classification_refactor/__init__.py
-nemo/collections/nlp/models/intent_slot_classification_refactor/intent_slot_classification_model.py
 nemo/collections/nlp/models/language_modeling/__init__.py
 nemo/collections/nlp/models/language_modeling/bert_lm_model.py
 nemo/collections/nlp/models/language_modeling/megatron_bart_model.py
 nemo/collections/nlp/models/language_modeling/megatron_base_model.py
 nemo/collections/nlp/models/language_modeling/megatron_bert_model.py
+nemo/collections/nlp/models/language_modeling/megatron_finetune_model.py
 nemo/collections/nlp/models/language_modeling/megatron_glue_model.py
 nemo/collections/nlp/models/language_modeling/megatron_gpt_model.py
+nemo/collections/nlp/models/language_modeling/megatron_gpt_prompt_learning_model.py
 nemo/collections/nlp/models/language_modeling/megatron_lm_encoder_decoder_model.py
-nemo/collections/nlp/models/language_modeling/megatron_ptune_gpt_model.py
 nemo/collections/nlp/models/language_modeling/megatron_ptune_t5_model.py
 nemo/collections/nlp/models/language_modeling/megatron_t5_model.py
 nemo/collections/nlp/models/language_modeling/transformer_lm_model.py
 nemo/collections/nlp/models/language_modeling/megatron/__init__.py
 nemo/collections/nlp/models/language_modeling/megatron/bert_model.py
 nemo/collections/nlp/models/language_modeling/megatron/gpt_model.py
 nemo/collections/nlp/models/machine_translation/__init__.py
@@ -300,16 +330,17 @@
 nemo/collections/nlp/models/machine_translation/mt_enc_dec_config.py
 nemo/collections/nlp/models/machine_translation/mt_enc_dec_model.py
 nemo/collections/nlp/models/question_answering/__init__.py
 nemo/collections/nlp/models/question_answering/qa_model.py
 nemo/collections/nlp/models/text2sparql/__init__.py
 nemo/collections/nlp/models/text2sparql/text2sparql_model.py
 nemo/collections/nlp/models/text_classification/__init__.py
-nemo/collections/nlp/models/text_classification/ptune_text_classification_model.py
 nemo/collections/nlp/models/text_classification/text_classification_model.py
+nemo/collections/nlp/models/text_normalization_as_tagging/__init__.py
+nemo/collections/nlp/models/text_normalization_as_tagging/thutmose_tagger.py
 nemo/collections/nlp/models/token_classification/__init__.py
 nemo/collections/nlp/models/token_classification/punctuation_capitalization_config.py
 nemo/collections/nlp/models/token_classification/punctuation_capitalization_model.py
 nemo/collections/nlp/models/token_classification/token_classification_model.py
 nemo/collections/nlp/models/zero_shot_intent_recognition/__init__.py
 nemo/collections/nlp/models/zero_shot_intent_recognition/zero_shot_intent_model.py
 nemo/collections/nlp/modules/__init__.py
@@ -317,17 +348,19 @@
 nemo/collections/nlp/modules/common/bert_module.py
 nemo/collections/nlp/modules/common/classifier.py
 nemo/collections/nlp/modules/common/decoder_module.py
 nemo/collections/nlp/modules/common/encoder_module.py
 nemo/collections/nlp/modules/common/gpt_module.py
 nemo/collections/nlp/modules/common/lm_utils.py
 nemo/collections/nlp/modules/common/prompt_encoder.py
+nemo/collections/nlp/modules/common/prompt_table.py
 nemo/collections/nlp/modules/common/sequence_classifier.py
 nemo/collections/nlp/modules/common/sequence_regression.py
 nemo/collections/nlp/modules/common/sequence_token_classifier.py
+nemo/collections/nlp/modules/common/t5_prompt_encoder.py
 nemo/collections/nlp/modules/common/text_generation_server.py
 nemo/collections/nlp/modules/common/text_generation_utils.py
 nemo/collections/nlp/modules/common/token_classifier.py
 nemo/collections/nlp/modules/common/tokenizer_utils.py
 nemo/collections/nlp/modules/common/huggingface/__init__.py
 nemo/collections/nlp/modules/common/huggingface/albert.py
 nemo/collections/nlp/modules/common/huggingface/bert.py
@@ -340,22 +373,26 @@
 nemo/collections/nlp/modules/common/huggingface/roberta.py
 nemo/collections/nlp/modules/common/megatron/__init__.py
 nemo/collections/nlp/modules/common/megatron/clip_grads.py
 nemo/collections/nlp/modules/common/megatron/fused_bias_dropout_add.py
 nemo/collections/nlp/modules/common/megatron/fused_bias_gelu.py
 nemo/collections/nlp/modules/common/megatron/fused_layer_norm.py
 nemo/collections/nlp/modules/common/megatron/language_model.py
+nemo/collections/nlp/modules/common/megatron/layer_type.py
 nemo/collections/nlp/modules/common/megatron/megatron_decoders.py
 nemo/collections/nlp/modules/common/megatron/megatron_encoder_decoder.py
 nemo/collections/nlp/modules/common/megatron/megatron_encoders.py
 nemo/collections/nlp/modules/common/megatron/megatron_init.py
 nemo/collections/nlp/modules/common/megatron/megatron_transformer_decoder.py
 nemo/collections/nlp/modules/common/megatron/megatron_transformer_encoder.py
 nemo/collections/nlp/modules/common/megatron/megatron_utils.py
 nemo/collections/nlp/modules/common/megatron/module.py
+nemo/collections/nlp/modules/common/megatron/retrieval_token_level_encoder_decoder.py
+nemo/collections/nlp/modules/common/megatron/retrieval_transformer.py
+nemo/collections/nlp/modules/common/megatron/rotary_pos_embedding.py
 nemo/collections/nlp/modules/common/megatron/token_level_encoder_decoder.py
 nemo/collections/nlp/modules/common/megatron/transformer.py
 nemo/collections/nlp/modules/common/megatron/utils.py
 nemo/collections/nlp/modules/common/transformer/__init__.py
 nemo/collections/nlp/modules/common/transformer/bridge_encoders.py
 nemo/collections/nlp/modules/common/transformer/perceiver_encoders.py
 nemo/collections/nlp/modules/common/transformer/reduction_encoders.py
@@ -370,68 +407,41 @@
 nemo/collections/nlp/modules/dialogue_state_tracking/__init__.py
 nemo/collections/nlp/modules/dialogue_state_tracking/sgd_decoder.py
 nemo/collections/nlp/modules/dialogue_state_tracking/sgd_encoder.py
 nemo/collections/nlp/parts/__init__.py
 nemo/collections/nlp/parts/nlp_overrides.py
 nemo/collections/nlp/parts/utils_funcs.py
 nemo/collections/tts/__init__.py
-nemo/collections/tts/data/__init__.py
-nemo/collections/tts/data/datalayers.py
 nemo/collections/tts/helpers/__init__.py
 nemo/collections/tts/helpers/helpers.py
 nemo/collections/tts/losses/__init__.py
 nemo/collections/tts/losses/aligner_loss.py
 nemo/collections/tts/losses/fastpitchloss.py
-nemo/collections/tts/losses/fastspeech2loss.py
-nemo/collections/tts/losses/glow_tts_loss.py
 nemo/collections/tts/losses/hifigan_losses.py
 nemo/collections/tts/losses/stftlosses.py
 nemo/collections/tts/losses/tacotron2loss.py
-nemo/collections/tts/losses/uniglowloss.py
 nemo/collections/tts/losses/waveglowloss.py
 nemo/collections/tts/models/__init__.py
 nemo/collections/tts/models/aligner.py
 nemo/collections/tts/models/base.py
-nemo/collections/tts/models/degli.py
-nemo/collections/tts/models/ed_mel2spec.py
 nemo/collections/tts/models/fastpitch.py
-nemo/collections/tts/models/fastpitch_hifigan_e2e.py
-nemo/collections/tts/models/fastspeech2.py
-nemo/collections/tts/models/fastspeech2_hifigan_e2e.py
-nemo/collections/tts/models/glow_tts.py
 nemo/collections/tts/models/hifigan.py
-nemo/collections/tts/models/melgan.py
 nemo/collections/tts/models/mixer_tts.py
-nemo/collections/tts/models/squeezewave.py
 nemo/collections/tts/models/tacotron2.py
-nemo/collections/tts/models/talknet.py
 nemo/collections/tts/models/two_stages.py
-nemo/collections/tts/models/uniglow.py
 nemo/collections/tts/models/univnet.py
 nemo/collections/tts/models/waveglow.py
 nemo/collections/tts/modules/__init__.py
 nemo/collections/tts/modules/aligner.py
-nemo/collections/tts/modules/degli.py
-nemo/collections/tts/modules/ed_mel2spec.py
 nemo/collections/tts/modules/fastpitch.py
-nemo/collections/tts/modules/fastspeech2.py
-nemo/collections/tts/modules/fastspeech2_submodules.py
-nemo/collections/tts/modules/glow_tts.py
-nemo/collections/tts/modules/glow_tts_parser.py
-nemo/collections/tts/modules/glow_tts_submodules.py
 nemo/collections/tts/modules/hifigan_modules.py
-nemo/collections/tts/modules/melgan_modules.py
 nemo/collections/tts/modules/mixer_tts.py
-nemo/collections/tts/modules/squeezewave.py
-nemo/collections/tts/modules/squeezewave_submodules.py
 nemo/collections/tts/modules/submodules.py
 nemo/collections/tts/modules/tacotron2.py
-nemo/collections/tts/modules/talknet.py
 nemo/collections/tts/modules/transformer.py
-nemo/collections/tts/modules/uniglow.py
 nemo/collections/tts/modules/univnet_modules.py
 nemo/collections/tts/modules/waveglow.py
 nemo/collections/tts/torch/__init__.py
 nemo/collections/tts/torch/data.py
 nemo/collections/tts/torch/de_utils.py
 nemo/collections/tts/torch/en_utils.py
 nemo/collections/tts/torch/g2ps.py
@@ -442,14 +452,18 @@
 nemo/core/classes/__init__.py
 nemo/core/classes/common.py
 nemo/core/classes/dataset.py
 nemo/core/classes/exportable.py
 nemo/core/classes/loss.py
 nemo/core/classes/modelPT.py
 nemo/core/classes/module.py
+nemo/core/classes/mixins/__init__.py
+nemo/core/classes/mixins/access_mixins.py
+nemo/core/classes/mixins/adapter_mixin_strategies.py
+nemo/core/classes/mixins/adapter_mixins.py
 nemo/core/config/__init__.py
 nemo/core/config/base_config.py
 nemo/core/config/hydra_runner.py
 nemo/core/config/modelPT.py
 nemo/core/config/optimizers.py
 nemo/core/config/pytorch.py
 nemo/core/config/pytorch_lightning.py
@@ -495,15 +509,14 @@
 nemo/utils/formatters/base.py
 nemo/utils/formatters/colors.py
 nemo/utils/formatters/utils.py
 nemo_text_processing/__init__.py
 nemo_text_processing/inverse_text_normalization/__init__.py
 nemo_text_processing/inverse_text_normalization/inverse_normalize.py
 nemo_text_processing/inverse_text_normalization/run_evaluate.py
-nemo_text_processing/inverse_text_normalization/run_predict.py
 nemo_text_processing/inverse_text_normalization/de/__init__.py
 nemo_text_processing/inverse_text_normalization/de/taggers/__init__.py
 nemo_text_processing/inverse_text_normalization/de/taggers/cardinal.py
 nemo_text_processing/inverse_text_normalization/de/taggers/date.py
 nemo_text_processing/inverse_text_normalization/de/taggers/decimal.py
 nemo_text_processing/inverse_text_normalization/de/taggers/electronic.py
 nemo_text_processing/inverse_text_normalization/de/taggers/fraction.py
@@ -797,15 +810,14 @@
 nemo_text_processing/inverse_text_normalization/vi/verbalizers/whitelist.py
 nemo_text_processing/inverse_text_normalization/vi/verbalizers/word.py
 nemo_text_processing/text_normalization/__init__.py
 nemo_text_processing/text_normalization/data_loader_utils.py
 nemo_text_processing/text_normalization/normalize.py
 nemo_text_processing/text_normalization/normalize_with_audio.py
 nemo_text_processing/text_normalization/run_evaluate.py
-nemo_text_processing/text_normalization/run_predict.py
 nemo_text_processing/text_normalization/token_parser.py
 nemo_text_processing/text_normalization/de/__init__.py
 nemo_text_processing/text_normalization/de/utils.py
 nemo_text_processing/text_normalization/de/data/__init__.py
 nemo_text_processing/text_normalization/de/data/fractions.tsv
 nemo_text_processing/text_normalization/de/data/whitelist.tsv
 nemo_text_processing/text_normalization/de/data/electronic/__init__.py
@@ -866,69 +878,86 @@
 nemo_text_processing/text_normalization/de/verbalizers/verbalize.py
 nemo_text_processing/text_normalization/de/verbalizers/verbalize_final.py
 nemo_text_processing/text_normalization/en/__init__.py
 nemo_text_processing/text_normalization/en/clean_eval_data.py
 nemo_text_processing/text_normalization/en/graph_utils.py
 nemo_text_processing/text_normalization/en/utils.py
 nemo_text_processing/text_normalization/en/data/__init__.py
-nemo_text_processing/text_normalization/en/data/magnitudes.tsv
-nemo_text_processing/text_normalization/en/data/math_operations.tsv
-nemo_text_processing/text_normalization/en/data/measurements.tsv
 nemo_text_processing/text_normalization/en/data/suppletive.tsv
-nemo_text_processing/text_normalization/en/data/time_suffix.tsv
-nemo_text_processing/text_normalization/en/data/time_zone.tsv
-nemo_text_processing/text_normalization/en/data/whitelist.tsv
-nemo_text_processing/text_normalization/en/data/whitelist_alternatives.tsv
-nemo_text_processing/text_normalization/en/data/whitelist_lj_speech.tsv
 nemo_text_processing/text_normalization/en/data/address/__init__.py
-nemo_text_processing/text_normalization/en/data/address/address_words.tsv
-nemo_text_processing/text_normalization/en/data/address/states.tsv
-nemo_text_processing/text_normalization/en/data/currency/__init__.py
-nemo_text_processing/text_normalization/en/data/currency/currency.tsv
-nemo_text_processing/text_normalization/en/data/currency/currency_minor_plural.tsv
-nemo_text_processing/text_normalization/en/data/currency/currency_minor_singular.tsv
+nemo_text_processing/text_normalization/en/data/address/address_word.tsv
+nemo_text_processing/text_normalization/en/data/address/state.tsv
+nemo_text_processing/text_normalization/en/data/date/__init__.py
+nemo_text_processing/text_normalization/en/data/date/day.tsv
+nemo_text_processing/text_normalization/en/data/date/month_abbr.tsv
+nemo_text_processing/text_normalization/en/data/date/month_name.tsv
+nemo_text_processing/text_normalization/en/data/date/month_number.tsv
+nemo_text_processing/text_normalization/en/data/date/year_suffix.tsv
 nemo_text_processing/text_normalization/en/data/electronic/__init__.py
 nemo_text_processing/text_normalization/en/data/electronic/domain.tsv
-nemo_text_processing/text_normalization/en/data/electronic/server_name.tsv
-nemo_text_processing/text_normalization/en/data/electronic/symbols.tsv
-nemo_text_processing/text_normalization/en/data/months/__init__.py
-nemo_text_processing/text_normalization/en/data/months/abbr.tsv
-nemo_text_processing/text_normalization/en/data/months/days.tsv
-nemo_text_processing/text_normalization/en/data/months/names.tsv
-nemo_text_processing/text_normalization/en/data/months/numbers.tsv
-nemo_text_processing/text_normalization/en/data/numbers/__init__.py
-nemo_text_processing/text_normalization/en/data/numbers/cardinal_number_name.far
-nemo_text_processing/text_normalization/en/data/numbers/digit.tsv
-nemo_text_processing/text_normalization/en/data/numbers/hundred.tsv
-nemo_text_processing/text_normalization/en/data/numbers/teen.tsv
-nemo_text_processing/text_normalization/en/data/numbers/thousands.tsv
-nemo_text_processing/text_normalization/en/data/numbers/ties.tsv
-nemo_text_processing/text_normalization/en/data/numbers/zero.tsv
-nemo_text_processing/text_normalization/en/data/ordinals/__init__.py
-nemo_text_processing/text_normalization/en/data/ordinals/digit.tsv
-nemo_text_processing/text_normalization/en/data/ordinals/teen.tsv
+nemo_text_processing/text_normalization/en/data/electronic/symbol.tsv
+nemo_text_processing/text_normalization/en/data/measure/__init__.py
+nemo_text_processing/text_normalization/en/data/measure/math_operation.tsv
+nemo_text_processing/text_normalization/en/data/measure/unit.tsv
+nemo_text_processing/text_normalization/en/data/measure/unit_alternatives.tsv
+nemo_text_processing/text_normalization/en/data/money/__init__.py
+nemo_text_processing/text_normalization/en/data/money/currency_major.tsv
+nemo_text_processing/text_normalization/en/data/money/currency_minor_plural.tsv
+nemo_text_processing/text_normalization/en/data/money/currency_minor_singular.tsv
+nemo_text_processing/text_normalization/en/data/money/per_unit.tsv
+nemo_text_processing/text_normalization/en/data/number/__init__.py
+nemo_text_processing/text_normalization/en/data/number/cardinal_number_name.far
+nemo_text_processing/text_normalization/en/data/number/digit.tsv
+nemo_text_processing/text_normalization/en/data/number/fraction.tsv
+nemo_text_processing/text_normalization/en/data/number/hundred.tsv
+nemo_text_processing/text_normalization/en/data/number/quantity_abbr.tsv
+nemo_text_processing/text_normalization/en/data/number/teen.tsv
+nemo_text_processing/text_normalization/en/data/number/thousand.tsv
+nemo_text_processing/text_normalization/en/data/number/ty.tsv
+nemo_text_processing/text_normalization/en/data/number/zero.tsv
+nemo_text_processing/text_normalization/en/data/ordinal/__init__.py
+nemo_text_processing/text_normalization/en/data/ordinal/digit.tsv
+nemo_text_processing/text_normalization/en/data/ordinal/teen.tsv
 nemo_text_processing/text_normalization/en/data/roman/__init__.py
-nemo_text_processing/text_normalization/en/data/roman/digit_teen.tsv
-nemo_text_processing/text_normalization/en/data/roman/hundreds.tsv
-nemo_text_processing/text_normalization/en/data/roman/ties.tsv
+nemo_text_processing/text_normalization/en/data/roman/female.tsv
+nemo_text_processing/text_normalization/en/data/roman/key_word.tsv
+nemo_text_processing/text_normalization/en/data/roman/male.tsv
+nemo_text_processing/text_normalization/en/data/roman/roman_to_spoken.tsv
+nemo_text_processing/text_normalization/en/data/telephone/__init__.py
+nemo_text_processing/text_normalization/en/data/telephone/ip_prompt.tsv
+nemo_text_processing/text_normalization/en/data/telephone/ssn_prompt.tsv
+nemo_text_processing/text_normalization/en/data/telephone/telephone_prompt.tsv
+nemo_text_processing/text_normalization/en/data/time/__init__.py
+nemo_text_processing/text_normalization/en/data/time/suffix.tsv
+nemo_text_processing/text_normalization/en/data/time/zone.tsv
+nemo_text_processing/text_normalization/en/data/whitelist/__init__.py
+nemo_text_processing/text_normalization/en/data/whitelist/alternatives.tsv
+nemo_text_processing/text_normalization/en/data/whitelist/alternatives_all_format.tsv
+nemo_text_processing/text_normalization/en/data/whitelist/asr.tsv
+nemo_text_processing/text_normalization/en/data/whitelist/lj_speech.tsv
+nemo_text_processing/text_normalization/en/data/whitelist/symbol.tsv
+nemo_text_processing/text_normalization/en/data/whitelist/tts.tsv
 nemo_text_processing/text_normalization/en/taggers/__init__.py
 nemo_text_processing/text_normalization/en/taggers/abbreviation.py
 nemo_text_processing/text_normalization/en/taggers/cardinal.py
 nemo_text_processing/text_normalization/en/taggers/date.py
 nemo_text_processing/text_normalization/en/taggers/decimal.py
 nemo_text_processing/text_normalization/en/taggers/electronic.py
 nemo_text_processing/text_normalization/en/taggers/fraction.py
 nemo_text_processing/text_normalization/en/taggers/measure.py
 nemo_text_processing/text_normalization/en/taggers/money.py
 nemo_text_processing/text_normalization/en/taggers/ordinal.py
 nemo_text_processing/text_normalization/en/taggers/punctuation.py
+nemo_text_processing/text_normalization/en/taggers/range.py
 nemo_text_processing/text_normalization/en/taggers/roman.py
+nemo_text_processing/text_normalization/en/taggers/serial.py
 nemo_text_processing/text_normalization/en/taggers/telephone.py
 nemo_text_processing/text_normalization/en/taggers/time.py
 nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify.py
+nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify_lm.py
 nemo_text_processing/text_normalization/en/taggers/tokenize_and_classify_with_audio.py
 nemo_text_processing/text_normalization/en/taggers/whitelist.py
 nemo_text_processing/text_normalization/en/taggers/word.py
 nemo_text_processing/text_normalization/en/verbalizers/__init__.py
 nemo_text_processing/text_normalization/en/verbalizers/abbreviation.py
 nemo_text_processing/text_normalization/en/verbalizers/cardinal.py
 nemo_text_processing/text_normalization/en/verbalizers/date.py
@@ -1129,26 +1158,29 @@
 tests/nemo_text_processing/de/test_ordinal.py
 tests/nemo_text_processing/de/test_telephone.py
 tests/nemo_text_processing/de/test_time.py
 tests/nemo_text_processing/de/test_whitelist.py
 tests/nemo_text_processing/de/test_word.py
 tests/nemo_text_processing/en/__init__.py
 tests/nemo_text_processing/en/test_address.py
-tests/nemo_text_processing/en/test_boundary.py
 tests/nemo_text_processing/en/test_cardinal.py
 tests/nemo_text_processing/en/test_date.py
 tests/nemo_text_processing/en/test_decimal.py
 tests/nemo_text_processing/en/test_electronic.py
 tests/nemo_text_processing/en/test_fraction.py
 tests/nemo_text_processing/en/test_math.py
 tests/nemo_text_processing/en/test_measure.py
 tests/nemo_text_processing/en/test_money.py
 tests/nemo_text_processing/en/test_normalization_with_audio.py
 tests/nemo_text_processing/en/test_ordinal.py
 tests/nemo_text_processing/en/test_punctuation.py
+tests/nemo_text_processing/en/test_range.py
+tests/nemo_text_processing/en/test_roman.py
+tests/nemo_text_processing/en/test_serial.py
+tests/nemo_text_processing/en/test_special_text.py
 tests/nemo_text_processing/en/test_telephone.py
 tests/nemo_text_processing/en/test_time.py
 tests/nemo_text_processing/en/test_whitelist.py
 tests/nemo_text_processing/en/test_word.py
 tests/nemo_text_processing/es/__init__.py
 tests/nemo_text_processing/es/test_cardinal.py
 tests/nemo_text_processing/es/test_date.py
@@ -1199,8 +1231,9 @@
 tests/nemo_text_processing/vi/test_electronic.py
 tests/nemo_text_processing/vi/test_fraction.py
 tests/nemo_text_processing/vi/test_measure.py
 tests/nemo_text_processing/vi/test_money.py
 tests/nemo_text_processing/vi/test_ordinal.py
 tests/nemo_text_processing/vi/test_telephone.py
 tests/nemo_text_processing/vi/test_time.py
+tests/nemo_text_processing/vi/test_whitelist.py
 tests/nemo_text_processing/vi/test_word.py
```

### Comparing `nemo_toolkit-1.8.2/nemo_toolkit.egg-info/requires.txt` & `nemo_toolkit-1.9.0/nemo_toolkit.egg-info/requires.txt`

 * *Files 14% similar despite different names*

```diff
@@ -24,40 +24,38 @@
 sphinxcontrib-bibtex
 wrapt
 wget
 wandb
 inflect
 regex
 pynini==2.1.4
-pytorch-lightning>=1.6.0
+pytorch-lightning<1.6.4,>=1.6.1
 torchmetrics>=0.4.1rc0
 transformers>=4.0.1
 webdataset<=0.1.62,>=0.1.48
-omegaconf>=2.1.0
-hydra-core>=1.1.0
+omegaconf<2.2,>=2.1.2
+hydra-core<1.2,>=1.1.0
 pyyaml<6
 sentencepiece<1.0.0
 youtokentome>=1.0.5
 pandas
 braceexpand
 editdistance
-kaldi-io
 librosa
 marshmallow
 packaging
 soundfile
 sox
 kaldi-python-io
 kaldiio
 scipy>=0.14
 g2p_en
 pydub
 pyannote.core
 pyannote.metrics
-torch-stft
 ipywidgets
 matplotlib
 pillow
 torchvision
 boto3
 h5py
 matplotlib>=3.3.2
@@ -69,47 +67,47 @@
 nltk>=3.6.5
 fasttext
 opencc
 pangu
 jieba
 ftfy
 flask_restful
+einops
+ijson
 nltk
 pypinyin
 attrdict
 pystoi
 pesq
 
 [asr]
 braceexpand
 editdistance
 inflect
-kaldi-io
 librosa
 marshmallow
 packaging
 ruamel.yaml
 soundfile
 sox
 kaldi-python-io
 kaldiio
 scipy>=0.14
 g2p_en
 pydub
 pyannote.core
 pyannote.metrics
-torch-stft
 ipywidgets
 matplotlib
-pytorch-lightning>=1.6.0
+pytorch-lightning<1.6.4,>=1.6.1
 torchmetrics>=0.4.1rc0
 transformers>=4.0.1
 webdataset<=0.1.62,>=0.1.48
-omegaconf>=2.1.0
-hydra-core>=1.1.0
+omegaconf<2.2,>=2.1.2
+hydra-core<1.2,>=1.1.0
 pyyaml<6
 sentencepiece<1.0.0
 youtokentome>=1.0.5
 pandas
 regex
 pynini==2.1.4
 
@@ -118,39 +116,44 @@
 youtokentome>=1.0.5
 pandas
 inflect
 regex
 pynini==2.1.4
 
 [core]
-pytorch-lightning>=1.6.0
+pytorch-lightning<1.6.4,>=1.6.1
 torchmetrics>=0.4.1rc0
 transformers>=4.0.1
 webdataset<=0.1.62,>=0.1.48
-omegaconf>=2.1.0
-hydra-core>=1.1.0
+omegaconf<2.2,>=2.1.2
+hydra-core<1.2,>=1.1.0
 pyyaml<6
 
 [cv]
 pillow
 torchvision
-pytorch-lightning>=1.6.0
+pytorch-lightning<1.6.4,>=1.6.1
 torchmetrics>=0.4.1rc0
 transformers>=4.0.1
 webdataset<=0.1.62,>=0.1.48
-omegaconf>=2.1.0
-hydra-core>=1.1.0
+omegaconf<2.2,>=2.1.2
+hydra-core<1.2,>=1.1.0
 pyyaml<6
 sentencepiece<1.0.0
 youtokentome>=1.0.5
 pandas
 inflect
 regex
 pynini==2.1.4
 
+[nemo_text_processing]
+inflect
+regex
+pynini==2.1.4
+
 [nlp]
 boto3
 h5py
 matplotlib>=3.3.2
 numpy
 rapidfuzz
 gdown
@@ -160,20 +163,22 @@
 nltk>=3.6.5
 fasttext
 opencc
 pangu
 jieba
 ftfy
 flask_restful
-pytorch-lightning>=1.6.0
+einops
+ijson
+pytorch-lightning<1.6.4,>=1.6.1
 torchmetrics>=0.4.1rc0
 transformers>=4.0.1
 webdataset<=0.1.62,>=0.1.48
-omegaconf>=2.1.0
-hydra-core>=1.1.0
+omegaconf<2.2,>=2.1.2
+hydra-core<1.2,>=1.1.0
 pyyaml<6
 sentencepiece<1.0.0
 youtokentome>=1.0.5
 pandas
 regex
 pynini==2.1.4
 
@@ -183,62 +188,55 @@
 matplotlib
 pypinyin
 attrdict
 pystoi
 pesq
 pandas
 inflect
-pytorch-lightning>=1.6.0
+pytorch-lightning<1.6.4,>=1.6.1
 torchmetrics>=0.4.1rc0
 transformers>=4.0.1
 webdataset<=0.1.62,>=0.1.48
-omegaconf>=2.1.0
-hydra-core>=1.1.0
+omegaconf<2.2,>=2.1.2
+hydra-core<1.2,>=1.1.0
 pyyaml<6
 sentencepiece<1.0.0
 youtokentome>=1.0.5
 regex
 pynini==2.1.4
 
-[text_processing]
-inflect
-regex
-pynini==2.1.4
-
 [tts]
 librosa
 nltk
 matplotlib
 pypinyin
 attrdict
 pystoi
 pesq
 pandas
 inflect
-pytorch-lightning>=1.6.0
+pytorch-lightning<1.6.4,>=1.6.1
 torchmetrics>=0.4.1rc0
 transformers>=4.0.1
 webdataset<=0.1.62,>=0.1.48
-omegaconf>=2.1.0
-hydra-core>=1.1.0
+omegaconf<2.2,>=2.1.2
+hydra-core<1.2,>=1.1.0
 pyyaml<6
 sentencepiece<1.0.0
 youtokentome>=1.0.5
 regex
 pynini==2.1.4
 braceexpand
 editdistance
-kaldi-io
 marshmallow
 packaging
 ruamel.yaml
 soundfile
 sox
 kaldi-python-io
 kaldiio
 scipy>=0.14
 g2p_en
 pydub
 pyannote.core
 pyannote.metrics
-torch-stft
 ipywidgets
```

### Comparing `nemo_toolkit-1.8.2/setup.cfg` & `nemo_toolkit-1.9.0/setup.cfg`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/setup.py` & `nemo_toolkit-1.9.0/setup.py`

 * *Files 1% similar despite different names*

```diff
@@ -76,15 +76,15 @@
 
 install_requires = req_file("requirements.txt")
 
 extras_require = {
     # User packages
     'test': req_file("requirements_test.txt"),
     # NeMo Tools
-    'text_processing': req_file("requirements_text_processing.txt"),
+    'nemo_text_processing': req_file("requirements_nemo_text_processing.txt"),
     # Torch Packages
     # 'torch_tts': req_file("requirements_torch_tts.txt"),  ## Removed in 1.7.0
     # Lightning Collections Packages
     'core': req_file("requirements_lightning.txt"),
     'common': req_file('requirements_common.txt'),
     'asr': req_file("requirements_asr.txt"),
     'cv': req_file("requirements_cv.txt"),
@@ -92,15 +92,15 @@
     'tts': req_file("requirements_tts.txt") + req_file("requirements_torch_tts.txt"),
 }
 
 
 extras_require['all'] = list(chain(extras_require.values()))
 
 # Add lightning requirements as needed
-extras_require['common'] = list(chain([extras_require['common'], extras_require['text_processing']]))
+extras_require['common'] = list(chain([extras_require['common'], extras_require['nemo_text_processing']]))
 extras_require['test'] = list(chain([extras_require['tts'], extras_require['core'], extras_require['common']]))
 extras_require['asr'] = list(chain([extras_require['asr'], extras_require['core'], extras_require['common']]))
 extras_require['cv'] = list(chain([extras_require['cv'], extras_require['core'], extras_require['common']]))
 extras_require['nlp'] = list(chain([extras_require['nlp'], extras_require['core'], extras_require['common']]))
 extras_require['tts'] = list(chain([extras_require['tts'], extras_require['core'], extras_require['common']]))
 
 # TTS has extra dependencies
```

### Comparing `nemo_toolkit-1.8.2/tests/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/taggers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/check_copyright_header.py` & `nemo_toolkit-1.9.0/tests/check_copyright_header.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/conftest.py` & `nemo_toolkit-1.9.0/tests/conftest.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/__init__.py` & `nemo_toolkit-1.9.0/nemo_text_processing/text_normalization/ru/verbalizers/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/test_config_utils.py` & `nemo_toolkit-1.9.0/tests/core/test_config_utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/test_exp_manager.py` & `nemo_toolkit-1.9.0/tests/core/test_exp_manager.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/test_fileio.py` & `nemo_toolkit-1.9.0/tests/core/test_fileio.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/test_neural_types.py` & `nemo_toolkit-1.9.0/tests/core/test_neural_types.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/test_optimizers_schedulers.py` & `nemo_toolkit-1.9.0/tests/core/test_optimizers_schedulers.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/test_save_restore.py` & `nemo_toolkit-1.9.0/tests/core/test_save_restore.py`

 * *Files 10% similar despite different names*

```diff
@@ -28,14 +28,32 @@
 from nemo.utils.app_state import AppState
 
 
 def classpath(cls):
     return f'{cls.__module__}.{cls.__name__}'
 
 
+def get_dir_size(path='.'):
+    total = 0
+    with os.scandir(path) as it:
+        for entry in it:
+            if entry.is_file():
+                total += entry.stat().st_size
+            elif entry.is_dir():
+                total += get_dir_size(entry.path)
+    return total
+
+
+def get_size(path='.'):
+    if os.path.isfile(path):
+        return os.path.getsize(path)
+    elif os.path.isdir(path):
+        return get_dir_size(path)
+
+
 def getattr2(object, attr):
     if not '.' in attr:
         return getattr(object, attr)
     else:
         arr = attr.split('.')
         return getattr2(getattr(object, arr[0]), '.'.join(arr[1:]))
 
@@ -519,7 +537,71 @@
         cfg.model.model = 'aaa'
         OmegaConf.set_struct(cfg, True)
 
         # Failing due to collision.
         with pytest.raises(ValueError, match="Creating model config node is forbidden"):
             model = MockModel(cfg=cfg.model, trainer=None)  # type: MockModel
             model = model.to('cpu')
+
+    @pytest.mark.unit
+    def test_restore_from_save_restore_connector_extracted_dir(self):
+        class MySaveRestoreConnector(save_restore_connector.SaveRestoreConnector):
+            def save_to(self, model, save_path: str):
+                save_path = save_path.replace(".nemo", "_XYZ.nemo")
+                super().save_to(model, save_path)
+
+        class MockModelV2(MockModel):
+            pass
+
+        with tempfile.TemporaryDirectory() as extracted_tempdir:
+            with tempfile.TemporaryDirectory() as tmpdir:
+                # Update config
+                cfg = _mock_model_config()
+
+                # Create model
+                save_path = os.path.join(tmpdir, 'save_custom.nemo')
+                model_with_custom_connector = MockModel(cfg=cfg.model, trainer=None)
+                model_with_custom_connector._save_restore_connector = MySaveRestoreConnector()
+                model_with_custom_connector.save_to(save_path)
+
+                nemo_filepath = os.path.join(tmpdir, 'save_custom_XYZ.nemo')
+                assert os.path.exists(nemo_filepath)
+
+                # extract the contents to this dir apriori
+                # simulate by extracting now before calling restore_from
+                connector = MySaveRestoreConnector()
+                MySaveRestoreConnector._unpack_nemo_file(nemo_filepath, extracted_tempdir)
+                assert get_size(extracted_tempdir) > 0
+
+            # delete the old directory and preserve only the new extracted directory (escape scope of old dir)
+
+            # next, set the model's extracted directory path
+            connector.model_extracted_dir = extracted_tempdir
+
+            # note, we pass in the "old" nemo_filepath, stored somewhere other than the extracted directory
+            # this nemo_filepath is no longer valid, and has been deleted.
+            restored_model = MockModelV2.restore_from(nemo_filepath, save_restore_connector=connector)
+        assert type(restored_model) == MockModelV2
+        assert type(restored_model._save_restore_connector) == MySaveRestoreConnector
+
+        # assert models have correct restoration information and paths
+        appstate = AppState()
+        original_metadata = appstate.get_model_metadata_from_guid(model_with_custom_connector.model_guid)
+        assert original_metadata.restoration_path is None
+
+        restored_metadata = appstate.get_model_metadata_from_guid(restored_model.model_guid)
+        assert restored_metadata.restoration_path is not None
+
+        # assert that the restore path was the path of the pre-extracted directory
+        # irrespective of whether an old `nemo_filepath` (which doesnt exist anymore) was passed to restore_from.
+        assert extracted_tempdir in restored_metadata.restoration_path
+        assert extracted_tempdir not in nemo_filepath
+        assert not os.path.exists(nemo_filepath)
+
+        # test for parameter equality
+        model_with_custom_connector = model_with_custom_connector.to('cpu')
+        restored_model = restored_model.to('cpu')
+
+        original_state_dict = model_with_custom_connector.state_dict()
+        restored_state_dict = restored_model.state_dict()
+        for orig, restored in zip(original_state_dict.keys(), restored_state_dict.keys()):
+            assert (original_state_dict[orig] - restored_state_dict[restored]).abs().mean() < 1e-6
```

### Comparing `nemo_toolkit-1.8.2/tests/core/test_serialization.py` & `nemo_toolkit-1.9.0/tests/core/test_serialization.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/core/test_typecheck.py` & `nemo_toolkit-1.9.0/tests/core/test_typecheck.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,14 +8,16 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+from typing import List, NamedTuple
+
 import pytest
 import torch
 
 from nemo.core import Typing, typecheck
 from nemo.core.neural_types import *
 
 
@@ -161,14 +163,40 @@
         assert result_y.sum() == torch.tensor(10.0)
         assert result_y.neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
 
         assert result_z.sum() == torch.tensor(20.0)
         assert result_z.neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
 
     @pytest.mark.unit
+    def test_multiple_output_types_only_namedtuple(self):
+        class NamedTupleOutputType(NamedTuple):
+            y: torch.Tensor
+            z: torch.Tensor
+
+        class MultipleOutputTypesWithNamedTuple(Typing):
+            @property
+            def output_types(self):
+                return {"y": NeuralType(('B',), ElementType()), "z": NeuralType(('B',), ElementType())}
+
+            @typecheck()
+            def __call__(self, x):
+                y = x + 1
+                z = x + 2
+                return NamedTupleOutputType(y=y, z=z)
+
+        obj = MultipleOutputTypesWithNamedTuple()
+        result = obj(x=torch.zeros(10))
+
+        assert result.y.sum() == torch.tensor(10.0)
+        assert result.y.neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
+
+        assert result.z.sum() == torch.tensor(20.0)
+        assert result.z.neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
+
+    @pytest.mark.unit
     def test_multiple_mixed_output_types_only(self):
         class MultipleMixedOutputTypes(Typing):
             @property
             def output_types(self):
                 return {"y": NeuralType(('B',), ElementType()), "z": [NeuralType(('B',), ElementType())]}
 
             @typecheck()
@@ -186,14 +214,43 @@
         assert result_z[0].sum() == torch.tensor(20.0)
         assert result_z[0].neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
 
         assert result_z[1].sum() == torch.tensor(20.0)
         assert result_z[1].neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
 
     @pytest.mark.unit
+    def test_multiple_mixed_output_types_only_namedtuple(self):
+        class NamedTupleOutputType(NamedTuple):
+            y: torch.Tensor
+            zs: List[torch.Tensor]
+
+        class MultipleMixedOutputTypes(Typing):
+            @property
+            def output_types(self):
+                return {"y": NeuralType(('B',), ElementType()), "zs": [NeuralType(('B',), ElementType())]}
+
+            @typecheck()
+            def __call__(self, x):
+                y = x + 1
+                z = x + 2
+                return NamedTupleOutputType(y=y, zs=[z, z])
+
+        obj = MultipleMixedOutputTypes()
+        result_y, result_z = obj(x=torch.zeros(10))
+
+        assert result_y.sum() == torch.tensor(10.0)
+        assert result_y.neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
+
+        assert result_z[0].sum() == torch.tensor(20.0)
+        assert result_z[0].neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
+
+        assert result_z[1].sum() == torch.tensor(20.0)
+        assert result_z[1].neural_type.compare(NeuralType(('B',), ElementType())) == NeuralTypeComparisonResult.SAME
+
+    @pytest.mark.unit
     def test_multiple_mixed_output_types_only_mismatched(self):
         class MultipleMixedOutputTypes(Typing):
             @property
             def output_types(self):
                 return {"y": NeuralType(('B',), ElementType()), "z": [NeuralType(('B',), ElementType())]}
 
             @typecheck()
@@ -204,14 +261,36 @@
                 return [y, y], z
 
         obj = MultipleMixedOutputTypes()
         with pytest.raises(TypeError):
             result_y, result_z = obj(x=torch.zeros(10))
 
     @pytest.mark.unit
+    def test_multiple_mixed_output_types_only_namedtuple_mismatched(self):
+        class NamedTupleOutputType(NamedTuple):
+            ys: List[torch.Tensor]
+            z: torch.Tensor
+
+        class MultipleMixedOutputTypes(Typing):
+            @property
+            def output_types(self):
+                return {"ys": NeuralType(('B',), ElementType()), "z": [NeuralType(('B',), ElementType())]}
+
+            @typecheck()
+            def __call__(self, x):
+                # Use list of y, single z, contrary to signature
+                y = x + 1
+                z = x + 2
+                return NamedTupleOutputType(ys=[y, y], z=z)
+
+        obj = MultipleMixedOutputTypes()
+        with pytest.raises(TypeError):
+            _ = obj(x=torch.zeros(10))
+
+    @pytest.mark.unit
     def test_incorrect_inheritance(self):
         class IncorrectInheritance(object):
             @property
             def input_types(self):
                 return {"x": NeuralType(('B',), ElementType())}
 
             @property
```

### Comparing `nemo_toolkit-1.8.2/tests/manualtest_model_downloads.py` & `nemo_toolkit-1.9.0/tests/manualtest_model_downloads.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/__init__.py` & `nemo_toolkit-1.9.0/tests/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/__init__.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_cardinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_date.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_decimal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_electronic.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_fraction.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_measure.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_money.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_normalization_with_audio.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_normalization_with_audio.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,27 +17,27 @@
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, get_test_cases_multiple
 
 
 class TestNormalizeWithAudio:
 
-    normalizer_de = (
-        NormalizerWithAudio(input_case='cased', lang='de', cache_dir=CACHE_DIR, overwrite_cache=False)
+    normalizer_es = (
+        NormalizerWithAudio(input_case='cased', lang='es', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE
         else None
     )
 
-    @parameterized.expand(get_test_cases_multiple('de/data_text_normalization/test_cases_normalize_with_audio.txt'))
+    @parameterized.expand(get_test_cases_multiple('es/data_text_normalization/test_cases_normalize_with_audio.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
-        pred = self.normalizer_de.normalize(test_input, n_tagged=1000, punct_post_process=False)
+        pred = self.normalizer_es.normalize(test_input, n_tagged=50, punct_post_process=False)
         print(expected)
         print("pred")
         print(pred)
         assert len(set(pred).intersection(set(expected))) == len(
             expected
         ), f'missing: {set(expected).difference(set(pred))}'
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_ordinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_telephone.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_time.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_whitelist.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/de/test_word.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/__init__.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_address.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_address.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_boundary.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_punctuation.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,35 +16,35 @@
 from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestBoundary:
-
+class TestPunctuation:
     normalizer_en = (
         Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE
         else None
     )
     normalizer_with_audio_en = (
         NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE and CACHE_DIR
         else None
     )
 
-    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_boundary.txt'))
+    # address is tagged by the measure class
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_punctuation.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
-        pred = self.normalizer_en.normalize(test_input, verbose=False)
-        assert pred == expected
+        pred = self.normalizer_en.normalize(test_input, verbose=True, punct_post_process=True)
+        assert pred == expected, f"input: {test_input}"
 
         if self.normalizer_with_audio_en:
             pred_non_deterministic = self.normalizer_with_audio_en.normalize(
-                test_input, n_tagged=30, punct_post_process=False
+                test_input, n_tagged=30, punct_post_process=True
             )
-            assert expected in pred_non_deterministic
+            assert expected in pred_non_deterministic, f"input: {test_input}"
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_cardinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_date.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_date.py`

 * *Files 2% similar despite different names*

```diff
@@ -57,15 +57,15 @@
         pred = self.normalizer_en.normalize(test_input, verbose=False)
         assert pred == expected
 
         if self.normalizer_with_audio_en:
             pred_non_deterministic = self.normalizer_with_audio_en.normalize(
                 test_input, punct_post_process=False, n_tagged=100
             )
-            assert expected in pred_non_deterministic
+            assert expected in pred_non_deterministic, f"INPUT: {test_input}"
 
     normalizer_uppercased = (
         Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE
         else None
     )
     cases_uppercased = {"Aug. 8": "august eighth", "8 Aug.": "the eighth of august", "aug. 8": "august eighth"}
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_decimal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_electronic.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_fraction.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_math.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_math.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_measure.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_money.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_time.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,30 +8,29 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestMoney:
+class TestTime:
     inverse_normalizer_en = (
         InverseNormalizer(lang='en', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('en/data_inverse_text_normalization/test_cases_money.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_inverse_text_normalization/test_cases_time.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer_en.inverse_normalize(test_input, verbose=False)
@@ -44,22 +43,22 @@
     )
     normalizer_with_audio_en = (
         NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE and CACHE_DIR
         else None
     )
 
-    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_money.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_time.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
         pred = self.normalizer_en.normalize(test_input, verbose=False)
         assert pred == expected
 
         if self.normalizer_with_audio_en:
             pred_non_deterministic = self.normalizer_with_audio_en.normalize(
-                test_input, n_tagged=30, punct_post_process=False,
+                test_input, n_tagged=10, punct_post_process=False
             )
             assert expected in pred_non_deterministic
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_normalization_with_audio.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_normalization_with_audio.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,24 +17,24 @@
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, get_test_cases_multiple
 
 
 class TestNormalizeWithAudio:
     normalizer_with_audio_en = (
-        NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
+        NormalizerWithAudio(input_case='cased', lang='en', lm=False, cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE and CACHE_DIR
         else None
     )
 
     @parameterized.expand(get_test_cases_multiple('en/data_text_normalization/test_cases_normalize_with_audio.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
         if self.normalizer_with_audio_en:
-            pred = self.normalizer_with_audio_en.normalize(test_input, n_tagged=100, punct_post_process=True)
+            pred = self.normalizer_with_audio_en.normalize(test_input, n_tagged=200, punct_post_process=True)
             assert len(set(pred).intersection(set(expected))) == len(
                 expected
             ), f'missing: {set(expected).difference(set(pred))}'
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_ordinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_punctuation.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_roman.py`

 * *Files 6% similar despite different names*

```diff
@@ -16,35 +16,36 @@
 from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestPunctuation:
+class TestRoman:
     normalizer_en = (
         Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE
         else None
     )
     normalizer_with_audio_en = (
         NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE and CACHE_DIR
         else None
     )
 
     # address is tagged by the measure class
-    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_punctuation.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_roman.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
-        pred = self.normalizer_en.normalize(test_input, verbose=True, punct_post_process=True)
-        assert pred == expected, f"input: {test_input}"
-
-        if self.normalizer_with_audio_en:
-            pred_non_deterministic = self.normalizer_with_audio_en.normalize(
-                test_input, n_tagged=30, punct_post_process=True
-            )
-            assert expected in pred_non_deterministic, f"input: {test_input}"
+        # pred = self.normalizer_en.normalize(test_input, verbose=False)
+        # assert pred == expected
+        #
+        # if self.normalizer_with_audio_en:
+        #     pred_non_deterministic = self.normalizer_with_audio_en.normalize(
+        #         test_input, n_tagged=30, punct_post_process=False,
+        #     )
+        #     assert expected in pred_non_deterministic
+        pass
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_telephone.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_time.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_word.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,29 +8,30 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestTime:
+class TestWord:
     inverse_normalizer_en = (
         InverseNormalizer(lang='en', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('en/data_inverse_text_normalization/test_cases_time.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_inverse_text_normalization/test_cases_word.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer_en.inverse_normalize(test_input, verbose=False)
@@ -43,22 +44,22 @@
     )
     normalizer_with_audio_en = (
         NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE and CACHE_DIR
         else None
     )
 
-    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_time.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_word.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
         pred = self.normalizer_en.normalize(test_input, verbose=False)
-        assert pred == expected
+        assert pred == expected, f"input: {test_input}"
 
         if self.normalizer_with_audio_en:
             pred_non_deterministic = self.normalizer_with_audio_en.normalize(
-                test_input, n_tagged=10, punct_post_process=False
+                test_input, n_tagged=200, punct_post_process=False
             )
-            assert expected in pred_non_deterministic
+            assert expected in pred_non_deterministic, f"input: {test_input}"
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_whitelist.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/en/test_word.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_word.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,65 +1,64 @@
-# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
 class TestWord:
-    inverse_normalizer_en = (
-        InverseNormalizer(lang='en', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+    inverse_normalizer_es = (
+        InverseNormalizer(lang='es', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('en/data_inverse_text_normalization/test_cases_word.txt'))
+    @parameterized.expand(parse_test_case_file('es/data_inverse_text_normalization/test_cases_word.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
-    def test_denorm(self, test_input, expected):
-        pred = self.inverse_normalizer_en.inverse_normalize(test_input, verbose=False)
+    def test_denorm_es(self, test_input, expected):
+        pred = self.inverse_normalizer_es.inverse_normalize(test_input, verbose=False)
         assert pred == expected
 
-    normalizer_en = (
-        Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
+    normalizer_es = (
+        Normalizer(input_case='cased', lang='es', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE
         else None
     )
-    normalizer_with_audio_en = (
-        NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
+    normalizer_with_audio_es = (
+        NormalizerWithAudio(input_case='cased', lang='es', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE and CACHE_DIR
         else None
     )
 
-    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_word.txt'))
+    @parameterized.expand(parse_test_case_file('es/data_text_normalization/test_cases_word.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
-        pred = self.normalizer_en.normalize(test_input, verbose=False)
+        pred = self.normalizer_es.normalize(test_input, verbose=False)
         assert pred == expected, f"input: {test_input}"
 
-        if self.normalizer_with_audio_en:
-            pred_non_deterministic = self.normalizer_with_audio_en.normalize(
+        if self.normalizer_with_audio_es:
+            pred_non_deterministic = self.normalizer_with_audio_es.normalize(
                 test_input, n_tagged=150, punct_post_process=False
             )
             assert expected in pred_non_deterministic, f"input: {test_input}"
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/__init__.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_cardinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_date.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_decimal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_decimal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_electronic.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_fraction.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_measure.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_money.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_normalization_with_audio.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_special_text.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,43 +1,39 @@
-# Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import pytest
+from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
-from ..utils import CACHE_DIR, PYNINI_AVAILABLE, get_test_cases_multiple
+from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestNormalizeWithAudio:
+class TestSpecialText:
 
-    normalizer_es = (
-        NormalizerWithAudio(input_case='cased', lang='es', cache_dir=CACHE_DIR, overwrite_cache=False)
+    normalizer_en = (
+        Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE
         else None
     )
 
-    @parameterized.expand(get_test_cases_multiple('es/data_text_normalization/test_cases_normalize_with_audio.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_special_text.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
-        pred = self.normalizer_es.normalize(test_input, n_tagged=50, punct_post_process=False)
-        print(expected)
-        print("pred")
-        print(pred)
-        assert len(set(pred).intersection(set(expected))) == len(
-            expected
-        ), f'missing: {set(expected).difference(set(pred))}'
+        pred = self.normalizer_en.normalize(test_input, verbose=False)
+        assert pred == expected
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_ordinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_telephone.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_time.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_whitelist.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/es/test_whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/es/test_word.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_money.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,64 +1,65 @@
-# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from nemo_text_processing.text_normalization.normalize import Normalizer
 from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestWord:
-    inverse_normalizer_es = (
-        InverseNormalizer(lang='es', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+class TestMoney:
+    inverse_normalizer_en = (
+        InverseNormalizer(lang='en', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('es/data_inverse_text_normalization/test_cases_word.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_inverse_text_normalization/test_cases_money.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
-    def test_denorm_es(self, test_input, expected):
-        pred = self.inverse_normalizer_es.inverse_normalize(test_input, verbose=False)
-        assert pred == expected
+    def test_denorm(self, test_input, expected):
+        pred = self.inverse_normalizer_en.inverse_normalize(test_input, verbose=False)
+        assert pred == expected, f"input: {test_input}"
 
-    normalizer_es = (
-        Normalizer(input_case='cased', lang='es', cache_dir=CACHE_DIR, overwrite_cache=False)
+    normalizer_en = (
+        Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE
         else None
     )
-    normalizer_with_audio_es = (
-        NormalizerWithAudio(input_case='cased', lang='es', cache_dir=CACHE_DIR, overwrite_cache=False)
+    normalizer_with_audio_en = (
+        NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
         if PYNINI_AVAILABLE and CACHE_DIR
         else None
     )
 
-    @parameterized.expand(parse_test_case_file('es/data_text_normalization/test_cases_word.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_money.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_norm(self, test_input, expected):
-        pred = self.normalizer_es.normalize(test_input, verbose=False)
+        pred = self.normalizer_en.normalize(test_input, verbose=False)
         assert pred == expected, f"input: {test_input}"
 
-        if self.normalizer_with_audio_es:
-            pred_non_deterministic = self.normalizer_with_audio_es.normalize(
-                test_input, n_tagged=150, punct_post_process=False
+        if self.normalizer_with_audio_en:
+            pred_non_deterministic = self.normalizer_with_audio_en.normalize(
+                test_input, n_tagged=30, punct_post_process=False,
             )
-            assert expected in pred_non_deterministic, f"input: {test_input}"
+            assert expected in pred_non_deterministic
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/__init__.py` & `nemo_toolkit-1.9.0/tests/core/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_cardinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_date.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_date.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_decimal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_decimal.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,18 +17,18 @@
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
 class TestDecimal:
     inverse_normalizer = (
-        InverseNormalizer(lang='fr', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+        InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('fr/data_inverse_text_normalization/test_cases_decimal.txt'))
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_decimal.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_electronic.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_fraction.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_fraction.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_measure.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_measure.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_money.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_money.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_ordinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_ordinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_telephone.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_telephone.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_time.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_time.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_whitelist.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_whitelist.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/fr/test_word.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/test_word.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/__init__.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/__init__.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/fr/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal.txt` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal_normalize_with_audio.txt` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_cardinal_normalize_with_audio.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_decimal.txt` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_decimal.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_electronic.txt` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_electronic.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_measure.txt` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_measure.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_money.txt` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_money.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/data_text_normalization/test_cases_ordinal.txt` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/data_text_normalization/test_cases_ordinal.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/test_ru_inverse_normalization.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/test_ru_inverse_normalization.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/ru/test_ru_normalization.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/test_ru_normalization.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/utils.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/utils.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/__init__.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/ru/__init__.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_cardinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_cardinal.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_date.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_telephone.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,27 +8,28 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestDate:
+class TestTelephone:
     inverse_normalizer = (
         InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_date.txt'))
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_telephone.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_decimal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_fraction.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,27 +8,28 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestDecimal:
+class TestFraction:
     inverse_normalizer = (
         InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_decimal.txt'))
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_fraction.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_electronic.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_electronic.py`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_fraction.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_time.py`

 * *Files 6% similar despite different names*

```diff
@@ -8,28 +8,27 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestFraction:
+class TestTime:
     inverse_normalizer = (
         InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_fraction.txt'))
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_time.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_measure.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_money.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,20 +16,20 @@
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestMeasure:
+class TestMoney:
     inverse_normalizer = (
         InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_measure.txt'))
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_money.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_money.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_ordinal.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,20 +16,20 @@
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestMoney:
+class TestOrdinal:
     inverse_normalizer = (
         InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_money.txt'))
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_ordinal.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_ordinal.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/vi/test_whitelist.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,20 +16,20 @@
 import pytest
 from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestOrdinal:
+class TestWhitelist:
     inverse_normalizer = (
         InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_ordinal.txt'))
+    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_whitelist.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
     def test_denorm(self, test_input, expected):
         pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_telephone.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/de/test_normalization_with_audio.py`

 * *Files 14% similar despite different names*

```diff
@@ -8,29 +8,37 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
 import pytest
-from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
+from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
-from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
+from ..utils import CACHE_DIR, PYNINI_AVAILABLE, get_test_cases_multiple
+from nemo.utils import logging
+
 
+class TestNormalizeWithAudio:
 
-class TestTelephone:
-    inverse_normalizer = (
-        InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+    normalizer_de = (
+        NormalizerWithAudio(input_case='cased', lang='de', cache_dir=CACHE_DIR, overwrite_cache=False)
+        if PYNINI_AVAILABLE
+        else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_telephone.txt'))
+    @parameterized.expand(get_test_cases_multiple('de/data_text_normalization/test_cases_normalize_with_audio.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
-    def test_denorm(self, test_input, expected):
-        pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
-        assert pred == expected
+    def test_norm(self, test_input, expected):
+        pred = self.normalizer_de.normalize(test_input, n_tagged=1000, punct_post_process=False)
+        logging.info(expected)
+        logging.info("pred")
+        logging.info(pred)
+        assert len(set(pred).intersection(set(expected))) == len(
+            expected
+        ), f'missing: {set(expected).difference(set(pred))}'
```

### Comparing `nemo_toolkit-1.8.2/tests/nemo_text_processing/vi/test_time.py` & `nemo_toolkit-1.9.0/tests/nemo_text_processing/en/test_serial.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,35 +1,49 @@
-# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.
+# Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import pytest
-from nemo_text_processing.inverse_text_normalization.inverse_normalize import InverseNormalizer
+from nemo_text_processing.text_normalization.normalize import Normalizer
+from nemo_text_processing.text_normalization.normalize_with_audio import NormalizerWithAudio
 from parameterized import parameterized
 
 from ..utils import CACHE_DIR, PYNINI_AVAILABLE, parse_test_case_file
 
 
-class TestTime:
-    inverse_normalizer = (
-        InverseNormalizer(lang='vi', cache_dir=CACHE_DIR, overwrite_cache=False) if PYNINI_AVAILABLE else None
+class TestSerial:
+    normalizer_en = (
+        Normalizer(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
+        if PYNINI_AVAILABLE
+        else None
+    )
+    normalizer_with_audio_en = (
+        NormalizerWithAudio(input_case='cased', lang='en', cache_dir=CACHE_DIR, overwrite_cache=False)
+        if PYNINI_AVAILABLE and CACHE_DIR
+        else None
     )
 
-    @parameterized.expand(parse_test_case_file('vi/data_inverse_text_normalization/test_cases_time.txt'))
+    @parameterized.expand(parse_test_case_file('en/data_text_normalization/test_cases_serial.txt'))
     @pytest.mark.skipif(
         not PYNINI_AVAILABLE, reason="`pynini` not installed, please install via nemo_text_processing/setup.sh"
     )
     @pytest.mark.run_only_on('CPU')
     @pytest.mark.unit
-    def test_denorm(self, test_input, expected):
-        pred = self.inverse_normalizer.inverse_normalize(test_input, verbose=False)
-        assert pred == expected
+    def test_norm(self, test_input, expected):
+        pred = self.normalizer_en.normalize(test_input, verbose=False, punct_post_process=False)
+        assert pred == expected, f"input: {test_input}"
+
+        if self.normalizer_with_audio_en:
+            pred_non_deterministic = self.normalizer_with_audio_en.normalize(
+                test_input, n_tagged=30, punct_post_process=False,
+            )
+            assert expected in pred_non_deterministic, f"input: {test_input}"
```

### Comparing `nemo_toolkit-1.8.2/tests/py_cprheader.txt` & `nemo_toolkit-1.9.0/tests/py_cprheader.txt`

 * *Files identical despite different names*

### Comparing `nemo_toolkit-1.8.2/tests/test_data_dir.py` & `nemo_toolkit-1.9.0/tests/test_data_dir.py`

 * *Files identical despite different names*

